{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "function", "project_path": "Text-Processing/python-benedict", "completion_path": "Text-Processing/python-benedict/benedict/utils/type_util.py", "signature_position": [53, 53], "body_position": [54, 55], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the input value is JSON serializable. It checks if the input value is of the JSON serializable types.", "Arguments": ":param val: Any. The input value to be checked for JSON serializability.\n:return: Bool. True if the input value is JSON serializable, False otherwise."}, "tests": ["tests/utils/test_type_util.py::type_util_test_case::test_is_json_serializable"], "indent": 4}
{"namespace": "feedparser.urls.convert_to_idn", "type": "function", "project_path": "Text-Processing/feedparser", "completion_path": "Text-Processing/feedparser/feedparser/urls.py", "signature_position": [61, 61], "body_position": [66, 83], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a URL to IDN notation. It checks if the host can be encoded in ASCII. If not, it converts the host to IDN form.", "Arguments": ":param url: String. The URL to be converted to IDN notation.\n:return: String. The URL in IDN notation."}, "tests": ["tests/runtests.py::TestConvertToIdn::test_port", "tests/runtests.py::TestConvertToIdn::test_idn", "tests/runtests.py::TestConvertToIdn::test_control"], "indent": 4}
{"namespace": "mistune.toc.add_toc_hook", "type": "function", "project_path": "Text-Processing/mistune", "completion_path": "Text-Processing/mistune/src/mistune/toc.py", "signature_position": [4, 4], "body_position": [23, 44], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds a hook to save table of contents (TOC) items into the state.env. It is usually helpful for doc generator.", "Arguments": ":param md: Markdown instance. The instance of the Markdown class.\n:param min_level: Integer. The minimum heading level to include in the TOC.\n:param max_level: Integer. The maximum heading level to include in the TOC.\n:param heading_id: Function. A function to generate heading_id.\n:return: No return values."}, "tests": ["tests/test_hooks.py::TestTocHook::test_customize_heading_id_func"], "indent": 4}
{"namespace": "mistune.plugins.table.table_in_quote", "type": "function", "project_path": "Text-Processing/mistune", "completion_path": "Text-Processing/mistune/src/mistune/plugins/table.py", "signature_position": [170, 170], "body_position": [172, 173], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function enables the table plugin in block quotes by inserting rules for table and nptable before the paragraph in the block quote rules.", "Arguments": ":param md: Markdown. The Markdown instance.\n:return: No return values."}, "tests": ["tests/test_plugins.py::TestExtraPlugins::test_table_in_quote"], "indent": 4}
{"namespace": "mistune.plugins.table.table_in_list", "type": "function", "project_path": "Text-Processing/mistune", "completion_path": "Text-Processing/mistune/src/mistune/plugins/table.py", "signature_position": [176, 176], "body_position": [178, 179], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function enables the table plugin in the list. It inserts the table and nptable rules before the paragraph rule in the list.", "Arguments": ":param md: Markdown. The Markdown instance to enable the table plugin in the list.\n:return: No return values."}, "tests": ["tests/test_plugins.py::TestExtraPlugins::test_table_in_list"], "indent": 4}
{"namespace": "parsel.utils.shorten", "type": "function", "project_path": "Text-Processing/parsel", "completion_path": "Text-Processing/parsel/parsel/utils.py", "signature_position": [87, 87], "body_position": [89, 95], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Shorten the given text to fit in the given width. If the length of the text is less than or equal to the width, the original text is returned. If the width is greater than the length of the suffix, the text is truncated to fit the width and the suffix is added. If the width is greater than or equal to 0, the suffix is returned based on the width. Otherwise, a ValueError(\"width must be equal or greater than 0\") is raised.", "Arguments": ":param text: String. The input text to be shortened.\n:param width: Integer. The width to which the text should be shortened.\n:param suffix: String. The suffix to be added at the end of the shortened text. Defaults to \"...\".\n:return: String. The shortened text."}, "tests": ["tests/test_utils.py::test_shorten"], "indent": 4}
{"namespace": "parsel.xpathfuncs.set_xpathfunc", "type": "function", "project_path": "Text-Processing/parsel", "completion_path": "Text-Processing/parsel/parsel/xpathfuncs.py", "signature_position": [13, 13], "body_position": [27, 31], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function registers a custom extension function to use in XPath expressions. The function registered under the fname identifier will be called for every matching node, being passed a context parameter as well as any parameters passed from the corresponding XPath expression.", "Arguments": ":param fname: String. The identifier under which the function will be registered.\n:param func: Callable. The function to be registered. If None, the extension function will be removed.\n:return: No return values."}, "tests": ["tests/test_xpathfuncs.py::XPathFuncsTestCase::test_set_xpathfunc"], "indent": 4}
{"namespace": "dominate.dom_tag._get_thread_context", "type": "function", "project_path": "Text-Processing/dominate", "completion_path": "Text-Processing/dominate/dominate/dom_tag.py", "signature_position": [47, 47], "body_position": [48, 51], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the hash value of the current thread context. It first creates a list of the current thread and greenlet (if available) and then returns the hash value of the tuple of the context list.", "Arguments": ":param: No input parameters.\n:return: Integer. The hash value of the current thread context."}, "tests": ["tests/test_dom_tag.py::test___get_thread_context"], "indent": 2}
{"namespace": "dominate.util.system", "type": "function", "project_path": "Text-Processing/dominate", "completion_path": "Text-Processing/dominate/dominate/util.py", "signature_position": [45, 45], "body_position": [49, 52], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function runs a system command and returns the output as a string. It uses the subprocess module to run the command and capture the output.", "Arguments": ":param cmd: String. The system command to be executed.\n:param data: Bytes. Optional input data to be passed to the command.\n:return: String. The output of the system command as a decoded string."}, "tests": ["tests/test_utils.py::test_system"], "indent": 2}
{"namespace": "dominate.util.url_unescape", "type": "function", "project_path": "Text-Processing/dominate", "completion_path": "Text-Processing/dominate/dominate/util.py", "signature_position": [118, 118], "body_position": [119, 120], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a string as input and unescapes any URL-encoded characters in the string.", "Arguments": ":param data: String. The URL-encoded string to be unescaped.\n:return: String. The unescaped string."}, "tests": ["tests/test_utils.py::test_url"], "indent": 2}
{"namespace": "rows.fields.DatetimeField.serialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [390, 390], "body_position": [391, 394], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Serialize the given datetime value into a string in ISO 8601 format.", "Arguments": ":param cls: Class. The class instance.\n:param value: Datetime. The datetime value to be serialized.\n:param *args: Additional positional arguments.\n:param **kwargs: Additional keyword arguments.\n:return: String. The serialized datetime value in ISO 8601 format."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_DatetimeField"], "indent": 8}
{"namespace": "rows.fields.Field.serialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [77, 77], "body_position": [84, 86], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function serializes a value to be exported. It should always return a unicode value, except for BinaryField.", "Arguments": ":param cls: Class. The class instance.\n:param value: Any. The value to be serialized.\n:param *args: Tuple. Additional positional arguments.\n:param **kwargs: Dictionary. Additional keyword arguments.\n:return: Any. The serialized value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_Field", "tests/tests_fields.py::FieldsTestCase::test_TextField"], "indent": 8}
{"namespace": "rows.fields.EmailField.serialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [438, 438], "body_position": [439, 442], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Serialize the value of the email field. If the value is None, it returns an empty string. Otherwise, it returns the string representation of the value.", "Arguments": ":param cls: Class. The class itself.\n:param value: Any. The value to be serialized.\n:param *args: Tuple. Additional positional arguments.\n:param **kwargs: Dictionary. Additional keyword arguments.\n:return: String. The serialized value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_EmailField"], "indent": 8}
{"namespace": "rows.fields.as_string", "type": "function", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [478, 478], "body_position": [479, 484], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the input value to a string. If the input value is already a string, it returns the input value. If the input value is a binary type, it raises a ValueError.", "Arguments": ":param value: Any. The input value to be converted to a string.\n:return: String. The input value converted to a string."}, "tests": ["tests/tests_fields.py::FieldsFunctionsTestCase::test_as_string"], "indent": 4}
{"namespace": "rows.fields.get_items", "type": "function", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [506, 506], "body_position": [513, 515], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a callable that fetches the given indexes of an object. It always returns a tuple even when len(indexes) == 1. It is similar to `operator.itemgetter`, but will insert `None` when the object does not have the desired index (instead of raising IndexError).", "Arguments": ":param indexes: Tuple. The indexes of the object to be fetched.\n:return: Lambda function. A callable that fetches the given indexes of an object."}, "tests": ["tests/tests_fields.py::FieldsFunctionsTestCase::test_get_items"], "indent": 4}
{"namespace": "natasha.span.envelop_spans", "type": "function", "project_path": "Text-Processing/natasha", "completion_path": "Text-Processing/natasha/natasha/span.py", "signature_position": [23, 23], "body_position": [24, 37], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function envelops the spans based on the given envelopes. It iterates through the spans and envelopes and yields the chunk of spans that are enveloped by each envelope.", "Arguments": ":param spans: List of spans. The spans to be enveloped.\n:param envelopes: List of envelopes. The envelopes used to envelop the spans.\n:return: Yield the chunk of spans for each envelope."}, "tests": ["tests/test_span.py::test_envelope_spans"], "indent": 4}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "function", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/_helpers.py", "signature_position": [141, 141], "body_position": [153, 163], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function parses unique key-value parameters from URL-encoded content. It first parses the URL-encoded content and then checks for repeated keys. If a repeated key is found, it raises a ValueError.", "Arguments": ":param content: string. URL-encoded key-value pairs.\n:return: dict. The key-value pairs from the input content.\nRaises:\nValueError: if one of the keys is repeated."}, "tests": ["tests/test__helpers.py::Test_parse_unique_urlencoded::test_without_repeats", "tests/test__helpers.py::Test_parse_unique_urlencoded::test_with_repeats"], "indent": 4}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "function", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/async_utils.py", "signature_position": [70, 72], "body_position": [73, 78], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates an asynchronous iterator from the given iterable. It checks if the iterable has an __aiter__ attribute and if so, it yields items asynchronously, otherwise, it yields items synchronously.", "Arguments": ":param iterable: Union of AsyncIterable and Iterable. The input iterable from which the iterator is created.\n:return: AsyncIterator. The created asynchronous iterator."}, "tests": ["tests/test_async.py::test_async_iteration_in_templates_extended"], "indent": 4}
{"namespace": "jinja2.utils.consume", "type": "function", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/utils.py", "signature_position": [112, 112], "body_position": [114, 115], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function consumes an iterable without doing anything with it. It iterates through the given iterable and does nothing with the elements.", "Arguments": ":param iterable: Iterable. The iterable to be consumed.\n:return: No return values."}, "tests": ["tests/test_utils.py::test_consume"], "indent": 4}
{"namespace": "jinja2.utils.object_type_repr", "type": "function", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/utils.py", "signature_position": [165, 165], "body_position": [170, 180], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the name of the object's type. For some recognized singletons, the name of the object is returned instead. (For example for `None` and `Ellipsis`). If the object is built-in, the output format is \"{object's name} object\". Otherwise, the output format is \"{object's module} {object's name} object\".", "Arguments": ":param obj: Any. The object for which the type name is to be returned.\n:return: str. The name of the object's type or the name of the object if it is a recognized singleton."}, "tests": ["tests/test_utils.py::TestHelpers::test_object_type_repr"], "indent": 4}
{"namespace": "jinja2.utils.LRUCache.setdefault", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/utils.py", "signature_position": [470, 470], "body_position": [474, 478], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set the default value for a key if it is not already in the cache. If the key is already in the cache, the value remains unchanged. It then returns the value of the key.", "Arguments": ":param self: LRUCache. An instance of the LRUCache class.\n:param key: Any. The key to be checked and set in the cache.\n:param default: Any. The default value to be set for the key if it is not already in the cache. Defaults to None.\n:return: Any. The value of the key."}, "tests": ["tests/test_utils.py::TestLRUCache::test_setdefault"], "indent": 8}
{"namespace": "sumy.evaluation.rouge._get_ngrams", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/evaluation/rouge.py", "signature_position": [9, 9], "body_position": [10, 15], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates n-grams from the given text.", "Arguments": ":param n: Integer. The size of the n-grams.\n:param text: String. The input text from which n-grams are generated.\n:return: Set. A set of n-grams generated from the input text."}, "tests": ["tests/test_evaluation/test_evaluation_rouge.py::test_get_ngrams"], "indent": 4}
{"namespace": "falcon.inspect.register_router", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [71, 71], "body_position": [89, 98], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that registers a new function for a custom router class. It takes the router class as input and returns a new function that can be used to inspect the router. If the router class is already registered, raise a ValueError.", "Arguments": ":param router_class: Type. The router class to register. If already registered, an error will be raised.\n:return: The new function that inspects the router."}, "tests": ["tests/test_inspect.py::TestRouter::test_register_other_router", "tests/test_inspect.py::TestRouter::test_register_router_multiple_time"], "indent": 4}
{"namespace": "falcon.inspect.inspect_compiled_router", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [204, 204], "body_position": [216, 245], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function inspects a compiled router to return a list of defined routes. It walks through the compiled router and extracts information about the defined routes.", "Arguments": ":param router: CompiledRouter. The router to inspect.\n:return: List[RouteInfo]. A list of RouteInfo objects representing the defined routes."}, "tests": ["tests/test_inspect.py::TestRouter::test_compiled_partial", "tests/test_inspect.py::TestRouter::test_compiled_no_method_map"], "indent": 4}
{"namespace": "falcon.inspect._is_internal", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [787, 787], "body_position": [789, 792], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the module of the object is a falcon module.", "Arguments": ":param obj: Object. The object to be checked.\n:return: Bool. True if the module of the object is a falcon module, False otherwise."}, "tests": ["tests/test_inspect.py::test_is_internal"], "indent": 4}
{"namespace": "falcon.cmd.inspect_app.load_app", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/cmd/inspect_app.py", "signature_position": [61, 62], "body_position": [63, 86], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function loads the app based on the given parser and args. It first splits the app_module into module and instance. Then, it tries to get the app instance from the module. If the app is not an instance of falcon.App, it tries to create an instance from the callable app. If the app is still not an instance of falcon.App, it raises an error.", "Arguments": ":param parser: The parser object.\n:param args: The arguments object.\n:return: falcon.App. The loaded falcon app instance."}, "tests": ["tests/test_cmd_inspect_app.py::TestLoadApp::test_load_app_module_error", "tests/test_cmd_inspect_app.py::TestLoadApp::test_load_app", "tests/test_cmd_inspect_app.py::TestLoadApp::test_load_app_error"], "indent": 4}
{"namespace": "falcon.cmd.inspect_app.make_parser", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/cmd/inspect_app.py", "signature_position": [31, 31], "body_position": [33, 58], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a parser for the application with the specified arguments and options. The arguments contains \"-r (--router)\", \"-v (--verbose)\", \"-i (--internal)\", and \"app_module\".", "Arguments": ":param: No input parameters.\n:return: ArgumentParser. The created parser instance."}, "tests": ["tests/test_cmd_inspect_app.py::TestLoadApp::test_load_app_module_error", "tests/test_cmd_inspect_app.py::TestMakeParser::test_make_parser_error", "tests/test_cmd_inspect_app.py::TestMakeParser::test_make_parser", "tests/test_cmd_inspect_app.py::TestLoadApp::test_load_app_error"], "indent": 4}
{"namespace": "falcon.util.uri.unquote_string", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/util/uri.py", "signature_position": [505, 505], "body_position": [518, 534], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function unquotes an RFC 7320 \"quoted-string\" by removing the quotes and escaping characters.", "Arguments": ":param quoted: str. Original quoted string.\n:return: str. Unquoted string.\n:raises: TypeError: If the input is not a string."}, "tests": ["tests/test_utils.py::TestFalconUtils::test_unquote_string"], "indent": 4}
{"namespace": "falcon.util.misc.get_argnames", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/util/misc.py", "signature_position": [287, 287], "body_position": [298, 313], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function introspects the arguments of a callable and returns a list of argument names, excluding *arg and **kwargs arguments.", "Arguments": ":param func: The callable to introspect.\n:return: A list of argument names, excluding *arg and **kwargs arguments."}, "tests": ["tests/test_utils.py::test_get_argnames"], "indent": 4}
{"namespace": "falcon.testing.client._is_asgi_app", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/testing/client.py", "signature_position": [2161, 2161], "body_position": [2162, 2173], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the given app is an ASGI app by inspecting the number of arguments it accepts. If the number of arguments is 3, it is considered an ASGI app. The \"self\" and \"cls\" arguments are ignored.", "Arguments": ":param app: The app to be checked.\n:return: Boolean. True if the app is an ASGI app, False otherwise."}, "tests": ["tests/asgi/test_testing_asgi.py::test_is_asgi_app_cls"], "indent": 4}
{"namespace": "falcon.routing.converters.UUIDConverter.convert", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/routing/converters.py", "signature_position": [128, 128], "body_position": [129, 132], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the input value to a UUID. If the input value is not a valid UUID, return None.", "Arguments": ":param self: UUIDConverter. An instance of the UUIDConverter class.\n:param value: The value to be converted to a UUID.\n:return: UUID. The UUID value if the input is a valid UUID, otherwise None."}, "tests": ["tests/test_uri_converters.py::test_uuid_converter"], "indent": 8}
{"namespace": "boto.sdb.db.sequence.fib", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/sdb/db/sequence.py", "signature_position": [91, 91], "body_position": [94, 98], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the next number in the Fibonacci sequence based on the last two numbers.", "Arguments": ":param cv: int. The current value in the sequence. Defaults to 1.\n:param lv: int. The last value in the sequence. Defaults to 0.\n:return: int. The next number in the Fibonacci sequence."}, "tests": ["tests/db/test_sequence.py::TestDBHandler::test_fib"], "indent": 4}
{"namespace": "boto.s3.website.RoutingRules.add_rule", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/website.py", "signature_position": [142, 142], "body_position": [152, 153], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Add a routing rule to the RoutingRules object and return the updated object. This function allows chaining of subsequent calls.", "Arguments": ":param rule: RoutingRule. A routing rule to be added.\n:return: RoutingRules. The updated RoutingRules object."}, "tests": ["tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_routing_rules_to_host_on_404", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_routing_rules_key_prefix", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_key_prefix", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_builders"], "indent": 8}
{"namespace": "boto.cloudfront.distribution.Distribution._canned_policy", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudfront/distribution.py", "signature_position": [617, 617], "body_position": [621, 624], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a canned policy string based on the given resource and expiration time '{\"Statement\":[{\"Resource\":\"%(resource)s\",\"Condition\":{\"DateLessThan\":{\"AWS:EpochTime\":%(expires)s}}}]}'.", "Arguments": ":param resource: String. The resource for which the policy is created.\n:param expires: String. The expiration time for the policy.\n:return: String. The created canned policy string."}, "tests": ["tests/unit/cloudfront/test_signed_urls.py::CloudfrontSignedUrlsTest::test_create_canned_policy"], "indent": 8}
{"namespace": "boto.cloudfront.invalidation.InvalidationBatch.escape", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudfront/invalidation.py", "signature_position": [70, 70], "body_position": [72, 74], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function escapes a path. It prepends a slash if it does not start with one and then escapes the path but retaining '/' and '*'.", "Arguments": ":param self: InvalidationBatch. An instance of the InvalidationBatch class.\n:param p: str. The path to escape.\n:return: str. The escaped path."}, "tests": ["tests/unit/cloudfront/test_invalidation.py::CFInvalidationTest::test_wildcard_escape"], "indent": 8}
{"namespace": "proxybroker.utils.get_status_code", "type": "function", "project_path": "Internet/proxybroker", "completion_path": "Internet/proxybroker/proxybroker/utils.py", "signature_position": [59, 59], "body_position": [60, 65], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function extracts the status code from the response string and returns it. If the status code is not found, it returns 400.", "Arguments": ":param resp: String. The response string from which the status code is to be extracted.\n:param start: Integer. The starting index of the status code in the response string. Defaults to 9.\n:param stop: Integer. The ending index of the status code in the response string. Defaults to 12.\n:return: Integer. The extracted status code or 400 if not found."}, "tests": ["tests/test_utils.py::test_get_status_code"], "indent": 4}
{"namespace": "authlib.oauth2.rfc6749.util.scope_to_list", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/oauth2/rfc6749/util.py", "signature_position": [15, 15], "body_position": [17, 21], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a space separated string to a list of scopes. It checks if the input is a tuple, list, or set and converts each element to a unicode string. If the input is None, it returns None. Otherwise, it splits the input string by space and returns the list of scopes.", "Arguments": ":param scope: The space separated string of scopes or a tuple, list, or set of scopes or None.\n:return: list[str] or None. The list of scopes. If the input is None, it returns None."}, "tests": ["tests/core/test_oauth2/test_rfc6749_misc.py::OAuth2UtilTest::test_scope_to_list"], "indent": 4}
{"namespace": "authlib.common.encoding.to_unicode", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/common/encoding.py", "signature_position": [18, 18], "body_position": [19, 23], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the input to a string. It first checks if the input is None or already a string, and returns it. If the input is a byte string, it decodes it using the specified charset and error handling. Otherwise, it converts the input to a string using the str() function.", "Arguments": ":param x: Any. The input to be converted to Unicode.\n:param charset: String. The character set to be used for decoding byte strings. Defaults to 'utf-8'.\n:param errors: String. The error handling scheme to be used for decoding byte strings. Defaults to 'strict'.\n:return: String. The Unicode representation of the input."}, "tests": ["tests/jose/test_jwe.py::JWETest::test_deserialize_json_fails_if_protected_header_contains_unknown_field_while_private_fields_restricted"], "indent": 4}
{"namespace": "authlib.common.encoding.to_bytes", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/common/encoding.py", "signature_position": [6, 6], "body_position": [7, 15], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the input to bytes based on the given charset and error handling. It first checks if the input is None, bytes, string, int, or float and then converts it to bytes accordingly.", "Arguments": ":param x: Any. The input to be converted to bytes.\n:param charset: String. The character set to be used for encoding. Defaults to 'utf-8'.\n:param errors: String. The error handling scheme to be used. Defaults to 'strict'.\n:return: Bytes. The converted bytes. Or None if the input is None."}, "tests": ["tests/jose/test_ecdh_1pu.py::ECDH1PUTest::test_ecdh_1pu_key_agreement_computation_appx_b", "tests/jose/test_ecdh_1pu.py::ECDH1PUTest::test_ecdh_1pu_encryption_with_json_serialization", "tests/jose/test_jwe.py::JWETest::test_deserialize_json_fails_if_protected_header_contains_unknown_field_while_private_fields_restricted"], "indent": 4}
{"namespace": "authlib.common.encoding.urlsafe_b64decode", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/common/encoding.py", "signature_position": [40, 40], "body_position": [41, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Decode the URL-safe base64-encoded string. It pads the input string with '=' until the length is a multiple of 4 before decoding it.", "Arguments": ":param s: bytes. The URL-safe base64-encoded string to be decoded.\n:return: bytes. The decoded string."}, "tests": ["tests/jose/test_ecdh_1pu.py::ECDH1PUTest::test_ecdh_1pu_encryption_with_json_serialization"], "indent": 4}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "function", "project_path": "Database/csvs-to-sqlite", "completion_path": "Database/csvs-to-sqlite/csvs_to_sqlite/utils.py", "signature_position": [257, 257], "body_position": [258, 264], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the table exists in the database.", "Arguments": ":param conn: Connection. The connection to the database.\n:param table: String. The name of the table to check.\n:return: Bool. True if the table exists, False otherwise."}, "tests": ["tests/test_utils.py::test_table_exists"], "indent": 4}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "method", "project_path": "Database/sqlitedict", "completion_path": "Database/sqlitedict/sqlitedict.py", "signature_position": [359, 359], "body_position": [361, 368], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the names of the tables in an SQLite database and returns them as a list. If the file does not exist, it raises an IOError 'file {} does not exist'.", "Arguments": ":param filename: String. The name of the SQLite database file.\n:return: List of strings. The names of the tables in the SQLite database."}, "tests": ["tests/test_core.py::TablenamesTest::test_tablenams_named", "tests/test_core.py::NamedSqliteDictCreateOrReuseTest::test_readonly_table", "tests/test_core.py::TablenamesTest::test_tablenames_unnamed"], "indent": 8}
{"namespace": "litecli.packages.parseutils.query_starts_with", "type": "function", "project_path": "Database/litecli", "completion_path": "Database/litecli/litecli/packages/parseutils.py", "signature_position": [204, 204], "body_position": [206, 208], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the query starts with any item from the given list of prefixes. It first converts all the prefixes to lowercase and then formats the query to lowercase and removes comments. It then checks if the formatted query is not empty and if the first word of the query is in the list of prefixes.", "Arguments": ":param query: String. The input query to be checked.\n:param prefixes: List of strings. The list of prefixes to check if the query starts with.\n:return: Bool. True if the query starts with any item from the prefixes, False otherwise."}, "tests": ["tests/test_parseutils.py::test_query_starts_with_comment", "tests/test_parseutils.py::test_query_starts_with"], "indent": 4}
{"namespace": "rest_framework.negotiation.DefaultContentNegotiation.filter_renderers", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/negotiation.py", "signature_position": [80, 80], "body_position": [85, 89], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function filters the renderers based on the given format. It only keeps the renderers that accept the given format. If no renderer is found, it raises 404.", "Arguments": ":param renderers: List of Renderer. The list of renderers to be filtered.\n:param format: String. The format to be used for filtering the renderers.\n:return: List of Renderer. The filtered list of renderers."}, "tests": ["tests/test_negotiation.py::TestAcceptedMediaType::test_raise_error_if_no_suitable_renderers_found"], "indent": 8}
{"namespace": "rest_framework.templatetags.rest_framework.as_string", "type": "function", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/templatetags/rest_framework.py", "signature_position": [159, 159], "body_position": [160, 162], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the input value to a string. If the input value is None, it returns an empty string.", "Arguments": ":param value: Any. The input value to be converted to a string.\n:return: String. The converted string value."}, "tests": ["tests/test_templatetags.py::TemplateTagTests::test_as_string_with_none"], "indent": 4}
{"namespace": "rest_framework.templatetags.rest_framework.add_nested_class", "type": "function", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/templatetags/rest_framework.py", "signature_position": [286, 286], "body_position": [287, 291], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "The function checks if the input value is a dictionary or a list containing a dictionary or a list. If it is, it returns 'class=nested', otherwise, it returns an empty string.", "Arguments": ":param value: Any. The input value to be checked.\n:return: String. It returns 'class=nested' if the input value is a dictionary or a list containing a dictionary or a list. Otherwise, it returns an empty string."}, "tests": ["tests/test_templatetags.py::TemplateTagTests::test_add_nested_class"], "indent": 4}
{"namespace": "pyramid.session.PickleSerializer.loads", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/session.py", "signature_position": [67, 67], "body_position": [69, 74], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Deserialize a byte stream to a Python object using the pickle module. It raises a ValueError if there is any exception.", "Arguments": ":param self: PickleSerializer. An instance of the PickleSerializer class.\n:param bstruct: Bytes. The byte stream to be deserialized.\n:return: Python object. The deserialized Python object."}, "tests": ["tests/test_session.py::TestPickleSerializer::test_loads", "tests/test_session.py::TestPickleSerializer::test_loads_raises_ValueError_on_invalid_data", "tests/test_session.py::TestPickleSerializer::test_loads_raises_ValueError_on_bad_import"], "indent": 8}
{"namespace": "pyramid.testing.DummySession.flash", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [247, 247], "body_position": [248, 250], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds a message to the flash storage. It first checks if the message is already in the storage and if it is not, it appends the message to the storage.", "Arguments": ":param self: DummySession. An instance of the DummySession class.\n:param msg: The message to be added to the flash storage.\n:param queue: String. The queue to which the message is added. Defaults to an empty string.\n:param allow_duplicate: Bool. Whether to allow duplicate messages in the storage. Defaults to True.\n:return: No return values."}, "tests": ["tests/test_testing.py::TestDummySession::test_flash_mixed", "tests/test_testing.py::TestDummySession::test_flash_default"], "indent": 8}
{"namespace": "pyramid.testing.DummySession.pop_flash", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [252, 252], "body_position": [253, 254], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes and returns the flash message from the session storage. It removes the flash message from the session storage based on the queue and returns it.", "Arguments": ":param self: DummySession. An instance of the DummySession class.\n:param queue: String. The queue from which the flash message is to be removed. Defaults to an empty string.\n:return: List. The flash message storage."}, "tests": ["tests/test_testing.py::TestDummySession::test_pop_flash_nodefault_queue", "tests/test_testing.py::TestDummySession::test_pop_flash_default_queue"], "indent": 8}
{"namespace": "pyramid.testing.DummySession.peek_flash", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [256, 256], "body_position": [257, 258], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Return the flash messages from the session storage without removing them.", "Arguments": ":param self: DummySession. An instance of the DummySession class.\n:param queue: String. The queue name to retrieve the flash messages from. Defaults to an empty string.\n:return: List. The list of flash messages from the session storage."}, "tests": ["tests/test_testing.py::TestDummySession::test_peek_flash_default_queue", "tests/test_testing.py::TestDummySession::test_peek_flash_nodefault_queue"], "indent": 8}
{"namespace": "pyramid.testing.DummySession.new_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [260, 260], "body_position": [261, 263], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Generate a new CSRF token '0123456789012345678901234567890123456789' and store it in the DummySession instance. It then returns the generated token.", "Arguments": ":param self: DummySession. An instance of the DummySession class.\n:return: String. The generated CSRF token."}, "tests": ["tests/test_testing.py::TestDummySession::test_new_csrf_token"], "indent": 8}
{"namespace": "pyramid.view.view_defaults", "type": "function", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/view.py", "signature_position": [264, 264], "body_position": [273, 277], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that, when applied to a class, provides defaults for all view configurations that use the class. It accepts all the arguments accepted by pyramid.view.view_config and each has the same meaning. The settings is stored in the `__view_defaults__` attribute.", "Arguments": ":param **settings: Arbitrary keyword arguments. The settings to be applied as defaults for all view configurations that use the class.\n:return: A decorator function that sets the defaults for all view configurations that use the class."}, "tests": ["tests/test_view.py::Test_view_defaults::test_it_inheritance_overriden", "tests/test_view.py::Test_view_defaults::test_it_inheritance_not_overridden", "tests/test_view.py::Test_view_defaults::test_it", "tests/test_view.py::Test_view_defaults::test_it_inheritance_overriden_empty"], "indent": 4}
{"namespace": "pyramid.util.bytes_", "type": "function", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [38, 38], "body_position": [41, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a string and encodes it using the specified encoding and error handling. If the input is not a string, it returns the input as is.", "Arguments": ":param s: String. The input string to be encoded.\n:param encoding: String. The encoding to be used for encoding the input string. Defaults to 'latin-1'.\n:param errors: String. The error handling scheme to use for encoding errors. Defaults to 'strict'.\n:return: Bytes. The encoded bytes if the input is a string, otherwise the input itself."}, "tests": ["tests/test_authentication.py::TestBasicAuthAuthenticationPolicy::test_unauthenticated_userid_invalid_payload", "tests/test_authentication.py::TestBasicAuthAuthenticationPolicy::test_authenticated_userid", "tests/test_authentication.py::TestExtractHTTPBasicCredentials::test_not_a_basic_auth_scheme", "tests/test_authentication.py::TestExtractHTTPBasicCredentials::test_invalid_payload", "tests/test_authentication.py::TestBasicAuthAuthenticationPolicy::test_unauthenticated_userid"], "indent": 4}
{"namespace": "pyramid.scripts.common.parse_vars", "type": "function", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/scripts/common.py", "signature_position": [4, 4], "body_position": [9, 15], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of strings in the format 'a=b' and turns it into a dictionary with keys and values.", "Arguments": ":param args: List of strings. The list of strings in the format 'a=b'.\n:return: Dictionary. The dictionary with keys and values."}, "tests": ["tests/test_scripts/test_common.py::TestParseVars::test_parse_vars_good", "tests/test_scripts/test_common.py::TestParseVars::test_parse_vars_bad"], "indent": 4}
{"namespace": "pyramid.scripts.pviews.PViewsCommand._find_multi_routes", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/scripts/pviews.py", "signature_position": [70, 70], "body_position": [71, 79], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function finds all routes that match the path of the given request, regardless of predicates. It iterates through all routes in the mapper and checks if the path matches the route. If it does, it adds the route and the match to the list of infos.", "Arguments": ":param self: PViewsCommand. An instance of the PViewsCommand class.\n:param mapper: The mapper object that contains routes.\n:param request: The request object that contains the path information.\n:return: A list of dictionaries, each containing the 'match' and the 'route' that matches the given path."}, "tests": ["tests/test_scripts/test_pviews.py::TestPViewsCommand::test__find_multi_routes_some_match", "tests/test_scripts/test_pviews.py::TestPViewsCommand::test__find_multi_routes_all_match", "tests/test_scripts/test_pviews.py::TestPViewsCommand::test__find_multi_routes_none_match"], "indent": 8}
{"namespace": "pyramid.scripts.pserve.PServeCommand.guess_server_url", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/scripts/pserve.py", "signature_position": [174, 174], "body_position": [175, 178], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "It guesses the server URL based on the given server name and global configuration. The function first sets server_name to 'main' if the server_name parameter is empty. Then it load the configuration for the specified server, which is 'server:' + server_name, using the global_conf. If the port number is specified in the settings, the function will return the URL of the server, which is 'http://127.0.0.1:{port}', with the port number replaced by the value in the settings.", "Arguments": ":param self: PServeCommand. An instance of the PServeCommand class.\n:param loader: The loader to get the settings.\n:param server_name: The name of the server. Defaults to 'main'.\n:param global_conf: The global configuration settings. Defaults to None.\n:return: String. The guessed server URL."}, "tests": ["tests/test_scripts/test_pserve.py::TestPServeCommand::test_guess_server_url"], "indent": 8}
{"namespace": "aiohappybase._util.pep8_to_camel_case", "type": "function", "project_path": "Database/happybase", "completion_path": "Database/happybase/aiohappybase/_util.py", "signature_position": [27, 27], "body_position": [29, 34], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a PEP8 style name to camel case. It splits the input name by underscore and capitalizes each chunk. If the initial flag is set to True, it returns the whole name in camel case. Otherwise, it returns the name in camel case starting with a lowercase letter.", "Arguments": ":param name: String. The PEP8 style name to be converted to camel case.\n:param initial: Bool. Whether to capitalize the first letter of the camel case name. Defaults to False.\n:return: String. The name in camel case."}, "tests": ["tests/test_util.py::TestUtil::test_camel_case_to_pep8"], "indent": 4}
{"namespace": "aiohappybase._util.bytes_increment", "type": "function", "project_path": "Database/happybase", "completion_path": "Database/happybase/aiohappybase/_util.py", "signature_position": [61, 61], "body_position": [72, 78], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function increments and truncates a byte string for sorting purposes. It returns the shortest string that sorts after the given string when compared using regular string comparison semantics. It increments the last byte that is smaller than 0xFF and drops everything after it. If the input string only contains 0xFF bytes, None is returned.", "Arguments": ":param b: bytes. The byte string to be incremented and truncated.\n:return: Optional[bytes]. The incremented and truncated byte string. If the string only contains ``0xFF`` bytes, `None` is returned."}, "tests": ["tests/test_util.py::TestUtil::test_bytes_increment"], "indent": 4}
{"namespace": "mssqlcli.config.ensure_dir_exists", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/config.py", "signature_position": [29, 29], "body_position": [30, 32], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function ensures that the directory of the given path exists. If the parent directory of the path does not exist, it creates the directory.", "Arguments": ":param path: String. The path for which the directory existence needs to be ensured.\n:return: No return values."}, "tests": ["tests/test_config.py::ConfigTests::test_ensure_existing_dir"], "indent": 4}
{"namespace": "mssqlcli.telemetry._user_id_file_is_old", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/telemetry.py", "signature_position": [188, 188], "body_position": [189, 194], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the user id file is older than 24 hours. It compares the modified time of the file with the current time and returns True if the file is older than 24 hours, otherwise False.", "Arguments": ":param id_file_path: String. The path to the user id file.\n:return: Bool. True if the file is older than 24 hours, otherwise False."}, "tests": ["tests/test_telemetry.py::TelemetryTests::test_file_time_check_rotation"], "indent": 4}
{"namespace": "mssqlcli.util.is_command_valid", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/util.py", "signature_position": [21, 21], "body_position": [26, 36], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the command is recognized on the machine. It is used to determine the installation of the 'less' pager. If the command is empty or if calling the command silently throws an OSError, the function returns False. Otherwise, it returns True.", "Arguments": ":param command: String. The command to be checked.\n:return: Bool. True if the command is recognized, False otherwise."}, "tests": ["tests/test_interactive_mode.py::TestInteractiveModeRun::test_valid_command"], "indent": 4}
{"namespace": "mssqlcli.packages.parseutils.utils.find_prev_keyword", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/packages/parseutils/utils.py", "signature_position": [65, 65], "body_position": [71, 99], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function finds the last SQL keyword in an SQL statement and returns the value of the last keyword and the text of the query with everything after the last keyword stripped.", "Arguments": ":param sql: String. The SQL statement to be processed.\n:param n_skip: Integer. The number of tokens to skip from the end of the SQL statement. Defaults to 0.\n:return: Tuple. The value of the last keyword and the text of the query with everything after the last keyword stripped."}, "tests": ["tests/parseutils/test_parseutils.py::test_find_prev_keyword_using", "tests/parseutils/test_parseutils.py::test_find_prev_keyword_where", "tests/parseutils/test_parseutils.py::test_find_prev_keyword_open_parens"], "indent": 4}
{"namespace": "pyramid.util.text_", "type": "function", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [30, 30], "body_position": [33, 35], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the input string is an instance of bytes. If it is, it decodes the bytes using the specified encoding and error handling. If not, it returns the input string as is.", "Arguments": ":param s: String or bytes. The input string to be checked and decoded if it is an instance of bytes.\n:param encoding: String. The encoding to be used for decoding the bytes. Defaults to 'latin-1'.\n:param errors: String. The error handling scheme to be used for decoding. Defaults to 'strict'.\n:return: String. The decoded string if the input is bytes, otherwise the input string as is."}, "tests": ["tests/test_urldispatch.py::TestCompileRoute::test_generate_with_mixedtype_values", "tests/test_urldispatch.py::TestCompileRoute::test_pattern_generate_with_high_order_dynamic", "tests/test_urldispatch.py::TestCompileRoute::test_pattern_with_high_order_literal", "tests/test_urldispatch.py::TestCompileRoute::test_docs_sample_generate", "tests/test_urldispatch.py::TestCompileRoute::test_generate_with_string_remainder_and_unicode_replacement"], "indent": 4}
{"namespace": "datasette.utils.path_with_added_args", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [273, 273], "body_position": [274, 286], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a new path with added arguments. It first checks if the path is provided, if not, it uses the request path. Then, it processes the input arguments and adds them to the path.", "Arguments": ":param request: The request object.\n:param args: Dictionary. The arguments to be added to the path.\n:param path: String. The path to which the arguments are to be added. Defaults to None.\n:return: String. The new path with added arguments."}, "tests": ["tests/test_utils.py::test_path_with_added_args"], "indent": 4}
{"namespace": "datasette.utils.path_with_replaced_args", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [318, 318], "body_position": [319, 331], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function replaces the query string in the given path with the provided arguments and returns the updated path. It takes a request object and a list of arguments as input, and replaces specific parameters in the request path based on the list of arguments. It returns the modified path. If the list of arguments is a dictionary, it is converted to a list of tuples. The function iterates through the query string of the request and adds the tuples from the list of arguments to a new list if the key is not in the set of keys to be replaced. It then appends the keys with non-null values from the list of arguments to the new list. The new list is then converted back to a query string form. Finally, the query string is appended to the path and the final path is returned.", "Arguments": ":param request: The request object.\n:param args: Dictionary or list of tuples. The arguments to replace in the query string.\n:param path: String. The path to be updated. Defaults to None, in which case the path from the request object is used.\n:return: String. The updated path with replaced arguments."}, "tests": ["tests/test_utils.py::test_path_with_replaced_args"], "indent": 4}
{"namespace": "datasette.utils.format_bytes", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [870, 870], "body_position": [871, 879], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the input bytes to the largest possible unit (\"bytes\", \"KB\", \"MB\", \"GB\", and \"TB\") and return the formatted string.", "Arguments": ":param bytes: int. The number of bytes to be converted.\n:return: str. The formatted string of the converted bytes."}, "tests": ["tests/test_utils.py::test_format_bytes"], "indent": 4}
{"namespace": "datasette.utils.actor_matches_allow", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1013, 1013], "body_position": [1014, 1036], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the actor matches the allow condition. It returns True if the actor matches the allow condition, otherwise False.", "Arguments": ":param actor: Any. The actor to be checked against the allow condition.\n:param allow: Any. The allow condition to be checked against the actor.\n:return: Bool. True if the actor matches the allow condition, otherwise False."}, "tests": ["tests/test_utils.py::test_actor_matches_allow"], "indent": 4}
{"namespace": "datasette.utils.resolve_env_secrets", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1039, 1039], "body_position": [1041, 1054], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a copy of the input config that recursively replaces {\"$env\": \"NAME\"} with values from the environ. It also replaces {\"$file\": \"NAME\"} with the content of the file with the name \"NAME\".", "Arguments": ":param config: Dictionary or List. The input configuration to be resolved.\n:param environ: Dictionary. The environment dictionary containing the values to be replaced.\n:return: Dictionary or List. The resolved configuration."}, "tests": ["tests/test_utils.py::test_resolve_env_secrets"], "indent": 4}
{"namespace": "datasette.utils.display_actor", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1057, 1057], "body_position": [1058, 1061], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Display the actor information based on the given priority. It first checks if the actor has a display name, then a name, username, login, and id. If none of these are found, it returns the string representation of the actor.", "Arguments": ":param actor: Dictionary. The actor information.\n:return: String. The displayed actor information based on the priority."}, "tests": ["tests/test_utils.py::test_display_actor"], "indent": 4}
{"namespace": "datasette.utils.initial_path_for_datasette", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1076, 1076], "body_position": [1078, 1089], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the suggested path for opening the given Datasette instance based on the number of databases and tables it contains. It first checks the number of databases and if there is only one database, it returns the path to that database. If the database contains only one table, it returns the path to that table. If there are multiple databases, it returns the path to the instance.", "Arguments": ":param datasette: Datasette. The Datasette instance for which the path is to be suggested.\n:return: String. The suggested path for opening the Datasette instance."}, "tests": ["tests/test_utils.py::test_initial_path_for_datasette"], "indent": 4}
{"namespace": "datasette.utils.tilde_decode", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1176, 1176], "body_position": [1179, 1182], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Decode a tilde-encoded string to its original form. It first replaces the % symbol with a temporary string to avoid accidental decoding of %2f style sequences. Then, it decodes the tilde-encoded string and replaces the temporary string with %.", "Arguments": ":param s: String. The tilde-encoded string to be decoded.\n:return: String. The decoded string.\n```"}, "tests": ["tests/test_utils.py::test_tilde_encoding"], "indent": 4}
{"namespace": "datasette.utils.resolve_routes", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1185, 1185], "body_position": [1186, 1190], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function resolves the routes based on the given path. It iterates through the routes and returns the first match found.", "Arguments": ":param routes: List of tuples. A list of tuples containing regex and view.\n:param path: String. The path to be resolved.\n:return: Tuple. The first match and the corresponding view. If no match is found, it returns None."}, "tests": ["tests/test_routes.py::test_routes"], "indent": 4}
{"namespace": "datasette.utils.truncate_url", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1193, 1193], "body_position": [1194, 1200], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "The function is used to truncate a given URL to a specified length, adding ellipsis at the end if the URL is longer than the specified length. If the URL ends with a file extension and the extension length is between 1 and 4 characters without a slash, it truncates the URL to the specified length and adds ellipsis and the extension at the end. If the URL length is less than or equal to the specified length, it returns the entire URL.", "Arguments": ":param url: String. The URL to be truncated.\n:param length: Integer. The maximum length of the truncated URL.\n:return: String. The truncated URL. If the URL is shorter than the specified length, the original URL is returned."}, "tests": ["tests/test_utils.py::test_truncate_url"], "indent": 4}
{"namespace": "kinto.core.authorization.groupfinder", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/authorization.py", "signature_position": [21, 21], "body_position": [26, 41], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function fetches principals from the permission backend for the specified `userid`. It checks if the permission backend is configured and if so, queries the permission backend only once per request and returns the principals.", "Arguments": ":param userid: The user id for which the principals are to be fetched.\n:param request: The request object.\n:return: List. The list of principals fetched from the permission backend. If the permission backend is not configured, an empty list is returned."}, "tests": ["tests/core/test_authorization.py::GroupFinderTest::test_uses_provided_id_if_no_prefixed_userid", "tests/core/test_authorization.py::GroupFinderTest::test_uses_prefixed_as_userid"], "indent": 4}
{"namespace": "kinto.core.utils.json.dumps", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [35, 35], "body_position": [36, 37], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "The function is a custom serialization function that uses the rapidjson library to convert a Python object into a JSON string. It accepts one parameter v and optional keyword parameters kw, where the bytes_mode parameter is set to rapidjson.BM_NONE by default in the kw parameter. The function then calls the rapidjson.dumps method to perform JSON serialization and returns the resulting string.", "Arguments": ":param v: Object. Python object to be serialized.\n:param kw: Dict. Additional keyword arguments to be passed to the rapidjson.dumps function.\n:return: String. The JSON string corresponding to the Python object."}, "tests": ["tests/core/resource/test_pagination.py::PaginationTest::test_raises_bad_request_if_token_has_bad_data_structure", "tests/core/test_views_batch.py::BatchServiceTest::test_subrequests_body_are_json_serialized", "tests/core/test_views_batch.py::BatchServiceTest::test_subrequests_body_have_utf8_charset"], "indent": 8}
{"namespace": "kinto.core.utils.json.loads", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [43, 43], "body_position": [44, 45], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function loads the given JSON string and returns the corresponding Python object. It sets the default number mode to \"rapidjson.NM_NATIVE\" if not specified.", "Arguments": ":param v: String. The JSON string to be loaded.\n:param kw: Dict. Additional keyword arguments to be passed to the rapidjson.loads function.\n:return: Object. The Python object corresponding to the JSON string."}, "tests": ["tests/core/resource/test_pagination.py::BuildPaginationTokenTest::test_sorting_handle_both_rules", "tests/core/resource/test_pagination.py::BuildPaginationTokenTest::test_multiple_sorting_keep_all", "tests/core/resource/test_pagination.py::BuildPaginationTokenTest::test_token_contains_current_offset", "tests/core/resource/test_pagination.py::BuildPaginationTokenTest::test_sorting_handle_ordering_direction", "tests/core/resource/test_pagination.py::BuildPaginationTokenTest::test_no_sorting_default_to_modified_field"], "indent": 8}
{"namespace": "kinto.core.utils.hmac_digest", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [161, 161], "body_position": [163, 165], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "The function calculates the hexadecimal digest of a message using the HMAC-SHA256 algorithm. It takes a secret key, a message, and an optional encoding as parameters. The function returns the hash value represented in hexadecimal form. If the secret key is of string type, it is converted to bytes type.", "Arguments": ":param secret: String or bytes. The secret key used for generating the HMAC digest.\n:param message: String. The message for which the HMAC digest is to be generated.\n:param encoding: String. The encoding to be used for encoding the secret key and the message. Defaults to \"utf-8\".\n:return: String. The hex digest of the HMAC."}, "tests": ["tests/plugins/test_default_bucket.py::DefaultBucketViewTest::test_default_bucket_exists_and_has_user_id_fallback_to_hmac_secret", "tests/plugins/test_default_bucket.py::DefaultBucketViewTest::test_default_bucket_exists_and_has_user_id", "tests/core/test_utils.py::HmacDigestTest::test_supports_secret_as_bytes", "tests/plugins/test_accounts.py::AccountCreationTest::test_authentication_refresh_the_cache_each_time_we_authenticate", "tests/core/test_utils.py::HmacDigestTest::test_supports_secret_as_text"], "indent": 4}
{"namespace": "kinto.core.utils.current_service", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [285, 285], "body_position": [291, 299], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that is used to get the Cornice service matching the specified request. If the request matches a route, it retrieves the Cornice services from the request's registry and returns the corresponding service based on the matching route pattern. If no matching service is found, it returns None.", "Arguments": ":param request: The request object.\n:return: The service or None if unmatched."}, "tests": ["tests/core/test_utils.py::CurrentServiceTest::test_current_service_returns_the_service_for_existing_patterns"], "indent": 4}
{"namespace": "kinto.core.utils.prefixed_principals", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [328, 328], "body_position": [332, 344], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of principals with a prefixed user id. It first retrieves the list of principals from the request object. If the \"Authenticated\" principal is not in the list, it returns the original list of principals. Otherwise, it removes the unprefixed user id from the effective principals to avoid conflicts, and then adds the prefixed user id to the beginning of the list.", "Arguments": ":param request: Request. The request object containing the effective principals and the prefixed user id.\n:return: List. The list of principals with the prefixed user id."}, "tests": ["tests/core/test_utils.py::PrefixedPrincipalsTest::test_works_if_userid_is_not_in_principals", "tests/core/test_utils.py::PrefixedPrincipalsTest::test_removes_unprefixed_from_principals"], "indent": 4}
{"namespace": "kinto.plugins.accounts.views.on_account_created", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/accounts/views/__init__.py", "signature_position": [176, 176], "body_position": [177, 190], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is called when an account is created. It checks if the account validation is enabled in the settings. If it is enabled, the function proceeds to iterate through each impacted object in the event. For each impacted object, it retrieves the account information, which includes the user email, and an activation key. If the activation key is not found (i.e., it is None), the function skips to the next impacted object. Otherwise, the function sends an email to the user using the Emailer class, passing the request object and the account information as arguments to the send_activation method. The email contains a link for the user to activate their account.", "Arguments": ":param event: The event object containing the request and impacted objects.\n:return: No return values."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_user_creation_listener"], "indent": 4}
{"namespace": "kinto.plugins.accounts.utils.hash_password", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/accounts/utils.py", "signature_position": [13, 15], "body_position": [16, 18], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a password as input, hashes it using bcrypt, and returns the hashed password as a string.", "Arguments": ":param password: String. The password to be hashed.\n:return: String. The hashed password."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_previously_created_accounts_can_still_authenticate"], "indent": 4}
{"namespace": "kinto.views.admin.get_parent_uri", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/views/admin.py", "signature_position": [44, 44], "body_position": [52, 58], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a function that retrieves the parent URI of an object's URI. It achieves universality by performing string operations on the URI, rather than attempting to parse the URI, identify the parent resource, and generate a new URI. It obtains the parent URI by splitting it by \"/\". If the path length is less than 3, an empty string is returned. Otherwise, return the first element of the path as the parent URI.", "Arguments": ":param object_uri: String. The URI of the object.\n:return: String. The parent URI for the object URI. If the object URI does not conform to the URL scheme, an empty string is returned."}, "tests": ["tests/test_views_admin.py::GetParentUriTest::test_parent_uri_behaves_sensibly_for_unknown_resources", "tests/test_views_admin.py::GetParentUriTest::test_parent_uri_accepts_pathological_urls"], "indent": 4}
{"namespace": "alembic.script.write_hooks.register", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/write_hooks.py", "signature_position": [23, 23], "body_position": [35, 39], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a function decorator that registers the function as a write hook. It adds the function to the registry with the given name.", "Arguments": ":param name: String. The name to register the function with.\n:return: Callable. A callable function that registers the input function."}, "tests": ["tests/test_post_write.py::RunHookTest::test_generic", "tests/test_post_write.py::HookTest::test_invoke", "tests/test_post_write.py::HookTest::test_register"], "indent": 4}
{"namespace": "bplustree.memory.open_file_in_dir", "type": "function", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [23, 23], "body_position": [32, 49], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function opens a file and its directory. The file is opened in binary mode and created if it does not exist. Both file descriptors must be closed after use to prevent them from leaking. On Windows, the directory is not opened, as it is useless.", "Arguments": ":param path: String. The path of the file to be opened.\n:return: Tuple[io.FileIO, Optional[int]]. The file descriptor and directory descriptor."}, "tests": ["tests/test_memory.py::test_open_file_in_dir_windows", "tests/test_memory.py::test_open_file_in_dir"], "indent": 4}
{"namespace": "bplustree.memory.FileMemory.read_transaction", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [167, 168], "body_position": [169, 177], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a read transaction for the FileMemory instance. When the transaction begins ( __enter__ method), it acquires a reader lock, ensuring thread-safe read access to a shared resource. Upon completion or exit of the transaction ( __exit__ method), it releases this reader lock.", "Arguments": ":param self: FileMemory. An instance of the FileMemory class.\n:return: ReadTransaction. The created ReadTransaction instance."}, "tests": ["tests/test_memory.py::test_file_memory_write_transaction"], "indent": 8}
{"namespace": "bplustree.utils.pairwise", "type": "function", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/utils.py", "signature_position": [5, 5], "body_position": [10, 12], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function iterates over elements two by two in the given iterable.", "Arguments": ":param iterable: Iterable. The input iterable to iterate over.\n:return: Zip. The pairs of elements in the iterable."}, "tests": ["tests/test_utils.py::test_pairwise"], "indent": 4}
{"namespace": "bplustree.utils.iter_slice", "type": "function", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/utils.py", "signature_position": [15, 15], "body_position": [20, 31], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function yields slices of the given size from the input iterable and indicates if each slice is the last one.", "Arguments": ":param iterable: bytes. The input iterable to be sliced.\n:param n: int. The size of each slice.\n:return: Yields a tuple containing the slice and a boolean indicating if it is the last slice."}, "tests": ["tests/test_utils.py::test_iter_slice"], "indent": 4}
{"namespace": "bplustree.serializer.StrSerializer.serialize", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/serializer.py", "signature_position": [44, 44], "body_position": [45, 47], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Serialize the input string to bytes using the UTF-8 encoding and assert if the length of the bytes is less than or equal to the specified key size.", "Arguments": ":param self: StrSerializer. An instance of the StrSerializer class.\n:param obj: String. The input string to be serialized.\n:param key_size: Integer. The maximum size of the serialized bytes.\n:return: Bytes. The serialized bytes of the input string."}, "tests": ["tests/test_serializer.py::test_str_serializer"], "indent": 8}
{"namespace": "psd_tools.utils.pack", "type": "function", "project_path": "Multimedia/psd-tools", "completion_path": "Multimedia/psd-tools/src/psd_tools/utils.py", "signature_position": [18, 18], "body_position": [19, 20], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function packs the input arguments into a binary string according to the given format like \">{format}\".", "Arguments": ":param fmt: String. The format string that specifies the format of the returned string.\n:param *args: Tuple. The input arguments to be packed.\n:return: Binary string. The packed binary string."}, "tests": ["tests/psd_tools/test_utils.py::test_pack"], "indent": 4}
{"namespace": "psd_tools.utils.unpack", "type": "function", "project_path": "Multimedia/psd-tools", "completion_path": "Multimedia/psd-tools/src/psd_tools/utils.py", "signature_position": [23, 23], "body_position": [24, 25], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function unpacks the given data according to the specified format like \">{format}\".", "Arguments": ":param fmt: String. The format string to be used for unpacking the data.\n:param data: Data. The data to be unpacked.\n:return: Tuple. A tuple containing the unpacked values."}, "tests": ["tests/psd_tools/test_utils.py::test_unpack"], "indent": 4}
{"namespace": "psd_tools.api.numpy_io.get_pattern", "type": "function", "project_path": "Multimedia/psd-tools", "completion_path": "Multimedia/psd-tools/src/psd_tools/api/numpy_io.py", "signature_position": [105, 105], "body_position": [107, 112], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function gets the pattern array from the input pattern. It first extracts the height and width from the third place and fourth place of the rectangle in the pattern's \"data\" attribute and then creates a pattern array by parsing the data from the channels in the pattern's \"data\" attribute.", "Arguments": ":param pattern: Pattern. The input pattern from which the pattern array is to be extracted.\n:return: Numpy array. The pattern array extracted from the input pattern."}, "tests": ["tests/psd_tools/api/test_numpy_io.py::test_get_pattern"], "indent": 4}
{"namespace": "sqlite_utils.utils.maximize_csv_field_size_limit", "type": "function", "project_path": "Database/sqlite-utils", "completion_path": "Database/sqlite-utils/sqlite_utils/utils.py", "signature_position": [45, 45], "body_position": [50, 57], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Increase the CSV field size limit to the maximum possible. It first set the limit of the field's size to be max size of system and then iteratively tries to set the field size limit to the maximum possible value until it succeeds.", "Arguments": ":param: No input parameters.\n:return: No return values."}, "tests": ["tests/test_utils.py::test_maximize_csv_field_size_limit"], "indent": 4}
{"namespace": "sqlite_utils.utils.column_affinity", "type": "function", "project_path": "Database/sqlite-utils", "completion_path": "Database/sqlite-utils/sqlite_utils/utils.py", "signature_position": [123, 125], "body_position": [126, 139], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the affinity of the given column type based on SQLite affinity rules including \"INT\", \"CHAR\", \"CLOB\", \"TEXT\", \"BLOB\", \"REAL\", \"FLOA\", \"DOUB\".", "Arguments": ":param column_type: str. The type of the column.\n:return: The affinity of the given column type."}, "tests": ["tests/test_column_affinity.py::test_column_affinity"], "indent": 4}
{"namespace": "sqlite_utils.utils.decode_base64_values", "type": "function", "project_path": "Database/sqlite-utils", "completion_path": "Database/sqlite-utils/sqlite_utils/utils.py", "signature_position": [142, 143], "body_position": [144, 153], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Decode the base64 encoded values in the given document. It looks for the values with the format '{\"$base64\": true..., \"encoded\": ...}' and decodes them.", "Arguments": ":param doc: Dictionary. The input document containing base64 encoded values.\n:return: Dictionary. The document with base64 encoded values decoded."}, "tests": ["tests/test_utils.py::test_decode_base64_values"], "indent": 4}
{"namespace": "sqlite_utils.utils.chunks", "type": "function", "project_path": "Database/sqlite-utils", "completion_path": "Database/sqlite-utils/sqlite_utils/utils.py", "signature_position": [489, 489], "body_position": [496, 498], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Iterate over chunks of the sequence of the given size. It takes a sequence and a size as input and yields chunks of the sequence of the given size.", "Arguments": ":param sequence: Iterable. Any Python iterator.\n:param size: int. The size of each chunk.\n:return: Iterable[Iterable]. An iterator that yields chunks of the sequence."}, "tests": ["tests/test_utils.py::test_chunks"], "indent": 4}
{"namespace": "sqlite_utils.utils.hash_record", "type": "function", "project_path": "Database/sqlite-utils", "completion_path": "Database/sqlite-utils/sqlite_utils/utils.py", "signature_position": [501, 501], "body_position": [522, 529], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a sha1 hash of the keys and values in the given record. If a subset of keys is provided, it uses only those keys to generate the hash.", "Arguments": ":param record: Dict. A Python dictionary representing the record to generate a hash for.\n:param keys: Optional[Iterable[str]]. A subset of keys to use for generating the hash. Defaults to None.\n:return: The sha1 hash of the keys and values in the record."}, "tests": ["tests/test_utils.py::test_hash_record", "tests/test_create.py::test_insert_hash_id_columns"], "indent": 4}
{"namespace": "arctic.decorators._get_host", "type": "function", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/decorators.py", "signature_position": [16, 16], "body_position": [17, 28], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a dictionary containing the host information of the given store. It first checks if the store is not empty. If the store is not empty, it checks whether it's a list or tuple and takes the first element if so. The function then gathers the store's library name, the MongoDB nodes (formatted as \"host:port\"), and the MongoDB host associated with the Arctic library.", "Arguments": ":param store: Object. The store object from which the host information is to be retrieved.\n:return: Dictionary. A dictionary containing the host information of the given store."}, "tests": ["tests/unit/test_decorators_unit.py::test_get_host_list", "tests/unit/test_decorators_unit.py::test_get_host_not_a_vs", "tests/unit/test_decorators_unit.py::test_get_host"], "indent": 4}
{"namespace": "arctic.decorators.mongo_retry", "type": "function", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/decorators.py", "signature_position": [35, 35], "body_position": [40, 66], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that handles AutoReconnect and OperationFailure errors from PyMongo. It catches all exceptions and logs them if the module name contains 'arctic' and finally set the global attribute _retry_count and _in_retry.", "Arguments": ":param f: The function to be decorated.\n:return: The decorated function."}, "tests": ["tests/unit/test_decorators_unit.py::test_mongo_retry_hook_changes", "tests/unit/test_decorators_unit.py::test_retry_nested", "tests/unit/test_decorators_unit.py::test_mongo_retry_fails", "tests/unit/test_decorators_unit.py::test_all_other_exceptions_logged", "tests/unit/test_decorators_unit.py::test_mongo_retry"], "indent": 4}
{"namespace": "arctic._util.are_equals", "type": "function", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/_util.py", "signature_position": [37, 37], "body_position": [38, 44], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if two objects are equal. If the objects are DataFrames, it uses the assert_frame_equal function to check for equality. Otherwise, it uses the equality operator to compare the objects.", "Arguments": ":param o1: Any. The first object to compare.\n:param o2: Any. The second object to compare.\n:param kwargs: Any. Additional keyword arguments to be passed to the assert_frame_equal function if o1 and o2 are DataFrames.\n:return: Bool. True if the objects are equal, False otherwise. If an exception occurs during the comparison, it returns False."}, "tests": ["tests/unit/test_util.py::test_are_equals_not_df"], "indent": 4}
{"namespace": "arctic.hooks.register_resolve_mongodb_hook", "type": "function", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/hooks.py", "signature_position": [18, 18], "body_position": [19, 20], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function registers a MongoDB hook for resolving MongoDB connections.", "Arguments": ":param hook: The MongoDB hook to be registered.\n:return: No return values."}, "tests": ["tests/unit/test_hooks.py::test_get_mongodb_uri_hook"], "indent": 4}
{"namespace": "arctic.hooks.register_log_exception_hook", "type": "function", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/hooks.py", "signature_position": [30, 30], "body_position": [31, 32], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function registers a log exception hook to be used globally.", "Arguments": ":param hook: The hook to be registered for logging exceptions.\n:return: No return values."}, "tests": ["tests/unit/test_decorators_unit.py::test_mongo_retry_hook_changes", "tests/unit/test_hooks.py::test_log_exception_hook"], "indent": 4}
{"namespace": "arctic.hooks.register_get_auth_hook", "type": "function", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/hooks.py", "signature_position": [35, 35], "body_position": [36, 37], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Register a hook function to be used for getting authentication information.", "Arguments": ":param hook: Function. The hook function to be registered for getting authentication information.\n:return: No return values."}, "tests": ["tests/unit/test_hooks.py::test_get_auth_hook"], "indent": 4}
{"namespace": "arctic.store._version_store_utils._split_arrs", "type": "function", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/store/_version_store_utils.py", "signature_position": [17, 17], "body_position": [22, 31], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function splits a 2D array into multiple sub-arrays based on the given slices. It avoids using fancy indexing and is equivalent to numpy.split(array_2d, slices).", "Arguments": ":param array_2d: 2D array. The input 2D array to be split.\n:param slices: List of integers. The indices where the array is split.\n:return: 1D array. The resulting array of sub-arrays."}, "tests": ["tests/unit/store/test_version_store_utils.py::test_split_arrs"], "indent": 4}
{"namespace": "arctic.store._version_store_utils.checksum", "type": "function", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/store/_version_store_utils.py", "signature_position": [34, 34], "body_position": [38, 46], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the checksum of the passed-in dictionary. It uses the SHA1 algorithm to calculate the checksum and returns the result as a Binary object.", "Arguments": ":param symbol: String. The symbol to be encoded and used in the checksum calculation.\n:param doc: Dictionary. The dictionary for which the checksum needs to be calculated.\n:return: Binary. The calculated checksum as a Binary object."}, "tests": ["tests/unit/store/test_version_store_utils.py::test_checksum_handles_p3strs_and_binary", "tests/unit/store/test_version_store_utils.py::test_checksum"], "indent": 4}
{"namespace": "arctic.store.versioned_item.VersionedItem.__str__", "type": "method", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/store/versioned_item.py", "signature_position": [18, 18], "body_position": [19, 20], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Return a string representation of the VersionedItem instance in the format \"VersionedItem(symbol={symbol},library={library},data={data},version={version},metadata={metadata},host={host})\".", "Arguments": ":param self: VersionedItem. An instance of the VersionedItem class.\n:return: String. The string representation of the VersionedItem instance."}, "tests": ["tests/unit/store/test_version_item.py::test_versioned_item_str_handles_none", "tests/unit/store/test_version_item.py::test_versioned_item_str"], "indent": 8}
{"namespace": "arctic.store._ndarray_store.NdarrayStore._dtype", "type": "method", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/store/_ndarray_store.py", "signature_position": [313, 313], "body_position": [314, 318], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a numpy dtype object based on the input string including the string starting with \"[\" and so on, and metadata. If the metadata is not provided, it defaults to an empty dictionary.", "Arguments": ":param self: NdarrayStore. An instance of the NdarrayStore class.\n:param string: String. The input string to create the dtype object.\n:param metadata: Dictionary. Additional metadata to be passed to the dtype object. Defaults to an empty dictionary.\n:return: Numpy dtype. The created dtype object."}, "tests": ["tests/unit/store/test_ndarray_store.py::test_dtype_parsing"], "indent": 8}
{"namespace": "arctic.store._ndarray_store._promote_struct_dtypes", "type": "function", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/store/_ndarray_store.py", "signature_position": [26, 26], "body_position": [27, 38], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function promotes the data types of two structured arrays. It first checks if the fields of dtype1 are a superset of dtype2. Then, it promotes the data types of the two structured arrays and returns the promoted data type.", "Arguments": ":param dtype1: The data type of the first structured array.\n:param dtype2: The data type of the second structured array.\n:return: The promoted data type of the two structured arrays."}, "tests": ["tests/unit/store/test_ndarray_store.py::test_promote_dtype_throws_if_column_is_removed", "tests/unit/store/test_ndarray_store.py::test_promote_dtype_handles_rearrangement_of_columns_favouring_dtype1", "tests/unit/store/test_ndarray_store.py::test_promote_dtype_handles_string_decrease", "tests/unit/store/test_ndarray_store.py::test_promote_dtype_handles_new_column", "tests/unit/store/test_ndarray_store.py::test_promote_dtype_handles_string_increase"], "indent": 4}
{"namespace": "arctic.chunkstore.passthrough_chunker.PassthroughChunker.exclude", "type": "method", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/chunkstore/passthrough_chunker.py", "signature_position": [62, 62], "body_position": [72, 75], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes data within the bounds of the range object. Since the range object is not valid for this chunk type, it returns an empty dataframe or series.", "Arguments": ":param self: PassthroughChunker. An instance of the PassthroughChunker class.\n:param data: DataFrame or Series. The data to be processed.\n:param range_obj: Range object. The range object to be used for exclusion.\n:return: Empty DataFrame or Series. The result of the exclusion process."}, "tests": ["tests/unit/chunkstore/test_passthrough_chunker.py::test_pass_thru"], "indent": 8}
{"namespace": "arctic.chunkstore.date_chunker.DateChunker.to_chunks", "type": "method", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/chunkstore/date_chunker.py", "signature_position": [10, 10], "body_position": [28, 55], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function chunks the dataframe/series by dates based on the given chunk size. It then applies the given function to each chunk generated by the chunker. The function cannot modify the date column of the dataframe.", "Arguments": ":param df: pandas dataframe or series. The dataframe or series to be chunked.\n:param chunk_size: str. Any valid Pandas frequency string.\n:param func: function. The function to be applied to each chunk generated by the chunker. This function CANNOT modify the date column of the dataframe.\n:param kwargs: Additional keyword arguments.\n:return: generator. A generator that produces tuples: (start date, end date, chunk_size, dataframe/series)."}, "tests": ["tests/unit/chunkstore/test_date_chunker.py::test_to_chunks_exceptions"], "indent": 8}
{"namespace": "arctic.chunkstore.date_chunker.DateChunker.exclude", "type": "method", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/chunkstore/date_chunker.py", "signature_position": [135, 135], "body_position": [143, 150], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "The exclude function filters and returns data that falls outside the specified date range. It first checks if the range_obj is either a pd.DatetimeIndex or a tuple, and converts it to a DateRange object. The function then determines if 'date' is present in either the index names or columns of the data and filters the data to include only those records where the date is either before the start or after the end of the specified range.", "Arguments": ":param self: DateChunker. An instance of the DateChunker class.\n:param data: DataFrame. The data to be filtered.\n:param range_obj: DatetimeIndex or tuple. The range object to filter the data.\n:return: DataFrame. The data filtered by range_obj."}, "tests": ["tests/unit/chunkstore/test_date_chunker.py::test_exclude", "tests/unit/chunkstore/test_date_chunker.py::test_exclude_no_index"], "indent": 8}
{"namespace": "mopidy.httpclient.format_proxy", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/httpclient.py", "signature_position": [8, 8], "body_position": [19, 33], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts a Mopidy proxy config to the commonly used proxy string format. It outputs \"scheme://host:port\", \"scheme://user:pass@host:port\" or None depending on the proxy config provided. You can also opt out of getting the basic auth by setting \"auth\" to False.", "Arguments": ":param proxy_config: Dictionary. The Mopidy proxy config.\n:param auth: Bool. Whether to include basic authentication in the proxy string. Defaults to True.\n:return: String. The commonly used proxy string format."}, "tests": ["tests/test_httpclient.py::test_format_proxy_without_auth", "tests/test_httpclient.py::test_format_proxy"], "indent": 4}
{"namespace": "arctic.chunkstore.date_chunker.DateChunker.filter", "type": "method", "project_path": "Database/arctic-latest", "completion_path": "Database/arctic-latest/arctic/chunkstore/date_chunker.py", "signature_position": [101, 101], "body_position": [114, 133], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function ensures that the data is properly subset to the range in range_obj. It checks the type of range_obj and converts it to DateRange if it is a tuple or pd.DatetimeIndex. Then, it filters the data based on the Pandas DateRange.", "Arguments": ":param self: DateChunker. An instance of the DateChunker class.\n:param data: DataFrame. The data to be filtered.\n:param range_obj: DateRange or tuple. The range to filter the data.\n:return: DataFrame. The data filtered by range_obj."}, "tests": ["tests/unit/chunkstore/test_date_chunker.py::test_with_tuples", "tests/unit/chunkstore/test_date_chunker.py::test_date_filter_with_pd_date_range", "tests/unit/chunkstore/test_date_chunker.py::test_date_filter", "tests/unit/chunkstore/test_date_chunker.py::test_date_filter_no_index"], "indent": 8}
{"namespace": "mopidy.config.validators.validate_required", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/validators.py", "signature_position": [4, 4], "body_position": [10, 11], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function validates that the value is set if it is required. It is normally called in the mopidy.config.types.ConfigValue.deserialize method on the raw string, not the converted value.", "Arguments": ":param value: The value to be validated.\n:param required: Boolean. Whether the value is required or not.\n:return: No return values."}, "tests": ["tests/config/test_validator.py::ValidateRequiredTest::test_blocks_when_required_and_emtpy"], "indent": 4}
{"namespace": "mopidy.config.validators.validate_choice", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/validators.py", "signature_position": [14, 14], "body_position": [19, 21], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function validates whether the given value is one of the choices provided. If the value is not in the choices, it raises a ValueError in the format \"must be one of {names}, not {value}.\".", "Arguments": ":param value: The value to be validated.\n:param choices: List. The list of choices to validate the value against.\n:return: No return values."}, "tests": ["tests/config/test_validator.py::ValidateChoiceTest::test_empty_choices_fails", "tests/config/test_validator.py::ValidateChoiceTest::test_invalid_value_fails"], "indent": 4}
{"namespace": "mopidy.config.validators.validate_minimum", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/validators.py", "signature_position": [24, 24], "body_position": [29, 30], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function validates that the input value is at least the minimum value. If the input value is less than the minimum value, it raises a ValueError in the format \"{value!r} must be larger than {minimum!r}.\".", "Arguments": ":param value: The input value to be validated.\n:param minimum: The minimum value that the input value should be compared against.\n:return: No return values."}, "tests": ["tests/config/test_validator.py::ValidateMinimumTest::test_to_small_value_fails_with_zero_as_minimum", "tests/config/test_validator.py::ValidateMinimumTest::test_to_small_value_fails"], "indent": 4}
{"namespace": "mopidy.config.validators.validate_maximum", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/validators.py", "signature_position": [33, 33], "body_position": [38, 39], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function validates that the given value is at most the given maximum value. If the maximum is not None or value is bigger than maximum, it raises a ValueError in the format \"\"{value!r} must be smaller than {maximum!r}.\".", "Arguments": ":param value: The value to be validated.\n:param maximum: The maximum value that the given value should not exceed.\n:return: No return values."}, "tests": ["tests/config/test_validator.py::ValidateMaximumTest::test_to_large_value_fails_with_zero_as_maximum", "tests/config/test_validator.py::ValidateMaximumTest::test_to_large_value_fails"], "indent": 4}
{"namespace": "mopidy.config.schemas._did_you_mean", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/schemas.py", "signature_position": [6, 6], "body_position": [8, 17], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function suggests the most likely setting based on the Levenshtein distance. It calculates the Levenshtein distance between the input name and each choice, sorts the results, and returns the most likely setting if the distance is less than or equal to 3.", "Arguments": ":param name: String. The input name for which the most likely setting is to be suggested.\n:param choices: List of strings. The list of choices to compare with the input name.\n:return: String. The most likely setting based on the Levenshtein distance, or None if no choices are provided or the distance is greater than 3."}, "tests": ["tests/config/test_schemas.py::DidYouMeanTest::test_suggestions"], "indent": 4}
{"namespace": "mopidy.config.types.encode", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [21, 21], "body_position": [22, 30], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function encodes the given value. If the value is of type bytes, it decodes it using the \"surrogateescape\" error handler. Then, it replaces the characters \"\\\" with \"\\\\n\" and \"\\t\" with \"\\\\t\" and returns the encoded value.", "Arguments": ":param value: The value to be encoded.\n:return: The encoded value."}, "tests": ["tests/config/test_types.py::test_encode_decode_invalid_utf8", "tests/config/test_types.py::test_encode"], "indent": 4}
{"namespace": "mopidy.config.types.decode", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [9, 9], "body_position": [10, 18], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Decode the given value. If the value is of type bytes, it decodes it using the \"surrogateescape\" error handler. Then, it replaces the escape sequences for backslash, newline, and tab with their corresponding characters.", "Arguments": ":param value: Any. The value to be decoded.\n:return: Any. The decoded value."}, "tests": ["tests/config/test_types.py::test_encode_decode_invalid_utf8", "tests/config/test_types.py::test_decode"], "indent": 4}
{"namespace": "mopidy.config.types.ConfigValue.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [66, 66], "body_position": [68, 70], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts the input value to a string for saving purposes. If the input value is None, it returns an empty string.", "Arguments": ":param self: ConfigValue. An instance of the ConfigValue class.\n:param value: Any. The value to be converted to a string.\n:param display: Bool. Whether to display the value. Defaults to False.\n:return: String. The converted string value."}, "tests": ["tests/config/test_types.py::TestConfigValue::test_serialize_none", "tests/config/test_types.py::TestConfigValue::test_serialize_supports_display", "tests/config/test_types.py::TestConfigValue::test_serialize_conversion_to_string"], "indent": 8}
{"namespace": "mopidy.config.types.Boolean.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [213, 213], "body_position": [214, 219], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Serialize the given value to a string representation of a boolean. If the value is True, it returns \"true\". If the value is False or None, it returns \"false\". Otherwise, it raises a ValueError in the format \"{value!r} is not a boolean\".", "Arguments": ":param self: Boolean. An instance of the Boolean class.\n:param value: Any. The value to be serialized.\n:param display: Bool. Whether to display the value. Defaults to False.\n:return: String. The serialized value."}, "tests": ["tests/config/test_types.py::TestBoolean::test_serialize_true", "tests/config/test_types.py::TestBoolean::test_serialize_false", "tests/config/test_types.py::TestBoolean::test_serialize_invalid_values", "tests/config/test_types.py::TestBoolean::test_serialize_none_as_false"], "indent": 8}
{"namespace": "hypertools._shared.helpers.center", "type": "function", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/_shared/helpers.py", "signature_position": [20, 20], "body_position": [21, 23], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function first asserts the type of input is list and then centers the input list of data by subtracting the mean of the input data from each element of the list.", "Arguments": ":param x: list. The input list of data to be centered.\n:return: list. The centered list of data."}, "tests": ["tests/test_helpers.py::test_center"], "indent": 4}
{"namespace": "hypertools._shared.helpers.group_by_category", "type": "function", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/_shared/helpers.py", "signature_position": [35, 35], "body_position": [36, 39], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function groups the input values by category. It first checks if the input values contain any list. If so, it flattens the list. Then, it creates a sorted set of unique values and returns the index of each value in the sorted set.", "Arguments": ":param vals: List. The input list of values.\n:return: List. The list of indices of the input values in the sorted set."}, "tests": ["tests/test_helpers.py::test_group_by_category_ints", "tests/test_helpers.py::test_group_by_category_str"], "indent": 4}
{"namespace": "hypertools._shared.helpers.vals2colors", "type": "function", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/_shared/helpers.py", "signature_position": [42, 42], "body_position": [52, 58], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function maps the input values to colors based on the given color map and resolution. It first flattens the input list if it is a list of lists. Then, it gets the color palette from seaborn and maps the input values to colors based on the color map and resolution.", "Arguments": ":param vals: List or list of lists. List of values to map to colors.\n:param cmap: String. The color map to be used. It defaults to 'GnBu' if not specified.\n:param res: Integer. The resolution of the color map. It defaults to 100.\n:return: List of RGB tuples. The list of RGB tuples representing the mapped colors."}, "tests": ["tests/test_helpers.py::test_vals2colors_list", "tests/test_helpers.py::test_vals2colors_list_of_lists"], "indent": 4}
{"namespace": "hypertools._shared.helpers.vals2bins", "type": "function", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/_shared/helpers.py", "signature_position": [61, 61], "body_position": [70, 72], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function maps the input values to bins based on the given resolution. It first flattens the input list if it is a list of lists and then maps the values to bins based on the resolution.", "Arguments": ":param vals: List or list of lists. List of values to map to colors.\n:param res: Int. Resolution of the color map. Defaults to 100.\n:return: List of numbers representing bins."}, "tests": ["tests/test_helpers.py::test_vals2bins"], "indent": 4}
{"namespace": "hypertools._shared.helpers.interp_array", "type": "function", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/_shared/helpers.py", "signature_position": [75, 75], "body_position": [76, 79], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function interpolates the given array using piecewise cubic Hermite interpolation.", "Arguments": ":param arr: Array. The input array to be interpolated.\n:param interp_val: Integer. The interpolation value. Defaults to 10.\n:return: Array. The interpolated array."}, "tests": ["tests/test_helpers.py::test_interp_array"], "indent": 4}
{"namespace": "hypertools._shared.helpers.parse_args", "type": "function", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/_shared/helpers.py", "signature_position": [89, 89], "body_position": [90, 103], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes two input parameters, x and args, and creates a list of tuples. It iterates through the elements of x and for each element, it creates a tuple by combining the elements of args. If the element of args is a list or tuple, it checks if its length is the same as that of x. If not, it prints an error message and exits the program.", "Arguments": ":param x: List. The input list of elements.\n:param args: List. The list of arguments to be combined with the elements of x.\n:return: List of tuples. A list of tuples, where each tuple contains the combined elements of x and args."}, "tests": ["tests/test_helpers.py::test_parse_args_array", "tests/test_helpers.py::test_parse_args_list"], "indent": 4}
{"namespace": "hypertools._shared.helpers.parse_kwargs", "type": "function", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/_shared/helpers.py", "signature_position": [106, 106], "body_position": [107, 119], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a list of dictionaries based on the input list and the input keyword arguments. It iterates through the input list and creates a dictionary for each item in the list using the keyword arguments.", "Arguments": ":param x: List. The input list.\n:param kwargs: Dictionary. The keyword arguments.\n:return: List of Dictionary. A list of dictionaries created based on the input list and keyword arguments."}, "tests": ["tests/test_helpers.py::test_parse_kwargs_list", "tests/test_helpers.py::test_parse_kwargs_array"], "indent": 4}
{"namespace": "gif_for_cli.utils._get_default_display_mode", "type": "function", "project_path": "Multimedia/gif-for-cli", "completion_path": "Multimedia/gif-for-cli/gif_for_cli/utils.py", "signature_position": [39, 39], "body_position": [40, 47], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the default display mode based on the environment variables. It checks the TERM and COLORTERM environment variables and returns the display mode based on the values of these variables. If \"truecolor\" in TERM or COLORTERM, it will return \"truecolor\". If \"256\" in TERM or COLORTERM, it will return \"256fgbg\". In other conditions, it returns \"nocolor\".", "Arguments": ":param environ: Dictionary. The environment variables.\n:return: String. The default display mode based on the environment variables."}, "tests": ["tests/test_utils.py::TestGetDefaultDisplayMode::test_truecolor", "tests/test_utils.py::TestGetDefaultDisplayMode::test_256", "tests/test_utils.py::TestGetDefaultDisplayMode::test_empty_env"], "indent": 4}
{"namespace": "gif_for_cli.utils._pool_type", "type": "function", "project_path": "Multimedia/gif-for-cli", "completion_path": "Multimedia/gif-for-cli/gif_for_cli/utils.py", "signature_position": [50, 50], "body_position": [51, 56], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts the input value to an integer and checks if it is greater than 0. If not, it raises an exception.", "Arguments": ":param val: The input value to be converted to an integer.\n:return: Integer. The converted value. Or an exception is raised if the value is less than or equal to 0."}, "tests": ["tests/test_utils.py::TestPoolType::test_int_string_0", "tests/test_utils.py::TestPoolType::test_int_string"], "indent": 4}
{"namespace": "gif_for_cli.generate.utils.get_avg_for_em", "type": "function", "project_path": "Multimedia/gif-for-cli", "completion_path": "Multimedia/gif-for-cli/gif_for_cli/generate/utils.py", "signature_position": [65, 65], "body_position": [66, 71], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the average of the pixels in a given area of an image.", "Arguments": ":param px: List. The list of pixels in the image.\n:param x: Integer. The x-coordinate of the top-left corner of the area.\n:param y: Integer. The y-coordinate of the top-left corner of the area.\n:param cell_height: Integer. The height of the area.\n:param cell_width: Integer. The width of the area.\n:return: List. The average of the pixels in the given area."}, "tests": ["tests/generate/test_utils.py::TestGetAvgForEm::test_white_block", "tests/generate/test_utils.py::TestGetAvgForEm::test_separate_color_channels", "tests/generate/test_utils.py::TestGetAvgForEm::test_gray_block", "tests/generate/test_utils.py::TestGetAvgForEm::test_default_black_block"], "indent": 4}
{"namespace": "gif_for_cli.generate.utils.process_input_source", "type": "function", "project_path": "Multimedia/gif-for-cli", "completion_path": "Multimedia/gif-for-cli/gif_for_cli/generate/utils.py", "signature_position": [74, 74], "body_position": [75, 116], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function processes the input source to get the GIF URL. It first checks if the input source is a Tenor GIF URL by checking the input source start with \"https://tenor.com/view/\". If it is, it extracts the GIF ID and uses it to get the GIF URL. If the input source is not a URL, it sends a request to the Tenor GIF API to get the GIF URL based on the input source.", "Arguments": ":param input_source: String. The input source, which can be a Tenor GIF URL, a local file path, or a search query.\n:param api_key: String. The API key for accessing the Tenor GIF API.\n:return: String. The GIF URL obtained from the input source."}, "tests": ["tests/generate/test_utils.py::TestProcessInputSource::test_http_url", "tests/generate/test_utils.py::TestProcessInputSource::test_file", "tests/generate/test_utils.py::TestProcessInputSource::test_tenor_search", "tests/generate/test_utils.py::TestProcessInputSource::test_tenor_trending", "tests/generate/test_utils.py::TestProcessInputSource::test_https_url"], "indent": 4}
{"namespace": "hypertools._shared.helpers.reshape_data", "type": "function", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/_shared/helpers.py", "signature_position": [122, 122], "body_position": [123, 132], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Reshape the input data based on the hue and labels. It stacks the input data and reshapes it based on the categories in the hue. It also reshapes the labels based on the categories in the hue.", "Arguments": ":param x: Array. The input data to be reshaped.\n:param hue: Array. The categories based on which the data is reshaped.\n:param labels: Array. The labels corresponding to the input data. Defaults to None.\n:return: List of arrays. The reshaped input data based on the categories in the hue, and the reshaped labels."}, "tests": ["tests/test_helpers.py::test_reshape_data"], "indent": 4}
{"namespace": "mingus.extra.lilypond.from_Note", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/extra/lilypond.py", "signature_position": [37, 37], "body_position": [46, 73], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a Note object and returns the LilyPond equivalent in a string. It can ignore all data regarding octaves and produce a valid output.", "Arguments": ":param note: Note. The Note object to be converted.\n:param process_octaves: Bool. Whether to process octaves. Defaults to True.\n:param standalone: Bool. Whether the result can be used by functions like to_png. Defaults to True.\n:return: String. The LilyPond equivalent of the Note object."}, "tests": ["tests/integration/test_lilypond.py::test_LilyPond::test_from_Note"], "indent": 4}
{"namespace": "mingus.extra.tablature._get_qsize", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/extra/tablature.py", "signature_position": [452, 452], "body_position": [454, 459], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates and returns a reasonable quarter note size based on the input tuning and width.", "Arguments": ":param tuning: Tuning. The tuning object used to calculate the quarter note size.\n:param width: Integer. The width used to calculate the quarter note size.\n:return: Integer. The calculated quarter note size."}, "tests": ["tests/unit/extra/test_tablature.py::test_Tablature::test__get_qsize"], "indent": 4}
{"namespace": "mingus.core.notes.augment", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/notes.py", "signature_position": [147, 147], "body_position": [156, 159], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function augments a given note. If the note does not end with \"b\", it adds \"#\" to the note. Otherwise, it removes the last character \"b\" from the note.", "Arguments": ":param note: String. The note to be augmented.\n:return: String. The augmented note."}, "tests": ["tests/unit/core/test_notes.py::test_notes::test_augment"], "indent": 4}
{"namespace": "mingus.core.meter.valid_beat_duration", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/meter.py", "signature_position": [30, 30], "body_position": [32, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the duration is a valid beat duration. A valid beat duration is when log2(duration) is an integer.", "Arguments": ":param duration: Integer. The duration to be checked.\n:return: Bool. True if log2(duration) is an integer, False otherwise."}, "tests": ["tests/unit/core/test_meter.py::test_meter::test_valid_beat_duration"], "indent": 4}
{"namespace": "mingus.core.notes.diminish", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/notes.py", "signature_position": [162, 162], "body_position": [171, 174], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Diminish a given note. If the note does not end with \"#\", it adds \"b\" to the note. Otherwise, it removes the last character \"#\" from the note.", "Arguments": ":param note: String. The note to be diminished.\n:return: String. The diminished note."}, "tests": ["tests/unit/core/test_notes.py::test_notes::test_diminish"], "indent": 4}
{"namespace": "mingus.core.intervals.invert", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [312, 312], "body_position": [319, 322], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Invert an interval. It reverses the order of the elements in the input interval list and returns the reversed list.", "Arguments": ":param interval: List. The input interval list to be inverted.\n:return: List. The inverted interval list."}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_invert"], "indent": 4}
{"namespace": "mingus.core.progressions.parse_string", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/progressions.py", "signature_position": [215, 215], "body_position": [224, 239], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function parses the input string and returns a tuple containing the roman numeral, accidentals, and chord suffix.", "Arguments": ":param progression: String. The input string to be parsed.\n:return: Tuple. A tuple containing the roman numeral, accidentals, and chord suffix."}, "tests": ["tests/unit/core/test_progressions.py::test_progressions::test_parse_string"], "indent": 4}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [35, 35], "body_position": [37, 41], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a byte string into an integer. It first unpacks the byte string into characters and then converts the characters into an integer.", "Arguments": ":param bytes: Byte string. The byte string to be converted into an integer.\n:param byteorder: String. The byte order to be used. It defaults to \"big\" if not specified.\n:return: Integer. The converted integer value."}, "tests": ["tests/test_bundling.py::test_bytes_to_int"], "indent": 4}
{"namespace": "exodus_bundler.templating.render_template", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/templating.py", "signature_position": [13, 13], "body_position": [14, 16], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function replaces the placeholders in the input string with the corresponding values from the context dictionary.", "Arguments": ":param string: String. The input string containing placeholders.\n:param context: Dictionary. The key-value pairs to replace the placeholders in the input string.\n:return: String. The modified string after replacing the placeholders."}, "tests": ["tests/test_templating.py::test_render_template"], "indent": 4}
{"namespace": "exodus_bundler.input_parsing.strip_pid_prefix", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/input_parsing.py", "signature_position": [105, 105], "body_position": [107, 110], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes the `[pid XXX] ` prefix from the input line if it is present.", "Arguments": ":param line: String. The input line that may contain the `[pid XXX] ` prefix.\n:return: String. The line with the `[pid XXX] ` prefix removed if present. If not present, the original line is returned."}, "tests": ["tests/test_input_parsing.py::test_strip_pid_prefix"], "indent": 4}
{"namespace": "fs.path.abspath", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [169, 170], "body_position": [184, 186], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts the given path to an absolute path. It adds a leading \"/\" character if the path doesn't already have one.", "Arguments": ":param path: Text. A PyFilesytem path.\n:return: Text. An absolute path."}, "tests": ["tests/test_path.py::TestPathFunctions::test_abspath"], "indent": 4}
{"namespace": "fs.path.combine", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [244, 245], "body_position": [264, 266], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function joins two paths together. It is faster than fs.path.join, but only works when the second path is relative, and there are no back references in either path. For example, it convert (\"foo/bar\", \"baz\") into \"foo/bar/baz\".", "Arguments": ":param path1: Text. A PyFilesytem path.\n:param path2: Text. A PyFilesytem path.\n:return: Text. The joint path."}, "tests": ["tests/test_path.py::TestPathFunctions::test_combine"], "indent": 4}
{"namespace": "fs.path.split", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [293, 294], "body_position": [315, 318], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Split a path into a pair (head, tail) where 'tail' is the last pathname component and 'head' is all preceding components.", "Arguments": ":param path: Text. The path to split.\n:return: Tuple[Text, Text]. A tuple containing the head and the tail of the path."}, "tests": ["tests/test_path.py::TestPathFunctions::test_pathsplit"], "indent": 4}
{"namespace": "fs.path.isparent", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [464, 465], "body_position": [486, 495], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the first path is a parent directory of the second path. It compares the two paths and returns True if the first path is a parent directory of the second path. Example: isparent(\"foo/bar\", \"foo/bar/spam.txt\") -> True; isparent(\"foo/bar/\", \"foo/bar\") -> True; isparent(\"foo/barry\", \"foo/baz/bar\") -> False; isparent(\"foo/bar/baz/\", \"foo/baz/bar\") -> False", "Arguments": ":param path1: Text. The first path to be compared.\n:param path2: Text. The second path to be compared.\n:return: bool. True if path1 is a parent directory of path2."}, "tests": ["tests/test_path.py::TestPathFunctions::test_isparent"], "indent": 4}
{"namespace": "fs.path.forcedir", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [498, 499], "body_position": [517, 519], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Ensure the path ends with a trailing forward slash. If the path does not end with a slash, it appends a slash to the path and returns it.", "Arguments": ":param path: Text. A PyFilesytem path.\n:return: Text. The path, ending with a slash."}, "tests": ["tests/test_path.py::TestPathFunctions::test_forcedir"], "indent": 4}
{"namespace": "fs.wildcard.match_any", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/wildcard.py", "signature_position": [61, 62], "body_position": [76, 78], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function tests if a name matches any of a list of patterns. It returns True if the patterns list is empty.", "Arguments": ":param patterns: Iterable of Text. A list of wildcard patterns, e.g., [\"*.py\", \"*.pyc\"].\n:param name: Text. A filename.\n:return: bool. True if the name matches at least one of the patterns."}, "tests": ["tests/test_wildcard.py::TestFNMatch::test_match_any"], "indent": 4}
{"namespace": "fs.wildcard.imatch_any", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/wildcard.py", "signature_position": [81, 82], "body_position": [96, 98], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function tests if a name matches any of a list of patterns in a case-insensitive manner. It returns True if the patterns list is empty.", "Arguments": ":param patterns: Iterable of Text. A list of wildcard patterns, e.g., [\"*.py\", \"*.pyc\"].\n:param name: Text. A filename.\n:return: bool. True if the name matches at least one of the patterns."}, "tests": ["tests/test_wildcard.py::TestFNMatch::test_match_any"], "indent": 4}
{"namespace": "wal_e.cmd.parse_boolean_envvar", "type": "function", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/cmd.py", "signature_position": [161, 161], "body_position": [163, 168], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function parses a boolean environment variable. It checks if the input value is a valid boolean value 'false', '0', 'true', '1' and returns the corresponding boolean value. Otherwise raises an error.", "Arguments": ":param val: String. The value of the environment variable to be parsed.\n:return: Boolean. The parsed boolean value."}, "tests": ["tests/test_cmd.py::test_parse_boolean_envvar"], "indent": 4}
{"namespace": "wal_e.log_help.get_log_destinations", "type": "function", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/log_help.py", "signature_position": [111, 111], "body_position": [114, 115], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function parses the environment string \"WALE_LOG_DESTINATION\" and returns the log destinations from the corresponding environment varialbe. If the environment variable is not set, it defaults to \"stderr,syslog\".", "Arguments": ":param: No input parameters.\n:return: List of strings. The log destinations."}, "tests": ["tests/test_log_help.py::test_get_log_destinations_empty", "tests/test_log_help.py::test_get_log_destinations_notempty"], "indent": 4}
{"namespace": "wal_e.log_help.WalELogger._fmt_structured", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/log_help.py", "signature_position": [145, 145], "body_position": [151, 158], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function formats a dictionary into a string. The dictionary is formatted as '{k1:v1, k2:v2}' and the output is formatted as 'time=... pid=... k1=v1 k2=v2', in which the time is time=%Y-%m-%dT%H:%M:%S.%f-00. The output is sorted lexically, except the time and pid always come first.", "Arguments": ":param d: Dictionary. The input dictionary to be formatted.\n:return: String. The formatted string."}, "tests": ["tests/test_log_help.py::test_format_structured_info"], "indent": 8}
{"namespace": "wal_e.tar_partition._fsync_files", "type": "function", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/tar_partition.py", "signature_position": [158, 158], "body_position": [164, 184], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calls fsync() on a list of file names. It opens each file, calls fsync() and then closes the file. It also calls fsync() on the directory where the file is created.", "Arguments": ":param filenames: List of string. A list of absolute file paths.\n:return: No return values."}, "tests": ["tests/test_tar_hacks.py::test_fsync_tar_members"], "indent": 4}
{"namespace": "wal_e.blobstore.file.calling_format.Bucket.list", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/blobstore/file/calling_format.py", "signature_position": [72, 72], "body_position": [73, 77], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "List all the files in the bucket with the given prefix. It first constructs the path based on \"/\" + prefix, then retrieves all the file paths under the path, and finally creates an array of FileKey instances based on the file paths.", "Arguments": ":param self: Bucket. An instance of the Bucket class.\n:param prefix: String. The prefix to be used for listing files.\n:return: List of FileKey. An array of FileKey instances representing the files in the bucket with the given prefix."}, "tests": ["tests/test_file_blobstore.py::test_bucket_list"], "indent": 8}
{"namespace": "pyinfra.operations.util.files.unix_path_join", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/util/files.py", "signature_position": [7, 7], "body_position": [8, 10], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Join the given path parts into a single path. It removes the trailing slashes from all parts except the last one and joins them using a forward slash.", "Arguments": ":param path_parts: Tuple. The parts of the path to be joined.\n:return: String. The joined path."}, "tests": ["tests/test_operations_utils.py::TestUnixPathJoin::test_end_slash_path", "tests/test_operations_utils.py::TestUnixPathJoin::test_simple_path", "tests/test_operations_utils.py::TestUnixPathJoin::test_multiple_slash_path", "tests/test_operations_utils.py::TestUnixPathJoin::test_absolute_path"], "indent": 4}
{"namespace": "pyinfra.api.util.try_int", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/util.py", "signature_position": [55, 55], "body_position": [56, 59], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function tries to convert the input value to an integer. If it fails, it returns the original value.", "Arguments": ":param value: Any. The value to be converted to an integer.\n:return: int. The converted integer value if successful, otherwise the original value."}, "tests": ["tests/test_api/test_api_util.py::TestApiUtil::test_try_int_fail", "tests/test_api/test_api_util.py::TestApiUtil::test_try_int_number"], "indent": 4}
{"namespace": "mrjob.job.MRJob.mr_job_script", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [927, 927], "body_position": [931, 934], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Returns the path of the source file containing the MRJob class. Returns None on error.", "Arguments": ":param cls: The MRJob class.\n:return: Optional[str]. The path of the script containing the MRJob class or None."}, "tests": ["tests/test_job.py::LibjarsTestCase::test_libjars_attr_relative_path", "tests/test_job.py::LibjarsTestCase::test_libjars_environment_variables"], "indent": 8}
{"namespace": "mrjob.compat.map_version", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/compat.py", "signature_position": [623, 623], "body_position": [638, 654], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function allows you to look up something by version (e.g. which jobconf variable to use, specifying only the versions where that value changed). It returns the value for the earliest version in the version map if the version is less than any version in the version map.", "Arguments": ":param version: String. The version to look up.\n:param version_map: Map. A map from version (as a string) that a value changed to the new value. For efficiency, version_map can also be a list of tuples of (LooseVersion(version_as_string), value), with oldest versions first.\n:return: The value for the earliest version in the version map if the version is less than any version in the version map."}, "tests": ["tests/test_compat.py::MapVersionTestCase::test_empty", "tests/test_compat.py::MapVersionTestCase::test_dict", "tests/test_compat.py::MapVersionTestCase::test_version_may_not_be_None", "tests/test_compat.py::MapVersionTestCase::test_list_of_tuples"], "indent": 4}
{"namespace": "mrjob.conf.combine_values", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [378, 378], "body_position": [383, 387], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the last value in the input *values which is not None.", "Arguments": ":param *values: Any. The input values to be combined.\n:return: Any. The last non-None value in the input values. If all values are None, it returns None."}, "tests": ["tests/test_conf.py::CombineValuesTestCase::test_picks_last_value", "tests/test_conf.py::CombineValuesTestCase::test_falseish_values", "tests/test_conf.py::CombineValuesTestCase::test_skips_None", "tests/test_conf.py::CombineCmdsTestCase::test_skips_None"], "indent": 4}
{"namespace": "mrjob.protocol.BytesProtocol.read", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/protocol.py", "signature_position": [361, 361], "body_position": [362, 366], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function reads a line and splits it into two parts - key and value - using the tab delimiter. If there is only one part, it uses None as the value.", "Arguments": ":param self: BytesProtocol. An instance of the BytesProtocol class.\n:param line: Bytes. The line to be read and processed.\n:return: Tuple. A tuple containing the key-value pair."}, "tests": ["tests/test_protocol.py::BytesProtocolTestCase::test_extra_tabs", "tests/test_protocol.py::BytesProtocolTestCase::test_no_strip", "tests/test_protocol.py::BytesProtocolTestCase::test_no_tabs"], "indent": 8}
{"namespace": "mrjob.protocol.TextProtocol.write", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/protocol.py", "signature_position": [418, 418], "body_position": [419, 420], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Write the key and value to the TextProtocol instance. It encodes the key and value to utf-8 and joins them with a tab character. If either key or value is None, it is not included in the string.", "Arguments": ":param self: TextProtocol. An instance of the TextProtocol class.\n:param key: The key to write to the instance.\n:param value: The value to write to the instance.\n:return: bytes. The encoded key and value joined by a tab character."}, "tests": ["tests/test_protocol.py::TextProtocolTestCase::test_extra_tabs", "tests/test_protocol.py::TextProtocolTestCase::test_no_tabs"], "indent": 8}
{"namespace": "mrjob.protocol.TextProtocol.read", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/protocol.py", "signature_position": [406, 406], "body_position": [407, 416], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function reads a line and decodes it using utf_8. If it fails, it decodes it using latin_1. It then splits the line into key and value using the tab character and returns the tuple of key and value.", "Arguments": ":param self: TextProtocol. An instance of the TextProtocol class.\n:param line: The line to be read and processed.\n:return: Tuple. The tuple of key and value."}, "tests": ["tests/test_protocol.py::TextProtocolTestCase::test_no_strip", "tests/test_protocol.py::TextProtocolTestCase::test_extra_tabs", "tests/test_protocol.py::TextProtocolTestCase::test_no_tabs", "tests/test_protocol.py::TextProtocolTestCase::test_latin_1_fallback", "tests/test_protocol.py::TextProtocolTestCase::test_utf_8"], "indent": 8}
{"namespace": "mrjob.protocol.TextValueProtocol.read", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/protocol.py", "signature_position": [444, 444], "body_position": [445, 448], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function reads a line and decodes it using the utf-8 encoding. If a UnicodeDecodeError occurs, it decodes the line using the latin-1 encoding.", "Arguments": ":param self: TextValueProtocol. An instance of the TextValueProtocol class.\n:param line: The line to be read and decoded.\n:return: Tuple. The first element is None and the second element is the decoded line."}, "tests": ["tests/test_protocol.py::TextValueProtocolTestCase::test_fall_back_to_latin_1", "tests/test_protocol.py::TextValueProtocolTestCase::test_utf_8_decode", "tests/test_protocol.py::TextValueProtocolTestCase::test_converts_raw_line_to_unicode", "tests/test_protocol.py::TextValueProtocolTestCase::test_no_strip"], "indent": 8}
{"namespace": "mrjob.util.file_ext", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/util.py", "signature_position": [67, 67], "body_position": [79, 84], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the file extension of the given filename, including the \".\" character. It first strips the leading \".\" from the filename and then finds the index of the first occurrence of \".\". If no \".\" is found, it returns an empty string.", "Arguments": ":param filename: str. The name of the file.\n:return: str. The file extension, including the \".\" character. If no extension is found, an empty string is returned."}, "tests": ["tests/test_util.py::FileExtTestCase::test_file_ext"], "indent": 4}
{"namespace": "mrjob.util.cmd_line", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/util.py", "signature_position": [49, 49], "body_position": [52, 53], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function builds a command line that works in a shell. It takes a list of arguments and converts each argument to a string. Then, it joins the arguments with a space and quotes each argument.", "Arguments": ":param args: List. A list of arguments to be used in the command line.\n:return: str. The command line that works in a shell."}, "tests": ["tests/test_local.py::PythonBinTestCase::test_python_dash_v_as_python_bin", "tests/test_bin.py::SparkUploadArgsTestCase::test_setup_disabled", "tests/test_bin.py::SparkUploadArgsTestCase::test_no_setup", "tests/test_util.py::CmdLineTestCase::test_cmd_line", "tests/test_bin.py::SparkUploadArgsTestCase::test_setup_interpolation"], "indent": 4}
{"namespace": "mrjob.util.save_cwd", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/util.py", "signature_position": [186, 186], "body_position": [189, 195], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a context manager that saves the current working directory and finally: chdir back to it.", "Arguments": ":param: No input parameters.\n:return: No return values."}, "tests": ["tests/test_parse.py::URITestCase::test_relative_path_to_uri"], "indent": 4}
{"namespace": "mrjob.util.save_sys_std", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/util.py", "signature_position": [199, 199], "body_position": [204, 224], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a context manager that saves the current values of `sys.stdin`, `sys.stdout`, and `sys.stderr`, and flushes these file handles before and after switching them out, finally: restore them.", "Arguments": ":param: No input parameters.\n:return: No return values."}, "tests": ["tests/test_util.py::SaveSysStdTestCase::test_basic", "tests/test_util.py::SaveSysStdTestCase::test_bad_flush", "tests/test_util.py::SaveSysStdTestCase::test_flushing"], "indent": 4}
{"namespace": "mrjob.util.unarchive", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/util.py", "signature_position": [334, 334], "body_position": [348, 367], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Extract the contents of a tar or zip file at *archive_path* into the directory *dest*. It first checks the type of the archive file and then extracts the contents accordingly. tar files can be gzip compressed, bzip2 compressed, or uncompressed. Files within zip files can be deflated or stored.", "Arguments": ":param archive_path: str. Path to the archive file.\n:param dest: str. Path to the directory where the archive will be extracted. The path will be created if it doesn't already exist.\n:return: No return values."}, "tests": ["tests/test_util.py::ArchiveTestCase::test_unarchive_non_archive"], "indent": 4}
{"namespace": "mrjob.util.unique", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/util.py", "signature_position": [322, 322], "body_position": [324, 331], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function yields items from the input list in order, skipping duplicates.", "Arguments": ":param items: List. The input list of items.\n:return: Generator[items]."}, "tests": ["tests/test_util.py::UniqueTestCase::test_de_duplication", "tests/test_util.py::UniqueTestCase::test_preserves_order", "tests/test_util.py::UniqueTestCase::test_empty", "tests/test_util.py::UniqueTestCase::test_mixed_types_ok"], "indent": 4}
{"namespace": "mrjob.parse.urlparse", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [79, 79], "body_position": [85, 91], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a wrapper for the urlparse.urlparse function. It splits the fragment correctly in all URIs, not just Web-related ones.", "Arguments": ":param urlstring: String. The URL to be parsed.\n:param scheme: String. The URL scheme. Defaults to an empty string.\n:param allow_fragments: Bool. Whether to allow fragments in the URL. Defaults to True.\n:param *args: Additional positional arguments.\n:param **kwargs: Additional keyword arguments.\n:return: ParseResult. The result of parsing the URL."}, "tests": ["tests/test_parse.py::URITestCase::test_urlparse"], "indent": 4}
{"namespace": "mrjob.util.which", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/util.py", "signature_position": [370, 370], "body_position": [379, 386], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function searches for the executable named *cmd* in the specified *path*. If *path* is not specified, it defaults to :envvar:`PATH`. It returns ``None`` if no such executable is found.", "Arguments": ":param cmd: str. The name of the executable to search for.\n:param path: str. The path to search for the executable. Defaults to :envvar:`PATH`.\n:return: Optional[str]. The path to the executable if found, otherwise ``None``."}, "tests": ["tests/test_util.py::WhichTestCase::test_path_from_environment", "tests/test_util.py::WhichTestCase::test_explicit_path"], "indent": 4}
{"namespace": "sshuttle.ssh.parse_hostport", "type": "function", "project_path": "System/sshuttle", "completion_path": "System/sshuttle/sshuttle/ssh.py", "signature_position": [33, 33], "body_position": [46, 84], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Parse the given rhostport variable looking like [username[:password]@]host[:port]. If only host is given, can be a hostname, IPv4/v6 address or a ssh alias from ~/.ssh/config. It returns a tuple containing username, password, port, and host. It first checks if the rhostport is empty and returns None for all values. Then, it parses the rhostport and extracts the username, password, port, and host based on the given format.", "Arguments": ":param rhostport: str. The input rhostport variable to be parsed.\n:return: Tuple. A tuple containing username, password, port, and host.\n```"}, "tests": ["tests/ssh/test_parse_hostport.py::test_username_and_host", "tests/ssh/test_parse_hostport.py::test_host_and_port", "tests/ssh/test_parse_hostport.py::test_host_only"], "indent": 4}
{"namespace": "flower.utils.search.stringified_dict_contains_value", "type": "function", "project_path": "System/flower", "completion_path": "System/flower/flower/utils/search.py", "signature_position": [62, 62], "body_position": [67, 80], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if a dictionary in the form of a string like \"{'test': 5}\" contains the input key/value pair. It is faster than creating an actual dictionary from a string since this operation is called for each task in case of kwargs search.", "Arguments": ":param key: The key to be searched in the dictionary.\n:param value: The value to be searched in the dictionary.\n:param str_dict: str. The dictionary in the form of a string.\n:return: bool. True if the key/value pair is found in the dictionary, False otherwise."}, "tests": ["tests/unit/utils/test_search.py::TestStringfiedDictChecker::test_works_for_nonexisting_kwargs", "tests/unit/utils/test_search.py::TestStringfiedDictChecker::test_works_for_kwargs_in_different_parts_of_string", "tests/unit/utils/test_search.py::TestStringfiedDictChecker::test_works_for_no_kwargs", "tests/unit/utils/test_search.py::TestStringfiedDictChecker::test_stringifies_args"], "indent": 4}
{"namespace": "flower.utils.abs_path", "type": "function", "project_path": "System/flower", "completion_path": "System/flower/flower/utils/__init__.py", "signature_position": [32, 32], "body_position": [33, 37], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the absolute path of the given input path. It first expands the user path and then checks if the path is absolute. If not, it appends the current working directory to the path.", "Arguments": ":param path: str. The input path.\n:return: str. The absolute path of the input path."}, "tests": ["tests/unit/utils/test_utils.py::TestAbsPath::test_home_path", "tests/unit/utils/test_utils.py::TestAbsPath::test_relative_path_with_pwd", "tests/unit/utils/test_utils.py::TestAbsPath::test_absolute_path"], "indent": 4}
{"namespace": "flower.utils.strtobool", "type": "function", "project_path": "System/flower", "completion_path": "System/flower/flower/utils/__init__.py", "signature_position": [44, 44], "body_position": [51, 56], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a string representation of truth to true (1) or false (0). It checks the input string and returns 1 if the input string is a true value and 0 if the input string is a false value. It raises a ValueError if the input string is neither a true value nor a false value.", "Arguments": ":param val: str. The string representation of truth. True values are 'y', 'yes', 't', 'true', 'on', and '1'; false values are 'n', 'no', 'f', 'false', 'off', and '0'. Raises ValueError if 'val' is anything else.\n:return: int. 1 if the input string is a true value, 0 if the input string is a false value."}, "tests": ["tests/unit/utils/test_utils.py::TestStrtobool::test_invalid_value", "tests/unit/utils/test_utils.py::TestStrtobool::test_false_values", "tests/unit/utils/test_utils.py::TestStrtobool::test_true_values"], "indent": 4}
{"namespace": "sshuttle.methods.get_method", "type": "function", "project_path": "System/sshuttle", "completion_path": "System/sshuttle/sshuttle/methods/__init__.py", "signature_position": [103, 103], "body_position": [104, 105], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function imports a module named \"sshuttle.methods.{method_name}\" and returns an instance of the Method class from the module.", "Arguments": ":param method_name: str. The name of the method to import.\n:return: Method. An instance of the Method class from the imported module.\n```"}, "tests": ["tests/client/test_methods_nat.py::test_recv_udp", "tests/client/test_methods_nat.py::test_setup_tcp_listener", "tests/client/test_methods_nat.py::test_send_udp", "tests/client/test_methods_nat.py::test_get_tcp_dstip", "tests/client/test_methods_nat.py::test_get_supported_features"], "indent": 4}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/iam.py", "signature_position": [173, 173], "body_position": [175, 176], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of all known IAM actions. It joins the dirname of the current python script and 'known-iam-actions.txt' and return the lines in the file as a line set.", "Arguments": ":param: No input parameters.\n:return: set. A set of lines."}, "tests": ["tests/iam/known_iam_actions_test.py::test_all_iam_permissions"], "indent": 4}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/cloudtrail.py", "signature_position": [240, 240], "body_position": [242, 243], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of JSON records and converts them into Record objects. It uses the _parse_record function to parse each JSON record and then filters out any None values from the parsed records.", "Arguments": ":param json_records: List. A list of JSON records to be parsed.\n:return: List. A list of Record objects parsed from the JSON records."}, "tests": ["tests/cloudtrail/cloudtrail_test.py::test_parse_records_should_ignore_records_that_cant_be_parsed"], "indent": 4}
{"namespace": "pycoin.satoshi.IntStreamer.IntStreamer.int_to_script_bytes", "type": "method", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/IntStreamer.py", "signature_position": [31, 31], "body_position": [32, 46], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert an integer to a script byte. It first checks if the integer is 0 and returns an empty byte if true. Then, it checks if the integer is negative and converts it to a positive value. It then converts the integer to a bytearray and cast it to bytes.", "Arguments": ":param class_: A class.\n:param v: int. The integer to be converted to a script byte.\n:return: bytes. The bytes corresponding to the input integer."}, "tests": ["tests/tools_test.py::ToolsTest::test_int_to_from_script_bytes"], "indent": 8}
{"namespace": "pycoin.satoshi.stackops.do_OP_2DROP", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [33, 33], "body_position": [34, 35], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function pops the top two elements from the stack.", "Arguments": ":param stack: List. The stack from which the top two elements are removed.\n:return: No return values."}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_2DROP"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_2DUP", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [38, 39], "body_position": [40, 41], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function duplicates the top two elements of the stack and appends them to the stack, like this: (x1 x2 -- x1 x2 x1 x2)", "Arguments": ":param stack: List. The stack containing elements.\n:return: No return values."}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_2DUP"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_3DUP", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [44, 45], "body_position": [46, 48], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function duplicates the top three elements of the stack and appends them to the stack, like this: (x1 x2 x3 -- x1 x2 x3 x1 x2 x3)", "Arguments": ":param stack: List. The stack containing elements.\n:return: No return values."}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_3DUP"], "indent": 4}
{"namespace": "trailscraper.s3_download._s3_key_prefixes", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/s3_download.py", "signature_position": [22, 22], "body_position": [23, 36], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a list of S3 key prefixes based on the given parameters. It first calculates the delta between the two dates, then generates a list of dates based on the delta. It then creates a list of S3 key prefixes based on the organization IDs, account IDs, regions, and dates.", "Arguments": ":param prefix: String. The prefix for the S3 key.\n:param org_ids: List of Strings. The organization IDs.\n:param account_ids: List of Strings. The account IDs.\n:param regions: List of Strings. The regions.\n:param from_date: Datetime. The start date.\n:param to_date: Datetime. The end date.\n:return: List of Strings. The list of S3 key prefixes."}, "tests": ["tests/s3/key_prefixes_test.py::test_should_generate_prefixes_for_multiple_days", "tests/s3/key_prefixes_test.py::test_should_generate_prefixes_for_one_day", "tests/s3/key_prefixes_test.py::test_should_generate_prefixes_for_multiple_accounts_on_one_day", "tests/s3/key_prefixes_test.py::test_should_generate_prefixes_for_regions", "tests/s3/key_prefixes_test.py::test_should_generate_prefixes_for_one_day_when_datetime_contains_time"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_2OVER", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [51, 52], "body_position": [53, 54], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function duplicates the -3rd and -4th element to the top of the stack, like this: (x1 x2 x3 x4 \"top\" -- x1 x2 x3 x4 x1 x2 \"top\")", "Arguments": ":param stack: List. The stack containing the items to be duplicated.\n:return: No return values."}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_2OVER"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_2SWAP", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [63, 63], "body_position": [64, 65], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function move the third and fourth elements to the top of the stack, preserving their order.", "Arguments": ":param stack: List. The stack containing elements to be swapped.\n:return: No return values."}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_2SWAP"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_IFDUP", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [68, 68], "body_position": [69, 70], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function duplicates the top element of the stack onto the top if it is not zero.", "Arguments": ":param stack: List. The stack to be operated on.\n:return: No return values."}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_IFDUP"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_NIP", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [81, 81], "body_position": [82, 84], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes the second item from the top of the stack and keeps the top item unchanged.", "Arguments": ":param stack: List. The stack from which the items are popped and appended.\n:return: No return values."}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_NIP"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_TUCK", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [99, 99], "body_position": [100, 104], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function performs the TUCK operation on the input stack. It pops the top two elements from the stack, and then pushes them back in the reverse order, followed by the original top element.", "Arguments": ":param stack: List. The input stack on which the TUCK operation is to be performed.\n:return: No return values."}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_TUCK"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_CAT", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [107, 107], "body_position": [108, 110], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function pops the top two values from the stack, concatenates them, and pushes the result back to the stack.", "Arguments": ":param stack: List. The stack containing the values to be concatenated.\n:return: No return values."}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_CAT"], "indent": 4}
{"namespace": "pycoin.crack.ecdsa.crack_secret_exponent_from_k", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/crack/ecdsa.py", "signature_position": [2, 2], "body_position": [6, 7], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Given a signature of a signed value and a known k, this function returns the secret exponent for RSA.", "Arguments": ":param generator: The generator.\n:param signed_value: The signed value.\n:param sig: The signature.\n:param k: The known k value.\n:return: The secret exponent."}, "tests": ["tests/crack_sig_test.py::CrackSigTest::test_crack_secret_exponent_from_k"], "indent": 4}
{"namespace": "pycoin.crack.ecdsa.crack_k_from_sigs", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/crack/ecdsa.py", "signature_position": [10, 10], "body_position": [29, 34], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the value of k from the given signatures and values in RSA domain.", "Arguments": ":param generator: The generator value.\n:param sig1: The first signature.\n:param val1: The first value.\n:param sig2: The second signature.\n:param val2: The second value.\n:return: The value of k."}, "tests": ["tests/crack_sig_test.py::CrackSigTest::test_crack_k_from_sigs"], "indent": 4}
{"namespace": "pycoin.message.make_parser_and_packer.standard_streamer", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/message/make_parser_and_packer.py", "signature_position": [209, 209], "body_position": [214, 217], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a satoshi_streamer, which parses and packs using the bitcoin protocol (mostly the custom way arrays and integers are parsed and packed) through register array length parsing function and register other parsing functions.", "Arguments": ":param parsing_functions: The parsing functions to be registered with the streamer.\n:param parse_satoshi_int: The function to parse satoshi integers. Defaults to parse_satoshi_int.\n:return: Streamer. The created streamer instance."}, "tests": ["tests/message_test.py::MessageTest::test_make_parser_and_packer"], "indent": 4}
{"namespace": "pycoin.key.subpaths.subpaths_for_path_range", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/key/subpaths.py", "signature_position": [4, 4], "body_position": [16, 36], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns an iterator of paths based on the given path range. It processes the input path range like the format \"xx/xx/x-x\" and returns an iterator of paths based on the given conditions \"xx/xx/x1, xx/xx/x2\" and so on.", "Arguments": ":param path_range: String. The input path range.\n:param hardening_chars: String. The characters that indicate hardening. Defaults to \"'pH\".\n:return: Iterator. An iterator of paths based on the given path range."}, "tests": ["tests/keychain_test.py::KeychainTest::test_keychain"], "indent": 4}
{"namespace": "pyt.core.project_handler._is_python_file", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/core/project_handler.py", "signature_position": [73, 73], "body_position": [74, 76], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the given file path is a Python file by checking its file extension.", "Arguments": ":param path: String. The file path to be checked.\n:return: Bool. True if the file is a Python file, False otherwise."}, "tests": ["tests/core/project_handler_test.py::ProjectHandlerTest::test_is_python_file"], "indent": 4}
{"namespace": "pycoin.encoding.hexbytes.h2b", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/encoding/hexbytes.py", "signature_position": [4, 4], "body_position": [12, 15], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts a hexadecimal string to a binary string using the binascii.unhexlify method. It accepts a unicode string and raises a ValueError on failure.", "Arguments": ":param h: String. The hexadecimal string to be converted to binary.\n:return: Binary string. The converted binary string."}, "tests": ["tests/sign_test.py::SignTest::test_p2sh_multisig_sequential_signing", "tests/sign_test.py::SignTest::test_sign_p2sh", "tests/hexbytes.py::HexbytesTest::test_h2b", "tests/validation_test.py::ValidationTest::test_validate_block_data", "tests/tools_test.py::ToolsTest::test_tx_7e0114e93f903892b4dff5526a8cab674b2825fd715c4a95f852a1aed634a0f6"], "indent": 4}
{"namespace": "zxcvbn.scoring.calc_average_degree", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [10, 10], "body_position": [11, 17], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Calculate the average degree of a graph. It iterates through the graph and calculates the average degree based on the number of neighbors for each node.", "Arguments": ":param graph: Dictionary. The input graph represented as a dictionary where keys are nodes and values are lists of neighboring nodes.\n:return: Float. The average degree of the graph."}, "tests": ["tests/scoring_test.py::test_returns_average_degree"], "indent": 4}
{"namespace": "zxcvbn.scoring.nCk", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [29, 29], "body_position": [31, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Calculate the number of combinations of n items taken k at a time.", "Arguments": ":param n: Integer. The total number of items.\n:param k: Integer. The number of items to choose.\n:return: Integer. The number of combinations of n items taken k at a time."}, "tests": ["tests/scoring_test.py::test_uppercase_variants", "tests/scoring_test.py::test_l33t_variants", "tests/scoring_test.py::test_nCk", "tests/scoring_test.py::test_spatial_guesses"], "indent": 4}
{"namespace": "zxcvbn.matching.relevant_l33t_subtable", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [134, 134], "body_position": [135, 145], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a subtable based on the given password and table. It first creates a dictionary of characters in the password and then creates a subtable based on the relevant substitutions in the table.", "Arguments": ":param password: String. The password to be used for creating the subtable.\n:param table: Dictionary. The table containing the substitutions for each letter.\n:return: Dictionary. The created subtable."}, "tests": ["tests/matching_test.py::test_l33t_matching"], "indent": 4}
{"namespace": "zxcvbn.matching.translate", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [204, 204], "body_position": [205, 212], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Translate the input string based on the given character map. It replaces the characters in the input string with the corresponding values from the character map. The output format is splitted by the space.", "Arguments": ":param string: String. The input string to be translated.\n:param chr_map: Dictionary. The character map containing the mapping of characters to their corresponding values.\n:return: String. The translated string."}, "tests": ["tests/matching_test.py::test_matching_utils"], "indent": 4}
{"namespace": "tools.cgrep.get_nets", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [380, 380], "body_position": [390, 394], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a list of all networks that are inside a network object. It iterates through the input network objects, retrieves the networks inside each object from the network and service definitions, and returns the results.", "Arguments": ":param objects: network objects. List of network objects for which the networks need to be retrieved.\n:param db: network and service definitions. The database containing network and service definitions.\n:return: List. List of tuples containing the network object and the corresponding network inside it."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_token_to_ips", "tests/lib/cgrep_test.py::CgrepTest::test_token_to_ip_fail"], "indent": 2}
{"namespace": "tools.cgrep.get_ports", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [447, 447], "body_position": [458, 462], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function gets the ports and protocols defined in a service group. It iterates through each service in the service group and retrieves the corresponding port and protocol from the network and service definitions.", "Arguments": ":param svc_group: List of strings. A list of strings for each service group.\n:param db: Network and service definitions.\n:return: List of tuples. A list of tuples for each service defined, in the format: (service name, \"<port>/<protocol>\")."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_svc_to_port_fail", "tests/lib/cgrep_test.py::CgrepTest::test_svc_to_port"], "indent": 2}
{"namespace": "tools.cgrep.compare_ip_token", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [426, 426], "body_position": [436, 444], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if a network IP is contained in a network object. It iterates through the list of IPs and checks if each IP is in the network object. It then returns a string stating the results.", "Arguments": ":param options: The options sent to the script.\n:param db: Network and service definitions.\n:return: String. The end-user string stating the results."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_ip_in_token", "tests/lib/cgrep_test.py::CgrepTest::test_ipv6_in_token", "tests/lib/cgrep_test.py::CgrepTest::test_ipv6_in_token_fail", "tests/lib/cgrep_test.py::CgrepTest::test_ip_in_token_fail"], "indent": 2}
{"namespace": "tools.cgrep.get_services", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [465, 465], "body_position": [476, 482], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function finds any services that include a specific port/protocol pair. It retrieves the port and protocol from the options and then searches the network and service definitions to find services containing this pair.", "Arguments": ":param options: The options sent to the script.\n:param db: Network and service definitions.\n:return: Tuple. The port, protocol, and a list of services containing this pair."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_get_port_parents_range_udp", "tests/lib/cgrep_test.py::CgrepTest::test_get_port_parents", "tests/lib/cgrep_test.py::CgrepTest::test_get_port_parents_fail", "tests/lib/cgrep_test.py::CgrepTest::test_get_port_parents_range_tcp"], "indent": 2}
{"namespace": "asyncssh.packet.String", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/packet.py", "signature_position": [67, 67], "body_position": [70, 73], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function encodes a byte string or UTF-8 string value. It first checks if the input value is a string, then encodes it to UTF-8. It then returns the length of the value in bytes followed by the value itself.", "Arguments": ":param value: Union[bytes, str]. The input value to be encoded, which can be either a byte string or a UTF-8 string.\n:return: bytes. The encoded byte string value."}, "tests": ["tests/test_agent.py::_TestAgent::test_get_sk_keys", "tests/test_agent.py::_TestAgent::test_query_extensions", "tests/test_packet.py::_TestPacket::test_unicode"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.laplace_smooth.laplace_smooth_value_counts", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/laplace_smooth.py", "signature_position": [102, 107], "body_position": [132, 142], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Apply laplace smoothing to the input counts for the values. It adds 1 to each of the counts, including the unk_token. By including the unk_token, it can handle unseen values. It smooths individual value counts (value_counts) and value conditional on parameter counts (param_value_counts).", "Arguments": ":param params: List of string. List of all possible params, including the unk_token.\n:param value_counts: DefaultDict of string and integer. Individual value counts.\n:param param_value_counts: DefaultDict of string and DefaultDict of string and integer. Value conditional on param counts.\n:param unk_token: String. Dummy command to signify an unseen command (e.g. \"##UNK##\").\n:return: Tuple of DefaultDict of string and integer, DefaultDict of string and DefaultDict of string and integer. Individual value probabilities, value conditional on param probabilities."}, "tests": ["tests/analysis/test_anom_seq_laplace_smooth.py::TestLaplaceSmooth::test_laplace_smooth_value_counts"], "indent": 4}
{"namespace": "diffprivlib.validation.check_epsilon_delta", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/validation.py", "signature_position": [28, 28], "body_position": [47, 57], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the epsilon and delta are valid values for differential privacy. It raises errors including \"Epsilon and delta must be numeric\", \"Epsilon must be non-negative\",\"Delta must be in [0, 1]\",\"Epsilon and Delta cannot both be zero\" if the checks fail. It also checks that both epsilon and delta cannot be simultaneously zero unless allow_zero is set to True.", "Arguments": ":param epsilon: float. Epsilon parameter for differential privacy. Must be non-negative.\n:param delta: float. Delta parameter for differential privacy. Must be on the unit interval, [0, 1].\n:param allow_zero: bool, default: False. Allow epsilon and delta both be zero.\n:return: No return value."}, "tests": ["tests/test_check_epsilon_delta.py::TestCheckEpsilonDelta::test_real_inputs", "tests/test_check_epsilon_delta.py::TestCheckEpsilonDelta::test_wrong_delta", "tests/test_check_epsilon_delta.py::TestCheckEpsilonDelta::test_all_zero", "tests/test_check_epsilon_delta.py::TestCheckEpsilonDelta::test_neg_eps"], "indent": 4}
{"namespace": "diffprivlib.utils.check_random_state", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/utils.py", "signature_position": [75, 75], "body_position": [93, 102], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function turns the seed into a np.random.RandomState or secrets.SystemRandom instance based on the given condition. If seed is None and secure is False, return the RandomState singleton used by np.random. If seed is None and secure is True, return a SystemRandom instance from secrets. If seed is an int, return a new RandomState instance seeded with seed. If seed is already a RandomState or SystemRandom instance, return it. Otherwise raise ValueError.", "Arguments": ":param seed : None, int or instance of RandomState.\n:param secure : bool, default: False. Specifies if a secure random number generator from secrets can be used.\n:return: np.random.RandomState or secrets.SystemRandom instance."}, "tests": ["tests/test_check_random_state.py::TestCheckRandomState::test_not_secure", "tests/models/test_GaussianNB.py::TestGaussianNB::test_noisy_count", "tests/models/test_GaussianNB.py::TestGaussianNB::test_missing_bounds", "tests/models/test_GaussianNB.py::TestGaussianNB::test_different_results", "tests/test_check_random_state.py::TestCheckRandomState::test_secure"], "indent": 4}
{"namespace": "diffprivlib.validation.clip_to_norm", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/validation.py", "signature_position": [135, 135], "body_position": [152, 164], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function clips the examples of a 2-dimensional array to a given maximum norm. After clipping, all examples have a 2-norm of at most `clip`. It raises errors including \"Input array must be a numpy array, got {type(array)}.\", \"input array must be 2-dimensional, got {array.ndim} dimensions.\", \"Clip value must be numeric, got {type(clip)}.\" and \"Clip value must be strictly positive, got {clip}.\".", "Arguments": ":param array: np.ndarray. Array to be clipped.\n:param clip: float. Norm at which to clip each example.\n:return: np.ndarray. The clipped array."}, "tests": ["tests/test_clip_to_norm.py::TestClipToNorm::test_simple", "tests/test_clip_to_norm.py::TestClipToNorm::test_iris", "tests/test_clip_to_norm.py::TestClipToNorm::test_incorrect_parameterisation"], "indent": 4}
{"namespace": "diffprivlib.models.pca.PCA.fit_transform", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/pca.py", "signature_position": [283, 283], "body_position": [284, 288], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "It fits the model with the input data and then applies the dimensionality reduction on it.", "Arguments": ":param self: PCA. An instance of the PCA class.\n:param X: Array-like. The input data.\n:param y: Array-like. The target variable. Defaults to None.\n:return: Array-like. The transformed data."}, "tests": ["tests/models/test_PCA.py::TestPCA::test_fit_transform"], "indent": 8}
{"namespace": "discord.utils.get_slots", "type": "function", "project_path": "Software-Development/discord-py", "completion_path": "Software-Development/discord-py/discord/utils.py", "signature_position": [721, 721], "body_position": [722, 726], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns an iterator that yields the names of the slots in the class and its base classes. It iterates through the class hierarchy and yields the slots of each class.", "Arguments": ":param cls: Type. The class for which the slots are to be retrieved.\n:return: Iterator. An iterator that yields the names of the slots in the class and its base classes."}, "tests": ["tests/test_utils.py::test_get_slots"], "indent": 4}
{"namespace": "discord.utils.is_inside_class", "type": "function", "project_path": "Software-Development/discord-py", "completion_path": "Software-Development/discord-py/discord/utils.py", "signature_position": [1178, 1186], "body_position": [1187, 1190], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Determine whether a given callable (function or method) is defined within a class. It checks the __qualname__ attribute of the callable to analyze the dotted path that denotes its qualified name, considering the possibility of nested functions.", "Arguments": ":param func: Callable. The function to be checked.\n:return: Bool. True if the function is defined inside a class, False otherwise."}, "tests": ["tests/test_utils.py::test_is_inside_class"], "indent": 4}
{"namespace": "faker.utils.decorators.slugify", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/decorators.py", "signature_position": [9, 10], "body_position": [11, 14], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that takes a function and returns a new function. The new function calls the original function and then slugifies the result.", "Arguments": ":param fn: Callable. The original function to be decorated.\n:return: Callable. The decorated function."}, "tests": ["tests/test_factory.py::FactoryTestCase::test_slugify"], "indent": 4}
{"namespace": "faker.utils.decorators.slugify_domain", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/decorators.py", "signature_position": [17, 18], "body_position": [19, 22], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that takes a function and returns a new function. The new function calls the original function and then slugifies the result using the `text.slugify` function with the `allow_dots` parameter set to True.", "Arguments": ":param fn: Callable. The original function to be decorated.\n:return: Callable. The decorated function."}, "tests": ["tests/test_factory.py::FactoryTestCase::test_slugify"], "indent": 4}
{"namespace": "faker.utils.decorators.slugify_unicode", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/decorators.py", "signature_position": [25, 26], "body_position": [27, 30], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that wraps the input function and returns a new function. The new function slugifies the output of the input function and returns the slugified string.", "Arguments": ":param fn: Callable. The input function to be wrapped and modified.\n:return: Callable. The wrapper function that slugifies the output of the input function."}, "tests": ["tests/test_factory.py::FactoryTestCase::test_slugify"], "indent": 4}
{"namespace": "faker.utils.loading.get_path", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/loading.py", "signature_position": [10, 10], "body_position": [11, 28], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Get the path of the given module. It first checks if the system is frozen. If it is, it checks if it is frozen by PyInstaller or others and then returns the path accordingly. If the system is not frozen, it returns the path of the module. If the file is None, it raises RuntimeError(f\"Can't find path from module `{module}.\").", "Arguments": ":param module: ModuleType. The module for which the path is to be found.\n:return: str. The path of the given module."}, "tests": ["tests/utils/test_utils.py::UtilsTestCase::test_get_path"], "indent": 4}
{"namespace": "faker.utils.checksums.luhn_checksum", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/checksums.py", "signature_position": [4, 4], "body_position": [5, 15], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Calculate the Luhn checksum for the given number. The Luhn algorithm is used to validate a variety of identification numbers, such as credit card numbers, IMEI numbers, National Provider Identifier numbers in the United States, and Canadian Social Insurance Numbers.", "Arguments": ":param number: float. The number for which the Luhn checksum needs to be calculated.\n:return: int. The Luhn checksum for the given number."}, "tests": ["tests/providers/test_company.py::TestFrFr::test_siret", "tests/utils/test_utils.py::UtilsTestCase::test_valid_luhn", "tests/providers/test_company.py::TestFrFr::test_siren"], "indent": 4}
{"namespace": "faker.utils.datasets.add_ordereddicts", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/datasets.py", "signature_position": [6, 6], "body_position": [7, 8], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes multiple ordered dictionaries and combines them into a single ordered dictionary. It first extracts the items from each input ordered dictionary and then combines them into a single ordered dictionary.", "Arguments": ":param odicts: OrderedDictType. Multiple ordered dictionaries to be combined.\n:return: OrderedDictType. The combined ordered dictionary."}, "tests": ["tests/utils/test_utils.py::UtilsTestCase::test_add_ordereddicts"], "indent": 4}
{"namespace": "faker.providers.person.pl_PL.checksum_identity_card_number", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/providers/person/pl_PL/__init__.py", "signature_position": [7, 7], "body_position": [11, 16], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates and returns a control digit for a given list of characters based on the Identity Card Number standards. This control digit is often used for error checking and validation of identity card numbers. The weights for check digits is [7, 3, 1, 0, 7, 3, 1, 7, 3].", "Arguments": ":param characters: Sequence of Union of string and integer. A list of characters for which the control digit is to be calculated.\n:return: Integer. The calculated control digit."}, "tests": ["tests/providers/test_person.py::TestPlPL::test_identity_card_number_checksum"], "indent": 4}
{"namespace": "faker.providers.company.pl_PL.regon_checksum", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/providers/company/pl_PL/__init__.py", "signature_position": [6, 6], "body_position": [10, 21], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates and returns a control digit for a given list of digits based on the REGON standard. Ths weights for check digits is [8, 9, 2, 3, 4, 5, 6, 7].", "Arguments": ":param digits: List of integers. The list of digits for which the control digit is to be calculated.\n:return: Integer. The calculated control digit."}, "tests": ["tests/providers/test_company.py::TestPlPl::test_regon_checksum"], "indent": 4}
{"namespace": "faker.providers.company.ru_RU.calculate_checksum", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/providers/company/ru_RU/__init__.py", "signature_position": [6, 6], "body_position": [7, 12], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "The function is designed to compute a checksum for a given string value based on a specific set of factors. This type of checksum is commonly used in various applications, including identification numbers. The function defines a list of factors [3, 7, 2, 4, 10, 3, 5, 9, 4, 6, 8].", "Arguments": ":param value: String. The input value for which the checksum needs to be calculated.\n:return: String. The calculated checksum value."}, "tests": ["tests/providers/test_company.py::TestRuRu::test_individuals_inn", "tests/providers/test_company.py::TestRuRu::test_calculate_checksum_nine_digits", "tests/providers/test_company.py::TestRuRu::test_businesses_inn"], "indent": 4}
{"namespace": "faker.providers.company.pl_PL.local_regon_checksum", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/providers/company/pl_PL/__init__.py", "signature_position": [24, 24], "body_position": [28, 39], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates and returns a control digit for a given list of digits based on the local REGON standard. Ths weights for check digits is [2, 4, 8, 5, 0, 9, 7, 3, 6, 1, 2, 4, 8].", "Arguments": ":param digits: List of integers. The list of digits for which the control digit is to be calculated.\n:return: Integer. The calculated control digit."}, "tests": ["tests/providers/test_company.py::TestPlPl::test_local_regon_checksum"], "indent": 4}
{"namespace": "faker.providers.company.pl_PL.company_vat_checksum", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/providers/company/pl_PL/__init__.py", "signature_position": [42, 42], "body_position": [46, 54], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates and returns a control digit for a given list of digits based on the NIP standard. The weights of check digits is [6, 5, 7, 2, 3, 4, 5, 6, 7].", "Arguments": ":param digits: List of integers. The list of digits for which the control digit needs to be calculated.\n:return: Integer. The calculated control digit."}, "tests": ["tests/providers/test_company.py::TestPlPl::test_company_vat_checksum"], "indent": 4}
{"namespace": "faker.providers.company.pt_BR.company_id_checksum", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/providers/company/pt_BR/__init__.py", "signature_position": [6, 6], "body_position": [7, 20], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Calculate the checksum of the company ID based on the given digits. It first calculates the checksum based on the weights and digits, and then appends the calculated checksum to the input digits. The weights of check digits is [6, 5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2].", "Arguments": ":param digits: List of integers. The list of digits representing the company ID.\n:return: List of integers. The calculated checksum digits."}, "tests": ["tests/providers/test_company.py::TestPtBr::test_company_id_checksum"], "indent": 4}
{"namespace": "faker.providers.misc.Provider.binary", "type": "method", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/providers/misc/__init__.py", "signature_position": [43, 43], "body_position": [52, 57], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Generate a random binary blob of the specified length. If the faker instance has been seeded, the performance will be significantly reduced to conform to the seeding.", "Arguments": ":param self: Provider. An instance of the Provider class.\n:param length: int. The length of the binary blob to be generated. Defaults to 1 * 1024 * 1024.\n:return: bytes. The generated random binary blob."}, "tests": ["tests/test_factory.py::FactoryTestCase::test_binary"], "indent": 8}
{"namespace": "faker.providers.python.Provider.pystr", "type": "method", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/providers/python/__init__.py", "signature_position": [105, 111], "body_position": [121, 131], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a random string of upper and lowercase letters. It can generate a random string of a specific length between the minimum and maximum length. It can also add a prefix and suffix to the random string.", "Arguments": ":param self: Provider. An instance of the Provider class.\n:param min_chars: Optional integer. The minimum length of the random part. Defaults to None.\n:param max_chars: Integer. The maximum length of the random part. Defaults to 20.\n:param prefix: String. An optional prefix to prepend to the random string. Defaults to an empty string.\n:param suffix: String. An optional suffix to append to the random string. Defaults to an empty string.\n:return: String. Random of random length between min and max characters."}, "tests": ["tests/test_factory.py::FactoryTestCase::test_random_pystr_characters"], "indent": 8}
{"namespace": "dash._utils.AttributeDict.set_read_only", "type": "method", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_utils.py", "signature_position": [92, 92], "body_position": [99, 103], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function designates named attributes as read-only with the corresponding message. It is an additive method, which means that making additional calls to this method will update existing messages and add to the current set of _read_only names.", "Arguments": ":param self: AttributeDict. An instance of the AttributeDict class.\n:param names: List of strings. The names of the attributes to be designated as read-only.\n:param msg: String. The message to be associated with the read-only attribute. Defaults to \"Attribute is read-only\".\n:return: No return value."}, "tests": ["tests/unit/library/test_utils.py::test_ddut001_attribute_dict"], "indent": 8}
{"namespace": "dash._utils.AttributeDict.first", "type": "method", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_utils.py", "signature_position": [125, 125], "body_position": [126, 131], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the first non-empty value from the given list of names. If no names are provided, it returns the first value from the instance.", "Arguments": ":param self: AttributeDict. An instance of the AttributeDict class.\n:param names: String. A list of names to search for in the instance.\n:return: The first non-empty value from the list of names or the first value from the instance."}, "tests": ["tests/unit/library/test_utils.py::test_ddut001_attribute_dict"], "indent": 8}
{"namespace": "dash._get_paths.app_get_asset_url", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_get_paths.py", "signature_position": [11, 11], "body_position": [12, 23], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the URL of the asset based on the given configuration and path. It first checks if the assets_external_path is set, if not, it uses requests_pathname_prefix. Then, it constructs the URL based on the configuration and path.", "Arguments": ":param config: Configuration. The configuration object.\n:param path: String. The path of the asset.\n:return: String. The URL of the asset."}, "tests": ["tests/unit/test_configs.py::test_pathname_prefix_assets"], "indent": 4}
{"namespace": "peewee.sort_models", "type": "function", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/peewee.py", "signature_position": [7058, 7058], "body_position": [7059, 7078], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Sort the given models based on their dependencies. It uses a depth-first search to sort the models based on their dependencies and returns the sorted list of models.", "Arguments": ":param models: List. A list of model instances to be sorted.\n:return: List. The sorted list of model instances based on their dependencies."}, "tests": ["tests/models.py::TestModelAPIs::test_deferred_fk_dependency_graph", "tests/db_tests.py::TestSortModels::test_sort_models"], "indent": 4}
{"namespace": "dash._grouping.grouping_len", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_grouping.py", "signature_position": [50, 50], "body_position": [59, 65], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "The function calculates the length of a grouping. The length is equal to the number of scalar values contained in the grouping, which is equivalent to the length of the list that would result from calling flatten_grouping on the grouping value.", "Arguments": ":param grouping: The grouping value to calculate the length of\n:return: non-negative integer"}, "tests": ["tests/unit/library/test_grouping.py::test_flatten_dict", "tests/unit/library/test_grouping.py::test_flatten_scalar", "tests/unit/library/test_grouping.py::test_flatten_dict_key_order", "tests/unit/library/test_grouping.py::test_flatten_list", "tests/unit/library/test_grouping.py::test_flatten_mixed"], "indent": 4}
{"namespace": "playhouse.kv.KeyValue.get", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/kv.py", "signature_position": [150, 150], "body_position": [151, 154], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Get the value of the given key in the KeyValue instance. If the key is not found, return the default value.", "Arguments": ":param self: KeyValue. An instance of the KeyValue class.\n:param key: The key to retrieve the value from the instance.\n:param default: The value to return if the key is not found in the instance. Defaults to None.\n:return: The value corresponding to the key or the default value if the key is not found."}, "tests": ["tests/kv.py::TestKeyValue::test_basic_apis"], "indent": 8}
{"namespace": "playhouse.kv.KeyValue.setdefault", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/kv.py", "signature_position": [156, 156], "body_position": [157, 161], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set the default value for the key in the KeyValue instance. If the key is not found, it sets the default value for the key and returns it.", "Arguments": ":param self: KeyValue. An instance of the KeyValue class.\n:param key: The key to set the default value.\n:param default: The default value to set for the key. Defaults to None.\n:return: The value corresponding to the key."}, "tests": ["tests/kv.py::TestKeyValue::test_basic_apis"], "indent": 8}
{"namespace": "sslyze.plugins.certificate_info._certificate_utils.get_public_key_sha256", "type": "function", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/certificate_info/_certificate_utils.py", "signature_position": [54, 54], "body_position": [55, 57], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "It returns the SHA-256 hash of the public key in the given certificate.", "Arguments": ":param certificate: Certificate. The input certificate from which the public key is extracted.\n:return: bytes. The SHA-256 hash of the public key."}, "tests": ["tests/plugins_tests/certificate_info/test_certificate_utils.py::TestCertificateUtils::test_get_public_key_sha256"], "indent": 4}
{"namespace": "ydata_profiling.report.formatters.fmt_bytesize", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/report/formatters.py", "signature_position": [61, 61], "body_position": [71, 75], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts a number of bytes into a human-readable format. It iteratively divides the input number by 1024 and appends the appropriate unit (e.g., KiB, MiB, GiB) until the absolute value of the number is less than 1024.", "Arguments": ":param num: float. The number of bytes to format.\n:param suffix: str. The suffix to be appended to the formatted value. Defaults to \"B\".\n:return: str. The formatted value in a human-readable format."}, "tests": ["tests/unit/test_formatters.py::test_fmt_bytesize"], "indent": 4}
{"namespace": "ydata_profiling.report.formatters.fmt_percent", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/report/formatters.py", "signature_position": [79, 79], "body_position": [89, 94], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Format a ratio as a percentage. It checks for edge cases and returns the percentage with 1 point precision.", "Arguments": ":param value: Float. The ratio to be formatted as a percentage.\n:param edge_cases: Bool. Whether to check for edge cases. Defaults to True.\n:return: String. The formatted percentage with 1 point precision."}, "tests": ["tests/issues/test_issue215.py::test_issue215"], "indent": 4}
{"namespace": "ydata_profiling.report.formatters.fmt_numeric", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/report/formatters.py", "signature_position": [237, 237], "body_position": [247, 255], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Format any numeric value with the given precision.", "Arguments": ":param value: float. The numeric value to format.\n:param precision: int. The numeric precision. It defaults to 10 if not specified.\n:return: str. The numeric value with the given precision."}, "tests": ["tests/unit/test_formatters.py::test_fmt_numeric"], "indent": 4}
{"namespace": "ydata_profiling.report.formatters.fmt_array", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/report/formatters.py", "signature_position": [272, 272], "body_position": [282, 285], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function formats numpy arrays. It sets the threshold at which to show ellipsis and returns the string representation of the numpy array.", "Arguments": ":param value: np.ndarray. The array to format.\n:param threshold: Any. The threshold at which to show ellipsis. Defaults to np.nan.\n:return: str. The string representation of the numpy array."}, "tests": ["tests/unit/test_formatters.py::test_fmt_array"], "indent": 4}
{"namespace": "ydata_profiling.report.formatters.fmt_monotonic", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/report/formatters.py", "signature_position": [305, 305], "body_position": [306, 317], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string based on the input value. The string returned is based on the value of the input integer.", "Arguments": ":param value: int. The input integer value.\n:return: str. The string based on the input value."}, "tests": ["tests/unit/test_formatters.py::test_fmt_monotonic", "tests/unit/test_formatters.py::test_fmt_monotonic_err"], "indent": 4}
{"namespace": "ydata_profiling.visualisation.plot._plot_pie_chart", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/visualisation/plot.py", "signature_position": [429, 431], "body_position": [445, 471], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function plots a pie chart to show category frequency based on the input data. It also allows the user to specify the colors and whether to hide the legend.", "Arguments": ":param data: pd.Series. Category frequencies with category names as index.\n:param colors: List. List of colors in a valid matplotlib format.\n:param hide_legend: Bool. If true, the legend is omitted. Defaults to False.\n:return: Tuple[plt.Axes, matplotlib.legend.Legend]. The pie chart and legend handler."}, "tests": ["tests/unit/test_plot.py::test_plot_pie_chart"], "indent": 4}
{"namespace": "ydata_profiling.visualisation.plot._prepare_heatmap_data", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/visualisation/plot.py", "signature_position": [802, 808], "body_position": [809, 842], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Prepare the data for a heatmap based on the given conditions. It processes the input dataframe and returns a new dataframe that is suitable for creating a heatmap.", "Arguments": ":param dataframe: pd.DataFrame. The input dataframe containing the data.\n:param entity_column: str. The name of the column containing the entities.\n:param sortby: Optional. Union[str, list]. The column or list of columns to sort by. Defaults to None.\n:param max_entities: int. The maximum number of entities to include in the heatmap. Defaults to 5.\n:param selected_entities: Optional. List of str. The list of selected entities to include in the heatmap. Defaults to None.\n:return: pd.DataFrame. The prepared dataframe for creating a heatmap.\n```"}, "tests": ["tests/unit/test_plot.py::test_timeseries_heatmap"], "indent": 4}
{"namespace": "ydata_profiling.visualisation.plot._create_timeseries_heatmap", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/visualisation/plot.py", "signature_position": [845, 849], "body_position": [850, 861], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a timeseries heatmap based on the given dataframe. It creates a heatmap with the specified color and size and returns the axes object.", "Arguments": ":param df: pd.DataFrame. The input dataframe for creating the heatmap.\n:param figsize: Tuple[int, int]. The size of the figure. Defaults to (12, 5).\n:param color: str. The color to be used for the heatmap. Defaults to \"#337ab7\".\n:return: plt.Axes. The axes object representing the created heatmap."}, "tests": ["tests/unit/test_plot.py::test_timeseries_heatmap"], "indent": 4}
{"namespace": "ydata_profiling.model.expectation_algorithms.generic_expectations", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/model/expectation_algorithms.py", "signature_position": [4, 6], "body_position": [7, 15], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function defines generic expectations for a given column in a batch. It checks if the column exists, if there are any missing values, and if all values are unique.", "Arguments": ":param name: str. The name of the column to be checked.\n:param summary: dict. A summary of the column statistics.\n:param batch: Any. The batch of data to be checked.\n:param *args: Additional arguments.\n:return: Tuple. A tuple containing the name of the column, its summary, and the batch."}, "tests": ["tests/unit/test_ge_integration_expectations.py::test_generic_expectations_min", "tests/unit/test_ge_integration_expectations.py::test_generic_expectations"], "indent": 4}
{"namespace": "ydata_profiling.model.expectation_algorithms.numeric_expectations", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/model/expectation_algorithms.py", "signature_position": [18, 20], "body_position": [21, 55], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "It checks the numeric expectations of the given batch and returns the name, summary, and batch.", "Arguments": ":param name: str. The name of the column.\n:param summary: dict. The summary of the column.\n:param batch: Any. The batch of data to be checked.\n:param *args: Any. Additional arguments.\n:return: Tuple[str, dict, Any]. The name, summary, and batch.\n```"}, "tests": ["tests/unit/test_ge_integration_expectations.py::test_numeric_expectations_min", "tests/unit/test_ge_integration_expectations.py::test_numeric_expectations"], "indent": 4}
{"namespace": "ydata_profiling.model.expectation_algorithms.categorical_expectations", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/model/expectation_algorithms.py", "signature_position": [58, 61], "body_position": [62, 71], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check the categorical expectations for the given batch and summary. It checks if the number of distinct values and the percentage of distinct values are below the threshold. If so, it expects the column values to be in the set of value counts without NaN.", "Arguments": ":param name: str. The name of the column.\n:param summary: dict. The summary of the column.\n:param batch: Any. The batch of data to be checked.\n:param *args: Any. Additional arguments.\n:return: Tuple[str, dict, Any]. The name, summary, and batch.\n```"}, "tests": ["tests/unit/test_ge_integration_expectations.py::test_categorical_expectations"], "indent": 4}
{"namespace": "ydata_profiling.model.expectation_algorithms.datetime_expectations", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/model/expectation_algorithms.py", "signature_position": [80, 82], "body_position": [83, 91], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets the expectations for the datetime values in the batch based on the summary. It checks if the \"min\" and \"max\" keys are present in the summary and then sets the corresponding expectations for the datetime values in the batch.", "Arguments": ":param name: str. The name of the column for which the expectations are set.\n:param summary: dict. A dictionary containing the summary of the column.\n:param batch: Any. The batch of data for which the expectations are set.\n:param *args: Additional positional arguments.\n:return: Tuple. A tuple containing the name of the column, the summary, and the batch with expectations set."}, "tests": ["tests/unit/test_ge_integration_expectations.py::test_datetime_expectations"], "indent": 4}
{"namespace": "ydata_profiling.model.expectation_algorithms.file_expectations", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/model/expectation_algorithms.py", "signature_position": [106, 109], "body_position": [110, 112], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if a file exists and returns the name, summary, and batch.", "Arguments": ":param name: str. The name of the file.\n:param summary: dict. The summary of the file.\n:param batch: Any. The batch of the file.\n:param *args: Any. Additional arguments.\n:return: Tuple[str, dict, Any]. The name, summary, and batch of the file."}, "tests": ["tests/unit/test_ge_integration_expectations.py::test_file_expectations"], "indent": 4}
{"namespace": "ydata_profiling.model.pandas.describe_categorical_pandas.word_summary_vc", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/model/pandas/describe_categorical_pandas.py", "signature_position": [154, 154], "body_position": [172, 186], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Count the number of occurrences of each individual word across all lines of the data Series, then sort from the word with the most occurrences to the word with the least occurrences. If a list of stop words is given, they will be ignored.", "Arguments": ":param vc: Series containing all unique categories as index and their frequency as value. Sorted from the most frequent down.\n:param stop_words: List of stop words to ignore, empty by default.\n:return: A dict containing the results as a Series with unique words as index and the computed frequency as value"}, "tests": ["tests/unit/test_pandas/test_describe_categorical_pandas.py::test_word_summary_vc", "tests/unit/test_pandas/test_describe_categorical_pandas.py::test_word_summary_vc_with_stop_words"], "indent": 4}
{"namespace": "ydata_profiling.model.pandas.imbalance_pandas.column_imbalance_score", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/model/pandas/imbalance_pandas.py", "signature_position": [8, 10], "body_position": [30, 35], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the class balance score for categorical and boolean variables using entropy to calculate a bounded score between 0 and 1. A perfectly uniform distribution would return a score of 0, and a perfectly imbalanced distribution would return a score of 1.", "Arguments": ":param value_counts: pd.Series. Frequency of each category.\n:param n_classes: int. Number of classes.\n:return: Union[float, int]. Float or integer bounded between 0 and 1 inclusively."}, "tests": ["tests/unit/test_pandas/test_imbalance.py::test_column_imbalance_score_many_classes", "tests/unit/test_pandas/test_imbalance.py::test_column_imbalance_score_one_class", "tests/unit/test_pandas/test_imbalance.py::test_column_imbalance_score_uniform_distribution"], "indent": 4}
{"namespace": "django.core.exceptions.ValidationError.messages", "type": "method", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/core/exceptions.py", "signature_position": [188, 188], "body_position": [189, 191], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the error messages. If the error_dict attribute exists, it returns the sum of the values of the error dictionary. Otherwise, it returns the list of errors.", "Arguments": ":param self: ValidationError. An instance of the ValidationError class.\n:return: List. The list of error messages."}, "tests": ["tests/test_exceptions/test_validation_error.py::TestValidationError::test_messages_concatenates_error_dict_values"], "indent": 8}
{"namespace": "django.utils.module_loading.module_has_submodule", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/utils/module_loading.py", "signature_position": [74, 74], "body_position": [76, 89], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the given module is in the package. It first checks if the package is a valid package and then tries to import the module. If the module is found, it returns True; otherwise, it returns False.", "Arguments": ":param package: The package to check.\n:param module_name: The name of the module to check.\n:return: Boolean. True if the module is found in the package; otherwise, False."}, "tests": ["tests/utils_tests/test_module_loading.py::EggLoader::test_deep_loader", "tests/utils_tests/test_module_loading.py::DefaultLoader::test_has_sumbodule_with_dotted_path", "tests/utils_tests/test_module_loading.py::EggLoader::test_shallow_loader", "tests/utils_tests/test_module_loading.py::DefaultLoader::test_loader"], "indent": 4}
{"namespace": "django.utils.timezone.get_fixed_timezone", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/utils/timezone.py", "signature_position": [59, 59], "body_position": [61, 66], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a tzinfo instance with a fixed offset from UTC. It first checks if the offset is an instance of timedelta and converts it to minutes if it is. Then, it creates a timezone instance with the given offset and name.", "Arguments": ":param offset: The offset from UTC. It can be an integer or a timedelta object.\n:return: timezone. The created timezone instance."}, "tests": ["tests/utils_tests/test_dateparse.py::DateParseTests::test_parse_datetime"], "indent": 4}
{"namespace": "django.utils.encoding.filepath_to_uri", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/utils/encoding.py", "signature_position": [236, 236], "body_position": [244, 248], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts a file system path to a URI portion that can be included in a URL. It encodes certain characters that would normally be recognized as special characters for URIs. It does not encode the ' character, as it is a valid character within URIs.", "Arguments": ":param path: String. The file system path to be converted to a URI.\n:return: String. The URI portion suitable for inclusion in a URL."}, "tests": ["tests/utils_tests/test_encoding.py::TestRFC3987IEncodingUtils::test_filepath_to_uri"], "indent": 4}
{"namespace": "django.utils._os.to_path", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/utils/_os.py", "signature_position": [56, 56], "body_position": [58, 62], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the input value to a pathlib.Path instance if it is not already a Path. If the input value is a string, it creates a Path instance with the string value.", "Arguments": ":param value: Any. The value to be converted to a Path instance.\n:return: Path. The converted Path instance."}, "tests": ["tests/utils_tests/test_os_utils.py::ToPathTests::test_to_path_invalid_value", "tests/utils_tests/test_os_utils.py::ToPathTests::test_to_path"], "indent": 4}
{"namespace": "django.utils.lorem_ipsum.sentence", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/utils/lorem_ipsum.py", "signature_position": [225, 225], "body_position": [234, 240], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a random sentence of lorem ipsum text. The first word is capitalized, and the sentence ends in either a period or question mark. Commas are added at random.", "Arguments": ":param: No input parameters.\n:return: String. A randomly generated sentence of lorem ipsum text."}, "tests": ["tests/utils_tests/test_lorem_ipsum.py::LoremIpsumTests::test_sentence_ending", "tests/utils_tests/test_lorem_ipsum.py::LoremIpsumTests::test_sentence_starts_with_capital", "tests/utils_tests/test_lorem_ipsum.py::LoremIpsumTests::test_sentence"], "indent": 4}
{"namespace": "ydata_profiling.utils.dataframe.sort_column_names", "type": "function", "project_path": "Software-Development/ydata-profiling", "completion_path": "Software-Development/ydata-profiling/src/ydata_profiling/utils/dataframe.py", "signature_position": [227, 227], "body_position": [228, 238], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Sort the column names of the given dictionary in ascending or descending order based on the input parameter. If the sort parameter is None, the original dictionary is returned.", "Arguments": ":param dct: Dict. The input dictionary to be sorted.\n:param sort: Optional string. The sorting order. It can be \"ascending\", \"descending\" or None.\n:return: Dict. The sorted dictionary."}, "tests": ["tests/unit/test_sort.py::test_ascending", "tests/unit/test_sort.py::test_descending", "tests/unit/test_sort.py::test_none"], "indent": 4}
{"namespace": "django.utils.ipv6.is_valid_ipv6_address", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/utils/ipv6.py", "signature_position": [39, 39], "body_position": [43, 47], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the given string is a valid IPv6 address.", "Arguments": ":param ip_str: String. The input string to be checked.\n:return: Bool. True if the input string is a valid IPv6 address, False otherwise."}, "tests": ["tests/utils_tests/test_ipv6.py::TestUtilsIPv6::test_validates_correct_plain_address", "tests/utils_tests/test_ipv6.py::TestUtilsIPv6::test_validates_correct_with_v4mapping", "tests/utils_tests/test_ipv6.py::TestUtilsIPv6::test_validates_incorrect_with_v4mapping"], "indent": 4}
{"namespace": "django.utils.http.urlsafe_base64_decode", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/utils/http.py", "signature_position": [199, 199], "body_position": [204, 208], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Decode a base64 encoded string. Add back any trailing equal signs that might have been stripped.", "Arguments": ":param s: String. The base64 encoded string to be decoded.\n:return: The decoded base64 string."}, "tests": ["tests/utils_tests/test_http.py::URLSafeBase64Tests::test_roundtrip"], "indent": 4}
{"namespace": "django.utils.http.parse_etags", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/utils/http.py", "signature_position": [211, 211], "body_position": [217, 222], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Parse a string of ETags given in an If-None-Match or If-Match header as defined by RFC 9110. Return a list of quoted ETags, or ['*'] if all ETags should be matched.", "Arguments": ":param etag_str: String. A string of ETags given in an If-None-Match or If-Match header.\n:return: List of quoted ETags, or ['*'] if all ETags should be matched."}, "tests": ["tests/utils_tests/test_http.py::ETagProcessingTests::test_parsing"], "indent": 4}
{"namespace": "django.utils.http.is_same_domain", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/utils/http.py", "signature_position": [236, 236], "body_position": [245, 253], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the given host is an exact match or a match to the wildcard pattern. It returns True if the host is either an exact match or a match to the wildcard pattern.", "Arguments": ":param host: String. The host to be checked.\n:param pattern: String. The wildcard pattern to be matched.\n:return: Bool. True if the host is either an exact match or a match to the wildcard pattern, False otherwise."}, "tests": ["tests/utils_tests/test_http.py::IsSameDomainTests::test_bad", "tests/utils_tests/test_http.py::IsSameDomainTests::test_good"], "indent": 4}
{"namespace": "django.utils.http.content_disposition_header", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/utils/http.py", "signature_position": [431, 431], "body_position": [436, 449], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Construct a Content-Disposition HTTP header value from the given filename as specified by RFC 6266. It constructs the header value based on the filename and the attachment flag.", "Arguments": ":param as_attachment: Bool. Whether the content should be treated as an attachment.\n:param filename: String. The name of the file to be included in the header value.\n:return: String. The constructed Content-Disposition HTTP header value."}, "tests": ["tests/utils_tests/test_http.py::ContentDispositionHeaderTests::test_basic"], "indent": 4}
{"namespace": "pysnooper.utils.truncate", "type": "function", "project_path": "Software-Development/PySnooper", "completion_path": "Software-Development/PySnooper/pysnooper/utils.py", "signature_position": [81, 81], "body_position": [82, 87], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Truncate the input string to the maximum length specified. If the length of the string is less than or equal to the maximum length, the original string is returned. Otherwise, the string is truncated and ellipsis is added at the beginning and end of the truncated string.", "Arguments": ":param string: String. The input string to be truncated.\n:param max_length: Integer. The maximum length to which the string should be truncated.\n:return: String. The truncated string. If the original string is less than or equal to the maximum length, the original string is returned. Otherwise, the truncated string is returned with ellipsis at the beginning and end."}, "tests": ["tests/test_pysnooper.py::test_truncate"], "indent": 4}
{"namespace": "pysnooper.variables.needs_parentheses", "type": "function", "project_path": "Software-Development/PySnooper", "completion_path": "Software-Development/PySnooper/pysnooper/variables.py", "signature_position": [13, 13], "body_position": [14, 17], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if parentheses are needed for the given source code. It compares the bytecode of the source code with and without parentheses to determine if they are needed.", "Arguments": ":param source: String. The source code to check for parentheses.\n:return: Bool. True if parentheses are needed, False otherwise."}, "tests": ["tests/test_pysnooper.py::test_needs_parentheses"], "indent": 4}
{"namespace": "django.test.utils.extend_sys_path", "type": "function", "project_path": "Software-Development/Django", "completion_path": "Software-Development/Django/django/test/utils.py", "signature_position": [779, 779], "body_position": [781, 786], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a context manager that temporarily adds paths to sys.path. It first saves the original sys.path, then extends sys.path with the given paths. After the yield, it restores the original sys.path.", "Arguments": ":param *paths: Tuple of strings. The paths to be added to sys.path.\n:return: None. No return values."}, "tests": ["tests/utils_tests/test_module_loading.py::EggLoader::test_deep_loader", "tests/utils_tests/test_module_loading.py::EggLoader::test_shallow_loader"], "indent": 4}
{"namespace": "albumentations.augmentations.functional.normalize_cv2", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/augmentations/functional.py", "signature_position": [67, 67], "body_position": [68, 78], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Normalize the input image using the given mean and denominator. It first checks the shape of the mean and denominator and converts them to the required shape. Then, it performs subtraction and multiplication operations on the input image using the mean and denominator.", "Arguments": ":param img: Numpy array. The input image to be normalized.\n:param mean: Numpy array. The mean values for normalization.\n:param denominator: Numpy array. The denominator values for normalization.\n:return: Numpy array. The normalized image."}, "tests": ["tests/test_functional.py::test_normalize_np_cv_equal"], "indent": 4}
{"namespace": "albumentations.augmentations.functional.normalize_numpy", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/augmentations/functional.py", "signature_position": [81, 81], "body_position": [82, 85], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Normalize the input image using the given mean and denominator. It first converts the image to a float32 type, then subtracts the mean and multiplies by the denominator.", "Arguments": ":param img: Numpy array. The input image to be normalized.\n:param mean: Numpy array. The mean value to be subtracted from the image.\n:param denominator: Numpy array. The value to be multiplied with the image after subtracting the mean.\n:return: Numpy array. The normalized image."}, "tests": ["tests/test_functional.py::test_normalize_np_cv_equal"], "indent": 4}
{"namespace": "albumentations.augmentations.functional.gamma_transform", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/augmentations/functional.py", "signature_position": [820, 820], "body_position": [821, 827], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function applies gamma correction to the input image. It first checks the data type of the input image and then applies the gamma correction accordingly.", "Arguments": ":param img: Numpy array. The input image.\n:param gamma: Float. The gamma value for the transformation.\n:return: Numpy array. The transformed image after applying gamma correction."}, "tests": ["tests/test_functional.py::test_gamma_transform_float", "tests/test_functional.py::test_gamma_transform", "tests/test_functional.py::test_gamma_float_equal_uint8"], "indent": 4}
{"namespace": "albumentations.augmentations.functional.swap_tiles_on_image", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/augmentations/functional.py", "signature_position": [975, 975], "body_position": [990, 997], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function swaps the tiles on the input image based on the given tile parameters.", "Arguments": ":param image: np.ndarray. Input image.\n:param tiles: np.ndarray. Array of tuples representing the tiles to be swapped. Each tuple contains the current and old left-up corner coordinates, height, and width of the tile.\n:return: np.ndarray. The output image after swapping the tiles."}, "tests": ["tests/test_functional.py::test_swap_tiles_on_image_with_non_empty_tiles", "tests/test_functional.py::test_swap_tiles_on_image_with_empty_tiles"], "indent": 4}
{"namespace": "albumentations.augmentations.geometric.functional.keypoint_rotate", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/augmentations/geometric/functional.py", "signature_position": [197, 197], "body_position": [210, 214], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Rotate a keypoint by a given angle. It calculates the new position of the keypoint after rotation and returns the updated keypoint.", "Arguments": ":param keypoint: Tuple. A keypoint `(x, y, angle, scale)`.\n:param angle: Float. The rotation angle.\n:param rows: Int. The height of the image.\n:param cols: Int. The width of the image.\n:return: Tuple. The updated keypoint `(x, y, angle, scale)`."}, "tests": ["tests/test_keypoint.py::test_keypoint_rotate"], "indent": 4}
{"namespace": "albumentations.augmentations.geometric.functional.keypoint_shift_scale_rotate", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/augmentations/geometric/functional.py", "signature_position": [236, 236], "body_position": [237, 253], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Shift, scale, and rotate the given keypoint based on the input parameters. It first extracts the x, y, angle, and scale values from the keypoint. Then, it calculates the center of the image and constructs a rotation matrix based on the input angle and scale. It then applies the transformation to the keypoint and returns the updated x, y, angle, and scale values.", "Arguments": ":param keypoint: List. The input keypoint containing x, y, angle, and scale values.\n:param angle: Float. The angle of rotation in degrees.\n:param scale: Float. The scale factor for scaling the keypoint.\n:param dx: Float. The shift in the x-direction.\n:param dy: Float. The shift in the y-direction.\n:param rows: Integer. The number of rows in the image.\n:param cols: Integer. The number of columns in the image.\n:param **params: Additional keyword arguments.\n:return: Tuple. The updated x, y, angle, and scale values of the keypoint."}, "tests": ["tests/test_keypoint.py::test_keypoint_shift_scale_rotate"], "indent": 4}
{"namespace": "albumentations.core.keypoints_utils.angle_to_2pi_range", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/core/keypoints_utils.py", "signature_position": [23, 23], "body_position": [24, 25], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts the input angle to the range of 0 to 2\u03c0.", "Arguments": ":param angle: Float. The input angle in radians.\n:return: Float. The angle in the range of 0 to 2\u03c0."}, "tests": ["tests/test_keypoint.py::test_angle_to_2pi_range"], "indent": 4}
{"namespace": "albumentations.augmentations.geometric.functional.rot90", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/augmentations/geometric/functional.py", "signature_position": [885, 885], "body_position": [886, 887], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Rotate the input image by 90 degrees in the plane specified by axes. The rotation is performed in the counter-clockwise direction for positive factor values.", "Arguments": ":param img: np.ndarray. The input image to be rotated.\n:param factor: int. The number of 90 degree rotations to be applied.\n:return: np.ndarray. The rotated image."}, "tests": ["tests/test_functional.py::test_rot90_float", "tests/test_functional.py::test_rot90"], "indent": 4}
{"namespace": "albumentations.core.keypoints_utils.convert_keypoints_to_albumentations", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/core/keypoints_utils.py", "signature_position": [261, 268], "body_position": [269, 272], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a list of keypoints to the format used by the Albumentations library. It iterates through each keypoint and converts it to the required format.", "Arguments": ":param keypoints: Sequence of Sequence. A list of keypoints to be converted.\n:param source_format: String. The format of the input keypoints.\n:param rows: Int. The number of rows in the image.\n:param cols: Int. The number of columns in the image.\n:param check_validity: Bool. Whether to check the validity of the keypoints. Defaults to False.\n:param angle_in_degrees: Bool. Whether the angle is in degrees. Defaults to True.\n:return: List of Tuple. The converted keypoints in the format used by the Albumentations library."}, "tests": ["tests/test_keypoint.py::test_convert_keypoints_to_albumentations"], "indent": 4}
{"namespace": "albumentations.core.keypoints_utils.convert_keypoints_from_albumentations", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/core/keypoints_utils.py", "signature_position": [275, 282], "body_position": [283, 286], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the keypoints from the albumentations format to the target format. It iterates through each keypoint and converts it to the target format.", "Arguments": ":param keypoints: Sequence of Sequence. The keypoints to be converted.\n:param target_format: String. The format to which the keypoints are to be converted.\n:param rows: Int. The number of rows in the image.\n:param cols: Int. The number of columns in the image.\n:param check_validity: Bool. Whether to check the validity of the keypoints. Defaults to False.\n:param angle_in_degrees: Bool. Whether the angle is in degrees. Defaults to True.\n:return: List of Tuple. The converted keypoints.\n```"}, "tests": ["tests/test_keypoint.py::test_convert_keypoints_from_albumentations"], "indent": 4}
{"namespace": "albumentations.core.transforms_interface.to_tuple", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/core/transforms_interface.py", "signature_position": [41, 41], "body_position": [50, 71], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the input argument to a min-max tuple. If the input is a scalar, it returns a tuple with the first element as the offset - value and the second element as the offset + value. If the input is a tuple, it returns the value + offset (broadcasted).", "Arguments": ":param param: scalar, tuple or list of 2+ elements. Input value.\nIf value is scalar, return value would be (offset - value, offset + value).\nIf value is tuple, return value would be value + offset (broadcasted).\n:param low: Second element of tuple can be passed as an optional argument.\n:param bias: An offset factor added to each element.\n:return: tuple. The min-max tuple of the input argument."}, "tests": ["tests/test_core.py::test_to_tuple"], "indent": 4}
{"namespace": "albumentations.core.composition.ReplayCompose.replay", "type": "method", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/core/composition.py", "signature_position": [462, 462], "body_position": [463, 464], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function replays the saved augmentations on the input data and returns the augmented data.", "Arguments": ":param saved_augmentations: Dict. A dictionary containing the saved augmentations.\n:param **kwargs: Any. Additional keyword arguments to be passed to the augmentations.\n:return: Dict. The augmented data after replaying the saved augmentations."}, "tests": ["tests/test_bbox.py::test_crop_boxes_replay_compose", "tests/test_core.py::test_deterministic_oneof", "tests/test_core.py::test_deterministic_sequential", "tests/test_core.py::test_deterministic_one_or_other"], "indent": 8}
{"namespace": "albumentations.core.serialization.shorten_class_name", "type": "function", "project_path": "Software-Development/albumentations", "completion_path": "Software-Development/albumentations/albumentations/core/serialization.py", "signature_position": [26, 26], "body_position": [27, 33], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function shortens the class name by removing the top module name if it is \"albumentations\".", "Arguments": ":param class_fullname: String. The full name of the class.\n:return: String. The shortened class name."}, "tests": ["tests/test_serialization.py::test_shorten_class_name"], "indent": 4}
{"namespace": "wandb.util.to_forward_slash_path", "type": "function", "project_path": "Scientific-Engineering/wandb", "completion_path": "Scientific-Engineering/wandb/wandb/util.py", "signature_position": [1399, 1399], "body_position": [1400, 1402], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the backslash path to a forward slash path if the platform is Windows.", "Arguments": ":param path: String. The path to be converted.\n:return: String. The converted path."}, "tests": ["tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_logical_path_is_idempotent"], "indent": 4}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "function", "project_path": "Scientific-Engineering/wandb", "completion_path": "Scientific-Engineering/wandb/wandb/util.py", "signature_position": [1728, 1728], "body_position": [1731, 1735], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function makes an artifact name safe for use in artifacts. It replaces any characters that are not alphanumeric, dashes, underscores, or dots with underscores. If the length of the cleaned name is greater than 128, it truncates the name with dots in the middle using regex.", "Arguments": ":param name: str. The original artifact name.\n:return: str. The cleaned and safe artifact name."}, "tests": ["tests/pytest_tests/unit_tests/test_job_builder.py::test_build_repo_job", "tests/pytest_tests/unit_tests/test_job_builder.py::test_build_image_job", "tests/pytest_tests/unit_tests/test_job_builder.py::test_build_artifact_job"], "indent": 4}
{"namespace": "wandb.sdk.wandb_settings._redact_dict", "type": "function", "project_path": "Scientific-Engineering/wandb", "completion_path": "Scientific-Engineering/wandb/wandb/sdk/wandb_settings.py", "signature_position": [145, 149], "body_position": [151, 155], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Redact a dictionary of unsafe values specified by their key. It replaces the values of the specified keys with a redacted string.", "Arguments": ":param d: Dict[str, Any]. The input dictionary.\n:param unsafe_keys: Union[Set[str], FrozenSet[str]]. Set of unsafe keys to be redacted. Defaults to {\"api_key\"}.\n:param redact_str: str. The redacted string to replace the unsafe values. Defaults to \"***REDACTED***\".\n:return: Dict[str, Any]. The redacted dictionary."}, "tests": ["tests/pytest_tests/unit_tests/test_wandb_settings.py::test_redact"], "indent": 4}
{"namespace": "wandb.sdk.launch.builder.build.get_current_python_version", "type": "function", "project_path": "Scientific-Engineering/wandb", "completion_path": "Scientific-Engineering/wandb/wandb/sdk/launch/builder/build.py", "signature_position": [164, 164], "body_position": [165, 168], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "It retrieves the current Python version and returns the major and full version of the Python.", "Arguments": ":param: No input parameters.\n:return: Tuple. The first element is the full version of the Python, and the second element is the major version of the Python."}, "tests": ["tests/pytest_tests/unit_tests/test_launch/test_create_job.py::test_create_artifact_metadata"], "indent": 4}
{"namespace": "wandb.sdk.artifacts.storage_policy.StoragePolicy.lookup_by_name", "type": "method", "project_path": "Scientific-Engineering/wandb", "completion_path": "Scientific-Engineering/wandb/wandb/sdk/artifacts/storage_policy.py", "signature_position": [15, 15], "body_position": [16, 21], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function looks up a storage policy by its name. It iterates through the subclasses of the class and returns the subclass with the matching name. If no matching subclass is found, it raises a NotImplementedError.", "Arguments": ":param cls: Class. The class instance.\n:param name: String. The name of the storage policy to look up.\n:return: Type[\"StoragePolicy\"]. The subclass of the StoragePolicy with the matching name."}, "tests": ["tests/pytest_tests/unit_tests/test_artifacts/test_storage.py::test_storage_policy_incomplete"], "indent": 8}
{"namespace": "wandb.sdk.lib.runid.generate_id", "type": "function", "project_path": "Scientific-Engineering/wandb", "completion_path": "Scientific-Engineering/wandb/wandb/sdk/lib/runid.py", "signature_position": [7, 7], "body_position": [11, 12], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Generate a random base-36 string of the specified length, the string is made up of lowercase letter and digits.", "Arguments": ":param length: Integer. The length of the generated string. Defaults to 8.\n:return: String. The generated random base-36 string of the specified length."}, "tests": ["tests/pytest_tests/unit_tests/test_lib/test_runid.py::test_generate_id_is_base36", "tests/pytest_tests/unit_tests/test_lib/test_runid.py::test_generate_id_default_8_chars"], "indent": 4}
{"namespace": "wandb.sdk.internal.file_stream.CRDedupeFilePolicy.get_consecutive_offsets", "type": "method", "project_path": "Scientific-Engineering/wandb", "completion_path": "Scientific-Engineering/wandb/wandb/sdk/internal/file_stream.py", "signature_position": [151, 151], "body_position": [166, 177], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function compresses consecutive line numbers into an interval. It takes a dictionary of offsets (line numbers) and returns a list of intervals.", "Arguments": ":param console: Dict[int, str]. A dictionary that maps offsets (line numbers) to lines of text. It represents a mini version of the console dashboard on the UI.\n:return: A list of intervals, each is a tuple of two numbers."}, "tests": ["tests/pytest_tests/unit_tests/test_file_stream.py::test_crdedupe_consecutive_offsets"], "indent": 8}
{"namespace": "wandb.sdk.internal.system.assets.ipu.IPUStats.sample", "type": "method", "project_path": "Scientific-Engineering/wandb", "completion_path": "Scientific-Engineering/wandb/wandb/sdk/internal/system/assets/ipu.py", "signature_position": [81, 81], "body_position": [82, 111], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function samples the IPU stats and logs the metrics for the devices. It first gets the devices and their metrics. Then, it filters the metrics based on the user process id and logs the metrics for the devices that have not been called before or have variable metric keys. An exception will be thrown if any errors occur.", "Arguments": ":param self: IPUStats. An instance of the IPUStats class.\n:return: None. No return value."}, "tests": ["tests/pytest_tests/unit_tests/test_system_metrics/test_ipu.py::test_profiler"], "indent": 8}
{"namespace": "csvkit.cleanup.join_rows", "type": "function", "project_path": "Scientific-Engineering/csvkit", "completion_path": "Scientific-Engineering/csvkit/csvkit/cleanup.py", "signature_position": [6, 6], "body_position": [11, 21], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Given a series of rows, return them as a single row where the inner edge cells are merged. By default joins with a single space character, but you can specify new-line, empty string, or anything else with the 'joiner' kwarg.", "Arguments": ":param rows: List. A series of rows to be joined.\n:param joiner: String. The character to be used for joining the rows. Defaults to a single space character.\n:return: List. The joined row."}, "tests": ["tests/test_cleanup.py::TestCleanup::test_fix_rows", "tests/test_cleanup.py::TestCleanup::test_real_world_join_fail"], "indent": 4}
{"namespace": "csvkit.convert.guess_format", "type": "function", "project_path": "Scientific-Engineering/csvkit", "completion_path": "Scientific-Engineering/csvkit/csvkit/convert/__init__.py", "signature_position": [4, 4], "body_position": [8, 21], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function tries to guess a file's format based on its extension (or lack thereof). It checks the file extension(in ['csv', 'dbf', 'fixed', 'xls', 'xlsx', 'json']) and returns the corresponding format. 'json' will be returned if the extension is 'js'.", "Arguments": ":param filename: String. The name of the file.\n:return: String. The guessed format of the file based on its extension. If the extension is not recognized, it returns None."}, "tests": ["tests/test_convert/test_convert.py::TestConvert::test_guess_csv", "tests/test_convert/test_convert.py::TestConvert::test_guess_xlsx", "tests/test_convert/test_convert.py::TestConvert::test_guess_fixed", "tests/test_convert/test_convert.py::TestConvert::test_guess_xls_uppercase", "tests/test_convert/test_convert.py::TestConvert::test_guess_xls"], "indent": 4}
{"namespace": "folium.utilities.normalize", "type": "function", "project_path": "Scientific-Engineering/folium", "completion_path": "Scientific-Engineering/folium/folium/utilities.py", "signature_position": [443, 443], "body_position": [445, 447], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes non-functional spaces and newlines from the input string and returns the modified string.", "Arguments": ":param rendered: String. The input string to be normalized.\n:return: String. The input string without non-functional spaces or newlines."}, "tests": ["tests/plugins/test_scroll_zoom_toggler.py::test_scroll_zoom_toggler", "tests/plugins/test_boat_marker.py::test_boat_marker", "tests/plugins/test_minimap.py::test_minimap", "tests/plugins/test_fullscreen.py::test_fullscreen", "tests/plugins/test_boat_marker.py::test_boat_marker_with_no_wind_speed_or_heading"], "indent": 4}
{"namespace": "bentoml._internal.utils.uri.path_to_uri", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/utils/uri.py", "signature_position": [11, 11], "body_position": [21, 26], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a given path to a URI. It first converts the path to an absolute path and then uses the appropriate method based on the operating system to convert it to a URI.", "Arguments": ":param path: String. The path to be converted to a URI.\n:return: String. The URI string (quoted, absolute)."}, "tests": ["tests/unit/_internal/utils/test_uri.py::test_uri_path_conversion"], "indent": 4}
{"namespace": "bentoml._internal.utils.uri.uri_to_path", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/utils/uri.py", "signature_position": [29, 29], "body_position": [39, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a file URI to a path. It first parses the input URI and then checks if the scheme is supported. Then, it constructs the path string and returns it.", "Arguments": ":param uri: String. The URI to convert to a path.\n:return: String. The path string (unquoted)."}, "tests": ["tests/unit/_internal/utils/test_uri.py::test_uri_path_conversion"], "indent": 4}
{"namespace": "bentoml._internal.utils.validate_labels", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/utils/__init__.py", "signature_position": [303, 303], "body_position": [304, 312], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function validates the labels dictionary. It checks if the input is a dictionary and if the keys and values are strings. ValueError will be raised if any checks fail.", "Arguments": ":param labels: Dictionary. The dictionary to be validated.\n:return: No return values."}, "tests": ["tests/unit/_internal/test_utils.py::test_validate_labels"], "indent": 4}
{"namespace": "bentoml._internal.configuration.helpers.is_valid_ip_address", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/configuration/helpers.py", "signature_position": [162, 162], "body_position": [164, 168], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the given string is a valid IP address. It uses the ipaddress module to check if the input string is a valid IP address.", "Arguments": ":param addr: String. The input string to be checked.\n:return: Bool. True if the input string is a valid IP address, False otherwise."}, "tests": ["tests/unit/_internal/configuration/test_helpers.py::test_valid_ip_address", "tests/unit/_internal/configuration/test_helpers.py::test_invalid_ip_address"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.PandasDataFrameContainer.batches_to_batch", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [348, 352], "body_position": [353, 362], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function concatenates the given batches of Pandas DataFrame along the specified batch dimension and returns the concatenated DataFrame and the indices of the subbatches.", "Arguments": ":param cls: PandasDataFrameContainer. The class instance.\n:param batches: Sequence of Pandas DataFrame. The batches of Pandas DataFrame to be concatenated.\n:param batch_dim: int. The dimension along which the concatenation is performed. Defaults to 0.\n:return: Tuple of Pandas DataFrame and list of int. The concatenated DataFrame and the indices of the subbatches."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_pandas_container"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.PandasDataFrameContainer.batch_to_batches", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [365, 370], "body_position": [371, 378], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a Pandas DataFrame and splits it into multiple batches based on the given indices. It returns a list of Pandas DataFrames.", "Arguments": ":param cls: PandasDataFrameContainer. The class instance.\n:param batch: ext.PdDataFrame. The input Pandas DataFrame to be split.\n:param indices: t.Sequence[int]. A sequence of indices to split the DataFrame.\n:param batch_dim: int. The dimension to split the DataFrame. It defaults to 0.\n:return: list[ext.PdDataFrame]. A list of Pandas DataFrames."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_pandas_container"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.DefaultContainer.batches_to_batch", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [497, 499], "body_position": [500, 508], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts a list of batches into a single batch and returns the indices of the subbatches. It concatenates the subbatches into a single batch and calculates the indices of the subbatches.", "Arguments": ":param cls: DefaultContainer. The class instance.\n:param batches: Sequence of lists of any type. The list of batches to be converted.\n:param batch_dim: Integer. The dimension of the batch. It defaults to 0.\n:return: Tuple of list of any type and list of integers. The concatenated batch and the indices of the subbatches."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_default_container"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.DefaultContainer.batch_to_batches", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [511, 513], "body_position": [514, 517], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function splits the input batch into multiple batches based on the given indices. It returns a list of batches.", "Arguments": ":param cls: Class. The class instance.\n:param batch: List. The input batch to be split.\n:param indices: Sequence of integers. The indices to split the batch.\n:param batch_dim: Integer. The dimension to split the batch. Defaults to 0.\n:return: List of lists. The list of batches."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_default_container"], "indent": 8}
{"namespace": "jwt.utils.force_bytes", "type": "function", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/utils.py", "signature_position": [16, 16], "body_position": [17, 22], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the input value to bytes. If the input value is a string, it is encoded to bytes using UTF-8. If the input value is already bytes, it is returned as is. Otherwise, a TypeError will be raised.", "Arguments": ":param value: Union[bytes, str]. The input value that needs to be converted to bytes.\n:return: bytes. The input value converted to bytes."}, "tests": ["tests/test_utils.py::test_force_bytes_raises_error_on_invalid_object"], "indent": 4}
{"namespace": "pytube.cli.display_progress_bar", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/cli.py", "signature_position": [209, 211], "body_position": [230, 239], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Display a simple, pretty progress bar in the terminal based on the bytes received and the total file size.", "Arguments": ":param int bytes_received: The delta between the total file size (bytes) and bytes already written to disk.\n:param int filesize: File size of the media stream in bytes.\n:param str ch: Character to use for presenting progress segment. Defaults to \"\u2588\".\n:param float scale: Scale multiplier to reduce progress bar size. Defaults to 0.55.\n:return: No return values."}, "tests": ["tests/test_cli.py::test_display_progress_bar"], "indent": 4}
{"namespace": "pytube.cli._download", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/cli.py", "signature_position": [251, 255], "body_position": [256, 264], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Download a file from the given stream to the target location. It calculates the file size in megabytes, prints the filename and file size, and then downloads the file to the target location.", "Arguments": ":param stream: Stream. The stream from which the file is to be downloaded.\n:param target: String. The target location where the file is to be downloaded. Defaults to None.\n:param filename: String. The name of the file to be downloaded. Defaults to None.\n:return: No return value."}, "tests": ["tests/test_cli.py::test_download_stream_file_exists"], "indent": 4}
{"namespace": "pytube.cli.display_streams", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/cli.py", "signature_position": [484, 484], "body_position": [491, 492], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function probes a YouTube video and lists its available formats.", "Arguments": ":param youtube: YouTube. A valid YouTube watch URL.\n:return: No return value."}, "tests": ["tests/test_cli.py::test_display_stream"], "indent": 4}
{"namespace": "pytube.cli._unique_name", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/cli.py", "signature_position": [267, 267], "body_position": [280, 286], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a unique filename for a given directory and file format based on the given base name, file format, and target directory. It checks for the existence of the file in the target directory and returns a unique filename.", "Arguments": ":param base: str. The given base-name.\n:param subtype: str. The filetype of the video which will be downloaded.\n:param media_type: str. The media_type of the file, i.e., \"audio\" or \"video\".\n:param target: Path. Target directory for download.\n:return: str. The unique filename for the given directory and file format."}, "tests": ["tests/test_cli.py::test_unique_name_counter", "tests/test_cli.py::test_unique_name"], "indent": 4}
{"namespace": "pytube.cli._print_available_captions", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/cli.py", "signature_position": [495, 495], "body_position": [496, 498], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Print the available caption codes from the given CaptionQuery instance.", "Arguments": ":param captions: CaptionQuery. An instance of the CaptionQuery class.\n:return: No return value."}, "tests": ["tests/test_cli.py::test_print_available_captions"], "indent": 4}
{"namespace": "pytube.cipher.throttling_reverse", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/cipher.py", "signature_position": [482, 482], "body_position": [489, 491], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Reverses the input list in place.", "Arguments": ":param arr: List. The input list to be reversed.\n:return: No return values."}, "tests": ["tests/test_cipher.py::test_throttling_reverse"], "indent": 4}
{"namespace": "pytube.helpers.setup_logger", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/helpers.py", "signature_position": [180, 180], "body_position": [186, 201], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a configured instance of a logger. It sets the severity level of the logs to handle and adds a stream handler to the logger. If a log filename is provided, it also adds a file handler to the logger.", "Arguments": ":param level: int. Describe the severity level of the logs to handle. Defaults to logging.ERROR.\n:param log_filename: Optional[str]. The name of the log file. Defaults to None.\n:return: No return value."}, "tests": ["tests/test_helpers.py::test_setup_logger"], "indent": 4}
{"namespace": "pytube.helpers.deprecated", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/helpers.py", "signature_position": [212, 212], "body_position": [219, 235], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that can be used to mark functions as deprecated. It will result in a warning being emitted when the function is used.", "Arguments": ":param reason: String. The reason for deprecation.\n:return: Callable. A callable object that can be used as a decorator."}, "tests": ["tests/test_helpers.py::test_deprecated"], "indent": 4}
{"namespace": "pytube.helpers.uniqueify", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/helpers.py", "signature_position": [264, 264], "body_position": [273, 280], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes duplicate items from a list while maintaining the order of the list.", "Arguments": ":param duped_list: List. The list from which duplicates are to be removed.\n:return: List. The de-duplicated list."}, "tests": ["tests/test_helpers.py::test_uniqueify"], "indent": 4}
{"namespace": "pytube.helpers.target_directory", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/helpers.py", "signature_position": [238, 238], "body_position": [249, 255], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function determines the target directory of a download. It returns an absolute path if a relative one is given or the current path if none is given. It also creates the directory if it does not exist.", "Arguments": ":param output_path: Optional string. The relative or absolute path of the target directory. Defaults to None.\n:return: String. An absolute directory path."}, "tests": ["tests/test_helpers.py::test_target_directory_with_relative_path", "tests/test_helpers.py::test_target_directory_with_no_path", "tests/test_helpers.py::test_target_directory_with_absolute_path"], "indent": 4}
{"namespace": "pytube.extract.is_private", "type": "function", "project_path": "Utilities/pytube", "completion_path": "Utilities/pytube/pytube/extract.py", "signature_position": [56, 56], "body_position": [65, 73], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the content is private by searching for specific strings in the HTML content of the watch page.", "Arguments": ":param watch_html: str. The html contents of the watch page.\n:return: bool. Whether or not the content is private."}, "tests": ["tests/test_extract.py::test_is_private"], "indent": 4}
{"namespace": "pymc.math.log1mexp", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/math.py", "signature_position": [293, 293], "body_position": [307, 316], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the log of 1 minus the exponential of the negative input. It is designed to be numerically more stable than the naive approach.", "Arguments": ":param x: Numeric. The input value.\n:param negative_input: Bool. Whether the input is negative. Defaults to False.\n:return: Numeric. The log of 1 minus the exponential of the negative input."}, "tests": ["tests/test_math.py::test_log1mexp_deprecation_warnings"], "indent": 4}
{"namespace": "pymc.math.log1mexp_numpy", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/math.py", "signature_position": [319, 319], "body_position": [325, 341], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the natural logarithm of 1 minus the exponential of the input value. It is designed to be numerically more stable than the naive approach.", "Arguments": ":param x: The input value for which the natural logarithm of 1 minus the exponential is to be calculated.\n:param negative_input: Bool. Whether the input value is negative. Defaults to False.\n:return: Numpy array. The natural logarithm of 1 minus the exponential of the input value."}, "tests": ["tests/test_math.py::test_log1mexp_numpy_integer_input", "tests/test_math.py::test_log1mexp_deprecation_warnings", "tests/test_math.py::test_log1mexp"], "indent": 4}
{"namespace": "pymc.util.drop_warning_stat", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/util.py", "signature_position": [263, 263], "body_position": [269, 274], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes the \"warning\" stat from the sample stats groups in the given InferenceData object and returns a new InferenceData object.", "Arguments": ":param idata: arviz.InferenceData. The input InferenceData object.\n:return: arviz.InferenceData. The new InferenceData object with the \"warning\" stat removed from sample stats groups."}, "tests": ["tests/test_util.py::test_drop_warning_stat"], "indent": 4}
{"namespace": "pymc.pytensorf.walk_model", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/pytensorf.py", "signature_position": [179, 183], "body_position": [195, 206], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function walks through the model graphs and yields their nodes. It uses a generator to yield the nodes of the model graphs.", "Arguments": ":param graphs: Iterable of TensorVariable. The graphs to walk.\n:param stop_at_vars: Optional set of TensorVariable. A set of variables at which the walk will terminate. Defaults to None.\n:param expand_fn: Callable function. A function that returns the next variable(s) to be traversed. Defaults to a lambda function that returns an empty list.\n:return: Generator of TensorVariable. A generator that yields the nodes of the model graphs."}, "tests": ["tests/test_pytensorf.py::TestReplaceRVsByValues::test_basic", "tests/test_pytensorf.py::test_walk_model"], "indent": 4}
{"namespace": "pymc.gp.cov.handle_args", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/gp/cov.py", "signature_position": [1149, 1149], "body_position": [1150, 1158], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that takes a function as input and returns a new function. The new function takes two arguments, the first one is the input for the original function, and the second one is a tuple of arguments. If the second argument is None, the original function is called with only the first argument. Otherwise, the original function is called with the first argument and the unpacked tuple of arguments.", "Arguments": ":param func: Callable. The original function to be decorated.\n:return: Callable. The decorated function."}, "tests": ["tests/gp/test_cov.py::TestHandleArgs::test_handleargs"], "indent": 4}
{"namespace": "pymc.gp.util.kmeans_inducing_points", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/gp/util.py", "signature_position": [98, 98], "body_position": [113, 133], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function uses the K-means algorithm to initialize the locations of the inducing points `fu` based on the input parameters.", "Arguments": ":param n_inducing: int. The number of inducing points (or k, the number of clusters).\n:param X: array-like. Gaussian process input matrix.\n:param **kmeans_kwargs: Extra keyword arguments that are passed to `scipy.cluster.vq.kmeans`.\n:return: array-like. The initialized locations of the inducing points `fu` multiplied by the scaling factor."}, "tests": ["tests/gp/test_util.py::TestKmeansInducing::test_kmeans", "tests/gp/test_util.py::TestKmeansInducing::test_kmeans_raises"], "indent": 4}
{"namespace": "pymc.distributions.multivariate.posdef", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/distributions/multivariate.py", "signature_position": [829, 830], "body_position": [831, 835], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the input matrix is positive definite by attempting to perform a Cholesky decomposition. If the decomposition is successful, the matrix is positive definite.", "Arguments": ":param AA: The input matrix to be checked for positive definiteness.\n:return: Bool. True if the matrix is positive definite, False otherwise."}, "tests": ["tests/distributions/test_multivariate.py::test_posdef_symmetric"], "indent": 4}
{"namespace": "pymc.distributions.dist_math.multigammaln", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/distributions/dist_math.py", "signature_position": [398, 398], "body_position": [407, 408], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Calculate the multivariate log gamma of the given parameters.", "Arguments": ":param a: tensor like. The input tensor.\n:param p: int. The degrees of freedom. It should be greater than 0.\n:return: The multivariate log gamma value."}, "tests": ["tests/distributions/test_dist_math.py::test_multigamma"], "indent": 4}
{"namespace": "pymc.distributions.dist_math.incomplete_beta", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/distributions/dist_math.py", "signature_position": [436, 436], "body_position": [437, 442], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to calculate the incomplete beta function. It calls the betainc function from the pt module to calculate the incomplete beta function.", "Arguments": ":param a: float. The first shape parameter of the beta distribution.\n:param b: float. The second shape parameter of the beta distribution.\n:param value: float. The upper limit of integration of the incomplete beta function.\n:return: float. The value of the incomplete beta function."}, "tests": ["tests/distributions/test_dist_math.py::test_incomplete_beta_deprecation"], "indent": 4}
{"namespace": "pymc.sampling.forward.observed_dependent_deterministics", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/sampling/forward.py", "signature_position": [335, 335], "body_position": [337, 344], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function finds the deterministics that depend directly on observed variables in the given model. It first retrieves the deterministics, observed random variables, and basic random variables from the model. Then, it returns a list of deterministics that depend directly on observed variables.", "Arguments": ":param model: Model. The input model.\n:return: List. A list of deterministics that depend directly on observed variables."}, "tests": ["tests/sampling/test_forward.py::test_observed_dependent_deterministics"], "indent": 4}
{"namespace": "pymc.smc.kernels.systematic_resampling", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/smc/kernels.py", "signature_position": [571, 571], "body_position": [585, 598], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function performs systematic resampling. It generates a vector of indices based on the given weights and random number generator.", "Arguments": ":param weights: The weights should be probabilities and the total sum should be 1.\n:param rng: Random number generator.\n:return: new_indices: array. A vector of indices in the interval 0, ..., len(normalized_weights)."}, "tests": ["tests/smc/test_smc.py::test_systematic"], "indent": 4}
{"namespace": "pymc.backends.base._squeeze_cat", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/backends/base.py", "signature_position": [571, 571], "body_position": [574, 581], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Squeeze and concatenate the results based on the values of `combine` and `squeeze`. It concatenates the results if `combine` is True and squeezes the results if `squeeze` is True.", "Arguments": ":param results: List. The list of results to be concatenated or squeezed.\n:param combine: Bool. Whether to combine the results.\n:param squeeze: Bool. Whether to squeeze the results.\n:return: List or concatenated array. The squeezed or concatenated results."}, "tests": ["tests/backends/test_ndarray.py::TestSqueezeCat::test_combine_false_squeeze_false", "tests/backends/test_ndarray.py::TestSqueezeCat::test_combine_true_squeeze_true", "tests/backends/test_ndarray.py::TestSqueezeCat::test_combine_false_squeeze_true_more_than_one_item", "tests/backends/test_ndarray.py::TestSqueezeCat::test_combine_false_squeeze_true_one_item", "tests/backends/test_ndarray.py::TestSqueezeCat::test_combine_true_squeeze_false"], "indent": 4}
{"namespace": "pymc.logprob.transforms.SimplexTransform.forward", "type": "method", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/logprob/transforms.py", "signature_position": [1113, 1113], "body_position": [1114, 1118], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function performs a forward transformation on the input value using the Simplex transformation method. It calculates the log of the input value, computes the sum of the log values, and then returns the transformed value.", "Arguments": ":param value: Tensor. The input value to be transformed.\n:param inputs: Variable number of input tensors.\n:return: Tensor. The transformed value after applying the Simplex transformation."}, "tests": ["tests/distributions/test_transform.py::test_simplex_accuracy"], "indent": 8}
{"namespace": "pymc.logprob.transforms.SimplexTransform.backward", "type": "method", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/logprob/transforms.py", "signature_position": [1120, 1120], "body_position": [1121, 1123], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function performs the backward transformation of the Simplex transform. It takes the value and a variable number of inputs and returns the transformed value.", "Arguments": ":param value: The value to be transformed.\n:param *inputs: Variable number of inputs.\n:return: The transformed value."}, "tests": ["tests/distributions/test_transform.py::test_simplex_accuracy"], "indent": 8}
{"namespace": "pymc.logprob.utils.walk_model", "type": "function", "project_path": "Scientific-Engineering/pymc", "completion_path": "Scientific-Engineering/pymc/pymc/logprob/utils.py", "signature_position": [70, 75], "body_position": [91, 106], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function walks through the model graphs and yields their nodes. It can be used to traverse the graph structure of a model and perform operations on the nodes.", "Arguments": ":param graphs: Iterable of TensorVariable. The graphs to walk.\n:param walk_past_rvs: Bool. If True, the walk will not terminate at MeasurableVariable nodes.\n:param stop_at_vars: Optional set of TensorVariable. A list of variables at which the walk will terminate.\n:param expand_fn: Callable function. A function that returns the next variable(s) to be traversed.\n:return: Generator of TensorVariable. A generator that yields the nodes of the model graphs.\n```"}, "tests": ["tests/logprob/test_utils.py::test_rvs_to_value_vars_intermediate_rv", "tests/logprob/test_utils.py::test_rvs_to_value_vars", "tests/logprob/test_basic.py::test_factorized_joint_logprob_basic", "tests/logprob/test_utils.py::test_walk_model", "tests/logprob/test_basic.py::test_joint_logp_basic"], "indent": 4}
{"namespace": "sacred.metrics_logger.linearize_metrics", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/metrics_logger.py", "signature_position": [80, 80], "body_position": [93, 105], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Group metrics by name. It takes a list of individual measurements, possibly belonging to different metrics and groups them by name.", "Arguments": ":param logged_metrics: A list of ScalarMetricLogEntries\n:return: Measured values grouped by the metric name:\n{\"metric_name1\": {\"steps\": [0,1,2], \"values\": [4, 5, 6],\n\"timestamps\": [datetime, datetime, datetime]},\n\"metric_name2\": {...}}"}, "tests": ["tests/test_observers/test_file_storage_observer.py::test_log_metrics", "tests/test_metrics_logger.py::test_linearize_metrics"], "indent": 4}
{"namespace": "sacred.utils.set_by_dotted_path", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [457, 457], "body_position": [474, 480], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets an entry in a nested dictionary using a dotted path. It creates dictionaries as needed.\nExamples\n--------\n>>> d = {'foo': {'bar': 7}}\n>>> set_by_dotted_path(d, 'foo.bar', 10)\n>>> d\n{'foo': {'bar': 10}}\n>>> set_by_dotted_path(d, 'foo.d.baz', 3)\n>>> d\n{'foo': {'bar': 10, 'd': {'baz': 3}}}", "Arguments": ":param d: Dictionary. The nested dictionary to be modified.\n:param path: String. The dotted path to the entry to be set.\n:param value: Any. The value to be set at the specified path.\n:return: No return value."}, "tests": ["tests/test_utils.py::test_set_by_dotted_path_creates_missing_dicts", "tests/test_utils.py::test_set_by_dotted_path"], "indent": 4}
{"namespace": "sacred.utils.get_by_dotted_path", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [483, 483], "body_position": [492, 500], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves an entry from nested dictionaries using a dotted path. It splits the path and iterates through the nested dictionaries to find the entry.\nExample:\n>>> get_by_dotted_path({'foo': {'a': 12}}, 'foo.a')\n12", "Arguments": ":param d: Dictionary. The nested dictionary from which to retrieve the entry.\n:param path: String. The dotted path to the entry in the nested dictionary.\n:param default: Any. The default value to return if the entry is not found. Defaults to None.\n:return: Any. The retrieved entry from the nested dictionary. If not found, returns the default value."}, "tests": ["tests/test_utils.py::test_get_by_dotted_path"], "indent": 4}
{"namespace": "sacred.utils.is_prefix", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [522, 522], "body_position": [524, 526], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if pre_path is a path-prefix of path. It returns True if pre_path is a path-prefix of path, otherwise False.", "Arguments": ":param pre_path: String. The path-prefix to be checked.\n:param path: String. The path to be checked.\n:return: Bool. True if pre_path is a path-prefix of path, otherwise False."}, "tests": ["tests/test_utils.py::test_is_prefix"], "indent": 4}
{"namespace": "sacred.utils.get_inheritors", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [613, 613], "body_position": [615, 623], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a set of all classes that inherit from the given class. It iterates through all the subclasses of the given class and adds them to the set of subclasses.", "Arguments": ":param cls: Class. The class for which the inheritors are to be found.\n:return: Set. A set of all classes that inherit from the given class."}, "tests": ["tests/test_utils.py::test_get_inheritors"], "indent": 4}
{"namespace": "sacred.utils.convert_camel_case_to_snake_case", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [628, 628], "body_position": [630, 631], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a string from CamelCase to snake_case.", "Arguments": ":param name: String. The input string in CamelCase.\n:return: String. The converted string in snake_case."}, "tests": ["tests/test_utils.py::test_convert_camel_case_to_snake_case"], "indent": 4}
{"namespace": "sacred.utils.module_exists", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [674, 674], "body_position": [676, 681], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if a module exists without actually importing it. It uses the pkgutil.find_loader method to check if the module exists.", "Arguments": ":param modname: String. The name of the module to check.\n:return: Bool. True if the module exists, False otherwise."}, "tests": ["tests/test_utils.py::test_module_exists_base_level_modules", "tests/test_utils.py::test_module_exists_does_not_import_module"], "indent": 4}
{"namespace": "sacred.utils.apply_backspaces_and_linefeeds", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [634, 634], "body_position": [644, 671], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Interpret backspaces and linefeeds in text like a terminal would. It removes backspace and linefeed characters and applies them line by line.", "Arguments": ":param text: String. The input text to be interpreted.\n:return: String. The interpreted text after removing backspace and linefeed characters."}, "tests": ["tests/test_experiment.py::test_captured_out_filter", "tests/test_utils.py::test_apply_backspaces_and_linefeeds", "tests/test_run.py::test_captured_out_filter"], "indent": 4}
{"namespace": "sacred.optional.optional_import", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/optional.py", "signature_position": [9, 9], "body_position": [10, 14], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function tries to import the given package names and returns the first successfully imported package. If none of the packages can be imported, it returns False and None.", "Arguments": ":param package_names: Tuple of strings. The names of the packages to be imported.\n:return: Tuple. The first element is a boolean indicating whether the import is successful. The second element is the first successfully imported package.\n```"}, "tests": ["tests/test_optional.py::test_optional_import", "tests/test_optional.py::test_optional_import_nonexisting"], "indent": 4}
{"namespace": "sacred.dependencies.get_py_file_if_possible", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/dependencies.py", "signature_position": [378, 378], "body_position": [380, 386], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Try to retrieve a .py file for a given .py[c] file. It first checks if the file ends with \".py\", \".so\", \".pyd\", or \".ipynb\". If so, it returns the file name. Otherwise, it checks if the .py file exists. If so, it returns the .py file name. Otherwise, it returns the original .pyc file name.", "Arguments": ":param pyc_name: String. The name of the .py[c] file.\n:return: String. The name of the .py file if found, otherwise the name of the .pyc file."}, "tests": ["tests/test_dependencies.py::test_get_py_file_if_possible_with_pyc_file", "tests/test_dependencies.py::test_get_py_file_if_possible_with_pyc_but_nonexistent_py_file", "tests/test_dependencies.py::test_get_py_file_if_possible_with_py_file"], "indent": 4}
{"namespace": "sacred.config.custom_containers.DogmaticDict.update", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/custom_containers.py", "signature_position": [97, 97], "body_position": [98, 106], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Update the DogmaticDict instance with the given iterable or keyword arguments. If the iterable is not None, it iterates through the keys and values of the iterable and updates the instance. If the iterable does not have keys, it iterates through the items of the iterable and updates the instance. Then, it updates the instance with the keyword arguments.", "Arguments": ":param self: DogmaticDict. An instance of the DogmaticDict class.\n:param iterable: Iterable. An iterable object to update the instance. Defaults to None.\n:param kwargs: Keyword arguments. Key-value pairs to update the instance.\n:return: No return values."}, "tests": ["tests/test_config/test_dogmatic_dict.py::test_dict_interface_update_with_list_of_items", "tests/test_config/test_dogmatic_dict.py::test_dict_interface_update_with_kwargs", "tests/test_config/test_dogmatic_dict.py::test_dict_interface_update_with_dict"], "indent": 8}
{"namespace": "sacred.config.config_scope.is_empty_or_comment", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/config_scope.py", "signature_position": [148, 148], "body_position": [149, 150], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the input line is empty or a comment. It removes leading and trailing whitespaces and checks if the line is empty or starts with a comment symbol.", "Arguments": ":param line: String. The input line to be checked.\n:return: Bool. True if the line is empty or a comment, False otherwise."}, "tests": ["tests/test_config/test_config_scope.py::test_is_empty_or_comment"], "indent": 4}
{"namespace": "boltons.funcutils.copy_function", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/funcutils.py", "signature_position": [194, 194], "body_position": [213, 220], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a shallow copy of the given function, including the code object, globals, closure, etc.", "Arguments": ":param orig: function. The function to be copied. Must be a function, not just any method or callable.\n:param copy_dict: bool. Also copy any attributes set on the function instance. Defaults to ``True``.\n:return: function. The copied function."}, "tests": ["tests/test_funcutils.py::test_copy_function"], "indent": 4}
{"namespace": "sacred.config.config_scope.dedent_line", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/config_scope.py", "signature_position": [157, 157], "body_position": [158, 164], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes the common leading whitespace from the input line based on the given indent.", "Arguments": ":param line: String. The input line to be processed.\n:param indent: String. The indent to be removed from the input line.\n:return: String. The processed line with the common leading whitespace removed."}, "tests": ["tests/test_config/test_config_scope.py::test_dedent_line"], "indent": 4}
{"namespace": "boltons.funcutils.format_invocation", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/funcutils.py", "signature_position": [338, 338], "body_position": [350, 366], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function formats a basic Python-style function call based on the given name, positional arguments, and keyword arguments. It returns the formatted function call.\nExample:\n>>> print(format_invocation('func', args=(1, 2), kwargs={'c': 3}))\nfunc(1, 2, c=3)\n>>> print(format_invocation('a_func', args=(1,)))\na_func(1)\n>>> print(format_invocation('kw_func', kwargs=[('a', 1), ('b', 2)]))\nkw_func(a=1, b=2)", "Arguments": ":param name: String. The name of the function.\n:param args: Tuple. The positional arguments of the function.\n:param kwargs: Dictionary. The keyword arguments of the function.\n:param kw: Dictionary. Additional keyword arguments.\n:return: String. The formatted function call."}, "tests": ["tests/test_funcutils.py::test_format_invocation"], "indent": 4}
{"namespace": "boltons.listutils.SplayList.shift", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/listutils.py", "signature_position": [352, 352], "body_position": [353, 356], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Shift the item at the given index to the destination index in the SplayList instance. It first removes the item at the given index and then inserts it at the destination index.", "Arguments": ":param self: SplayList. An instance of the SplayList class.\n:param item_index: Integer. The index of the item to be shifted.\n:param dest_index: Integer. The index where the item is to be shifted. Defaults to 0.\n:return: No return values."}, "tests": ["tests/test_listutils.py::test_splay_list"], "indent": 8}
{"namespace": "boltons.strutils.gzip_bytes", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/strutils.py", "signature_position": [670, 670], "body_position": [685, 689], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Compress the input bytes using gzip compression with the specified compression level.", "Arguments": ":param bytestring: Bytes. The input bytes to be compressed.\n:param level: Integer. An integer between 1-9 controlling the speed/compression. 1 is fastest, least compressed, 9 is slowest, but most compressed. Defaults to 6.\n:return: Bytes. The compressed bytes."}, "tests": ["tests/test_strutils.py::test_roundzip"], "indent": 4}
{"namespace": "boltons.strutils.is_uuid", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/strutils.py", "signature_position": [745, 745], "body_position": [759, 766], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the input argument is a valid UUID object or string. It also checks if the UUID version matches the specified version.", "Arguments": ":param obj: object. The test target. Strings and UUID objects are supported.\n:param version: int. The target UUID version. Set to 0 to skip version check.\n:return: bool. True if the input is a valid UUID object or string, and the version matches the specified version. False otherwise."}, "tests": ["tests/test_strutils.py::test_is_uuid"], "indent": 4}
{"namespace": "boltons.strutils.parse_int_list", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/strutils.py", "signature_position": [911, 911], "body_position": [928, 945], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a range string as input and returns a sorted list of positive integers based on the range string. It parses the input range string and returns a list of integers.\nExample:\n>>> parse_int_list('1,3,5-8,10-11,15')\n[1, 3, 5, 6, 7, 8, 10, 11, 15]", "Arguments": ":param range_string: String. The input range string containing comma-separated positive integers or ranges.\n:param delim: Char. The delimiter that separates integers and contiguous ranges of integers. Defaults to ','.\n:param range_delim: Char. The delimiter that indicates a contiguous range of integers. Defaults to '-'.\n:return: List of integers. A sorted list of positive integers based on the input range string."}, "tests": ["tests/test_strutils.py::test_parse_int_list"], "indent": 4}
{"namespace": "boltons.cacheutils.ThresholdCounter.get", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [798, 798], "body_position": [800, 803], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Get the count for the given key in the ThresholdCounter instance. If the key is not found, it returns the default value.", "Arguments": ":param self: ThresholdCounter. An instance of the ThresholdCounter class.\n:param key: The key to get the count for.\n:param default: Integer. The value to return if the key is not found in the instance. Defaults to 0.\n:return: Integer. The count for the key, or the default value if the key is not found."}, "tests": ["tests/test_cacheutils.py::test_threshold_counter"], "indent": 8}
{"namespace": "boltons.iterutils.backoff_iter", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [561, 561], "body_position": [616, 652], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a sequence of geometrically-increasing floats, suitable for usage with exponential backoff. It starts with the start value, increasing by a factor until the stop value is reached, optionally stopping iteration once a count of numbers are yielded.", "Arguments": ":param start (float): Positive number for baseline.\n:param stop (float): Positive number for maximum.\n:param count (int): Number of steps before stopping iteration. Defaults to the number of steps between start and stop. Pass the string, 'repeat', to continue iteration indefinitely.\n:param factor (float): Rate of exponential increase. Defaults to 2.0.\n:param jitter (float): A factor between -1.0 and 1.0, used to uniformly randomize and spread out timeouts in a distributed system, avoiding rhythm effects. Positive values use the base backoff curve as a maximum, negative values use the curve as a minimum. Set to 1.0 or True for a jitter approximating Ethernet's time-tested backoff solution. Defaults to False.\n:return: A sequence of geometrically-increasing floats."}, "tests": ["tests/test_iterutils.py::test_backoff_repeat"], "indent": 4}
{"namespace": "boltons.cacheutils.cached", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [543, 543], "body_position": [576, 578], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that caches the result of a function. It takes a cache object and returns a decorator that can be used to cache the result of a function.", "Arguments": ":param cache: Mapping. Any dict-like object suitable for use as a cache. Instances of the LRU and LRI are good choices, but a plain dict can work in some cases, as well. This argument can also be a callable which accepts no arguments and returns a mapping.\n:param scoped: Bool. Whether the function itself is part of the cache key. True by default, different functions will not read one another's cache entries, but can evict one another's results. False can be useful for certain shared cache use cases. More advanced behavior can be produced through the key argument.\n:param typed: Bool. Whether to factor argument types into the cache check. Default False, setting to True causes the cache keys for 3 and 3.0 to be considered unequal.\n:param key: The key to be used for caching. Defaults to None.\n:return: The decorator function that can be used to cache the result of a function."}, "tests": ["tests/test_cacheutils.py::test_callable_cached_dec", "tests/test_cacheutils.py::test_cached_dec", "tests/test_cacheutils.py::test_unscoped_cached_dec"], "indent": 4}
{"namespace": "boltons.timeutils.total_seconds", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/timeutils.py", "signature_position": [62, 62], "body_position": [75, 78], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the total number of seconds in a given timedelta object.", "Arguments": ":param td: datetime.timedelta. The timedelta to convert to seconds.\n:return: float. The total number of seconds in the given timedelta object."}, "tests": ["tests/test_timeutils.py::test_float_total_seconds"], "indent": 4}
{"namespace": "boltons.gcutils.get_all", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/gcutils.py", "signature_position": [71, 71], "body_position": [104, 119], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list containing all instances of a given type. It works for the vast majority of types, but there are some exceptions. It is optimized for getting instances of user-created types quite fast. Setting *include_subtypes* to ``False`` will further increase performance in cases where instances of subtypes aren't required.", "Arguments": ":param type_obj: Type. The type of object to get all instances of.\n:param include_subtypes: Bool. Whether to include instances of subtypes. Defaults to True.\n:return: List. A list containing all instances of the given type."}, "tests": ["tests/test_gcutils.py::test_get_all"], "indent": 4}
{"namespace": "boltons.timeutils.daterange", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/timeutils.py", "signature_position": [312, 312], "body_position": [363, 398], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a generator that yields a sequence of datetime.date objects, starting at the start date, incrementing by step, until the stop date is reached. It can also yield an infinite sequence of dates if the stop date is set to None.", "Arguments": ":param start (datetime.date): The starting date The first value in the sequence.\n:param stop (datetime.date): The stopping date. By default not included in return. Can be `None` to yield an infinite sequence.\n:param step (int): The value to increment *start* by to reach *stop*. Can be an :class:`int` number of days, a :class:`datetime.timedelta`, or a :class:`tuple` of integers, `(year, month, day)`. Positive and negative *step* values are supported.\n:param inclusive (bool): Whether or not the *stop* date can be returned. *stop* is only returned when a *step* falls evenly on it.\n:return: A generator that yields a sequence of datetime.date objects."}, "tests": ["tests/test_timeutils.py::test_daterange_years_step", "tests/test_timeutils.py::test_daterange_infinite", "tests/test_timeutils.py::test_daterange_years", "tests/test_timeutils.py::test_daterange_with_same_start_stop"], "indent": 4}
{"namespace": "boltons.mathutils.clamp", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/mathutils.py", "signature_position": [43, 43], "body_position": [69, 72], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Limit a value to a given range. The function takes a number and limits it to a given range. The returned value is guaranteed to be between the lower and upper bounds.", "Arguments": ":param x: int or float. Number to be clamped.\n:param lower: int or float. Minimum value for x. Defaults to negative infinity.\n:param upper: int or float. Maximum value for x. Defaults to positive infinity.\n:return: int or float. The clamped value.\nThe returned value is guaranteed to be between *lower* and *upper*. Integers, floats, and other comparable types can be mixed.\nThe function also provides examples of how to use it."}, "tests": ["tests/test_mathutils.py::test_clamp_examples", "tests/test_mathutils.py::test_clamp_transparent"], "indent": 4}
{"namespace": "boltons.mathutils.ceil", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/mathutils.py", "signature_position": [75, 75], "body_position": [91, 97], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Return the ceiling of the input number. If the options are set, return the smallest integer or float from the options that is greater than or equal to the input number.", "Arguments": ":param x: int or float. Number to be tested.\n:param options: iterable. Optional iterable of arbitrary numbers (ints or floats).\n:return: int or float. The ceiling of x. If options is not None, return the smallest integer or float from the options that is greater than or equal to x."}, "tests": ["tests/test_mathutils.py::test_ceil_basic", "tests/test_mathutils.py::test_ceil_oor_lower", "tests/test_mathutils.py::test_ceil_oor_upper"], "indent": 4}
{"namespace": "boltons.formatutils.get_format_args", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/formatutils.py", "signature_position": [156, 156], "body_position": [172, 200], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a format string and returns two lists of arguments referenced by the format string. One list contains positional arguments, and the other contains named arguments. Each element of the list includes the name and the nominal type of the field.", "Arguments": ":param fstr: String. The format string to be processed.\n:return: Tuple. Two lists of arguments referenced by the format string. The first list contains positional arguments, and the second list contains named arguments."}, "tests": ["tests/test_formatutils.py::test_get_fstr_args"], "indent": 4}
{"namespace": "boltons.mathutils.floor", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/mathutils.py", "signature_position": [100, 100], "body_position": [117, 124], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Return the floor of the input number. If the options are set, return the largest integer or float from the options that is less than or equal to the input number.", "Arguments": ":param x: int or float. Number to be tested.\n:param options: iterable. Optional iterable of arbitrary numbers (ints or floats).\n:return: int or float. The floor of x. If options is not None, return the largest integer or float from the options that is less than or equal to the input number."}, "tests": ["tests/test_mathutils.py::test_floor_basic", "tests/test_mathutils.py::test_floor_oor_lower", "tests/test_mathutils.py::test_floor_oor_upper"], "indent": 4}
{"namespace": "boltons.dictutils.OneToOne.setdefault", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [869, 869], "body_position": [870, 872], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set the default value for the key if the key is not in the instance, else returns the value.", "Arguments": ":param self: OneToOne. An instance of the OneToOne class.\n:param key: The key to set the default value.\n:param default: The default value to set for the key. Defaults to None.\n:return: The value corresponding to the key."}, "tests": ["tests/test_dictutils.py::test_one_to_one"], "indent": 8}
{"namespace": "boltons.dictutils.OneToOne.update", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [874, 874], "body_position": [875, 888], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Update the OneToOne instance with the given dictionary or iterable and keyword arguments. It first checks if the input is a dictionary or an iterable and then updates the instance with the input values.", "Arguments": ":param self: OneToOne. An instance of the OneToOne class.\n:param dict_or_iterable: Dictionary or Iterable. The dictionary or iterable to update the instance with.\n:param kw: Keyword arguments. Additional keyword arguments to update the instance with.\n:return: No return values."}, "tests": ["tests/test_dictutils.py::test_one_to_one"], "indent": 8}
{"namespace": "boltons.dictutils.ManyToMany.get", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [920, 920], "body_position": [921, 924], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the value corresponding to the key in the ManyToMany instance. If the key is not found, it returns the default value.", "Arguments": ":param self: ManyToMany. An instance of the ManyToMany class.\n:param key: The key to retrieve the value from the instance.\n:param default: Frozenset. The value to return if the key is not found in the instance. Defaults to an empty frozenset.\n:return: The value corresponding to the key or the default value."}, "tests": ["tests/test_dictutils.py::test_many_to_many"], "indent": 8}
{"namespace": "boltons.dictutils.FrozenDict.updated", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [1071, 1071], "body_position": [1076, 1078], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Make a copy of the FrozenDict and add items from a dictionary or iterable (and/or keyword arguments), overwriting values under an existing key.", "Arguments": ":param self: FrozenDict. An instance of the FrozenDict class.\n:param *a: Tuple. A tuple of dictionaries or iterables.\n:param **kw: Dict. A dictionary of keyword arguments.\n:return: The updated FrozenDict instance."}, "tests": ["tests/test_dictutils.py::test_frozendict"], "indent": 8}
{"namespace": "boltons.dictutils.subdict", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [1020, 1020], "body_position": [1042, 1049], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function computes the \"subdictionary\" of a dictionary. It returns a new dictionary with any keys in *drop* removed, and any keys in *keep* still present, provided they were in the original dictionary.", "Arguments": ":param d: Dictionary. The original dictionary.\n:param keep: List. The list of keys to keep in the original dictionary. Defaults to all keys.\n:param drop: List. The list of keys to remove from the original dictionary. Defaults to empty.\n:return: Dictionary. The subdictionary of the original dictionary."}, "tests": ["tests/test_dictutils.py::test_subdict_keep_type", "tests/test_dictutils.py::test_subdict"], "indent": 4}
{"namespace": "boltons.dictutils.FrozenDict.__repr__", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [1085, 1085], "body_position": [1086, 1087], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the FrozenDict instance. The format is f'{class_name}({dict_repr})'", "Arguments": ":param self: FrozenDict. An instance of the FrozenDict class.\n:return: String. The string representation of the FrozenDict instance."}, "tests": ["tests/test_dictutils.py::test_frozendict"], "indent": 8}
{"namespace": "gunicorn.config.validate_callable", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [420, 420], "body_position": [421, 441], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function validates the input value to ensure it is a callable object with the specified arity. It first checks if the input value is a string, then tries to import the module and get the object. If the input value is not callable or has a different arity, it raises a TypeError.", "Arguments": ":param arity: Integer. The arity of the callable object. If set to -1, it means the arity can be any value.\n:return: Callable. The validated callable object."}, "tests": ["tests/test_config.py::test_callable_validation_for_string"], "indent": 4}
{"namespace": "gunicorn.config.get_default_config_file", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [529, 529], "body_position": [530, 534], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the path of the default configuration file for Gunicorn. It first creates the path by joining the current working directory with the file name 'gunicorn.conf.py'. Then, it checks if the file exists and returns the path if it does.", "Arguments": ":param: No input parameters.\n:return: String. The path of the default configuration file for Gunicorn. If the file does not exist, it returns None."}, "tests": ["tests/test_config.py::test_default_config_file"], "indent": 4}
{"namespace": "gunicorn.util.is_ipv6", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/util.py", "signature_position": [217, 217], "body_position": [218, 224], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the given address is a valid IPv6 address.", "Arguments": ":param addr: String. The address to be checked.\n:return: Bool. True if the address is a valid IPv6 address, False otherwise."}, "tests": ["tests/test_util.py::test_is_ipv6"], "indent": 4}
{"namespace": "gunicorn.systemd.listen_fds", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/systemd.py", "signature_position": [12, 12], "body_position": [36, 46], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function gets the number of sockets inherited from systemd socket activation. It returns zero immediately if $LISTEN_PID is not set to the current pid. Otherwise, it returns the number of systemd activation sockets specified by $LISTEN_FDS. It also unsets the environment variables if the unset_environment flag is True.", "Arguments": ":param unset_environment: Bool. Clear systemd environment variables unless False.\n:return: Int. The number of sockets to inherit from systemd socket activation."}, "tests": ["tests/test_systemd.py::test_listen_fds_ignores_wrong_pid", "tests/test_systemd.py::test_listen_fds_returns_count"], "indent": 4}
{"namespace": "gunicorn.util.http_date", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/util.py", "signature_position": [460, 460], "body_position": [462, 465], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the current date and time formatted for a message header. If the timestamp is not provided, it uses the current time.", "Arguments": ":param timestamp: Float. The timestamp to be formatted. Defaults to None.\n:return: String. The formatted date and time for a message header."}, "tests": ["tests/test_util.py::test_http_date"], "indent": 4}
{"namespace": "gunicorn.util.parse_address", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/util.py", "signature_position": [227, 227], "body_position": [228, 255], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function parses the address and returns the host and port. It first checks if the address is a unix socket, then a file descriptor, and finally a TCP address. It then returns the host and port based on the address.", "Arguments": ":param netloc: String. The network location to parse.\n:param default_port: String. The default port to use if the port is not specified in the address. Defaults to '8000'.\n:return: Tuple. A tuple containing the host and port."}, "tests": ["tests/test_util.py::test_parse_fd_invalid", "tests/test_util.py::test_parse_address_invalid", "tests/test_util.py::test_parse_address"], "indent": 4}
{"namespace": "gunicorn.util.to_bytestring", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/util.py", "signature_position": [573, 573], "body_position": [575, 580], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Converts a string argument to a byte string using the specified encoding.", "Arguments": ":param value: String. The input string to be converted to a byte string.\n:param encoding: String. The encoding to be used for the conversion. Defaults to \"utf8\".\n:return: Bytes. The byte string converted from the input string."}, "tests": ["tests/test_util.py::test_to_bytestring", "tests/test_http.py::test_http_header_encoding"], "indent": 4}
{"namespace": "gunicorn.util.warn", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/util.py", "signature_position": [596, 596], "body_position": [597, 606], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Prints a warning message to the standard error output. The format of the message is \"WARNING: %s\\n\" % msg.", "Arguments": ":param msg: String. The warning message to be printed.\n:return: No return values."}, "tests": ["tests/test_util.py::test_warn"], "indent": 4}
{"namespace": "gunicorn.util.split_request_uri", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/util.py", "signature_position": [622, 622], "body_position": [623, 631], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function splits the given URI into its components. If the URI starts with \"//\", it is considered as a relative URI, but the function considers it as an absolute path. It uses a temporary dot prefix to work around this behavior.", "Arguments": ":param uri: String. The URI to be split.\n:return: The components of the URI."}, "tests": ["tests/test_util.py::test_split_request_uri"], "indent": 4}
{"namespace": "praw.models.listing.listing.ModNoteListing.after", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/models/listing/listing.py", "signature_position": [46, 46], "body_position": [48, 50], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This method returns the next attribute or None based on the condition. If the \"has_next_page\" attribute is False, it returns None. Otherwise, it returns the \"end_cursor\" attribute.", "Arguments": ":param self: ModNoteListing. An instance of the ModNoteListing class.\n:return: Optional[Any]. The next attribute or None."}, "tests": ["tests/unit/models/listing/test_listing.py::TestModNoteListing::test_has_next_page"], "indent": 8}
{"namespace": "praw.models.util.permissions_string", "type": "function", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/models/util.py", "signature_position": [11, 13], "body_position": [25, 32], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a comma-separated string of permission changes. It takes a set of known permissions and a list of permissions and returns a string of permission changes.", "Arguments": ":param known_permissions: Set of strings. A set of strings representing the available permissions.\n:param permissions: List of strings or None. A list of strings, or ``None``. These strings can exclusively contain ``+`` or ``-`` prefixes, or contain no prefixes at all. When prefixed, the resulting string will simply be the joining of these inputs. When not prefixed, all permissions are considered to be additions, and all permissions in the ``known_permissions`` set that aren't provided are considered to be removals. When ``None``, the result is ``\"+all\"``.\n:return: str. A comma-separated string of permission changes."}, "tests": ["tests/unit/models/test_util.py::TestPermissionsString::test_permissions_string__all_explicit", "tests/unit/models/test_util.py::TestPermissionsString::test_permissions_string__none", "tests/unit/models/test_util.py::TestPermissionsString::test_permissions_string__with_additional_permissions", "tests/unit/models/test_util.py::TestPermissionsString::test_permissions_string__empty_list"], "indent": 4}
{"namespace": "jc.cli.JcCli.json_out", "type": "method", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/cli.py", "signature_position": [382, 382], "body_position": [387, 406], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a JSON formatted string. The string may include color codes or be pretty printed based on the input parameters.", "Arguments": ":param self: JcCli. An instance of the JcCli class.\n:return: str. The JSON formatted string."}, "tests": ["tests/test_jc_cli.py::MyTests::test_cli_json_out_mono", "tests/test_jc_cli.py::MyTests::test_cli_json_out"], "indent": 8}
{"namespace": "pythonforandroid.pythonpackage.transform_dep_for_pip", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/pythonpackage.py", "signature_position": [55, 55], "body_position": [56, 74], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function transforms the dependency for pip. It checks if the dependency contains \"@\" and \"://\". If it does, it transforms the dependency to a URL format that pip can install. If not, it returns the original dependency.", "Arguments": ":param dependency: String. The dependency to be transformed.\n:return: String. The transformed dependency for pip."}, "tests": ["tests/test_pythonpackage_basic.py::test_transform_dep_for_pip"], "indent": 4}
{"namespace": "pythonforandroid.graph.fix_deplist", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/graph.py", "signature_position": [10, 10], "body_position": [14, 22], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function turns a dependency list into lowercase and ensures that all entries that are just a string become a tuple of strings.", "Arguments": ":param deps: List. A list of dependencies.\n:return: List. The modified dependency list."}, "tests": ["tests/test_graph.py::test_misc_obvious_conflict_checker", "tests/test_graph.py::test_valid_obvious_conflict_checker", "tests/test_graph.py::test_invalid_obvious_conflict_checker", "tests/test_graph.py::test_multichoice_obvious_conflict_checker", "tests/test_graph.py::test_indirectconflict_obvious_conflict_checker"], "indent": 4}
{"namespace": "pythonforandroid.util.walk_valid_filens", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/util.py", "signature_position": [48, 48], "body_position": [62, 75], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function walks through all the files and directories in the base directory, ignoring the directories and files that match the specified patterns. It yields the full path of the valid files.", "Arguments": ":param base_dir: String. The base directory to start walking from.\n:param invalid_dir_names: List of strings. A list of invalid directory names to be ignored.\n:param invalid_file_patterns: List of strings. A list of glob patterns to be compared against the full file path.\n:return: Yield the full path of the valid files."}, "tests": ["tests/test_util.py::TestUtil::test_walk_valid_filens"], "indent": 4}
{"namespace": "pythonforandroid.bootstrap._cmp_bootstraps_by_priority", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/bootstrap.py", "signature_position": [50, 50], "body_position": [51, 67], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function compares two bootstraps based on their priority and name. It first ranks the bootstraps based on their priority and then compares their names.", "Arguments": ":param a: The first bootstrap to compare.\n:param b: The second bootstrap to compare.\n:return: Integer. The difference in the priority of the two bootstraps."}, "tests": ["tests/test_bootstrap.py::TestBootstrapBasic::test__cmp_bootstraps_by_priority"], "indent": 4}
{"namespace": "pythonforandroid.bootstrap.Bootstrap.all_bootstraps", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/bootstrap.py", "signature_position": [194, 194], "body_position": [196, 205], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Find all the available bootstraps and return them. It first finds the bootstraps directory and then iterates through the files in the directory to find the available bootstraps.", "Arguments": ":param cls: Class. The class instance.\n:return: Set. A set of available bootstraps."}, "tests": ["tests/test_bootstrap.py::TestBootstrapBasic::test_all_bootstraps"], "indent": 8}
{"namespace": "mmcv.image.colorspace._convert_input_type_range", "type": "function", "project_path": "Utilities/mmcv", "completion_path": "Utilities/mmcv/mmcv/image/colorspace.py", "signature_position": [86, 86], "body_position": [102, 111], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts the type and range of the input image. It converts the input image to np.float32 type and range of [0, 1]. It is mainly used for pre-processing the input image in colorspace conversion functions such as rgb2ycbcr and ycbcr2rgb.", "Arguments": ":param img: ndarray. The input image. It accepts: 1. np.uint8 type with range [0, 255]; 2. np.float32 type with range [0, 1].\n:return: ndarray. The converted image with type of np.float32 and range of [0, 1]."}, "tests": ["tests/test_image/test_colorspace.py::test_convert_input_type_range"], "indent": 4}
{"namespace": "mackup.utils.error", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [184, 184], "body_position": [191, 193], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Throw an error with the given message and immediately quit the program.", "Arguments": ":param message: str. The message to display when the error occurs.\n:return: No return values."}, "tests": ["tests/utils_test.py::TestMackup::test_error"], "indent": 4}
{"namespace": "mmcv.image.colorspace._convert_output_type_range", "type": "function", "project_path": "Utilities/mmcv", "completion_path": "Utilities/mmcv/mmcv/image/colorspace.py", "signature_position": [114, 115], "body_position": [136, 143], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the type and range of the input image according to the specified destination type. It converts the image to the desired type and range based on the destination type.", "Arguments": ":param img: np.ndarray. The input image to be converted with np.float32 type and range [0, 255].\n:param dst_type: Union[np.uint8, np.float32]. The destination type to which the image should be converted. If dst_type is np.uint8, it converts the image to np.uint8 type with range [0, 255]. If dst_type is np.float32, it converts the image to np.float32 type with range [0, 1].\n:return: np.ndarray. The converted image with the desired type and range."}, "tests": ["tests/test_image/test_colorspace.py::test_convert_output_type_range"], "indent": 4}
{"namespace": "mackup.utils.is_process_running", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [301, 301], "body_position": [311, 319], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if a process with the given name is running. It uses the pgrep command to check if the process is running.", "Arguments": ":param process_name: str. The name of the process to check.\n:return: bool. True if the process is running, False otherwise."}, "tests": ["tests/utils_test.py::TestMackup::test_is_process_running"], "indent": 4}
{"namespace": "stellar.operations._get_pid_column", "type": "function", "project_path": "Utilities/stellar", "completion_path": "Utilities/stellar/stellar/operations.py", "signature_position": [28, 29], "body_position": [30, 33], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the name of the column that contains the process ID based on the server version. It first retrieves the server version from the raw connection and then processes it to extract the version number. It then compares the version number with a predefined value and returns the column name accordingly.", "Arguments": ":param raw_conn: The raw connection to the database.\n:return: String. The name of the column that contains the process ID."}, "tests": ["tests/test_operations.py::TestGetPidColumn::test_returns_procpid_for_version_older_than_9_2", "tests/test_operations.py::TestGetPidColumn::test_returns_pid_for_version_equal_or_newer_than_9_2"], "indent": 4}
{"namespace": "imapclient.imap_utf7.encode", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imap_utf7.py", "signature_position": [14, 14], "body_position": [20, 55], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Encode a folder name using IMAP modified UTF-7 encoding. It takes a string or bytes as input and returns the encoded bytes. If the input is not a string, it returns the input unchanged.", "Arguments": ":param s: Union[str, bytes]. The input string to be encoded.\n:return: bytes. The encoded bytes of the input string."}, "tests": ["tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_encode", "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_printable_singletons"], "indent": 4}
{"namespace": "imapclient.version._imapclient_version_string", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/version.py", "signature_position": [10, 10], "body_position": [11, 15], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "It creates a version string based on the given version information. It first extracts the major, minor, micro, and release level from the version information and then creates a version string based on the extracted information.", "Arguments": ":param vinfo: Tuple. A tuple containing version information in the format (major, minor, micro, releaselevel).\n:return: String. The version string created based on the version information."}, "tests": ["tests/test_version.py::TestVersionString::test_alpha", "tests/test_version.py::TestVersionString::test_dot_oh", "tests/test_version.py::TestVersionString::test_beta_point", "tests/test_version.py::TestVersionString::test_minor", "tests/test_version.py::TestVersionString::test_point_release"], "indent": 4}
{"namespace": "telethon.helpers.generate_key_data_from_nonce", "type": "function", "project_path": "Communications/Telethon", "completion_path": "Communications/Telethon/telethon/helpers.py", "signature_position": [271, 271], "body_position": [273, 281], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates the key data corresponding to the given nonce. It first converts the server_nonce and new_nonce to bytes and then uses them to generate hash1, hash2, and hash3. Finally, it combines hash1 and the first 12 bytes of hash2 to form the key, and combines the remaining bytes of hash2, hash3, and the first 4 bytes of new_nonce to form the iv.", "Arguments": ":param server_nonce: int. The server nonce.\n:param new_nonce: int. The new nonce.\n:return: Tuple. The key and iv generated from the nonces."}, "tests": ["tests/telethon/test_helpers.py::test_generate_key_data_from_nonce"], "indent": 4}
{"namespace": "hbmqtt.codecs.bytes_to_int", "type": "function", "project_path": "Communications/hbmqtt", "completion_path": "Communications/hbmqtt/hbmqtt/codecs.py", "signature_position": [18, 18], "body_position": [24, 27], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a sequence of bytes to an integer using big endian byte ordering. It first converts the byte sequence to an integer using big endian byte ordering.", "Arguments": ":param data: byte sequence. The sequence of bytes to be converted to an integer.\n:return: integer value. The integer value converted from the byte sequence."}, "tests": ["tests/test_codecs.py::TestCodecs::test_bytes_to_int"], "indent": 4}
{"namespace": "zulipterminal.helper.display_error_if_present", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/helper.py", "signature_position": [658, 658], "body_position": [659, 660], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the response contains an error and if the controller has a \"view\" attribute. If both conditions are met, it reports the error message.", "Arguments": ":param response: Dict[str, Any]. A dictionary containing the response data.\n:param controller: Any. An object that may have a \"view\" attribute.\n:return: None. No return value."}, "tests": ["tests/helper/test_helper.py::test_display_error_if_present"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.buttons.MessageLinkButton._decode_message_id", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [455, 455], "body_position": [459, 462], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function decodes the message ID to an integer if it is compatible, otherwise, it returns None.", "Arguments": ":param message_id: str. The message ID to be decoded.\n:return: Optional[int]. The compatible near message ID or None."}, "tests": ["tests/ui_tools/test_buttons.py::TestMessageLinkButton::test__decode_message_id"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.buttons.MessageLinkButton.handle_narrow_link", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [608, 608], "body_position": [613, 623], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function narrows to the respective narrow if the narrow link is valid or updates the footer with an appropriate validation error message.", "Arguments": ":param self: MessageLinkButton. An instance of the MessageLinkButton class.\n:return: None. No return value."}, "tests": ["tests/ui_tools/test_buttons.py::TestMessageLinkButton::test_handle_narrow_link"], "indent": 8}
{"namespace": "zulipterminal.config.color.color_properties", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/config/color.py", "signature_position": [55, 55], "body_position": [68, 77], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds properties(Bold, Italics, etc...) to Enum Colors in theme files. It creates a new Enum with the given properties and returns it.", "Arguments": ":param colors: Any. The Enum colors to which properties are to be added.\n:param prop: str. The properties to be added to the Enum colors.\n:return: Any. The updated Enum with the added properties."}, "tests": ["tests/config/test_color.py::test_color_properties"], "indent": 4}
{"namespace": "twilio.base.deserialize.decimal", "type": "function", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/base/deserialize.py", "signature_position": [56, 56], "body_position": [61, 63], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function parses a decimal string into a Decimal object using the BasicContext.", "Arguments": ":param d: Optional string. The decimal string to be parsed.\n:return: Union[Decimal, str]. The parsed Decimal object or the original string if it is empty."}, "tests": ["tests/unit/base/test_deserialize.py::DecimalTestCase::test_positive_string", "tests/unit/base/test_deserialize.py::DecimalTestCase::test_zero_string", "tests/unit/base/test_deserialize.py::DecimalTestCase::test_empty_string", "tests/unit/base/test_deserialize.py::DecimalTestCase::test_zero", "tests/unit/base/test_deserialize.py::DecimalTestCase::test_negative_string"], "indent": 4}
{"namespace": "twilio.base.deserialize.integer", "type": "function", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/base/deserialize.py", "signature_position": [66, 66], "body_position": [72, 75], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function parses an integer string into an integer. If the input string is not a valid integer, it returns the input string as it is.", "Arguments": ":param i: str. The input integer string.\n:return: Union[int, str]. The parsed integer if the input string is a valid integer, otherwise the input string itself."}, "tests": ["tests/unit/base/test_deserialize.py::IntegerTestCase::test_empty_string", "tests/unit/base/test_deserialize.py::IntegerTestCase::test_zero_string", "tests/unit/base/test_deserialize.py::IntegerTestCase::test_zero", "tests/unit/base/test_deserialize.py::IntegerTestCase::test_positive_string", "tests/unit/base/test_deserialize.py::IntegerTestCase::test_negative_string"], "indent": 4}
{"namespace": "twilio.base.serialize.object", "type": "function", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/base/serialize.py", "signature_position": [64, 64], "body_position": [69, 71], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a JSON string representation of the input object if the object is JSONifiable. Otherwise, it returns the object untouched.", "Arguments": ":param obj: Any. The input object to be converted to a JSON string.\n:return: String. The JSON string representation of the input object if it is JSONifiable, otherwise the input object itself."}, "tests": ["tests/unit/base/test_serialize.py::ObjectTestCase::test_object", "tests/unit/base/test_serialize.py::ObjectTestCase::test_list", "tests/unit/base/test_serialize.py::ObjectTestCase::test_does_not_change_other_types"], "indent": 4}
{"namespace": "twilio.base.serialize.map", "type": "function", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/base/serialize.py", "signature_position": [74, 74], "body_position": [78, 80], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function applies the serialize_func to every element in the input list lst.", "Arguments": ":param lst: list. The input list.\n:param serialize_func: function. The function to be applied to every element in the list.\n:return: list. The list of elements after applying the serialize_func to each element."}, "tests": ["tests/unit/base/test_serialize.py::MapTestCase::test_maps_func_to_list", "tests/unit/base/test_serialize.py::MapTestCase::test_does_not_change_other_types"], "indent": 4}
{"namespace": "twilio.base.obsolete.deprecated_method", "type": "function", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/base/obsolete.py", "signature_position": [24, 24], "body_position": [30, 47], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that can be used to mark deprecated methods. It will report a DeprecationWarning being emitted to stderr when the deprecated method is used.", "Arguments": ":param new_func: Function. The new function that replaces the deprecated method.\n:return: The deprecated_method_wrapper function."}, "tests": ["tests/unit/base/test_deprecation.py::DeprecatedMethodTest::test_deprecation_decorator", "tests/unit/base/test_deprecation.py::DeprecatedMethodTest::test_deprecation_decorator_with_new_method"], "indent": 4}
{"namespace": "chatette.utils.sample_indulgent", "type": "function", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/utils.py", "signature_position": [87, 87], "body_position": [93, 95], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is similar to the random.sample function but does not raise an error if the number of items to be sampled is larger than the length of the array. In that case, it simply returns a copy of the whole array.", "Arguments": ":param array: List. The input array from which items are to be sampled.\n:param nb_items: Integer. The number of items to be sampled from the array.\n:return: List. The sampled items from the array or a copy of the whole array if nb_items is larger than the length of the array."}, "tests": ["tests/unit-testing/test_utils.py::TestSampleIndulgent::test_sample", "tests/unit-testing/test_utils.py::TestSampleIndulgent::test_empty"], "indent": 4}
{"namespace": "chatette.utils.rchop", "type": "function", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/utils.py", "signature_position": [98, 98], "body_position": [100, 102], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes a specified substring from the end of a given string.", "Arguments": ":param string: String. The input string from which the substring will be removed.\n:param ending: String. The substring to be removed from the end of the input string.\n:return: String. The modified string after removing the specified substring from the end. If the input string does not end with the specified substring, the original string is returned."}, "tests": ["tests/unit-testing/test_utils.py::TestRChop::test_not_ending", "tests/unit-testing/test_utils.py::TestRChop::test_ending"], "indent": 4}
{"namespace": "chatette.utils.str_to_bool", "type": "function", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/utils.py", "signature_position": [105, 105], "body_position": [110, 115], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function transforms the strings 'True' and 'False' to their boolean counterparts. It raises a `ValueError` if `text` is neither of them.", "Arguments": ":param text: String. The input string to be transformed into a boolean.\n:return: Bool. The boolean counterpart of the input string."}, "tests": ["tests/unit-testing/test_utils.py::TestStrToBool::test_not_bool", "tests/unit-testing/test_utils.py::TestStrToBool::test_str_to_bool"], "indent": 4}
{"namespace": "chatette.utils.min_if_exist", "type": "function", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/utils.py", "signature_position": [122, 122], "body_position": [127, 133], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the minimum between two numbers, or the only defined number (in case the other is `None`) or `None` if none of the numbers are defined.", "Arguments": ":param n1: The first number.\n:param n2: The second number.\n:return: The minimum between the two numbers, or the only defined number, or `None` if none of the numbers are defined."}, "tests": ["tests/unit-testing/test_utils.py::TestMinIfExist::test_min_if_exist"], "indent": 4}
{"namespace": "chatette.utils.append_to_list_in_dict", "type": "function", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/utils.py", "signature_position": [143, 143], "body_position": [149, 152], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function appends the value to the list at the given key in the dictionary. If the list does not exist, it creates a new list containing the value and puts it at the key.", "Arguments": ":param dict_of_lists: Dictionary. The dictionary of key->lists.\n:param key: The key to which the value is to be appended.\n:param value: The value to be appended to the list at the given key.\n:return: No return values."}, "tests": ["tests/unit-testing/test_utils.py::TestAppendToListInDict::test_append"], "indent": 4}
{"namespace": "chatette.utils.extend_list_in_dict", "type": "function", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/utils.py", "signature_position": [154, 154], "body_position": [160, 163], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function extends the list at the given key in the dictionary with the given values if the list exists. Otherwise, it puts the list of values at the given key.", "Arguments": ":param dict_of_lists: Dictionary. The dictionary of key->lists.\n:param key: The key in the dictionary.\n:param values: List. The list of values to be extended or put in the dictionary.\n:return: No return values."}, "tests": ["tests/unit-testing/test_utils.py::TestExtendListInDict::test_extend"], "indent": 4}
{"namespace": "chatette.cli.interactive_commands.command_strategy.CommandStrategy._is_end_regex", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/cli/interactive_commands/command_strategy.py", "signature_position": [87, 87], "body_position": [89, 92], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the given word is the end of a regex '\\/(g?i?|i?g?)$'.", "Arguments": ":param word: String. The word to be checked.\n:return: Bool. True if the word is the end of a regex, False otherwise."}, "tests": ["tests/unit-testing/cli/interactive_commands/test_command_strategy.py::TestIsEndRegex::test_regexes"], "indent": 8}
{"namespace": "chatette.cli.interactive_commands.command_strategy.CommandStrategy.execute", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/cli/interactive_commands/command_strategy.py", "signature_position": [272, 272], "body_position": [279, 314], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function executes the whole command represented by the object. It can be overridden by subclasses if a different algorithm is required.", "Arguments": ":param self: CommandStrategy. An instance of the CommandStrategy class.\n:return: No return values."}, "tests": ["tests/unit-testing/cli/interactive_commands/test_show_command.py::test_err", "tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_err", "tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_execute", "tests/unit-testing/cli/interactive_commands/test_show_command.py::test_execute", "tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_variations"], "indent": 8}
{"namespace": "aioxmpp.network.group_and_order_srv_records", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/network.py", "signature_position": [399, 399], "body_position": [409, 435], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function orders a list of SRV record information and groups and orders them as specified by the RFC. It returns an iterable, yielding each ``(hostname, port)`` tuple inside the SRV records in the order specified by the RFC. For hosts with the same priority, the given `rng` implementation is used (if none is given, the :mod:`random` module is used).", "Arguments": ":param all_records: List. A list of SRV record information.\n:param rng: Random. The random number generator to be used for hosts with the same priority. Defaults to None.\n:return: Iterable. An iterable, yielding each ``(hostname, port)`` tuple inside the SRV records in the order specified by the RFC."}, "tests": ["tests/test_network.py::Testgroup_and_order_srv_records::test_group_by_priority", "tests/test_network.py::Testgroup_and_order_srv_records::test_one_record_with_zero_weight", "tests/test_network.py::Testgroup_and_order_srv_records::test_equal_prio_weight_and_uncomparable_object"], "indent": 4}
{"namespace": "aioxmpp.nonza.StreamFeatures.get_feature", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/nonza.py", "signature_position": [272, 272], "body_position": [279, 282], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the first instance of a feature of the given `feature_cls` type if it is contained in the current stream features set. Otherwise, it returns the default value.", "Arguments": ":param self: StreamFeatures. An instance of the StreamFeatures class.\n:param feature_cls: The type of feature to be returned.\n:param default: The value to return if the feature is not found in the instance. Defaults to None.\n:return: The first instance of the feature of the given `feature_cls` type if it is contained in the current stream features set. Otherwise, it returns the default value."}, "tests": ["tests/test_nonza.py::TestStreamFeatures::test_get_feature"], "indent": 8}
{"namespace": "aioxmpp.connector.XMPPOverTLSConnector._context_factory_factory", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/connector.py", "signature_position": [291, 291], "body_position": [292, 310], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a context factory for the XMPPOverTLSConnector. It sets the ALPN protocol to \"xmpp-client\" if the ssl_context has the set_alpn_protos method. It also sets up the context with the verifier and returns the ssl_context.", "Arguments": ":param self: XMPPOverTLSConnector. An instance of the XMPPOverTLSConnector class.\n:param logger: The logger to be used for logging.\n:param metadata: The metadata to be used for creating the ssl context.\n:param verifier: The verifier to be used for setting up the context.\n:return: The context factory function."}, "tests": ["tests/test_connector.py::TestXMPPOverTLSConnector::test_context_factory_warns_if_set_alpn_protos_is_not_defined", "tests/test_connector.py::TestXMPPOverTLSConnector::test_context_factory", "tests/test_connector.py::TestXMPPOverTLSConnector::test_context_factory_warns_if_set_alpn_protos_raises"], "indent": 8}
{"namespace": "aioxmpp.xmltestutils.element_path", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/xmltestutils.py", "signature_position": [25, 25], "body_position": [26, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the path of the given element in the XML tree. It starts from the given element and goes up to the root element or the specified element. It constructs the path based on the tag name and index of the element in the parent.", "Arguments": ":param el: Element. The given element for which the path is to be constructed.\n:param upto: Element. The element up to which the path is to be constructed. Defaults to None, which means the root element.\n:return: String. The constructed path of the element."}, "tests": ["tests/test_xmltestutils.py::TestTestUtils::test_element_path"], "indent": 4}
{"namespace": "aioxmpp.structs.JID.fromstr", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/structs.py", "signature_position": [796, 796], "body_position": [811, 819], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Construct a JID instance from a string containing it. It parses the input string and constructs a JID instance based on the parsed components.", "Arguments": ":param s: The string to parse.\n:type s: :class:`str`\n:param strict: Whether to enable strict parsing.\n:type strict: :class:`bool`\n:raises: See :class:`JID`\n:return: The parsed JID\n:rtype: :class:`JID`"}, "tests": ["tests/test_protocol.py::TestXMLStream::test_send_xso"], "indent": 8}
{"namespace": "aioxmpp.security_layer.extract_python_dict_from_x509", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/security_layer.py", "signature_position": [140, 140], "body_position": [151, 178], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function extracts a python dictionary from the given X509 object. It extracts the subject and subjectAltName attributes from the X509 object and puts them in the result dictionary.", "Arguments": ":param x509: X509. The X509 object from which the dictionary is to be extracted.\n:return: Dictionary. The extracted python dictionary containing the subject and subjectAltName attributes."}, "tests": ["tests/test_security_layer.py::Testextract_python_dict_from_x509::test_zombofant_net"], "indent": 4}
{"namespace": "aioxmpp.security_layer.extract_blob", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/security_layer.py", "signature_position": [181, 181], "body_position": [187, 189], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Extract an ASN.1 blob from the given X509 certificate. It returns the resulting bytes object.", "Arguments": ":param x509: X509. The OpenSSL.crypto.X509 certificate from which the ASN.1 blob is to be extracted.\n:return: bytes. The resulting ASN.1 blob."}, "tests": ["tests/test_security_layer.py::Testextract_blob::test_generic"], "indent": 4}
{"namespace": "aioxmpp.security_layer.blob_to_pyasn1", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/security_layer.py", "signature_position": [192, 192], "body_position": [198, 201], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts an ASN.1 encoded certificate to a pyasn1 structure and returns the result.", "Arguments": ":param blob: The ASN.1 encoded certificate to be converted to a pyasn1 structure.\n:return: The pyasn1 structure of the ASN.1 encoded certificate."}, "tests": ["tests/test_security_layer.py::Testblob_to_pyasn1::test_generic"], "indent": 4}
{"namespace": "aioxmpp.security_layer.extract_pk_blob_from_pyasn1", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/security_layer.py", "signature_position": [204, 204], "body_position": [210, 216], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function extracts an ASN.1 encoded public key blob from the given pyasn1 structure, which must represent a certificate.", "Arguments": ":param pyasn1_struct: The pyasn1 structure that represents a certificate.\n:return: The ASN.1 encoded public key blob extracted from the given pyasn1 structure."}, "tests": ["tests/test_security_layer.py::Testextract_pk_blob_from_pyasn1::test_generic"], "indent": 4}
{"namespace": "aioxmpp.callbacks.AdHocSignal.ASYNC_WITH_LOOP", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/callbacks.py", "signature_position": [389, 389], "body_position": [390, 400], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "The function creates a wrapper for the given function to be executed asynchronously with the given event loop. It first checks if the loop is provided, if not, it gets the default event loop. Then, it creates a wrapper for the given function to be executed asynchronously with the provided loop.", "Arguments": ":param cls: Class. The class instance.\n:param loop: Event loop. The event loop to be used for asynchronous execution. Defaults to None.\n:return: Wrapper function. The wrapper function for the given function to be executed asynchronously with the provided loop."}, "tests": ["tests/test_callbacks.py::TestAdHocSignal::test_connect_async", "tests/test_callbacks.py::TestAdHocSignal::test_ASYNC_WITH_LOOP_rejects_non_callable"], "indent": 8}
{"namespace": "aioxmpp.callbacks.AdHocSignal.SPAWN_WITH_LOOP", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/callbacks.py", "signature_position": [431, 431], "body_position": [432, 450], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a spawn function that can be used to spawn a coroutine function. It ensures that the function is a coroutine and then adds a done callback to the task to log the spawned task.", "Arguments": ":param cls: AdHocSignal. The class instance.\n:param loop: The event loop to be used. If not specified, the default event loop is used.\n:return: The spawn function."}, "tests": ["tests/test_callbacks.py::TestAdHocSignal::test_connect_spawn", "tests/test_callbacks.py::TestAdHocSignal::test_SPAWN_rejects_non_coroutine", "tests/test_callbacks.py::TestAdHocSignal::test_connect_spawn_emits_always"], "indent": 8}
{"namespace": "aioxmpp.callbacks.first_signal", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/callbacks.py", "signature_position": [850, 850], "body_position": [892, 895], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function connects to multiple signals and waits for the first signal to emit. It returns an awaitable for the first signal to emit. The awaitable returns the first argument passed to the signal. If the first argument is an exception, the exception is re-raised from the awaitable.", "Arguments": ":param signals: Signals to connect to. It can be of type AdHocSignal.\n:return: An awaitable for the first signal to emit."}, "tests": ["tests/test_callbacks.py::Testfirst_signal::test_works_for_common_use_case_with_success", "tests/test_callbacks.py::Testfirst_signal::test_works_for_common_use_case_with_exception", "tests/test_callbacks.py::Testfirst_signal::test_connects_future_to_both_and_returns_future"], "indent": 4}
{"namespace": "aioxmpp.tasks.TaskPool.spawn", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/tasks.py", "signature_position": [165, 165], "body_position": [198, 200], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function starts a new coroutine and adds it to the pool atomically. It checks if the groups have free slots available for the coroutine to be spawned and raises a RuntimeError if the limit on any of the groups or the total limit is exhausted.", "Arguments": ":param self: TaskPool. An instance of the TaskPool class.\n:param __groups: Set of group keys. The groups the coroutine belongs to.\n:param __coro_fun: Coroutine function to run.\n:param args: Positional arguments to pass to `coro_fun`.\n:param kwargs: Keyword arguments to pass to `coro_fun`.\n:raise RuntimeError: If the limit on any of the groups or the total limit is exhausted.\n:return: asyncio.Task. The task in which the coroutine runs."}, "tests": ["tests/test_tasks.py::TestTaskPool::test_spawn_accounting", "tests/test_tasks.py::TestTaskPool::test_spawn_starts_coroutine_and_returns_task"], "indent": 8}
{"namespace": "aioxmpp.protocol.send_and_wait_for", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/protocol.py", "signature_position": [872, 874], "body_position": [875, 920], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sends a message and waits for a response. It sends a message to the xmlstream and waits for a response. If the response is not received within the specified timeout, a TimeoutError is raised.", "Arguments": ":param xmlstream: The xmlstream to send the message to and wait for a response.\n:param send: The message to be sent.\n:param wait_for: The response to wait for.\n:param timeout: The time to wait for the response. If None, it waits indefinitely.\n:param cb: The callback function to be called when a response is received.\n:return: The response received from the xmlstream."}, "tests": ["tests/test_protocol.py::Testsend_and_wait_for::test_handles_setup_issues_properly", "tests/test_protocol.py::Testsend_and_wait_for::test_handles_send_issues_properly", "tests/test_protocol.py::Testsend_and_wait_for::test_receive_handler_invokes_cb"], "indent": 4}
{"namespace": "aioxmpp.testutils.run_coroutine_with_peer", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/testutils.py", "signature_position": [91, 95], "body_position": [96, 135], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Run the given coroutine and its peer coroutine concurrently with a timeout. It waits for both coroutines to complete and raises a timeout error if the timeout is reached.", "Arguments": ":param coroutine: Coroutine. The coroutine to be run.\n:param peer_coroutine: Coroutine. The peer coroutine to be run concurrently.\n:param timeout: Float. The maximum time to wait for the coroutines to complete. Defaults to 1.0.\n:param loop: Event loop. The event loop to run the coroutines. Defaults to None.\n:return: The result of the local future."}, "tests": ["tests/test_highlevel.py::TestProtocol::test_malformed_sm_failed_does_not_cause_loop", "tests/test_highlevel.py::TestProtocol::test_sm_bootstrap_race", "tests/test_highlevel.py::TestProtocol::test_sm_works_correctly_with_invalid_payload", "tests/test_highlevel.py::TestProtocol::test_sm_works_correctly_with_entirely_broken_stanza", "tests/test_testutils.py::TestTransportMock::test_starttls"], "indent": 4}
{"namespace": "aioxmpp.testutils.make_listener", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/testutils.py", "signature_position": [138, 138], "body_position": [145, 159], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a unittest.mock.Mock object which has children connected to each aioxmpp.callbacks.Signal of the given instance. The children are named exactly like the signals.", "Arguments": ":param instance: The instance for which the listener is to be created.\n:return: unittest.mock.Mock. The created mock object with children connected to each signal of the instance."}, "tests": ["tests/test_testutils.py::Testmake_listener::test_connects_to_signals", "tests/test_testutils.py::Testmake_listener::test_connects_to_signals_of_base_class", "tests/test_testutils.py::Testmake_listener::test_handles_overridden_attributes", "tests/muc/test_service.py::TestService::test_on_failure_is_emitted_on_join_error", "tests/muc/test_service.py::TestService::test_on_failure_is_emitted_on_stream_destruction_without_autorejoin"], "indent": 4}
{"namespace": "aioxmpp.vcard.service.VCardService.set_vcard", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/vcard/service.py", "signature_position": [69, 69], "body_position": [86, 91], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function stores the vCard `vcard` for the connected entity. It creates an IQ instance with the vCard payload and sends it to the client.", "Arguments": ":param self: VCardService. An instance of the VCardService class.\n:param vcard: The vCard to store.\n:param jid: The JID to which the vCard is to be stored. Defaults to None.\n:return: No return value."}, "tests": ["tests/vcard/test_service.py::TestService::test_set_vcard_for_foreign_jid", "tests/vcard/test_service.py::TestService::test_set_vcard"], "indent": 8}
{"namespace": "aioxmpp.rsm.xso.ResultSetMetadata.limit", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/rsm/xso.py", "signature_position": [217, 217], "body_position": [232, 237], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Limit the result set to a given number of items. It creates a new request set up to request at most `max_` items.", "Arguments": ":param self: ResultSetMetadata. An instance of the ResultSetMetadata class.\n:param max_: Maximum number of items to return.\n:return: A new request set up to request at most `max_` items."}, "tests": ["tests/rsm/test_xso.py::TestResultSetMetadata::test_limit_cls", "tests/rsm/test_xso.py::TestResultSetMetadata::test_limit_before_after_obj", "tests/rsm/test_xso.py::TestResultSetMetadata::test_limit_index_obj"], "indent": 8}
{"namespace": "aioxmpp.muc.service.Room.features", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/muc/service.py", "signature_position": [1019, 1019], "body_position": [1026, 1036], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a set of features supported by the MUC (Multi-User Chat) instance. The features may vary depending on the features exported by the MUC service.", "Arguments": ":param self: Room. An instance of the Room class.\n:return: Set. The set of features supported by the MUC instance."}, "tests": ["tests/muc/test_service.py::TestRoom::test_features", "tests/muc/test_service.py::TestRoom::test_expose_invite_features"], "indent": 8}
{"namespace": "aioxmpp.xso.query.EvaluationContext.eval_bool", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/xso/query.py", "signature_position": [168, 168], "body_position": [174, 184], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Evaluate the expression `expr` and return the truthness of its result. A result of an expression is said to be true if it contains at least one value. It has the same semantics as :func:`bool` on sequences.", "Arguments": ":param self: EvaluationContext. An instance of the EvaluationContext class.\n:param expr: The expression to be evaluated.\n:return: Boolean. The truthness of the evaluated expression."}, "tests": ["tests/xso/test_query.py::TestEvaluationContext::test_eval_bool_with_false_sequence", "tests/xso/test_query.py::TestEvaluationContext::test_eval_bool_with_true_generator", "tests/xso/test_query.py::TestEvaluationContext::test_eval_bool_with_false_generator", "tests/xso/test_query.py::TestEvaluationContext::test_eval_bool_with_true_sequence"], "indent": 8}
{"namespace": "aioxmpp.xso.query._BoolOpMixin.eval", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/xso/query.py", "signature_position": [341, 341], "body_position": [342, 343], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function evaluates the given expression context and yields True if the leaf is evaluated to True.", "Arguments": ":param self: _BoolOpMixin. An instance of the _BoolOpMixin class.\n:param ec: The expression context to be evaluated.\n:return: True if the leaf is evaluated to True."}, "tests": ["tests/xso/test_query.py::TestCmpOp::test_eval_returns_list_with_single_True_on_true", "tests/xso/test_query.py::TestNotOp::test_eval_returns_empty_list_on_false", "tests/xso/test_query.py::TestCmpOp::test_eval_returns_empty_list_on_false", "tests/xso/test_query.py::TestNotOp::test_eval_returns_list_with_single_True_on_true"], "indent": 8}
{"namespace": "aioxmpp.xso.model.drop_handler", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/xso/model.py", "signature_position": [2681, 2681], "body_position": [2682, 2688], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a generator that drops events until the depth is zero. It yields events until the depth is zero.", "Arguments": ":param ev_args: The event arguments.\n:return: No return values."}, "tests": ["tests/xso/test_model.py::Testdrop_handler::test_drop_handler"], "indent": 4}
{"namespace": "aioxmpp.xso.model.guard", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/xso/model.py", "signature_position": [2702, 2702], "body_position": [2703, 2722], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a generator that guards the destination generator. It sends events to the destination generator and returns the value of the destination generator when it is done. It also handles the exception and ensures that the depth is zero when the function is done.", "Arguments": ":param dest: The destination generator to be guarded.\n:param ev_args: The events to be sent to the destination generator.\n:return: The value of the destination generator when it is done."}, "tests": ["tests/xso/test_model.py::Testguard::test_return_only_after_end_even_on_exception_and_reraise", "tests/xso/test_model.py::Testguard::test_forward_to_argument_and_return_after_end", "tests/xso/test_model.py::Testguard::test_handles_increasing_nesting_while_dropping", "tests/xso/test_model.py::Testguard::test_eat_end_after_exception_on_start", "tests/xso/test_model.py::Testguard::test_handles_increasing_nesting_while_after_error_during_start"], "indent": 4}
{"namespace": "aioxmpp.xso.model.capture_events", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/xso/model.py", "signature_position": [2736, 2736], "body_position": [2755, 2798], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Capture all events sent to `receiver` in the sequence `dest`. This is a generator, and it is best used with ``yield from``. The observable effect of using this generator with ``yield from`` is identical to the effect of using `receiver` with ``yield from`` directly (including the return value), but in addition, the values which are *sent* to the receiver are captured in `dest`.\nIf `receiver` raises an exception or the generator is closed prematurely using its :meth:`close`, `dest` is cleared.\nThis is used to implement :class:`CapturingXSO`. See the documentation there for use cases.", "Arguments": ":param receiver: The receiver to capture events from.\n:param dest: The sequence to capture the events in.\n:return: return the value of the yield from generator."}, "tests": ["tests/xso/test_model.py::Testcapture_events::test_capture_initiation", "tests/xso/test_model.py::Testcapture_events::test_capture_and_forward_events", "tests/xso/test_model.py::Testcapture_events::test_clear_destination_on_exception", "tests/xso/test_model.py::Testcapture_events::test_clear_destination_on_exception_during_startup", "tests/xso/test_model.py::Testcapture_events::test_clear_destination_on_close_while_active"], "indent": 4}
{"namespace": "aioxmpp.xso.model.events_to_sax", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/xso/model.py", "signature_position": [2801, 2801], "body_position": [2806, 2817], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts an iterable `events` of XSO events to SAX events by calling the matching SAX methods on `dest`. It iterates through the events and calls the corresponding SAX methods on `dest` based on the event type.", "Arguments": ":param events: Iterable. An iterable of XSO events.\n:param dest: Object. The destination object on which the matching SAX methods will be called.\n:return: No return values."}, "tests": ["tests/xso/test_model.py::Testevents_to_sax::test_start", "tests/xso/test_model.py::Testevents_to_sax::test_start_and_end", "tests/xso/test_model.py::Testevents_to_sax::test_text", "tests/xso/test_model.py::Testevents_to_sax::test_nested_stuff"], "indent": 4}
{"namespace": "aioxmpp.adhoc.service.AdHocClient.get_command_info", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/adhoc/service.py", "signature_position": [93, 93], "body_position": [115, 120], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function obtains information about a command from a peer. It sends a service discovery query to the service discovery node of the command and returns the service discovery information about the command.", "Arguments": ":param self: AdHocClient. An instance of the AdHocClient class.\n:param peer_jid: JID. The JID of the peer to query.\n:param command_name: String. The node name of the command.\n:return: InfoQuery. Service discovery information about the command."}, "tests": ["tests/adhoc/test_service.py::TestAdHocClient::test_get_command_info_uses_disco"], "indent": 8}
{"namespace": "aioxmpp.entitycaps.caps115.build_identities_string", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps115.py", "signature_position": [34, 34], "body_position": [35, 50], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function builds a string of identities based on the given list of identities. It first processes each identity in the list and encodes it into a byte string. Then, it checks for duplicate identities and sorts the identities before joining them into a single byte string.", "Arguments": ":param identities: List of Identity. A list of identity objects.\n:return: Byte string. The concatenated byte string of identities which is seperated by '<'."}, "tests": ["tests/entitycaps/test_caps115.py::Testbuild_identities_string::test_escaping", "tests/entitycaps/test_caps115.py::Testbuild_identities_string::test_identities", "tests/entitycaps/test_caps115.py::Testbuild_identities_string::test_reject_duplicate_identities"], "indent": 4}
{"namespace": "aioxmpp.entitycaps.caps115.build_features_string", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps115.py", "signature_position": [53, 53], "body_position": [54, 61], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function builds a string of features. It first escapes each feature and encodes it in utf-8. Then, it checks for duplicate features and raises a ValueError if found. Finally, it sorts the features and joins them with \"<\".", "Arguments": ":param features: List. A list of features to be processed.\n:return: Bytes. The built features string which is seperated by '<'."}, "tests": ["tests/entitycaps/test_caps115.py::Testbuild_features_string::test_escaping", "tests/entitycaps/test_caps115.py::Testbuild_features_string::test_reject_duplicate_features", "tests/entitycaps/test_caps115.py::Testbuild_features_string::test_features"], "indent": 4}
{"namespace": "aioxmpp.entitycaps.caps115.build_forms_string", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps115.py", "signature_position": [64, 64], "body_position": [65, 110], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function builds a string of forms based on the input forms. It first processes the input forms and builds a list of forms. Then, it sorts the forms and builds a string based on the sorted forms.", "Arguments": ":param forms: List. A list of forms to be processed.\n:return: Bytes. The built string of forms, and the different parts are seperated by '<'."}, "tests": ["tests/entitycaps/test_caps115.py::Testbuild_forms_string::test_value_and_var_escaping", "tests/entitycaps/test_caps115.py::Testbuild_forms_string::test_reject_form_with_multiple_different_types", "tests/entitycaps/test_caps115.py::Testbuild_forms_string::test_reject_multiple_identical_form_types", "tests/entitycaps/test_caps115.py::Testbuild_forms_string::test_ignore_form_without_type", "tests/entitycaps/test_caps115.py::Testbuild_forms_string::test_xep_form"], "indent": 4}
{"namespace": "aioxmpp.entitycaps.caps115.Key.path", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps115.py", "signature_position": [133, 133], "body_position": [134, 136], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Return the path of the key. It first quotes the node and then returns the path of the key based on the quoted node, algorithm, and the directory \"hashes\".", "Arguments": ":param self: Key. An instance of the Key class.\n:return: Path. The path of the key, which is a pathlib.Path object."}, "tests": ["tests/entitycaps/test_caps115.py::TestKey::test_path_uses_urlescape", "tests/entitycaps/test_caps115.py::TestKey::test_path"], "indent": 8}
{"namespace": "aioxmpp.entitycaps.caps390._process_features", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [33, 33], "body_position": [45, 50], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates the `Features String` from an iterable of features. It encodes the features into bytes and concatenates them to form the `Features String`.", "Arguments": ":param features: Iterable of str. The features to generate the features string from.\n:return: bytes. The `Features String` as bytes."}, "tests": ["tests/entitycaps/test_caps390.py::Test_process_features::test_on_large_testcase", "tests/entitycaps/test_caps390.py::Test_process_features::test_on_small_testcase"], "indent": 4}
{"namespace": "aioxmpp.entitycaps.caps390._process_identities", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [62, 62], "body_position": [75, 80], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates the `Identities String` from an iterable of identities. It processes each identity in the iterable and generates the `Identities String` as specified in :xep:`390`.", "Arguments": ":param identities: Iterable. The identities to generate the features string from. It is an iterable of Identity objects.\n:return: Bytes. The `Identities String` generated from the given `identities`."}, "tests": ["tests/entitycaps/test_caps390.py::Test_process_identities::test_on_large_testcase", "tests/entitycaps/test_caps390.py::Test_process_identities::test_on_small_testcase"], "indent": 4}
{"namespace": "aioxmpp.entitycaps.caps390._process_extensions", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [103, 103], "body_position": [116, 121], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Generate the `Extensions String` from an iterable of data forms. It generates the `Extensions String` from the given `exts` as specified in :xep:`390`.", "Arguments": ":param exts: The data forms to generate the extensions string from.\n:type exts: :class:`~collections.abc.Iterable` of :class:`~.forms.xso.Data`.\n:return: The `Extensions String` as `bytes`."}, "tests": ["tests/entitycaps/test_caps390.py::Test_process_extensions::test_on_small_testcase", "tests/entitycaps/test_caps390.py::Test_process_extensions::test_on_large_testcase"], "indent": 4}
{"namespace": "aioxmpp.entitycaps.caps390._calculate_hash", "type": "function", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [132, 132], "body_position": [133, 135], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Calculate the hash of the given input using the specified algorithm.", "Arguments": ":param algo: String. The algorithm to be used for hashing.\n:param hash_input: The input data to be hashed.\n:return: The hash of the input data using the specified algorithm."}, "tests": ["tests/entitycaps/test_caps390.py::TestKey::test_verify_large_input_precalculated", "tests/entitycaps/test_caps390.py::Test_calculate_hash::test_uses_and_hash_from_algo", "tests/entitycaps/test_caps390.py::TestKey::test_verify_small_input", "tests/entitycaps/test_caps390.py::TestKey::test_verify_small_input_precalculated", "tests/entitycaps/test_caps390.py::TestKey::test_verify_large_input"], "indent": 4}
{"namespace": "aioxmpp.entitycaps.caps390.Key.node", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [143, 143], "body_position": [144, 147], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a node string based on the algorithm and digest of the Key instance.", "Arguments": ":param self: Key. An instance of the Key class.\n:return: String. The node string based on the algorithm and digest of the Key instance."}, "tests": ["tests/entitycaps/test_caps390.py::TestKey::test_node"], "indent": 8}
{"namespace": "aioxmpp.entitycaps.caps390.Key.path", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [150, 150], "body_position": [151, 158], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a path based on the given Key instance. It encodes the digest of the key and constructs a path using the encoded digest, algorithm, and file extension.", "Arguments": ":param self: Key. An instance of the Key class.\n:return: Path. The generated path based on the key instance."}, "tests": ["tests/entitycaps/test_caps390.py::TestKey::test_path", "tests/entitycaps/test_caps390.py::TestKey::test_path_urlencodes_algo"], "indent": 8}
{"namespace": "aioxmpp.entitycaps.caps390.Implementation.extract_keys", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/entitycaps/caps390.py", "signature_position": [172, 172], "body_position": [173, 180], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Extracts the keys from the presence instance if the xep0390_caps is not None. It returns the keys if the presence object contain information about the entity's capabilities, else it returns an empty generator.", "Arguments": ":param self: Implementation. An instance of the Implementation class.\n:param presence: Presence. The presence instance from which the keys are to be extracted.\n:return: The extracted keys as Tuple."}, "tests": ["tests/entitycaps/test_caps390.py::TestImplementation::test_extract_keys_returns_empty_if_caps_is_None", "tests/entitycaps/test_caps390.py::TestImplementation::test_extract_keys_creates_Key_objects_from_digests_and_checks_for_support"], "indent": 8}
{"namespace": "aioxmpp.roster.service.RosterClient.approve", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/roster/service.py", "signature_position": [693, 693], "body_position": [712, 715], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Approve a subscription request from the peer_jid. It sends a \"subscribed\" presence to the peer. If the peer has previously asked for a subscription, this will seal the deal and create the subscription. If the peer has not requested a subscription yet, it is marked as pre-approved by the server. A future subscription request by the peer will then be confirmed by the server automatically.", "Arguments": ":param self: RosterClient. An instance of the RosterClient class.\n:param peer_jid: The peer to (pre-)approve.\n:return: No return value."}, "tests": ["tests/roster/test_service.py::TestService::test_approve_sends_subscribed_presence"], "indent": 8}
{"namespace": "aioxmpp.roster.service.RosterClient.subscribe", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/roster/service.py", "signature_position": [717, 717], "body_position": [726, 729], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Request presence subscription with the given `peer_jid`. This is deliberately not a coroutine; we don\u2019t know whether the peer is online (usually) and they may defer the confirmation very long, if they confirm at all. Use :meth:`on_subscribed` to get notified when a peer accepted a subscription request.", "Arguments": ":param self: RosterClient. An instance of the RosterClient class.\n:param peer_jid: The peer JID to subscribe to.\n:return: No return values."}, "tests": ["tests/roster/test_service.py::TestService::test_subscribe_sends_subscribe_presence"], "indent": 8}
{"namespace": "aioxmpp.roster.service.RosterClient.unsubscribe", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/roster/service.py", "signature_position": [731, 731], "body_position": [735, 738], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Unsubscribe from the presence of the given `peer_jid`.", "Arguments": ":param self: RosterClient. An instance of the RosterClient class.\n:param peer_jid: The JID of the peer to unsubscribe from.\n:return: No return values."}, "tests": ["tests/roster/test_service.py::TestService::test_unsubscribe_sends_unsubscribe_presence"], "indent": 8}
{"namespace": "aioxmpp.forms.fields.BoundSingleValueField.value", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/forms/fields.py", "signature_position": [333, 333], "body_position": [334, 337], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Delete the value of the BoundSingleValueField instance if it exists.", "Arguments": ":param self: BoundSingleValueField. An instance of the BoundSingleValueField class.\n:return: No return values."}, "tests": ["tests/forms/test_fields.py::TestBoundSingleValueField::test_deleting_reverts_to_initial_behaviour"], "indent": 8}
{"namespace": "aioxmpp.forms.fields.BoundMultiValueField.value", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/forms/fields.py", "signature_position": [409, 409], "body_position": [410, 413], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to delete the value of the BoundMultiValueField instance.", "Arguments": ":param self: BoundMultiValueField. An instance of the BoundMultiValueField class.\n:return: No return values."}, "tests": ["tests/forms/test_fields.py::TestBoundMultiValueField::test_deleting_reverts_to_initial_behaviour"], "indent": 8}
{"namespace": "aioxmpp.forms.fields.BoundOptionsField.options", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/forms/fields.py", "signature_position": [510, 510], "body_position": [511, 514], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes the options attribute from the BoundOptionsField instance if it exists.", "Arguments": ":param self: BoundOptionsField. An instance of the BoundOptionsField class.\n:return: No return values."}, "tests": ["tests/forms/test_fields.py::TestBoundOptionsField::test_delete_resets_options_to_field"], "indent": 8}
{"namespace": "aioxmpp.forms.fields.BoundSelectField.value", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/forms/fields.py", "signature_position": [577, 577], "body_position": [578, 581], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function deletes the value of the BoundSelectField instance if it exists.", "Arguments": ":param self: BoundSelectField. An instance of the BoundSelectField class.\n:return: No return values."}, "tests": ["tests/forms/test_fields.py::TestBoundSelectField::test_deleting_reverts_to_initial_behaviour"], "indent": 8}
{"namespace": "aioxmpp.forms.fields.BoundMultiSelectField.value", "type": "method", "project_path": "Communications/aioxmpp", "completion_path": "Communications/aioxmpp/aioxmpp/forms/fields.py", "signature_position": [655, 655], "body_position": [656, 659], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function deletes the value of the BoundMultiSelectField instance if it exists.", "Arguments": ":param self: BoundMultiSelectField. An instance of the BoundMultiSelectField class.\n:return: No return values."}, "tests": ["tests/forms/test_fields.py::TestBoundMultiSelectField::test_deleting_reverts_to_initial_behaviour"], "indent": 8}
{"namespace": "datasets.table._in_memory_arrow_table_from_buffer", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/table.py", "signature_position": [42, 42], "body_position": [43, 46], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create an in-memory Arrow table from the given buffer. It first creates a BufferReader instance from the buffer and then opens a stream from it. Finally, it reads all the data from the stream and returns it as a table.", "Arguments": ":param buffer: pa.Buffer. The buffer from which the in-memory Arrow table is to be created.\n:return: pa.Table. The in-memory Arrow table created from the buffer."}, "tests": ["tests/test_table.py::test_in_memory_arrow_table_from_buffer"], "indent": 4}
{"namespace": "datasets.table._interpolation_search", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/table.py", "signature_position": [90, 90], "body_position": [104, 113], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the position i of a sorted array so that arr[i] <= x < arr[i+1]. Raise `IndexError` if the array is empty or if the query is outside the array values.", "Arguments": ":param arr: List[int]. A non-empty sorted list of integers.\n:param x: int. The query.\n:return: int. The position i so that arr[i] <= x < arr[i+1]."}, "tests": ["tests/test_table.py::test_interpolation_search"], "indent": 4}
{"namespace": "datasets.data_files._is_inside_unrequested_special_dir", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/data_files.py", "signature_position": [135, 135], "body_position": [163, 165], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if a path is inside a special directory that is ignored by default. It also checks if the path is explicitly requested inside such a directory.", "Arguments": ":param matched_rel_path: str. The path to be checked.\n:param pattern: str. The pattern to be matched.\n:return: bool. True if the path is inside an unrequested special directory, False otherwise."}, "tests": ["tests/test_data_files.py::test_is_inside_unrequested_special_dir", "tests/test_data_files.py::test_is_unrequested_hidden_file_or_is_inside_unrequested_hidden_dir"], "indent": 4}
{"namespace": "datasets.data_files._is_unrequested_hidden_file_or_is_inside_unrequested_hidden_dir", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/data_files.py", "signature_position": [168, 168], "body_position": [221, 227], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if a path matches a pattern and if it's a hidden file or inside a hidden directory that is ignored by default.", "Arguments": ":param matched_rel_path: str. The path to be checked.\n:param pattern: str. The pattern to be matched.\n:return: bool. True if the path is a hidden file or inside a hidden directory that is ignored by default, False otherwise."}, "tests": ["tests/test_data_files.py::test_is_unrequested_hidden_file_or_is_inside_unrequested_hidden_dir"], "indent": 4}
{"namespace": "datasets.iterable_dataset._batch_to_examples", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/iterable_dataset.py", "signature_position": [78, 78], "body_position": [80, 82], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a batch (dict of examples) to a list of examples. It iterates through the batch and creates a list of examples.", "Arguments": ":param batch: Dict. A dictionary of examples.\n:return: List of Dict. A list of examples."}, "tests": ["tests/test_iterable_dataset.py::test_mapped_examples_iterable", "tests/test_iterable_dataset.py::test_mapped_examples_iterable_drop_last_batch", "tests/test_iterable_dataset.py::test_mapped_examples_iterable_remove_columns", "tests/test_iterable_dataset.py::test_mapped_examples_iterable_with_indices", "tests/test_iterable_dataset.py::test_mapped_examples_iterable_fn_kwargs"], "indent": 4}
{"namespace": "datasets.iterable_dataset._examples_to_batch", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/iterable_dataset.py", "signature_position": [69, 71], "body_position": [72, 75], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts a list of dictionaries into a dictionary of lists. It first creates a set of columns based on the input examples. Then, it creates a list of lists where each list contains the values of a specific column from the input examples. Finally, it zips the columns and arrays into a dictionary.", "Arguments": ":param examples: List of dictionaries. The input list of dictionaries.\n:return: Dictionary of lists. The converted dictionary of lists."}, "tests": ["tests/test_iterable_dataset.py::test_mapped_examples_iterable", "tests/test_iterable_dataset.py::test_mapped_examples_iterable_drop_last_batch", "tests/test_iterable_dataset.py::test_mapped_examples_iterable_remove_columns", "tests/test_iterable_dataset.py::test_mapped_examples_iterable_with_indices", "tests/test_iterable_dataset.py::test_mapped_examples_iterable_fn_kwargs"], "indent": 4}
{"namespace": "datasets.iterable_dataset.RandomlyCyclingMultiSourcesExamplesIterable._iter_random_indices", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/iterable_dataset.py", "signature_position": [601, 606], "body_position": [608, 613], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns an infinite iterator that randomly samples the index of the source to pick examples from. It uses the numpy random number generator to achieve this.", "Arguments": ":param rng: np.random.Generator. The random number generator to be used.\n:param num_sources: int. The number of sources to pick examples from.\n:param random_batch_size: int. The size of the random batch. Defaults to 1000.\n:param p: List of float. The probabilities associated with each entry in the num_sources. Defaults to None.\n:return: Iterator of int. An infinite iterator that randomly samples the index of the source to pick examples from."}, "tests": ["tests/test_iterable_dataset.py::test_randomly_cycling_multi_sources_examples_iterable", "tests/test_iterable_dataset.py::test_interleave_datasets"], "indent": 8}
{"namespace": "datasets.iterable_dataset.BufferShuffledExamplesIterable._iter_random_indices", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/iterable_dataset.py", "signature_position": [972, 972], "body_position": [973, 974], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a generator that yields random indices from a buffer of shuffled examples. It uses a random number generator to generate random indices and yields them in batches.", "Arguments": ":param rng: np.random.Generator. A random number generator.\n:param buffer_size: int. The size of the buffer.\n:param random_batch_size: int. The size of the random batch to be generated. Defaults to 1000.\n:return: Iterator[int]. An iterator that yields random indices."}, "tests": ["tests/test_iterable_dataset.py::test_iterable_dataset_shuffle", "tests/test_iterable_dataset.py::test_buffer_shuffled_examples_iterable"], "indent": 8}
{"namespace": "datasets.iterable_dataset.IterableDataset.remove_columns", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/iterable_dataset.py", "signature_position": [1990, 1990], "body_position": [2015, 2028], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Remove one or several column(s) in the dataset and the features associated with them. The removal is done on-the-fly on the examples when iterating over the dataset.", "Arguments": ":param self: IterableDataset. An instance of the IterableDataset class.\n:param column_names (`Union[str, List[str]]`): Name of the column(s) to remove.\n:return: `IterableDataset`: A copy of the dataset object without the columns to remove."}, "tests": ["tests/test_iterable_dataset.py::test_concatenate_datasets_axis_1_resolves_features", "tests/test_iterable_dataset.py::test_concatenate_datasets_axis_1", "tests/test_iterable_dataset.py::test_concatenate_datasets_axis_1_with_different_lengths"], "indent": 8}
{"namespace": "datasets.dataset_dict.DatasetDict.with_format", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/dataset_dict.py", "signature_position": [643, 649], "body_position": [691, 693], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set the `__getitem__` return format (type and columns) for the dataset. The data formatting is applied on-the-fly. The format `type` (for example \"numpy\") is used to format batches when using `__getitem__`. The format is set for every dataset in the dataset dictionary.", "Arguments": ":param type: Optional string. Output type selected in `[None, 'numpy', 'torch', 'tensorflow', 'pandas', 'arrow', 'jax']`. `None` means `__getitem__` returns python objects (default).\n:param columns: Optional list of strings. Columns to format in the output. `None` means `__getitem__` returns all columns (default).\n:param output_all_columns: Bool. Keep un-formatted columns as well in the output (as python objects). Defaults to `False`.\n:param **format_kwargs: Additional keyword arguments. Keywords arguments passed to the convert function like `np.array`, `torch.tensor` or `tensorflow.ragged.constant`.\n:return: DatasetDict. A new `DatasetDict` object with new `Dataset` objects."}, "tests": ["tests/test_dataset_dict.py::DatasetDictTest::test_with_format"], "indent": 8}
{"namespace": "datasets.dataset_dict.DatasetDict.with_transform", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/dataset_dict.py", "signature_position": [695, 700], "body_position": [745, 747], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set `__getitem__` return format using this transform. The transform is applied on-the-fly on batches when `__getitem__` is called. The transform is set for every dataset in the dataset dictionary. It returns a new `DatasetDict` object with new `Dataset` objects.", "Arguments": ":param self: DatasetDict. An instance of the DatasetDict class.\n:param transform: Callable. User-defined formatting transform, replaces the format defined by [`~datasets.Dataset.set_format`].\n:param columns: List of string. Columns to format in the output. If specified, then the input batch of the transform only contains those columns.\n:param output_all_columns: Bool. Keep un-formatted columns as well in the output (as python objects). If set to `True`, then the other un-formatted columns are kept with the output of the transform.\n:return: \"DatasetDict\". The new `DatasetDict` object with new `Dataset` objects."}, "tests": ["tests/test_dataset_dict.py::DatasetDictTest::test_with_transform"], "indent": 8}
{"namespace": "datasets.dataset_dict.DatasetDict.align_labels_with_mapping", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/dataset_dict.py", "signature_position": [1549, 1549], "body_position": [1550, 1556], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Align the labels with the given mapping. It aligns the labels of the dataset with the given label2id mapping based on the label_column.", "Arguments": ":param self: DatasetDict. An instance of the DatasetDict class.\n:param label2id: Dict. A dictionary that maps labels to ids.\n:param label_column: String. The name of the label column.\n:return: DatasetDict. The updated DatasetDict instance."}, "tests": ["tests/test_dataset_dict.py::DatasetDictTest::test_align_labels_with_mapping"], "indent": 8}
{"namespace": "datasets.dataset_dict.IterableDatasetDict.map", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/dataset_dict.py", "signature_position": [1785, 1795], "body_position": [1858, 1872], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Apply a function to all the examples in the iterable dataset (individually or in batches) and update them. The function is applied on-the-fly on the examples when iterating over the dataset. The transformation is applied to all the datasets of the dataset dictionary.", "Arguments": ":param self: IterableDatasetDict. An instance of the IterableDatasetDict class.\n:param function: `Callable`, *optional*, defaults to `None`. Function applied on-the-fly on the examples when you iterate on the dataset.\n:param with_indices: `bool`, defaults to `False`. Provide example indices to `function`.\n:param input_columns: `[Union[str, List[str]]`, *optional*, defaults to `None`. The columns to be passed into `function` as positional arguments.\n:param batched: `bool`, defaults to `False`. Provide batch of examples to `function`.\n:param batch_size: `int`, *optional*, defaults to `1000`. Number of examples per batch provided to `function` if `batched=True`.\n:param drop_last_batch: `bool`, defaults to `False`. Whether a last batch smaller than the `batch_size` should be dropped instead of being processed by the function.\n:param remove_columns: `[List[str]]`, *optional*, defaults to `None`. Remove a selection of columns while doing the mapping.\n:param fn_kwargs: `Dict`, *optional*, defaults to `None`. Keyword arguments to be passed to `function`.\n:return: \"IterableDatasetDict\". The updated IterableDatasetDict instance."}, "tests": ["tests/test_dataset_dict.py::DatasetDictTest::test_iterable_map"], "indent": 8}
{"namespace": "datasets.dataset_dict.IterableDatasetDict.filter", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/dataset_dict.py", "signature_position": [1874, 1882], "body_position": [1923, 1935], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Apply a filter function to all the elements so that the dataset only includes examples according to the filter function. The filtering is done on-the-fly when iterating over the dataset. The filtering is applied to all the datasets of the dataset dictionary.", "Arguments": ":param self: IterableDatasetDict. An instance of the IterableDatasetDict class.\n:param function: Optional Callable. A function that filters the examples in the dataset. Defaults to an always True function if not provided.\n:param with_indices: Bool. Provide example indices to the function. Note that in this case the signature of the function should be def function(example, idx): ...\n:param input_columns: Optional Union of string or list of strings. The columns to be passed into the function as positional arguments. If None, a dict mapping to all formatted columns is passed as one argument.\n:param batched: Bool. Provide batch of examples to the function.\n:param batch_size: Optional int. Number of examples per batch provided to the function if batched=True.\n:param fn_kwargs: Optional dict. Keyword arguments to be passed to the function.\n:return: IterableDatasetDict. The filtered dataset dictionary."}, "tests": ["tests/test_dataset_dict.py::DatasetDictTest::test_iterable_filter"], "indent": 8}
{"namespace": "datasets.arrow_dataset.Dataset.num_rows", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/arrow_dataset.py", "signature_position": [1788, 1788], "body_position": [1800, 1802], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the number of rows in the dataset. It first checks if the indices are not None and returns the number of rows from the indices. If the indices are None, it returns the number of rows from the data.", "Arguments": ":param self: Dataset. An instance of the Dataset class.\n:return: int. The number of rows in the dataset."}, "tests": ["tests/test_arrow_reader.py::BaseReaderTest::test_read_files", "tests/test_arrow_reader.py::BaseReaderTest::test_read_sharded", "tests/test_arrow_reader.py::BaseReaderTest::test_read"], "indent": 8}
{"namespace": "datasets.filesystems.extract_path_from_uri", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/filesystems/__init__.py", "signature_position": [33, 33], "body_position": [41, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function preprocesses the `dataset_path` and removes the remote filesystem (e.g. removing `s3://`).", "Arguments": ":param dataset_path: str. The path or remote uri of the dataset directory.\n:return: str. The preprocessed dataset path."}, "tests": ["tests/test_filesystem.py::test_extract_path_from_uri"], "indent": 4}
{"namespace": "datasets.filesystems.is_remote_filesystem", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/filesystems/__init__.py", "signature_position": [46, 46], "body_position": [54, 58], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the given filesystem has a remote protocol.", "Arguments": ":param fs: fsspec.AbstractFileSystem. An abstract super-class for pythonic file-systems, e.g. `fsspec.filesystem('file')` or [`datasets.filesystems.S3FileSystem`].\n:return: bool. True if the filesystem has a remote protocol, False otherwise."}, "tests": ["tests/test_filesystem.py::test_is_remote_filesystem"], "indent": 4}
{"namespace": "datasets.utils.file_utils.hash_url_to_filename", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/file_utils.py", "signature_position": [125, 125], "body_position": [134, 146], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a URL and an optional etag and converts the URL into a hashed filename in a repeatable way. If the etag is specified, it appends its hash to the URL's hash, delimited by a period. If the URL ends with .h5 (Keras HDF5 weights), it adds '.h5' to the name so that TF 2.0 can identify it as an HDF5 file.", "Arguments": ":param url: String. The URL to be hashed into a filename.\n:param etag: String. The etag to be hashed and appended to the URL's hash. Defaults to None.\n:return: String. The hashed filename."}, "tests": ["tests/test_download_manager.py::test_download_manager_extract"], "indent": 4}
{"namespace": "datasets.utils.hub.hf_hub_url", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/hub.py", "signature_position": [8, 8], "body_position": [9, 12], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the URL of a file in the Hugging Face Hub based on the given repository ID, file path, and revision. It first checks the version of the Hugging Face Hub and encodes the file path if the version is older than 0.11.0.", "Arguments": ":param repo_id: String. The ID of the repository in the Hugging Face Hub.\n:param path: String. The file path in the repository.\n:param revision: String. The revision of the file. Defaults to None.\n:return: String. The URL of the file in the Hugging Face Hub."}, "tests": ["tests/test_hub.py::test_hf_hub_url"], "indent": 4}
{"namespace": "datasets.utils.sharding._number_of_shards_in_gen_kwargs", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/sharding.py", "signature_position": [6, 6], "body_position": [10, 22], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the number of possible shards according to the input gen_kwargs. It checks the length of the lists in the input dictionary and raises an error if the lengths are different.", "Arguments": ":param gen_kwargs: dict. The input dictionary containing the gen_kwargs.\n:return: int. The number of possible shards."}, "tests": ["tests/test_sharding_utils.py::test_number_of_shards_in_gen_kwargs"], "indent": 4}
{"namespace": "datasets.utils.sharding._distribute_shards", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/sharding.py", "signature_position": [25, 25], "body_position": [41, 49], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function distributes the shards among the jobs. It returns the range of shard indices per job. If the number of shards is less than the maximum number of jobs, then each job is given a range of one shard. The order of shard indices is preserved, and all the jobs are given approximately the same number of shards.", "Arguments": ":param num_shards: int. The total number of shards.\n:param max_num_jobs: int. The maximum number of jobs.\n:return: List[range]. The range of shard indices per job."}, "tests": ["tests/test_sharding_utils.py::test_distribute_shards"], "indent": 4}
{"namespace": "datasets.utils.py_utils.temporary_assignment", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/py_utils.py", "signature_position": [229, 229], "body_position": [231, 236], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Temporarily assign the value to the attribute of the object. It first gets the original value of the attribute, then sets the attribute to the new value. After the execution of the block, it sets the attribute back to the original value.", "Arguments": ":param obj: Object. The object to which the attribute belongs.\n:param attr: String. The name of the attribute to be temporarily assigned.\n:param value: Any. The value to be temporarily assigned to the attribute.\n:return: No return values."}, "tests": ["tests/test_py_utils.py::PyUtilsTest::test_temporary_assignment"], "indent": 4}
{"namespace": "datasets.utils.extract.TarExtractor.extract", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/extract.py", "signature_position": [125, 125], "body_position": [126, 129], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function extracts the contents of a tar file to the specified output path. It first creates the output directory if it does not exist, then opens the tar file, extracts all its contents to the output path, and closes the tar file.", "Arguments": ":param input_path: Union[Path, str]. The path to the input tar file.\n:param output_path: Union[Path, str]. The path to the output directory where the contents will be extracted.\n:return: No return value."}, "tests": ["tests/test_extract.py::test_tar_extract_insecure_files"], "indent": 8}
{"namespace": "datasets.utils.extract.Extractor.infer_extractor_format", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/extract.py", "signature_position": [314, 314], "body_position": [315, 319], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function infers the format of the extractor based on the given path. It reads the magic number from the file and checks if the extractor is extractable for the given path and magic number.", "Arguments": ":param cls: Extractor. The class itself.\n:param path: Union[Path, str]. The path of the file to infer the extractor format.\n:return: str. The inferred extractor format."}, "tests": ["tests/test_extract.py::test_extractor"], "indent": 8}
{"namespace": "datasets.utils.py_utils.asdict", "type": "function", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/py_utils.py", "signature_position": [189, 189], "body_position": [197, 225], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert an object to its dictionary representation recursively. It first checks if the object is a dataclass instance. If it is, it converts the object to a dictionary representation. If not, it checks if the object is a namedtuple, list, tuple, or dictionary and converts it accordingly.", "Arguments": ":param obj: Any. The object to be converted to a dictionary representation.\n:return: Dict. The dictionary representation of the input object."}, "tests": ["tests/test_tasks.py::test_reload_task_from_dict", "tests/test_splits.py::test_split_dict_asdict_has_dataset_name", "tests/test_py_utils.py::test_asdict", "tests/features/test_features.py::FeaturesTest::test_feature_named_self_as_kwarg", "tests/features/test_features.py::FeaturesTest::test_feature_named_type"], "indent": 4}
{"namespace": "datasets.utils.metadata.MetadataConfigs.from_dataset_card_data", "type": "method", "project_path": "Scientific-Engineering/datasets", "completion_path": "Scientific-Engineering/datasets/src/datasets/utils/metadata.py", "signature_position": [173, 173], "body_position": [174, 191], "dependency": {"intra_class": [], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a MetadataConfigs instance based on the given dataset card data. It first checks if the dataset card data contains the field name. If it does, it processes the metadata configurations and creates a MetadataConfigs instance.", "Arguments": ":param cls: Class. The class itself.\n:param dataset_card_data: DatasetCardData. The dataset card data to be used to create the MetadataConfigs instance.\n:return: MetadataConfigs. The created MetadataConfigs instance."}, "tests": ["tests/test_metadata_util.py::test_metadata_configs_incorrect_yaml", "tests/test_metadata_util.py::test_metadata_configs_dataset_card_data"], "indent": 8}
{"namespace": "boltons.socketutils.NetstringSocket.setmaxsize", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [667, 667], "body_position": [668, 669], "dependency": {"intra_class": ["boltons.socketutils.NetstringSocket._calc_msgsize_maxsize", "boltons.socketutils.NetstringSocket._msgsize_maxsize", "boltons.socketutils.NetstringSocket.maxsize"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set the maximum size for receiving netstrings in the NetstringSocket instance. It updates the maxsize of the instance and calculates the maximum size for a netstring message based on the new maxsize value.", "Arguments": ":param self: NetstringSocket. An instance of the NetstringSocket class.\n:param maxsize: The maximum size for receiving netstrings.\n:return: No return values."}, "tests": ["tests/test_socketutils.py::test_socketutils_netstring"], "indent": 8}
{"namespace": "boto.datapipeline.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/datapipeline/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.datapipeline.layer1.DataPipelineConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the AWS Data Pipeline service. It creates a connection to the Data Pipeline service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: DataPipelineConnection. The connection object to the Data Pipeline service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestDatapipelineConnection::test_connect_to_region"], "indent": 4}
{"namespace": "gunicorn.config.Config.__str__", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [54, 54], "body_position": [55, 62], "dependency": {"intra_class": ["gunicorn.config.Config.settings"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the Config instance. It iterates through the settings dictionary, format all callable values (\"<{qual_name}()>\"), then formats each key-value pair (\"{key:{key_max_length}} = {value}\"), and appends it to a list. Finally, it joins all the lines in the list with a newline character and returns the resulting string.", "Arguments": ":param self: Config. An instance of the Config class.\n:return: str. The string representation of the Config instance."}, "tests": ["tests/test_config.py::test_str"], "indent": 8}
{"namespace": "mingus.core.notes.int_to_note", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/notes.py", "signature_position": [36, 36], "body_position": [52, 63], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mingus.core.mt_exceptions.FormatError", "mingus.core.mt_exceptions.RangeError"]}, "requirement": {"Functionality": "This function converts integers in the range of 0-11 to notes in the form of C or C# or Db. It throws a RangeError exception if the note_int is not in the range 0-11. If not specified, sharps will be used.\n", "Arguments": ":param note_int: int. The integer value representing the note.\n:param accidentals: str. The type of accidentals to be used. Defaults to \"#\" if not specified.\n:return: str. The corresponding note in the form of C or C# or Db.\n"}, "tests": ["tests/unit/core/test_notes.py::test_notes::test_invalid_int_to_note", "tests/unit/core/test_notes.py::test_notes::test_int_to_note"], "indent": 4}
{"namespace": "mopidy.http.Extension.get_config_schema", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/http/__init__.py", "signature_position": [20, 20], "body_position": [21, 33], "dependency": {"intra_class": ["mopidy.ext.Extension", "mopidy.ext.Extension.get_config_schema"], "intra_file": [], "cross_file": ["mopidy.config", "mopidy.config.types.Boolean", "mopidy.config.types.Deprecated", "mopidy.config.types.Hostname", "mopidy.config.types.List", "mopidy.config.types.Port", "mopidy.config.types.String"]}, "requirement": {"Functionality": "This function returns the configuration schema for the Extension class. It first calls the parent class's method to get the base schema, and then adds additional configuration options specific to the Extension class.", "Arguments": ":param self: Extension. An instance of the Extension class.\n:return: dict. The configuration schema for the Extension class, including the base schema and additional options."}, "tests": ["tests/http/test_extension.py::test_get_config_schema", "tests/http/test_extension.py::test_default_config_is_valid"], "indent": 8}
{"namespace": "jinja2.meta.find_undeclared_variables", "type": "function", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/meta.py", "signature_position": [33, 33], "body_position": [52, 54], "dependency": {"intra_class": [], "intra_file": ["jinja2.meta.TrackingCodeGenerator", "jinja2.meta.TrackingCodeGenerator.__init__", "jinja2.meta.TrackingCodeGenerator.undeclared_identifiers"], "cross_file": ["jinja2.nodes.Node.environment", "jinja2.nodes.Template", "jinja2.visitor.NodeVisitor.visit"]}, "requirement": {"Functionality": "This function returns all undeclared variables in the given AST.", "Arguments": ":param ast: nodes.Template. The AST of a Jinja2 template.\n:return: Set[str]. A set of all variables in the AST that will be looked up from the context at runtime."}, "tests": ["tests/test_api.py::TestMeta::test_find_undeclared_variables"], "indent": 4}
{"namespace": "pyinfra.operations.files.file", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/files.py", "signature_position": [1191, 1202], "body_position": [1238, 1289], "dependency": {"intra_class": [], "intra_file": ["pyinfra.operations.files._create_remote_dir", "pyinfra.operations.files._raise_or_remove_invalid_path", "pyinfra.operations.files._validate_path"], "cross_file": ["pyinfra.facts.files.File", "pyinfra.operations.util.files.chmod", "pyinfra.operations.util.files.chown", "pyinfra.operations.util.files.ensure_mode_int", "pyinfra.api.host.Host.get_fact", "pyinfra.api.host.Host.noop", "pyinfra.operations.util.files"]}, "requirement": {"Functionality": "This function is used to add, remove, or update files. It performs different actions based on the input parameters. It can create a file, remove a file, or update the properties of an existing file.", "Arguments": ":param path: String. The name or path of the remote file.\n:param present: Bool. Whether the file should exist. If set to False, the file will be removed if it exists.\n:param user: String. The user to own the files.\n:param group: String. The group to own the files.\n:param mode: Integer. The permissions of the files.\n:param touch: Bool. Whether to touch the file.\n:param create_remote_dir: Bool. Whether to create the remote directory if it doesn't exist.\n:param force: Bool. If the target exists and is not a file, move or remove it and continue.\n:param force_backup: Bool. Whether to remove any existing non-file when force=True.\n:param force_backup_dir: String. The directory to move any backup to when force=True.\n:return: No return values."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_op"], "indent": 4}
{"namespace": "litecli.packages.parseutils.is_destructive", "type": "function", "project_path": "Database/litecli", "completion_path": "Database/litecli/litecli/packages/parseutils.py", "signature_position": [219, 219], "body_position": [221, 222], "dependency": {"intra_class": [], "intra_file": ["litecli.packages.parseutils.queries_start_with"], "cross_file": []}, "requirement": {"Functionality": "Check if any of the queries in the given list is considered destructive. It checks if any of the queries start with certain keywords that are commonly associated with destructive actions.", "Arguments": ":param queries: List of strings. The queries to be checked.\n:return: Bool. True if any of the queries is considered destructive, False otherwise."}, "tests": ["tests/test_parseutils.py::test_is_destructive"], "indent": 4}
{"namespace": "fs.path.frombase", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [522, 523], "body_position": [538, 540], "dependency": {"intra_class": [], "intra_file": ["fs.path.isparent"], "cross_file": []}, "requirement": {"Functionality": "Take two paths - `path1` and `path2` as input. Return the part of `path2` that is not present in `path1`. If `path1` is not a parent directory of `path2`, a ValueError raised. \n", "Arguments": ":param path1: String, a PyFileSystem path, e.g., ``'a/b/c'``.\n:param path2: String, a PyFileSystem path, e.g., ``'a/b/c'``.\n:return: String, the final part of path2 that is not present in path1.\n"}, "tests": ["tests/test_path.py::TestPathFunctions::test_frombase"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.utils.is_muted", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/utils.py", "signature_position": [56, 57], "body_position": [58, 67], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["zulipterminal.api_types.Message", "zulipterminal.model.Model.is_muted_stream", "zulipterminal.model.Model.is_muted_topic"]}, "requirement": {"Functionality": "Check if a message is muted based on the given model. It first checks if the message is a private message, in which case it is not muted. Then it checks if the message is in a topic narrow, in which case it is not muted. If neither of these conditions are met, it checks if the message's stream or topic is muted in the model.", "Arguments": ":param msg: Message. The message to check for muting.\n:param model: Any. The model object that contains information about muted streams and topics.\n:return: bool. True if the message is muted, False otherwise."}, "tests": ["tests/ui/test_utils.py::test_is_muted"], "indent": 4}
{"namespace": "pyramid.registry.Introspector.remove", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [163, 163], "body_position": [164, 173], "dependency": {"intra_class": ["pyramid.registry.Introspector._categories", "pyramid.registry.Introspector._refs", "pyramid.registry.Introspector.get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Remove an introspection object from the Introspector instance. It first retrieves the introspection object based on the category name and discriminator. If the object is found, it removes all references to the object and deletes it from the category dictionary.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param category_name: str. The name of the category where the introspection object belongs.\n:param discriminator: The discriminator of the introspection object.\n:return: No return values."}, "tests": ["tests/test_registry.py::TestIntrospector::test_remove"], "indent": 8}
{"namespace": "mrjob.job.MRJob.set_status", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [587, 587], "body_position": [594, 599], "dependency": {"intra_class": ["mrjob.job.MRJob.stderr"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets the job status in Hadoop streaming by printing a message to the standard error stream of the input MRJob instance. It is also used as a keepalive mechanism to prevent the job from timing out. The format of the message is \"reporter:status:{message}\\n\".", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:param msg: String. The message to set as the job status.\n:return: No return values."}, "tests": ["tests/test_job.py::CountersAndStatusTestCase::test_counters_and_status"], "indent": 8}
{"namespace": "pyramid.util.InstancePropertyHelper.make_property", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [104, 104], "body_position": [110, 134], "dependency": {"intra_class": [], "intra_file": ["pyramid.util.SettableProperty", "pyramid.util.SettableProperty.__init__", "pyramid.util.get_callable_name"], "cross_file": ["pyramid.decorator.reify.__init__"]}, "requirement": {"Functionality": "This function takes a callable object and converts it into a property suitable for adding to an instance. It returns a tuple containing the computed (name, property) pair.", "Arguments": ":param cls: type. InstancePropertyHelper.\n:param callable: Callable. The callable object to be converted into a property.\n:param name: str. The name of the property. If not specified, it will be derived from the callable's __name__ attribute. Defaults to None.\n:param reify: bool. Whether to use the reify decorator on the property. Defaults to False.\n:return: Tuple. A tuple containing the computed (name, property) pair."}, "tests": ["tests/test_scripting.py::Test_prepare::test_it_with_extensions", "tests/test_util.py::Test_InstancePropertyHelper::test_apply_properties_with_iterable", "tests/test_util.py::Test_InstancePropertyHelper::test_apply_properties_with_dict", "tests/test_util.py::Test_InstancePropertyHelper::test_make_property", "tests/test_router.py::TestRouter::test_call_with_request_extensions"], "indent": 8}
{"namespace": "falcon.request.Request.client_prefers", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [1101, 1101], "body_position": [1115, 1122], "dependency": {"intra_class": ["falcon.request.Request.accept"], "intra_file": [], "cross_file": ["falcon.vendor.mimeparse", "falcon.vendor.mimeparse.best_match"]}, "requirement": {"Functionality": "This function returns the client's preferred media type from a list of choices. It uses the Accept header of the client's request to determine the preferred type.", "Arguments": ":param self: Request. An instance of the Request class.\n:param media_types: Iterable of strings. One or more Internet media types from which to choose the client's preferred type.\n:return: String. The client's preferred media type based on the Accept header. Returns None if the client does not accept any of the given types."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_client_prefers"], "indent": 8}
{"namespace": "falcon.request.Request.content_length", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [600, 600], "body_position": [601, 625], "dependency": {"intra_class": ["falcon.request.Request.env"], "intra_file": [], "cross_file": ["falcon.errors.HTTPInvalidHeader", "falcon.errors"]}, "requirement": {"Functionality": "This function retrieves the value of the 'CONTENT_LENGTH' header from a Request instance. The value should be a positive integer. Otherwise, it returns None and raises a error message.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: int or None. The value of the 'CONTENT_LENGTH' header as an integer, or None if the header is not present or has an invalid value."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_content_length"], "indent": 8}
{"namespace": "pyramid.registry.Introspectable.discriminator_hash", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [232, 232], "body_position": [233, 234], "dependency": {"intra_class": ["pyramid.registry.Introspectable._assert_resolved", "pyramid.registry.Introspectable.discriminator"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Calculate the hash of the discriminator of the Introspectable instance.", "Arguments": ":param self: Introspectable. An instance of the Introspectable class.\n:return: int. The hash value of the discriminator in the instance."}, "tests": ["tests/test_registry.py::TestIntrospectable::test_discriminator_hash"], "indent": 8}
{"namespace": "zxcvbn.scoring.regex_guesses", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [297, 297], "body_position": [298, 315], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.scoring.MIN_YEAR_SPACE", "zxcvbn.scoring.REFERENCE_YEAR"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the number of possible guesses for a given regular expression match. It first defines a dictionary of character class bases, which represent the number of possible characters in each character class. Then, it checks the type of the regular expression match and calculates the number of possible guesses based on the match type.", "Arguments": ":param match: Dictionary. The regular expression match object, which contains information about the match.\n:return: Integer. The number of possible guesses for the given regular expression match."}, "tests": ["tests/scoring_test.py::test_regex_guesses"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox.stream_box_view", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [381, 383], "body_position": [384, 399], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._set_stream_write_box_style", "zulipterminal.ui_tools.boxes.WriteBox._setup_common_stream_compose", "zulipterminal.ui_tools.boxes.WriteBox._stream_box_autocomplete", "zulipterminal.ui_tools.boxes.WriteBox.model", "zulipterminal.ui_tools.boxes.WriteBox.stream_write_box"], "intra_file": [], "cross_file": ["zulipterminal.config.keys.primary_key_for_command"]}, "requirement": {"Functionality": "This function sets up the view for a stream box. It creates a stream write box with a specified caption and title, enables autocomplete functionality, and sets up the common stream compose. It also sets a callback to set the stream marker and connects a signal to update the style of the stream write box.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param stream_id: int. The ID of the stream.\n:param caption: str. The caption for the stream write box. Defaults to an empty string.\n:param title: str. The title for the stream write box. Defaults to an empty string.\n:return: No return values."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test__stream_box_autocomplete_with_spaces", "tests/ui_tools/test_boxes.py::TestWriteBox::test__set_stream_write_box_style_markers", "tests/ui_tools/test_boxes.py::TestWriteBox::test__compose_attributes_reset_for_stream_compose", "tests/ui_tools/test_boxes.py::TestWriteBox::test_write_box_header_contents", "tests/ui_tools/test_boxes.py::TestWriteBox::test_keypress_CYCLE_COMPOSE_FOCUS"], "indent": 8}
{"namespace": "boltons.funcutils.FunctionBuilder.get_arg_names", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/funcutils.py", "signature_position": [962, 962], "body_position": [963, 967], "dependency": {"intra_class": ["boltons.funcutils.FunctionBuilder.get_defaults_dict", "boltons.funcutils.FunctionBuilder.args", "boltons.funcutils.FunctionBuilder.kwonlyargs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a tuple of argument names for a function. It includes both positional arguments and keyword-only arguments. If the \"only_required\" parameter is set to True, it only returns the names of required arguments, excluding those with default values.", "Arguments": ":param self: FunctionBuilder. An instance of the FunctionBuilder class.\n:param only_required: bool. Whether to only return the names of required arguments. Defaults to False.\n:return: Tuple. A tuple of argument names."}, "tests": ["tests/test_funcutils_fb.py::test_get_arg_names", "tests/test_funcutils_fb_py3.py::test_get_arg_names"], "indent": 8}
{"namespace": "mrjob.hadoop.HadoopJobRunner._stream_history_log_dirs", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [546, 546], "body_position": [548, 555], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner._hadoop_log_dirs", "mrjob.hadoop.HadoopJobRunner.fs"], "intra_file": ["mrjob.hadoop.log"], "cross_file": ["mrjob.logs.mixin.LogInterpretationMixin._read_logs", "mrjob.logs.wrap._logs_exist", "mrjob.util.unique"]}, "requirement": {"Functionality": "This function yields lists of directories to search for the history log in. It first checks if logs should be read, and then iterates over unique log directories obtained from the hadoop log directories. If the directory exists, it logs an info message: 'Looking for history log in {directory}...'. It then yields a list containing the directory.", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:param output_dir: str. The output directory to search for the history log. Defaults to None.\n:return: Generator. Yields lists of directories to search for the history log in."}, "tests": ["tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_output_dir", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_basic", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_io_error_from_fs_exists", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_empty", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_no_read_logs"], "indent": 8}
{"namespace": "sslyze.plugins.session_renegotiation_plugin._SessionRenegotiationCliConnector.result_to_console_output", "type": "method", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/session_renegotiation_plugin.py", "signature_position": [57, 57], "body_position": [58, 76], "dependency": {"intra_class": [], "intra_file": ["sslyze.plugins.session_renegotiation_plugin.SessionRenegotiationScanResult", "sslyze.plugins.session_renegotiation_plugin.SessionRenegotiationScanResult.is_vulnerable_to_client_renegotiation_dos", "sslyze.plugins.session_renegotiation_plugin.SessionRenegotiationScanResult.supports_secure_renegotiation"], "cross_file": ["sslyze.plugins.plugin_base.ScanCommandCliConnector._format_field", "sslyze.plugins.plugin_base.ScanCommandCliConnector._format_title"]}, "requirement": {"Functionality": "This function takes a SessionRenegotiationScanResult object as input and converts the result into a list of strings that represent the output to be displayed on the console. It formats the different fields of the result and appends them to the result_txt list.", "Arguments": ":param cls: The class object of _SessionRenegotiationCliConnector.\n:param result: SessionRenegotiationScanResult. The result of a session renegotiation scan.\n:return: List of strings. The formatted output to be displayed on the console."}, "tests": ["tests/plugins_tests/test_session_renegotiation_plugin.py::TestSessionRenegotiationPlugin::test_renegotiation_is_vulnerable_to_client_renegotiation_dos"], "indent": 8}
{"namespace": "prometheus_client.mmap_dict.MmapedDict.read_value", "type": "method", "project_path": "System/prometheus-client", "completion_path": "System/prometheus-client/prometheus_client/mmap_dict.py", "signature_position": [121, 121], "body_position": [122, 125], "dependency": {"intra_class": ["prometheus_client.mmap_dict.MmapedDict._init_value", "prometheus_client.mmap_dict.MmapedDict._m", "prometheus_client.mmap_dict.MmapedDict._positions"], "intra_file": ["prometheus_client.mmap_dict._unpack_two_doubles"], "cross_file": []}, "requirement": {"Functionality": "Read the value corresponding to the given key from the MmapedDict instance. If the key is not found in the instance, it initializes the value and then returns it.", "Arguments": ":param self: MmapedDict. An instance of the MmapedDict class.\n:param key: The key to read the value from the instance.\n:return: The value corresponding to the key."}, "tests": ["tests/test_multiprocess.py::TestMmapedDict::test_process_restart"], "indent": 8}
{"namespace": "zulipterminal.server_url.near_message_url", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/server_url.py", "signature_position": [73, 73], "body_position": [79, 83], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.server_url.near_pm_message_url", "zulipterminal.server_url.near_stream_message_url"], "cross_file": ["zulipterminal.api_types.Message"]}, "requirement": {"Functionality": "This function returns the correct encoded URL of a message based on its type (stream or private message). It calls the appropriate helper function to generate the URL.", "Arguments": ":param server_url: String. The base URL of the server.\n:param message: Message. The message object for which the URL needs to be generated.\n:return: String. The encoded URL of the message."}, "tests": ["tests/server_url/test_server_url.py::test_near_message_url"], "indent": 4}
{"namespace": "falcon.response.Response.unset_cookie", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/response.py", "signature_position": [510, 510], "body_position": [561, 581], "dependency": {"intra_class": ["falcon.response.Response._cookies"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to unset a cookie in the response. It clears the contents of the cookie and instructs the user agent to immediately expire its own copy of the cookie.", "Arguments": ":param self: Response. An instance of the Response class.\n:param name: String. The name of the cookie to unset.\n:param domain: String [optional]. Restricts the cookie to a specific domain and any subdomains of that domain. By default, the user agent will return the cookie only to the origin server. When overriding this default behavior, the specified domain must include the origin server. Otherwise, the user agent will reject the cookie.\n:param path: String [optional]. Scopes the cookie to the given path plus any subdirectories under that path. If the cookie does not specify a path, the user agent defaults to the path component of the requested URI.\n:return: No return values."}, "tests": ["tests/test_cookies.py::test_response_unset_cookie"], "indent": 8}
{"namespace": "boto.s3.connection.S3Connection._required_auth_capability", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/connection.py", "signature_position": [204, 204], "body_position": [205, 208], "dependency": {"intra_class": ["boto.s3.connection.S3Connection.anon"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks the authentication capability required for the S3Connection instance.", "Arguments": ":param self: S3Connection. An instance of the S3Connection class.\n:return: List of strings. The required authentication capability."}, "tests": ["tests/unit/s3/test_connection.py::TestSignatureAlteration::test_switched", "tests/unit/s3/test_connection.py::TestSigV4HostError::test_sigv4_opt_in"], "indent": 8}
{"namespace": "datasette.facets.ArrayFacet.facet_results", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/facets.py", "signature_position": [370, 371], "body_position": [372, 453], "dependency": {"intra_class": ["datasette.facets.ArrayFacet.type"], "intra_file": ["datasette.facets.Facet.database", "datasette.facets.Facet.ds", "datasette.facets.Facet.get_configs", "datasette.facets.Facet.get_facet_size", "datasette.facets.Facet.get_querystring_pairs", "datasette.facets.Facet.params", "datasette.facets.Facet.request", "datasette.facets.Facet.sql"], "cross_file": ["datasette.database.QueryInterrupted", "datasette.utils.escape_sqlite", "datasette.utils.path_with_added_args", "datasette.utils.path_with_removed_args", "datasette.app.Datasette.absolute_url", "datasette.app.Datasette.execute", "datasette.app.Datasette.setting", "datasette.app.Datasette.urls", "datasette.url_builder.Urls.path"]}, "requirement": {"Functionality": "This function retrieves facet results for an ArrayFacet instance. It iterates through the configurations and generates facet SQL queries based on the column and other parameters. It then executes the queries and processes the results to create facet result objects. Finally, it returns the facet results and a list of columns that timed out during the execution.", "Arguments": ":param self: ArrayFacet. An instance of the ArrayFacet class.\n:return: Tuple. A tuple containing the facet results and a list of columns that timed out during the execution."}, "tests": ["tests/test_facets.py::test_array_facet_results"], "indent": 8}
{"namespace": "mingus.core.progressions.substitute_diminished_for_diminished", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/progressions.py", "signature_position": [363, 365], "body_position": [374, 395], "dependency": {"intra_class": [], "intra_file": ["mingus.core.progressions.interval_diff", "mingus.core.progressions.parse_string", "mingus.core.progressions.skip", "mingus.core.progressions.tuple_to_string"], "cross_file": []}, "requirement": {"Functionality": "This function substitutes a diminished chord for another diminished chord in a given progression based on certain conditions.\nThe function first parses the chord at the specified index in the given progression. It then checks if the chord suffix is 'dim7', 'dim', or an empty string with a Roman numeral 'VII'. If the ignore_suffix flag is set to True, the suffix is ignored. If any of the above conditions are met, the function adds a diminished chord to the result. Iterates three times, each time skipping to the next chord based on the last chord's position and adding the appropriate accidentals. The resulting chords are appended to the result list.\n", "Arguments": ":param progression: List of strings. The chord progression.\n:param substitute_index: Int. The index of the chord to be substituted.\n:param ignore_suffix: Bool. Whether to ignore the chord suffix when substituting. Defaults to False.\n:return: List of strings. The substituted chord progression.\n"}, "tests": ["tests/unit/core/test_progressions.py::test_progressions::test_substitute_diminished_for_diminished"], "indent": 4}
{"namespace": "jc.parsers.xrandr._parse_mode", "type": "function", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/parsers/xrandr.py", "signature_position": [440, 440], "body_position": [441, 473], "dependency": {"intra_class": [], "intra_file": ["jc.parsers.xrandr.Frequency", "jc.parsers.xrandr.Mode", "jc.parsers.xrandr._frequencies_pattern", "jc.parsers.xrandr._mode_pattern"], "cross_file": []}, "requirement": {"Functionality": "This function parses a line of text and extracts information about a mode. It checks if the line matches a specific pattern and if not, returns None. If it does match, it extracts the resolution width, resolution height, and whether it is a high resolution mode. It then extracts information about the frequencies associated with the mode, including the frequency value, whether it is the current frequency, and whether it is the preferred frequency. Finally, it returns a dictionary containing all the extracted information.", "Arguments": ":param line: str. The line of text to parse and extract mode information from.\n:return: Optional[Mode]. The extracted mode information as a dictionary, or None if the line does not match the expected pattern."}, "tests": ["tests/test_xrandr.py::XrandrTests::test_mode"], "indent": 4}
{"namespace": "boto.ec2.securitygroup.SecurityGroup.add_rule", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/securitygroup.py", "signature_position": [97, 99], "body_position": [105, 116], "dependency": {"intra_class": ["boto.ec2.securitygroup.SecurityGroup.rules"], "intra_file": ["boto.ec2.securitygroup.IPPermissions", "boto.ec2.securitygroup.IPPermissions.__init__", "boto.ec2.securitygroup.IPPermissions.add_grant", "boto.ec2.securitygroup.IPPermissions.from_port", "boto.ec2.securitygroup.IPPermissions.ip_protocol", "boto.ec2.securitygroup.IPPermissions.to_port"], "cross_file": []}, "requirement": {"Functionality": "Add a rule to a SecurityGroup instance. Note that this method only changes the local version of the instance. No information is sent to EC2.", "Arguments": ":param self: SecurityGroup. An instance of the SecurityGroup class.\n:param ip_protocol: String. The IP protocol for the rule.\n:param from_port: Integer. The starting port range for the rule.\n:param to_port: Integer. The ending port range for the rule.\n:param src_group_name: String. The name of the source security group.\n:param src_group_owner_id: String. The ID of the owner of the source security group.\n:param cidr_ip: String. The CIDR IP range for the rule.\n:param src_group_group_id: String. The ID of the source security group.\n:param dry_run: Bool. Whether to perform a dry run. Defaults to False.\n:return: No return values."}, "tests": ["tests/unit/ec2/test_securitygroup.py::SecurityGroupTest::test_add_rule"], "indent": 8}
{"namespace": "sumy.nlp.stemmers.null_stemmer", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/nlp/stemmers/__init__.py", "signature_position": [16, 16], "body_position": [18, 19], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["sumy._compat.to_unicode"]}, "requirement": {"Functionality": "This function takes an object as input and converts it to a lowercase Unicode string.", "Arguments": ":param object: Any data type. The object to be converted to lowercase Unicode.\n:return: String. The converted object in lowercase Unicode."}, "tests": ["tests/test_stemmers.py::test_null_stemmer"], "indent": 4}
{"namespace": "pyramid.scripts.pshell.PShellCommand.make_shell", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/scripts/pshell.py", "signature_position": [238, 238], "body_position": [239, 279], "dependency": {"intra_class": ["pyramid.scripts.pshell.PShellCommand.args", "pyramid.scripts.pshell.PShellCommand.default_runner", "pyramid.scripts.pshell.PShellCommand.find_all_shells", "pyramid.scripts.pshell.PShellCommand.preferred_shells"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to determine which shell to use for the PShellCommand instance. If the user has specified a shell, it will use that shell if it is available, otherwise it will raise a ValueError with 'could not find a shell named \"%s\"' as the message. If the user has not specified a shell, it will use the first available preferred shell if that is specified, otherwise it will use the first available shell, with python as the least preferred shell. If no shell is available at all, it will use the default runner.", "Arguments": ":param self: PShellCommand. An instance of the PShellCommand class.\n:return: The selected shell to be used."}, "tests": ["tests/test_scripts/test_pshell.py::TestPShellCommand::test_shell_ordering", "tests/test_scripts/test_pshell.py::TestPShellCommand::test_shell_override", "tests/test_scripts/test_pshell.py::TestPShellCommand::test_shell_entry_points"], "indent": 8}
{"namespace": "mrjob.hadoop.HadoopJobRunner._find_binaries_and_jars", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [334, 334], "body_position": [342, 348], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner.get_hadoop_streaming_jar", "mrjob.hadoop.HadoopJobRunner.get_hadoop_version"], "intra_file": [], "cross_file": ["mrjob.runner.MRJobRunner._has_hadoop_streaming_steps", "mrjob.runner.MRJobRunner._has_spark_steps", "mrjob.bin.MRJobBinRunner.get_spark_submit_bin"]}, "requirement": {"Functionality": "This function is used to find the necessary Hadoop and Spark binaries and jars before continuing with the job. It triggers the loading of the Hadoop binary and checks if there are Hadoop streaming steps or Spark steps in the job. If there are, it also loads the Hadoop streaming jar and the Spark submit binary.", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:return: No return values."}, "tests": ["tests/test_hadoop.py::FindBinariesAndJARsTestCase::test_always_call_get_hadoop_version"], "indent": 8}
{"namespace": "jinja2.loaders.split_template_path", "type": "function", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/loaders.py", "signature_position": [25, 25], "body_position": [29, 39], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["jinja2.exceptions.TemplateNotFound"]}, "requirement": {"Functionality": "This function takes a template path as input and splits it into segments and performs a sanity check. If it contains path separators or alternate path separators or parent directory references, it raises a template not found error.", "Arguments": ":param template: str. The template path to be split.\n:return: List[str]. The segments of the template path after splitting."}, "tests": ["tests/test_loader.py::test_package_zip_source", "tests/test_loader.py::test_package_file_source", "tests/test_loader.py::test_package_dir_source", "tests/test_loader.py::TestLoaders::test_split_template_path"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.DefaultContainer.from_batch_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [550, 554], "body_position": [555, 556], "dependency": {"intra_class": ["bentoml._internal.runner.container.DefaultContainer.batches_to_batch"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": []}, "requirement": {"Functionality": "This function takes a sequence of payloads and converts them into batches. It creates a list of batches on each payload in the sequence. Then, it combines the batches into a single batch along the specified batch dimension.", "Arguments": ":param cls: DefaultContainer. The class itself.\n:param payloads: Sequence of Payload. The payloads to be converted into batches.\n:param batch_dim: int. The dimension along which the batches will be combined. Defaults to 0.\n:return: tuple[list[Any], list[int]]. A tuple containing the list of batches and a list of integers representing the batch sizes."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_default_container"], "indent": 8}
{"namespace": "falcon.http_error.HTTPError.to_json", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/http_error.py", "signature_position": [178, 178], "body_position": [191, 195], "dependency": {"intra_class": ["falcon.http_error.HTTPError.to_dict"], "intra_file": ["falcon.http_error._DEFAULT_JSON_HANDLER"], "cross_file": ["falcon.constants.MEDIA_JSON", "falcon.media.json.JSONHandler.serialize"]}, "requirement": {"Functionality": "This function converts the HTTPError instance into a JSON representation. It takes an optional handler object to customize the serialization process. If no handler is provided, a default handler using the built-in JSON library is used.", "Arguments": ":param self: HTTPError. An instance of the HTTPError class.\n:param handler: Handler object. An optional handler object that will be used to serialize the representation of this error to JSON. Defaults to None.\n:return: bytes. A JSON document representing the error."}, "tests": ["tests/test_httperror.py::TestHTTPError::test_to_json_dumps"], "indent": 8}
{"namespace": "pyramid.i18n.Localizer.pluralize", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/i18n.py", "signature_position": [64, 64], "body_position": [103, 107], "dependency": {"intra_class": ["pyramid.i18n.Localizer.pluralizer", "pyramid.i18n.Localizer.translations"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is to pluralize a string translation based on a singular/plural pair and a given number. It uses gettext plural forms support to handle different pluralization rules in different languages.", "Arguments": ":param self: Localizer. An instance of the Localizer class.\n:param singular: String. The singular form of the translation message.\n:param plural: String. The plural form of the translation message.\n:param n: Integer. The number that appears in the message, used for pluralization.\n:param domain: String. The translation domain to use for pluralization. Defaults to None.\n:param mapping: Dictionary. The interpolation mapping to be used on the result. Defaults to None.\n:return: String. The pluralized translation message."}, "tests": ["tests/test_i18n.py::TestLocalizer::test_pluralize_default_translations", "tests/test_i18n.py::TestLocalizer::test_pluralize", "tests/test_i18n.py::TestLocalizer::test_pluralize_pluralizer_already_added"], "indent": 8}
{"namespace": "pymorphy2.dawg.assert_can_create", "type": "function", "project_path": "Text-Processing/pymorphy2", "completion_path": "Text-Processing/pymorphy2/pymorphy2/dawg.py", "signature_position": [13, 13], "body_position": [14, 17], "dependency": {"intra_class": [], "intra_file": ["pymorphy2.dawg.EXTENSION_AVAILABLE"], "cross_file": []}, "requirement": {"Functionality": "This function checks if the extension is available and raises a NotImplementedError if it is not.", "Arguments": ":param: No input parameters.\n:return: No return values."}, "tests": ["tests/test_opencorpora_dict.py::TestToyDictionary::test_convert_to_pymorphy2"], "indent": 4}
{"namespace": "boto.s3.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/__init__.py", "signature_position": [62, 62], "body_position": [63, 76], "dependency": {"intra_class": [], "intra_file": ["boto.s3.S3RegionInfo", "boto.s3.S3RegionInfo.connect"], "cross_file": ["boto.regioninfo.connect", "boto.s3.connection.S3Connection", "boto.regioninfo", "boto.regioninfo.RegionInfo.__init__"]}, "requirement": {"Functionality": "Connect to a specific region using the provided region name and additional parameters. It first checks if a custom host is provided in the input parameters. If so, it creates a custom region and connects to it using the provided parameters. Otherwise, it connects to the default S3 region using the region name and additional parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param kw_params: Additional keyword arguments that can be passed to the connection.\n:return: The connection to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestS3Connection::test_connect_to_custom_host", "tests/unit/test_connect_to_region.py::TestS3Connection::test_connect_to_region"], "indent": 4}
{"namespace": "sqlitedict.SqliteDict.commit", "type": "method", "project_path": "Database/sqlitedict", "completion_path": "Database/sqlitedict/sqlitedict.py", "signature_position": [370, 370], "body_position": [377, 378], "dependency": {"intra_class": ["sqlitedict.SqliteDict.conn"], "intra_file": ["sqlitedict.SqliteMultithread.commit"], "cross_file": []}, "requirement": {"Functionality": "This function is used to persist all data in the SqliteDict instance to disk. It commits the changes made to the database. If `blocking` is set to False, the commit command is queued but the data is not guaranteed to be persisted immediately.", "Arguments": ":param self: SqliteDict. An instance of the SqliteDict class.\n:param blocking: Bool. Whether to block until the commit is complete. Defaults to True.\n:return: No return values."}, "tests": ["tests/test_core.py::NamedSqliteDictCreateOrReuseTest::test_overwrite_using_flag_w", "tests/test_core.py::NamedSqliteDictCreateOrReuseTest::test_readonly", "tests/test_core.py::NamedSqliteDictCreateOrReuseTest::test_default_reuse_existing_flag_c"], "indent": 8}
{"namespace": "alembic.operations.ops.DropColumnOp.from_column_and_tablename", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [2202, 2207], "body_position": [2208, 2213], "dependency": {"intra_class": ["alembic.operations.ops.DropColumnOp.__init__"], "intra_file": ["alembic.operations.ops.AddColumnOp", "alembic.operations.ops.AddColumnOp.from_column_and_tablename"], "cross_file": []}, "requirement": {"Functionality": "This function creates an instance of the class based on the given parameters.", "Arguments": ":param cls: A class.\n:param schema: Optional string. The schema of the table.\n:param tname: String. The name of the table.\n:param col: Column. The column to be dropped.\n:return: The created instance."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_render_drop_column_w_schema", "tests/test_autogen_render.py::AutogenRenderTest::test_render_drop_column", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_column"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.count", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1604, 1604], "body_position": [1617, 1618], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.describe"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns an approximate count of the number of items in a table. The count may not be accurate due to lag time.", "Arguments": ":param self: Table. An instance of the Table class.\n:return: Integer. The approximate count of the number of items in the table."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_count"], "indent": 8}
{"namespace": "boto.dynamodb2.items.Item.get_keys", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [226, 226], "body_position": [232, 238], "dependency": {"intra_class": ["boto.dynamodb2.items.Item.table"], "intra_file": [], "cross_file": ["boto.dynamodb2.table.Table.get_key_fields"]}, "requirement": {"Functionality": "This function returns a Python-style dictionary of the keys and values of an Item instance. It retrieves the key fields from the table associated with the Item and creates a dictionary with the keys and their corresponding values from the Item instance.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: dict. A Python-style dictionary containing the keys and values of the Item instance."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_get_keys"], "indent": 8}
{"namespace": "pyramid.i18n.Translations.add", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/i18n.py", "signature_position": [277, 277], "body_position": [293, 307], "dependency": {"intra_class": ["pyramid.i18n.Translations.DEFAULT_DOMAIN", "pyramid.i18n.Translations._domains", "pyramid.i18n.Translations.domain", "pyramid.i18n.Translations.merge", "pyramid.i18n.Translations.plural"], "intra_file": ["pyramid.i18n.DEFAULT_PLURAL"], "cross_file": []}, "requirement": {"Functionality": "This function adds the given translations to the catalog. If the domain of the translations is different from the current catalog, they are added as a separate catalog. It also provides the option to merge translations for message domains that have already been added.", "Arguments": ":param self: Translations. An instance of the Translations class.\n:param translations: Translations. The Translations instance with the messages to add.\n:param merge: Bool. Whether translations for message domains that have already been added should be merged with the existing translations. Defaults to True.\n:return: Translations. The Translations instance (self) so that merge calls can be easily chained."}, "tests": ["tests/test_i18n.py::TestTranslations::test_add_default_domain_replaces_plural_first_time", "tests/test_i18n.py::TestTranslations::test_add_different_domain_merge_true_notexisting", "tests/test_i18n.py::TestTranslations::test_add_same_domain_merge_true", "tests/test_i18n.py::TestTranslations::test_add_different_domain_merge_true_existing"], "indent": 8}
{"namespace": "mrjob.job.MRJob.add_passthru_arg", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [1187, 1187], "body_position": [1205, 1207], "dependency": {"intra_class": ["mrjob.job.MRJob._passthru_arg_dests", "mrjob.job.MRJob.arg_parser"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to add a command-line argument that both the job runner and the job itself will respect. It creates options that can be used by the job to configure its behavior. The options are added to the argument parser of the job.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:param *args: Variable length argument list. The arguments to be passed to  the argument parser.\n:param **kwargs: Arbitrary keyword arguments. The keyword arguments to be passed to the argument parser.\n:return: No return values."}, "tests": ["tests/test_job.py::CommandLineArgsTestCase::test_bad_option_types"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.Dial.client", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [1974, 1983], "body_position": [1997, 2007], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Client", "twilio.twiml.voice_response.Client.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Client>` element with the given parameters and returns it. It is used to create a client element for making calls in the Dial class.", "Arguments": ":param self: Dial. An instance of the Dial class.\n:param identity: String [optional]. The identity of the client.\n:param url: String [optional]. The URL of the client.\n:param method: String [optional]. The method to be used for the client URL.\n:param status_callback_event: String [optional]. The events that trigger the status callback.\n:param status_callback: String [optional]. The URL for the status callback.\n:param status_callback_method: String [optional]. The method to be used for the status callback URL.\n:param kwargs: Additional attributes [optional].\n:return: `<Client>` element. The created client element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestDial::test_add_client", "tests/unit/twiml/test_voice_response.py::TestDial::test_add_empty_client"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table._build_filters", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [990, 990], "body_position": [995, 1052], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._dynamizer"], "intra_file": [], "cross_file": ["boto.dynamodb2.exceptions.UnknownFilterTypeError", "boto.dynamodb2.types.QUERY_OPERATORS", "boto.dynamodb2.exceptions", "boto.dynamodb.types.Dynamizer.encode"]}, "requirement": {"Functionality": "This function is an internal method used to convert query/scan-style keyword arguments into the raw structure that DynamoDB expects for filtering. It creates a dictionary of filters based on the input filter_kwargs.", "Arguments": ":param self: Table. An instance of the Table class.\n:param filter_kwargs: Dictionary. The query/scan-style keyword arguments to be converted into filters.\n:param using: Dictionary. The dictionary of query operators to be used for comparison. It defaults to QUERY_OPERATORS if not specified.\n:return: None."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test__build_filters"], "indent": 8}
{"namespace": "bplustree.memory.WAL.checkpoint", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [314, 314], "body_position": [316, 333], "dependency": {"intra_class": ["bplustree.memory.WAL._committed_pages", "bplustree.memory.WAL._dir_fd", "bplustree.memory.WAL._fd", "bplustree.memory.WAL._not_committed_pages", "bplustree.memory.WAL._page_size", "bplustree.memory.WAL.filename"], "intra_file": ["bplustree.memory.fsync_file_and_dir", "bplustree.memory.logger", "bplustree.memory.read_from_file"], "cross_file": []}, "requirement": {"Functionality": "This function is used to checkpoint the modified data back to the tree and close the Write-Ahead Log (WAL). It first checks if there are any uncommitted data and logs a warning message if there are. Then, it performs a file sync operation on the file descriptor and directory file descriptor. Next, it reads the committed pages from the file and yields each page along with its corresponding data. After that, it closes the file descriptor, deletes the WAL file, and performs a file sync operation on the directory file descriptor if it exists.", "Arguments": ":param self: WAL. An instance of the WAL class.\n:return: No return values."}, "tests": ["tests/test_memory.py::test_wal_checkpoint"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.NdarrayContainer.batch_to_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [323, 328], "body_position": [329, 332], "dependency": {"intra_class": ["bentoml._internal.runner.container.NdarrayContainer.batch_to_batches", "bentoml._internal.runner.container.NdarrayContainer.to_payload"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.external_typing.NpNDArray", "bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function converts a batch of ndarrays into a list of payloads. It first divides the batch into smaller batches based on the given indices and batch dimension. Then, it converts each subbatch into a payload.", "Arguments": ":param cls: NdarrayContainer. The class itself.\n:param batch: ext.NpNDArray. The input batch of ndarrays.\n:param indices: Sequence of integers. The indices used to divide the batch into smaller batches.\n:param batch_dim: Integer. The dimension along which the batch is divided. Defaults to 0.\n:return: list[Payload]. The list of payloads created from the batch."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_ndarray_container"], "indent": 8}
{"namespace": "pylatex.utils.dumps_list", "type": "function", "project_path": "Text-Processing/PyLaTeX", "completion_path": "Text-Processing/PyLaTeX/pylatex/utils.py", "signature_position": [150, 150], "body_position": [189, 201], "dependency": {"intra_class": [], "intra_file": ["pylatex.utils.NoEscape.__init__", "pylatex.utils._latex_item_to_string"], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of objects and generates a LaTeX string representation of the list. It converts each object in the list to a string and separates them using a specified token. It also provides options for escaping special LaTeX characters and applying additional mapping functions to the objects in the list.", "Arguments": ":param l: list. A list of objects to be converted into a single string.\n:param escape: bool. Whether to escape special LaTeX characters in converted text. Defaults to True.\n:param token: str. The token to separate objects in the list. Defaults to \"%\\n\".\n:param mapper: callable or list. A function, class, or a list of functions/classes that should be called on all entries of the list after converting them to a string.\n:param as_content: bool. Indicates whether the items in the list should be dumped using `~.LatexObject.dumps_as_content`.\n:return: NoEscape. A single LaTeX string."}, "tests": ["tests/test_utils_dumps_list.py::test_mapper"], "indent": 4}
{"namespace": "zxcvbn.scoring.uppercase_variations", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [374, 374], "body_position": [375, 390], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.scoring.ALL_LOWER", "zxcvbn.scoring.ALL_UPPER", "zxcvbn.scoring.END_UPPER", "zxcvbn.scoring.START_UPPER", "zxcvbn.scoring.nCk"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the number of uppercase variations in a given word. It checks if the word is all lowercase or if it is already in lowercase, and returns 1 in those cases. Otherwise, it checks if the word starts with an uppercase letter, ends with an uppercase letter, or is all uppercase, and returns 2 in those cases. If none of the above conditions are met, it calculates the number of uppercase and lowercase letters in the word and calculates the number of variations possible by combining them. It returns the total number of variations.", "Arguments": ":param match: Dictionary. A dictionary containing the token (word) to be checked.\n:return: Integer. The number of uppercase variations in the word."}, "tests": ["tests/scoring_test.py::test_dictionary_guesses", "tests/scoring_test.py::test_uppercase_variants"], "indent": 4}
{"namespace": "mingus.core.intervals.is_consonant", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [489, 489], "body_position": [502, 504], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.is_imperfect_consonant", "mingus.core.intervals.is_perfect_consonant"], "cross_file": []}, "requirement": {"Functionality": "This function determines if the given interval between two notes is consonant.\n", "Arguments": ":param note1: str. The first note. \n:param note2: str. The second note.\n:param include_fourths: bool. Whether to include perfect fourths as consonant intervals. Defaults to True.\n:return: bool. True if the interval is consonant, False otherwise.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_is_consonant"], "indent": 4}
{"namespace": "datasette.plugins.get_plugins", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/plugins.py", "signature_position": [35, 35], "body_position": [36, 65], "dependency": {"intra_class": [], "intra_file": ["datasette.plugins.DEFAULT_PLUGINS", "datasette.plugins.pm"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves information about the installed plugins. It iterates over the plugins obtained and collects information such as the plugin name, static path, templates path, and hooks. It also retrieves the version and project name if available. The collected information is stored in a list of dictionaries and returned.", "Arguments": ":param: No input parameters.\n:return: List of dictionaries. Each dictionary contains information about a plugin, including the plugin name, static path, templates path, hooks, version, and project name (if available)."}, "tests": ["tests/test_plugins.py::test_default_plugins_have_no_templates_path_or_static_path"], "indent": 4}
{"namespace": "mrjob.logs.history._parse_pre_yarn_history_records", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/history.py", "signature_position": [336, 336], "body_position": [360, 392], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.history._PRE_YARN_HISTORY_KEY_PAIR", "mrjob.logs.history._PRE_YARN_HISTORY_RECORD", "mrjob.logs.history._pre_yarn_history_unescape"], "cross_file": []}, "requirement": {"Functionality": "This function parses a sequence of lines and yields records based on the given format. The function extracts the fields and their values from each line. It handles unescaping values and can handle multi-line records. The format begins the line with the type, and then the fields are specified in the format 'field_name=\"field_value\"'. The fields are separated by spaces. Each record ends with a period that ends the line.", "Arguments": ":param lines: List[str]. The sequence of lines to parse.\n:return: Generator. Yields dict representing each record, with 'fields', 'num_lines', 'start_line' and 'type' as keys."}, "tests": ["tests/logs/test_history.py::ParsePreYARNHistoryRecordsTestCase::test_unescape", "tests/logs/test_history.py::ParsePreYARNHistoryRecordsTestCase::test_basic", "tests/logs/test_history.py::ParsePreYARNHistoryRecordsTestCase::test_empty", "tests/logs/test_history.py::ParsePreYARNHistoryRecordsTestCase::test_bad_records", "tests/logs/test_history.py::ParsePreYARNHistoryRecordsTestCase::test_multiline"], "indent": 4}
{"namespace": "boto.glacier.utils.chunk_hashes", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/glacier/utils.py", "signature_position": [74, 74], "body_position": [75, 83], "dependency": {"intra_class": [], "intra_file": ["boto.glacier.utils._MEGABYTE"], "cross_file": []}, "requirement": {"Functionality": "This function takes a bytestring and breaks it into chunks of a specified size. It then calculates the SHA256 hash for each chunk and returns a list of the hashes.", "Arguments": ":param bytestring: The input bytestring to be chunked and hashed.\n:param chunk_size: Integer. The size of each chunk. It defaults to _MEGABYTE if not specified.\n:return: List of bytes. The list of SHA256 hashes for each chunk. If the input bytestring is empty, it returns a list with a single hash of an empty bytestring."}, "tests": ["tests/unit/glacier/test_utils.py::TestChunking::test_chunks_with_leftovers", "tests/unit/glacier/test_utils.py::TestChunking::test_less_than_one_chunk", "tests/unit/glacier/test_utils.py::TestChunking::test_chunk_hashes_exact"], "indent": 4}
{"namespace": "pythonforandroid.pythonpackage.get_package_name", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/pythonpackage.py", "signature_position": [587, 588], "body_position": [589, 602], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.pythonpackage._extract_info_from_package", "pythonforandroid.pythonpackage.package_name_cache"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the package name for a given dependency. It first checks if the package name is already cached and if the cache is still valid. If not, it extracts the package name and updates the cache with the new value.", "Arguments": ":param dependency: The dependency for which the package name is to be retrieved.\n:param use_cache: Bool. Whether to use the cached value if available. Defaults to True.\n:return: The package name of the dependency."}, "tests": ["tests/test_pythonpackage_basic.py::test_get_package_name"], "indent": 4}
{"namespace": "feedparser.urls.make_safe_absolute_uri", "type": "function", "project_path": "Text-Processing/feedparser", "completion_path": "Text-Processing/feedparser/feedparser/urls.py", "signature_position": [86, 87], "body_position": [88, 103], "dependency": {"intra_class": [], "intra_file": ["feedparser.urls.ACCEPTABLE_URI_SCHEMES", "feedparser.urls._urljoin"], "cross_file": []}, "requirement": {"Functionality": "This function creates a safe absolute URI by joining a base URL and a relative URL. If the base URL is empty, it returns the relative URL. If the relative URL is empty, it outputs the base URL. Finally, if the resulting URI's scheme is not acceptable, it returns an empty string. Otherwise, it returns the resulting URI.", "Arguments": ":param base: String. The base URL to join with the relative URL.\n:param rel: String. The relative URL to join with the base URL. Defaults to None.\n:return: String. The safe absolute URI created by joining the base and relative URLs."}, "tests": ["tests/runtests.py::TestMakeSafeAbsoluteURI::test_catch_ValueError"], "indent": 4}
{"namespace": "twilio.twiml.voice_response.VoiceResponse.gather", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [152, 173], "body_position": [199, 221], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Gather", "twilio.twiml.voice_response.Gather.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a <Gather> element for Twilio VoiceResponse. It takes various input parameters and returns the <Gather> element with the specified attributes.", "Arguments": ":param self: VoiceResponse. An instance of the VoiceResponse class.\n:param input: String. The type of input that Twilio should accept.\n:param action: String. The URL where Twilio should send the gathered input.\n:param method: String. The HTTP method to be used when making the request to the action URL.\n:param timeout: Integer. The time in seconds that Twilio should wait for input.\n:param speech_timeout: String or Integer. The time in seconds that Twilio should wait for speech input. It can be either \"auto\" or a positive integer.\n:param max_speech_time: Integer. The maximum allowed time for speech input.\n:param profanity_filter: Boolean. Whether to enable the profanity filter on speech input.\n:param finish_on_key: String. The key that should end the gathering of input.\n:param num_digits: Integer. The number of digits to collect.\n:param partial_result_callback: String. The URL where Twilio should send partial recognition results.\n:param partial_result_callback_method: String. The HTTP method to be used when making the request to the partial result callback URL.\n:param language: String. The language to use for speech recognition.\n:param hints: List of strings. Speech recognition hints.\n:param barge_in: Boolean. Whether to stop playing media upon speech input.\n:param debug: Boolean. Whether to allow debug for the gather element.\n:param action_on_empty_result: Boolean. Whether to force the webhook to the action URL event if there is no input.\n:param speech_model: String. Specify the speech model that is best suited for your use case.\n:param enhanced: Boolean. Whether to use the enhanced speech model.\n:param kwargs: Additional attributes.\n:return: <Gather> element. The created <Gather> element with the specified attributes."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestGather::test_empty", "tests/unit/twiml/test_voice_response.py::TestResponse::test_nested_verbs"], "indent": 8}
{"namespace": "boltons.tbutils.ParsedException.to_string", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tbutils.py", "signature_position": [726, 726], "body_position": [733, 746], "dependency": {"intra_class": ["boltons.tbutils.ParsedException.exc_msg", "boltons.tbutils.ParsedException.exc_type", "boltons.tbutils.ParsedException.frames"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function formats the exception and its traceback into the standard format, as returned by the traceback module.", "Arguments": ":param self: ParsedException. An instance of the ParsedException class.\n:return: str. The formatted exception and traceback information."}, "tests": ["tests/test_tbutils_parsed_exc.py::test_parsed_exc_basic", "tests/test_tbutils_parsed_exc.py::test_parsed_exc_nosrcline"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.PkgConfigPrerequisite.darwin_installer", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [347, 347], "body_position": [348, 349], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pythonforandroid.logger.info"]}, "requirement": {"Functionality": "This function installs Pkg-Config on a macOS system using the Homebrew package manager.", "Arguments": ":param self: PkgConfigPrerequisite. An instance of the PkgConfigPrerequisite class.\n:return: No return values."}, "tests": ["tests/test_prerequisites.py::TestPkgConfigPrerequisite::test_darwin_installer"], "indent": 8}
{"namespace": "falcon.util.structures.ETag.loads", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/util/structures.py", "signature_position": [283, 283], "body_position": [303, 319], "dependency": {"intra_class": ["falcon.util.structures.ETag.is_weak", "falcon.util.structures.ETag.__init__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function deserializes a single entity-tag string from a precondition header. It parses the input string according to the rules defined in RFC 7232 and returns an instance of the ETag class representing the parsed entity-tag.", "Arguments": ":param cls: Class. The class to create an instance of.\n:param etag_str: String. An ASCII string representing a single entity-tag.\n:return: ETag. An instance of the ETag class representing the parsed entity-tag."}, "tests": ["tests/test_utils.py::TestFalconUtils::test_etag_strong_vs_weak_comparison"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.probabilities.compute_values_probs", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/probabilities.py", "signature_position": [133, 137], "body_position": [167, 186], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix"]}, "requirement": {"Functionality": "This function computes the probabilities of individual values and the probabilities of values conditional on a parameter. It takes the counts of individual values and the counts of values conditional on the parameter as input and returns the corresponding probabilities.", "Arguments": ":param value_counts: Union[StateMatrix, dict]. The counts of individual values.\n:param param_value_counts: Union[StateMatrix, dict]. The counts of values conditional on the parameter.\n:param unk_token: str. A dummy command to represent an unseen command.\n:return: Tuple[StateMatrix, StateMatrix]. The probabilities of individual values and the probabilities of values conditional on the parameter."}, "tests": ["tests/analysis/test_anom_seq_probabilities.py::TestProbabilities::test_compute_values_probs"], "indent": 4}
{"namespace": "mrjob.fs.composite.CompositeFilesystem.add_fs", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/composite.py", "signature_position": [63, 63], "body_position": [75, 82], "dependency": {"intra_class": ["mrjob.fs.composite.CompositeFilesystem._disable_if", "mrjob.fs.composite.CompositeFilesystem._fs_names"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds a filesystem to the CompositeFilesystem instance. It sets the filesystem as an attribute of the instance with the given name, and stores the name in a list of filesystem names. It also allows for disabling the filesystem based on a provided function.", "Arguments": ":param self: CompositeFilesystem. An instance of the CompositeFilesystem class.\n:param name: String. The name to assign to the filesystem.\n:param fs: Filesystem. The filesystem to add.\n:param disable_if: Function. A function that takes an exception raised by the filesystem as an argument and returns True if the filesystem should be disabled.\n:return: No return values."}, "tests": ["tests/fs/test_composite.py::CompositeFilesystemTestCase::test_pick_fs", "tests/fs/test_composite.py::CompositeFilesystemTestCase::test_disable_fs", "tests/fs/test_composite.py::CompositeFilesystemTestCase::test_forward_fs_extensions", "tests/fs/test_composite.py::CompositeFilesystemTestCase::test_forward_join", "tests/fs/test_composite.py::CompositeFilesystemTestCase::test_forward_put"], "indent": 8}
{"namespace": "pyramid.authentication.SessionAuthenticationHelper.remember", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [1265, 1265], "body_position": [1267, 1268], "dependency": {"intra_class": ["pyramid.authentication.SessionAuthenticationHelper.userid_key"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a request object, a user ID, and any additional keyword arguments. It then stores the user ID in the session.", "Arguments": ":param self: SessionAuthenticationHelper. An instance of the SessionAuthenticationHelper class.\n:param request: The request object.\n:param userid: The user ID to store in the session.\n:param **kw: Additional keyword arguments.\n:return: An empty list."}, "tests": ["tests/test_authentication.py::TestSessionAuthenticationHelper::test_remember"], "indent": 8}
{"namespace": "boto.utils.LazyLoadMetadata.values", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/utils.py", "signature_position": [345, 345], "body_position": [346, 347], "dependency": {"intra_class": ["boto.utils.LazyLoadMetadata._materialize"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the values of the LazyLoadMetadata instance after materializing it.", "Arguments": ":param self: LazyLoadMetadata. An instance of the LazyLoadMetadata class.\n:return: The dict values of the LazyLoadMetadata instance."}, "tests": ["tests/unit/utils/test_utils.py::TestLazyLoadMetadata::test_meta_data_with_invalid_json_format_happened_twice", "tests/unit/utils/test_utils.py::TestLazyLoadMetadata::test_meta_data_with_invalid_json_format_happened_once"], "indent": 8}
{"namespace": "falcon.inspect.inspect_error_handlers", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [141, 141], "body_position": [152, 157], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect.ErrorHandlerInfo", "falcon.inspect.ErrorHandlerInfo.__init__", "falcon.inspect._get_source_info_and_name", "falcon.inspect._is_internal"], "cross_file": ["falcon.app.App", "falcon.app.App._error_handlers"]}, "requirement": {"Functionality": "This function inspects the error handlers of an application. It iterates through the error handlers dictionary and creates a list of `ErrorHandlerInfo` objects containing information about each error handler.", "Arguments": ":param app: falcon.App. The application to inspect. It can be an instance of either `falcon.App` or `falcon.asgi.App`.\n:return: List[ErrorHandlerInfo]. A list of `ErrorHandlerInfo` objects representing the error handlers used by the application."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_error_handler", "tests/test_inspect.py::TestInspectApp::test_error_handler", "tests/test_inspect.py::TestStringVisitor::test_error_handler_verbose"], "indent": 4}
{"namespace": "jinja2.environment.Environment.get_template", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/environment.py", "signature_position": [976, 981], "body_position": [1005, 1010], "dependency": {"intra_class": ["jinja2.environment.Environment._load_template", "jinja2.environment.Environment.join_path"], "intra_file": ["jinja2.environment.Template"], "cross_file": []}, "requirement": {"Functionality": "This function loads a template by name using the specified loader and returns a Template object. If the template does not exist, a TemplateNotFound exception is raised. It also allows for specifying a parent template and additional global variables.", "Arguments": ":param self: Environment. An instance of the Environment class.\n:param name: Union[str, Template]. The name of the template to load. It can be either a string or a Template object.\n:param parent: Optional[str]. The name of the parent template importing this template.\n:param globals: Optional[MutableMapping[str, Any]]. Additional variables available for all renders of this template. If the template has already been loaded and cached, its globals are updated with any new items.\n:return: Template. The loaded template object."}, "tests": ["tests/test_imports.py::TestIncludes::test_context_include_with_overrides"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.OpenSSLPrerequisite.darwin_checker", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [269, 269], "body_position": [270, 275], "dependency": {"intra_class": ["pythonforandroid.prerequisites.OpenSSLPrerequisite.homebrew_formula_name"], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "Check if the OpenSSL prerequisite is met on a Darwin (MacOS) system. It checks if the Homebrew formula for OpenSSL is installed.", "Arguments": ":param self: OpenSSLPrerequisite. An instance of the OpenSSLPrerequisite class.\n:return: bool. True if the OpenSSL prerequisite is met, False otherwise."}, "tests": ["tests/test_prerequisites.py::TestOpenSSLPrerequisite::test_darwin_checker"], "indent": 8}
{"namespace": "mingus.containers.note.Note.to_hertz", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note.py", "signature_position": [226, 226], "body_position": [233, 234], "dependency": {"intra_class": ["mingus.containers.note.Note.__int__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts a given Note instance to Hertz (frequency in cycles per second).\n", "Arguments": ":param self: Note. An instance of the Note class.\n:param standard_pitch: float. The pitch of A-4, from which the rest of the notes are calculated. It defaults to 440 if not specified.\n:return: float. The frequency of the Note in Hertz.\n"}, "tests": ["tests/unit/containers/test_note.py::test_Note::test_to_hertz"], "indent": 8}
{"namespace": "jinja2.environment.Environment.from_string", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/environment.py", "signature_position": [1086, 1091], "body_position": [1103, 1105], "dependency": {"intra_class": ["jinja2.environment.Environment.compile", "jinja2.environment.Environment.make_globals", "jinja2.environment.Environment.template_class"], "intra_file": ["jinja2.environment.Template.from_code"], "cross_file": []}, "requirement": {"Functionality": "This function loads a template from a source string without using the loader. It compiles the source string into a template and returns an instance of the Template class.", "Arguments": ":param self: Environment. An instance of the Environment class.\n:param source: Union[str, nodes.Template]. The Jinja source to compile into a template.\n:param globals: Optional[MutableMapping[str, Any]]. Extra variables available for all renders of this template. If the template has already been loaded and cached, its globals are updated with any new items.\n:param template_class: Optional[Type[Template]]. The class of the template to be returned. If not specified, the default template class of the environment is used.\n:return: Template. The loaded template instance."}, "tests": ["tests/test_security.py::TestSandbox::test_attr_filter", "tests/test_security.py::TestSandbox::test_unary_operator_intercepting", "tests/test_security.py::TestStringFormat::test_basic_format_safety", "tests/test_security.py::TestStringFormat::test_safe_format_all_okay", "tests/test_security.py::TestStringFormat::test_empty_braces_format"], "indent": 8}
{"namespace": "wal_e.worker.pg.wal_transfer.WalTransferGroup.start", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/worker/pg/wal_transfer.py", "signature_position": [146, 146], "body_position": [149, 162], "dependency": {"intra_class": ["wal_e.worker.pg.wal_transfer.WalTransferGroup._complete_execution", "wal_e.worker.pg.wal_transfer.WalTransferGroup.closed", "wal_e.worker.pg.wal_transfer.WalTransferGroup.expect", "wal_e.worker.pg.wal_transfer.WalTransferGroup.greenlets", "wal_e.worker.pg.wal_transfer.WalTransferGroup.transferer"], "intra_file": [], "cross_file": ["wal_e.exception.UserCritical"]}, "requirement": {"Functionality": "This function starts the transfer process for a specified wal segment. It creates a gevent.Greenlet instance to execute the transferer function with the given segment as an argument. It then adds the gevent.Greenlet instance to the set of greenlets and starts the execution.", "Arguments": ":param self: WalTransferGroup. An instance of the WalTransferGroup class.\n:param segment: The wal segment to transfer.\n:return: No return values."}, "tests": ["tests/test_wal_transfer.py::test_simple_upload", "tests/test_wal_transfer.py::test_multi_upload", "tests/test_wal_transfer.py::test_multi_pipeline_fail", "tests/test_wal_transfer.py::test_start_after_join", "tests/test_wal_transfer.py::test_multi_explicit_fail"], "indent": 8}
{"namespace": "falcon.response.Response.set_header", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/response.py", "signature_position": [615, 615], "body_position": [641, 649], "dependency": {"intra_class": ["falcon.response.Response._headers"], "intra_file": [], "cross_file": ["falcon.errors.HeaderNotSupported"]}, "requirement": {"Functionality": "This function sets a header for the response with a given value. It overwrites any existing values for the header. It also performs some validations and conversions on the input values.", "Arguments": ":param self: Response. An instance of the Response class.\n:param name: String. The name of the header to be set. It should contain only US-ASCII characters.\n:param value: String. The value to be set for the header. It should contain only US-ASCII characters.\n:return: No return values."}, "tests": ["tests/test_headers.py::TestHeaders::test_set_cookie_disallowed"], "indent": 8}
{"namespace": "chatette.cli.interactive_commands.unhide_command.UnhideCommand.execute", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/cli/interactive_commands/unhide_command.py", "signature_position": [14, 14], "body_position": [19, 55], "dependency": {"intra_class": ["chatette.cli.interactive_commands.unhide_command.UnhideCommand.execute_on_unit"], "intra_file": [], "cross_file": ["chatette.cli.interactive_commands.command_strategy.CommandStrategy", "chatette.cli.interactive_commands.command_strategy.CommandStrategy.command_tokens", "chatette.cli.interactive_commands.command_strategy.CommandStrategy.get_regex_name", "chatette.cli.interactive_commands.command_strategy.CommandStrategy.get_unit_type_from_str", "chatette.cli.interactive_commands.command_strategy.CommandStrategy.print_wrapper", "chatette.cli.interactive_commands.command_strategy.CommandStrategy.split_exact_unit_name", "chatette.cli.interactive_commands.hide_command.HideCommand", "chatette.cli.interactive_commands.hide_command.HideCommand.stored_units", "chatette.cli.terminal_writer.TerminalWriter.write", "chatette.cli.terminal_writer.TerminalWriter.error_log"]}, "requirement": {"Functionality": "This function implements the command `unhide` which restores a unit definition that was hidden from the AST. It takes input arguments and performs certain actions based on the input. Initially, the function checks if the number of command tokens is less than three. It determines the unit type from the second command token and validate the type of unit. It tries to interpret the third command token as a regular expression and execute the restoration process on the unit with different regular expression conditions.", "Arguments": ":param self: UnhideCommand. An instance of the UnhideCommand class.\n:return: No return values."}, "tests": ["tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_variations", "tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_execute", "tests/unit-testing/cli/interactive_commands/test_hide_command.py::test_err"], "indent": 8}
{"namespace": "mingus.core.notes.reduce_accidentals", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/notes.py", "signature_position": [101, 101], "body_position": [108, 119], "dependency": {"intra_class": [], "intra_file": ["mingus.core.notes.int_to_note", "mingus.core.notes.note_to_int"], "cross_file": ["mingus.core.mt_exceptions.NoteFormatError"]}, "requirement": {"Functionality": "This function reduces any extra accidentals in a given note to proper notes.\n", "Arguments": ":param note: String. The note with accidentals\n:return: String. The reduced note without extra accidentals.\n"}, "tests": ["tests/unit/core/test_notes.py::test_notes::test_reduce_accidentals"], "indent": 4}
{"namespace": "mrjob.job.MRJob.run_combiner", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [769, 769], "body_position": [784, 787], "dependency": {"intra_class": ["mrjob.job.MRJob._wrap_protocols", "mrjob.job.MRJob.combine_pairs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function runs the combiner for the given step. It reads lines using the input protocol, combines them, and writes the combined output using the output protocol.\nThis function first selects the input and output protocol based on the given step and the combiner type. Then it iterates over the key-value pairs from the combine pairs. For each key-value pair, it writes the combined output using the output protocol.\n", "Arguments": ":param step_num: int. The index of the step to run (0-indexed).\n:return: no return values.\n"}, "tests": ["tests/test_job.py::StepNumTestCase::test_wrong_type_of_step"], "indent": 8}
{"namespace": "trackerjacker.ieee_mac_vendor_db.MacVendorDB.lookup", "type": "method", "project_path": "System/trackerjacker", "completion_path": "System/trackerjacker/trackerjacker/ieee_mac_vendor_db.py", "signature_position": [14, 14], "body_position": [16, 23], "dependency": {"intra_class": ["trackerjacker.ieee_mac_vendor_db.MacVendorDB.db"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function looks up the manufacturer name based on the MAC address provided. It takes a MAC address as input, converts it to uppercase and removes the colons. It then checks if the first 6 characters (':' removed) of the MAC address match any prefix in the database. If there is a match, it returns the corresponding manufacturer name.", "Arguments": ":param self: MacVendorDB. An instance of the MacVendorDB class.\n:param mac: String. The MAC address to lookup the manufacturer for.\n:return: String. The manufacturer name corresponding to the MAC address. If no match is found, an empty string is returned."}, "tests": ["tests/test_macvendordb.py::MacVendorDBTest::test_channel_parsing"], "indent": 8}
{"namespace": "datasette.app.Datasette.check_visibility", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [726, 734], "body_position": [736, 753], "dependency": {"intra_class": ["datasette.app.Datasette.ensure_permissions"], "intra_file": [], "cross_file": ["datasette.utils.asgi.Forbidden"]}, "requirement": {"Functionality": "This function checks the visibility of a resource for a given actor. It determines whether the actor can see the resource and whether the resource is private (visible only to the actor) or visible to everyone.", "Arguments": ":param self: Datasette. An instance of the Datasette class.\n:param actor: Dict. The actor for whom the visibility is checked.\n:param action: Optional[str]. The action to be performed on the resource. Defaults to None.\n:param resource: Optional[Union[str, Tuple[str, str]]]. The resource for which visibility is checked. Defaults to None.\n:param permissions: Optional[Sequence[Union[Tuple[str, Union[str, Tuple[str, str]]], str]]]. The permissions to be checked. Defaults to None.\n:return: Tuple[bool, bool]. A tuple containing two boolean values - visible (whether the actor can see the resource) and private (whether the resource is private)."}, "tests": ["tests/test_internals_datasette.py::test_datasette_ensure_permissions_check_visibility"], "indent": 8}
{"namespace": "mssqlcli.packages.sqlcompletion.suggest_type", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/packages/sqlcompletion.py", "signature_position": [133, 133], "body_position": [141, 160], "dependency": {"intra_class": [], "intra_file": ["mssqlcli.packages.sqlcompletion.Path", "mssqlcli.packages.sqlcompletion.SqlStatement", "mssqlcli.packages.sqlcompletion.SqlStatement.__init__", "mssqlcli.packages.sqlcompletion.SqlStatement.last_token", "mssqlcli.packages.sqlcompletion.SqlStatement.parsed", "mssqlcli.packages.sqlcompletion.SqlStatement.text_before_cursor", "mssqlcli.packages.sqlcompletion.SqlStatement.word_before_cursor", "mssqlcli.packages.sqlcompletion.suggest_based_on_last_token", "mssqlcli.packages.sqlcompletion.suggest_special"], "cross_file": []}, "requirement": {"Functionality": "This function suggests the completion type and scope based on the input text and the text before the cursor. It first checks if the input text starts with \"\\\\i \", and if so, it suggests a Path type. Then, it creates a SqlStatement instance with the input text and text before the cursor. If the SqlStatement is successfully parsed, it checks for special commands and handles them separately. Finally, it suggests the completion type and scope based on the last token of the SqlStatement.", "Arguments": ":param full_text: String. The full text that has been typed so far.\n:param text_before_cursor: String. The text before the cursor.\n:return: Tuple. A tuple with a type of entity ('table', 'column', etc.) and a scope. For a column category, the scope will be a list of tables."}, "tests": ["tests/test_sqlcompletion.py::SqlCompletionTests::test_where_in_suggests_columns", "tests/test_sqlcompletion.py::SqlCompletionTests::test_on_suggests_aliases_and_join_conditions", "tests/test_sqlcompletion.py::SqlCompletionTests::test_3_statements_2nd_current", "tests/test_sqlcompletion.py::SqlCompletionTests::test_statements_with_cursor_before_function_body", "tests/test_sqlcompletion.py::SqlCompletionTests::test_sub_select_suggests_keyword"], "indent": 4}
{"namespace": "pycoin.services.providers.providers_for_config_string", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/services/providers.py", "signature_position": [120, 120], "body_position": [121, 128], "dependency": {"intra_class": [], "intra_file": ["pycoin.services.providers.provider_for_descriptor_and_netcode"], "cross_file": []}, "requirement": {"Functionality": "This function takes a config string and a netcode as input and returns a list of providers. It iterates over each descriptor in the config string, gets the provider for that descriptor and netcode, and appends it to the list of providers. If a provider cannot be parsed for a descriptor, a warning is raised.", "Arguments": ":param config_string: String. The config string containing descriptors.\n:param netcode: The netcode to be used for provider lookup.\n:return: List of providers. The list of providers corresponding to the descriptors in the config string."}, "tests": ["tests/services/services_test.py::ServicesTest::test_env"], "indent": 4}
{"namespace": "mopidy.ext.validate_extension_data", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/ext.py", "signature_position": [271, 271], "body_position": [278, 357], "dependency": {"intra_class": [], "intra_file": ["mopidy.ext.Extension.validate_environment", "mopidy.ext.ExtensionData", "mopidy.ext.ExtensionData.config_defaults", "mopidy.ext.ExtensionData.config_schema", "mopidy.ext.ExtensionData.entry_point", "mopidy.ext.ExtensionData.extension", "mopidy.ext.logger"], "cross_file": ["mopidy.exceptions.ExtensionError", "mopidy.ext.Extension.ext_name", "mopidy.config", "mopidy.config.types.Boolean", "mopidy.config.types.ConfigValue", "mopidy.exceptions"]}, "requirement": {"Functionality": "This function validates the dependencies and environment of an extension. It checks if the extension's entry point name matches its extension name, if the required dependencies are installed, if the environment is valid, and if the extension has a valid config schema and default config.", "Arguments": ":param data: ExtensionData. The data of the extension to be validated.\n:return: bool. True if the extension is valid and should be run, False otherwise."}, "tests": ["tests/test_ext.py::TestValidateExtensionData::test_extenions_validate_environment_error", "tests/test_ext.py::TestValidateExtensionData::test_extenions_validate_environment_exception", "tests/test_ext.py::TestValidateExtensionData::test_entry_point_require_exception"], "indent": 4}
{"namespace": "mopidy.config.load", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/__init__.py", "signature_position": [107, 107], "body_position": [108, 116], "dependency": {"intra_class": [], "intra_file": ["mopidy.config._load", "mopidy.config._schemas", "mopidy.config._validate", "mopidy.config.read"], "cross_file": ["mopidy.config.keyring", "mopidy.config.keyring.fetch"]}, "requirement": {"Functionality": "This function loads configuration files and validates them against a set of schemas. It first determines the configuration directory based on the current file path. Then, it reads the default configuration file and appends it to an empty list. Then, it extends the list using ext_defaults. Next, it loads the configuration files, combines them with the default configurations and any overrides, and stores the result in the variable \"raw_config\". After that, it appends the external schemas to the list of schemas and validates the \"raw_config\" against the schemas.", "Arguments": ":param files: List of strings. The paths to the configuration files to be loaded.\n:param ext_schemas: List of strings. The paths to the external schemas to be used for validation.\n:param ext_defaults: List of strings. The paths to the external default configuration files.\n:param overrides: List of strings. The additional configuration overrides.\n:return: The validated configuration."}, "tests": ["tests/http/test_extension.py::test_default_config_is_valid"], "indent": 4}
{"namespace": "mrjob.logs.task._parse_task_syslog", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/task.py", "signature_position": [340, 340], "body_position": [357, 358], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.task._parse_task_syslog_records"], "cross_file": ["mrjob.logs.log4j._parse_hadoop_log4j_records"]}, "requirement": {"Functionality": "Parses an error out of a syslog file (or a Spark stderr file). \n", "Arguments": ":param lines: List of strings. The lines of the syslog file.\n:return: Dict. A dictionary containing the parsed information. It may contain the following keys:check_stdout, hadoop_error, split.\n"}, "tests": ["tests/logs/test_task.py::ParseTaskSyslogTestCase::test_spark_application_failed", "tests/logs/test_task.py::ParseTaskSyslogTestCase::test_opening_file", "tests/logs/test_task.py::ParseTaskSyslogTestCase::test_yarn_error", "tests/logs/test_task.py::ParseTaskSyslogTestCase::test_empty", "tests/logs/test_task.py::ParseTaskSyslogTestCase::test_spark_executor_exception"], "indent": 4}
{"namespace": "bentoml._internal.runner.strategy.DefaultStrategy.get_worker_count", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/strategy.py", "signature_position": [61, 66], "body_position": [67, 101], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.strategy.logger"], "cross_file": ["bentoml._internal.resource.get_resource", "bentoml._internal.resource.system_resources", "bentoml._internal.runner.runnable.Runnable"]}, "requirement": {"Functionality": "This function calculates the number of workers needed based on the given parameters. It first checks if there is a resource request for Nvidia GPUs and if the runnable class supports Nvidia GPUs. If so, it calculates the number of workers based on the number of available Nvidia GPUs and the workers per resource value. If not, it checks if there are CPUs available and if the runnable class supports CPUs. If so, it calculates the number of workers based on the number of available CPUs and the workers per resource value. If none of the conditions are met, it raises a ValueError indicating that there are no known supported resources available for the runnable class.", "Arguments": ":param cls: DefaultStrategy. The class itself.\n:param runnable_class: Type[Runnable]. The class of the runnable object.\n:param resource_request: Union[Dict[str, Any], None]. The resource request for the runnable object. Defaults to None.\n:param workers_per_resource: Union[int, float]. The number of workers per resource.\n:return: int. The number of workers needed based on the given parameters."}, "tests": ["tests/unit/_internal/runner/test_strategy.py::test_default_gpu_strategy", "tests/unit/_internal/runner/test_strategy.py::test_default_cpu_strategy"], "indent": 8}
{"namespace": "mopidy.config.types.String.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [114, 114], "body_position": [115, 119], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.types._TransformedValue", "mopidy.config.types.encode"], "cross_file": []}, "requirement": {"Functionality": "Serialize a value into a string representation. If the value is None, an empty string is returned. If the value is transformed, the original value is used for serialization. The value is then encoded into a string representation.", "Arguments": ":param self: String. An instance of the String class.\n:param value: Any. The value to be serialized.\n:param display: Bool. Whether to display the serialized value. Defaults to False.\n:return: str. The string representation of the serialized value."}, "tests": ["tests/config/test_types.py::TestString::test_serialize_transformed_value", "tests/config/test_types.py::TestString::test_serialize_handles_escapes", "tests/config/test_types.py::TestString::test_serialize_decodes_bytes", "tests/config/test_types.py::TestString::test_serialize_returns_text", "tests/config/test_types.py::TestString::test_serialize_none"], "indent": 8}
{"namespace": "twilio.base.deserialize.iso8601_date", "type": "function", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/base/deserialize.py", "signature_position": [10, 10], "body_position": [17, 24], "dependency": {"intra_class": [], "intra_file": ["twilio.base.deserialize.ISO8601_DATE_FORMAT"], "cross_file": []}, "requirement": {"Functionality": "This function parses an ISO 8601 date string and returns a UTC date object or the string itself if the parsing fails.", "Arguments": ":param s: str. The ISO 8601-formatted date string to be parsed.\n:return: Union[datetime.date, str]. The parsed UTC date object or the original string if parsing fails."}, "tests": ["tests/unit/base/test_deserialize.py::Iso8601DateTestCase::test_not_parsable", "tests/unit/base/test_deserialize.py::Iso8601DateTestCase::test_parsable"], "indent": 4}
{"namespace": "mssqlcli.packages.parseutils.ctes.extract_ctes", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/packages/parseutils/ctes.py", "signature_position": [49, 49], "body_position": [59, 93], "dependency": {"intra_class": [], "intra_file": ["mssqlcli.packages.parseutils.ctes.get_cte_from_token", "mssqlcli.packages.parseutils.ctes.token_start_pos"], "cross_file": []}, "requirement": {"Functionality": "This function extracts constant table expressions (CTEs) from a given SQL query. It parses the query using a parser and checks if the first meaningful token is \"WITH\", which indicates the presence of CTEs. It then extracts the CTEs from the query and returns them as a list of TableExpression namedtuples. The function also returns the remaining SQL text after the CTEs have been stripped.", "Arguments": ":param sql: String. The SQL query from which to extract CTEs.\n:return: Tuple. The first element is a list of TableExpression namedtuples representing the extracted CTEs. The second element is the remaining SQL text after the CTEs have been stripped."}, "tests": ["tests/parseutils/test_ctes.py::test_simple_cte_extraction", "tests/parseutils/test_ctes.py::test_cte_extraction_around_comments", "tests/parseutils/test_ctes.py::test_multiple_cte_extraction"], "indent": 4}
{"namespace": "fs.wildcard.imatch", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/wildcard.py", "signature_position": [41, 42], "body_position": [53, 58], "dependency": {"intra_class": [], "intra_file": ["fs.wildcard._PATTERN_CACHE", "fs.wildcard._translate"], "cross_file": []}, "requirement": {"Functionality": "This function tests whether a given name matches a wildcard pattern in a case-insensitive manner. It uses regular expressions to match the pattern against the name.", "Arguments": ":param pattern: Text. A wildcard pattern to match against the name.\n:param name: Text. A filename to test against the pattern.\n:return: bool. True if the filename matches the pattern, False otherwise."}, "tests": ["tests/test_wildcard.py::TestFNMatch::test_wildcard"], "indent": 4}
{"namespace": "praw.util.token_manager.SQLiteTokenManager.is_registered", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/util/token_manager.py", "signature_position": [160, 160], "body_position": [162, 165], "dependency": {"intra_class": ["praw.util.token_manager.SQLiteTokenManager._connection", "praw.util.token_manager.SQLiteTokenManager.key"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if a key is already registered (has a refresh token) in the SQLiteTokenManager instance. It queries the database to check if the key exists in the \"tokens\" table.", "Arguments": ":param self: SQLiteTokenManager. An instance of the SQLiteTokenManager class.\n:return: Bool. True if the key is registered, False otherwise."}, "tests": ["tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_register", "tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_multiple_instances"], "indent": 8}
{"namespace": "boltons.cacheutils.LRI.pop", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [268, 269], "body_position": [270, 279], "dependency": {"intra_class": ["boltons.cacheutils.LRI._lock", "boltons.cacheutils.LRI._remove_from_ll"], "intra_file": ["boltons.cacheutils._MISSING"], "cross_file": []}, "requirement": {"Functionality": "Pop the key in the LRI instance and return the corresponding value. If the key is not found and the default value is not passed, the exception is re-raised. This function bypasses the hit count and miss count.\n", "Arguments": ":param self: LRI, an instance of the LRI class.\n:param key: The key to remove in the instance.\n:param default: The value to return if the key is not found in the instance. Defaults to _UNSET.\n:return: The value corresponding to the key.\n"}, "tests": ["tests/test_cacheutils.py::test_lru_basic"], "indent": 8}
{"namespace": "awesome_autodl.autodl_topic2papers", "type": "function", "project_path": "Database/awesome-autodl", "completion_path": "Database/awesome-autodl/awesome_autodl/__init__.py", "signature_position": [58, 58], "body_position": [59, 76], "dependency": {"intra_class": [], "intra_file": ["awesome_autodl.autodl_topic2path"], "cross_file": []}, "requirement": {"Functionality": "This function loads YAML files containing information about papers related to different topics in the AutoDL field. It creates an OrderedDict where each key represents a topic and the corresponding value is a list of AutoDLpaper objects created from the data in the YAML file.", "Arguments": ":param: No input parameters.\n:return: OrderedDict. A dictionary where each key represents a topic and the corresponding value is a list of AutoDLpaper objects."}, "tests": ["tests/test_format.py::TestFormat::test_simple"], "indent": 4}
{"namespace": "boltons.fileutils.FilePerms.__repr__", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/fileutils.py", "signature_position": [214, 214], "body_position": [215, 217], "dependency": {"intra_class": ["boltons.fileutils.FilePerms.group", "boltons.fileutils.FilePerms.other", "boltons.fileutils.FilePerms.user"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the FilePerms instance. It includes the class name and the values of the user, group, and other attributes ('%s(user=%r, group=%r, other=%r)').", "Arguments": ":param self: FilePerms. An instance of the FilePerms class.\n:return: String. The string representation of the FilePerms instance."}, "tests": ["tests/test_fileutils.py::test_fileperms"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.buttons.MessageLinkButton._validate_and_patch_stream_data", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [521, 521], "body_position": [526, 549], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.ui_tools.buttons.ParsedNarrowLink"], "cross_file": ["zulipterminal.model.Model.is_user_subscribed_to_stream", "zulipterminal.model.Model.is_valid_stream", "zulipterminal.model.Model.stream_id_from_name"]}, "requirement": {"Functionality": "This function validates the stream data in a parsed link and patches the optional value in the nested DecodedStream dictionary. It checks if the stream ID and name are valid and subscribed to by the user. If not, it returns an error message. It also updates the stream ID or name in the parsed link if necessary.", "Arguments": ":param self: MessageLinkButton. An instance of the MessageLinkButton class.\n:param parsed_link: ParsedNarrowLink. The parsed link containing the stream data.\n:return: str. An empty string if the stream data is valid and patched successfully. Otherwise, an error message indicating the issue with the stream."}, "tests": ["tests/ui_tools/test_buttons.py::TestMessageLinkButton::test__validate_and_patch_stream_data"], "indent": 8}
{"namespace": "fs.info.Info.stem", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/info.py", "signature_position": [245, 246], "body_position": [255, 258], "dependency": {"intra_class": ["fs.info.Info.get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the stem of the name, which is the name minus any suffixes. It retrieves the name from the \"basic\" section of the instance and removes any suffixes by splitting the name at the first dot.", "Arguments": ":param self: Info. An instance of the Info class.\n:return: Text. The stem of the name."}, "tests": ["tests/test_info.py::TestInfo::test_suffix"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_values.compute_likelihood_windows_in_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_values.py", "signature_position": [447, 459], "body_position": [510, 541], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_values.compute_likelihood_window"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the likelihoods of a sliding window of a specified length in a given session. It uses the input parameters and calculates the likelihood for each window.", "Arguments": ":param session: List[Cmd]. A list of Cmd objects representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands (length 2).\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the params conditional on the commands.\n:param value_cond_param_probs: Union[StateMatrix, dict]. Computed probabilities of the values conditional on the params.\n:param modellable_params: set. A set of params for which the probabilities of their values will be included in the likelihood calculation.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, start_token and end_token will be added to the session before calculations.\n:param start_token: str. A dummy command to signify the start of the session.\n:param end_token: str. A dummy command to signify the end of the session.\n:param use_geo_mean: bool. If True, each likelihood of the sliding windows will be raised to the power of (1/window_len).\n:return: List[float]. A list of likelihoods for each sliding window."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_values.py::TestCmdsParamsValues::test_compute_likelihood_windows_in_session"], "indent": 4}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.mkdir", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [286, 286], "body_position": [287, 298], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem.get_hadoop_version", "mrjob.fs.hadoop.HadoopFilesystem.invoke_hadoop"], "intra_file": ["mrjob.fs.hadoop._HADOOP_FILE_EXISTS_RE"], "cross_file": ["mrjob.compat.uses_yarn"]}, "requirement": {"Functionality": "Create a directory in the Hadoop filesystem. It uses Hadoop 'fs -mkdir' command (additionally with '-p' option on Hadoop 2) to create the directory. If the command fails except for the case where the directory already exists, it raises an IOError: 'Could not mkdir {path}'.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:param path: str. The path of the directory to be created.\n:return: No return values."}, "tests": ["tests/fs/test_hadoop.py::HadoopFSTestCase::test_mkdir"], "indent": 8}
{"namespace": "boto.dynamodb.batch.Batch.to_dict", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb/batch.py", "signature_position": [58, 58], "body_position": [62, 80], "dependency": {"intra_class": ["boto.dynamodb.batch.Batch.attributes_to_get", "boto.dynamodb.batch.Batch.consistent_read", "boto.dynamodb.batch.Batch.keys", "boto.dynamodb.batch.Batch.table"], "intra_file": [], "cross_file": ["boto.dynamodb.layer2", "boto.dynamodb.layer2.Layer2.build_key_from_values", "boto.dynamodb.schema"]}, "requirement": {"Functionality": "This function converts a Batch object into the format required for Layer1.", "Arguments": ":param self: Batch. An instance of the Batch class.\n:return: dict. The Batch object converted into the required format for Layer1."}, "tests": ["tests/unit/dynamodb/test_batch.py::TestBatchObjects::test_batch_to_dict", "tests/unit/dynamodb/test_batch.py::TestBatchObjects::test_batch_consistent_read_defaults_to_false"], "indent": 8}
{"namespace": "sacred.config.custom_containers.DogmaticDict.get", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/custom_containers.py", "signature_position": [84, 84], "body_position": [85, 88], "dependency": {"intra_class": ["sacred.config.custom_containers.DogmaticDict.fallback"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the value associated with the given key from the DogmaticDict instance. If the key is not found in the instance, it checks the fallback dictionary and returns the value associated with the key from the fallback dictionary if found, otherwise it returns the default value.", "Arguments": ":param self: DogmaticDict. An instance of the DogmaticDict class.\n:param k: The key to retrieve the value from the instance.\n:param d: The default value to return if the key is not found in the instance or the fallback dictionary. Defaults to None.\n:return: The value associated with the key, or the value associated with the key in the fallback dictionary, or the default value."}, "tests": ["tests/test_config/test_dogmatic_dict.py::test_fallback"], "indent": 8}
{"namespace": "boto.vpc.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/vpc/__init__.py", "signature_position": [56, 56], "body_position": [70, 72], "dependency": {"intra_class": [], "intra_file": ["boto.vpc.VPCConnection"], "cross_file": ["boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns a connection object of type `boto.vpc.VPCConnection`.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param **kw_params: Additional parameters to be passed to the `connect` method of the region object.\n:return: `boto.vpc.VPCConnection` or None. A connection to the given region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestVpcConnection::test_connect_to_region"], "indent": 4}
{"namespace": "mrjob.job.MRJob.steps", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [497, 497], "body_position": [517, 546], "dependency": {"intra_class": ["mrjob.job.MRJob.spark_args"], "intra_file": [], "cross_file": ["mrjob.step.MRStep", "mrjob.step.SparkStep", "mrjob.step._JOB_STEP_FUNC_PARAMS"]}, "requirement": {"Functionality": "This function redefines the steps of the MRJob class to create a multi-step job. If the steps are not redefined, a one-step job will be automatically created using any of the redefined mapper, reducer, and other related methods.\nThe function creates a dictionary of redefined methods, excluding those that are not redefined. For special cases where the spark method is redefined, a SparkStep is created. MRStep takes commands as strings, but the user defines them in the class as functions that return strings, so the function calls these functions and updates the kwargs dictionary accordingly. Finally, the function returns a list of MRStep objects constructed with the updated kwargs.\n", "Arguments": ":param self: MRJob. An instance of MRJob class.\n:return: List of MRStep. A list of steps constructed with MRStep or other classes in mrjob.step.\n"}, "tests": ["tests/test_job.py::StepsTestCase::test_spark_and_streaming_dont_mix", "tests/test_job.py::StepsTestCase::test_spark_and_spark_args_methods", "tests/test_job.py::StepsTestCase::test_spark_args_ignored_without_spark", "tests/test_job.py::StepsTestCase::test_spark_method"], "indent": 8}
{"namespace": "kinto.core.resource.Resource.plural_post", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/resource/__init__.py", "signature_position": [411, 411], "body_position": [428, 454], "dependency": {"intra_class": ["kinto.core.resource.Resource._add_timestamp_header", "kinto.core.resource.Resource._get_object_or_404", "kinto.core.resource.Resource._raise_412_if_modified", "kinto.core.resource.Resource.model", "kinto.core.resource.Resource.object_id", "kinto.core.resource.Resource.postprocess", "kinto.core.resource.Resource.process_object", "kinto.core.resource.Resource.request"], "intra_file": [], "cross_file": ["kinto.core.resource.model.Model.create_object", "kinto.core.events.ACTIONS", "kinto.core.events.ACTIONS.CREATE", "kinto.core.events.ACTIONS.READ"]}, "requirement": {"Functionality": "This function is the \"POST\" endpoint for creating an object in a model. It first checks if the new object id conflicts with an existing one. If it does, the existing object is returned with a status code of 200. If the \"If-Match\" header is provided and the objects have been modified in the meantime, a \"HTTPPreconditionFailed\" exception is raised. If the object id is specified, it is added to the posted body and the existing object is looked up. If the object exists, it is returned with a status code of 200. If the object does not exist, the new object is processed, created, and returned with a status code of 201.", "Arguments": ":param self: Resource. An instance of the Resource class.\n:return: The created or existing object with the appropriate status code."}, "tests": ["tests/core/resource/test_model.py::CreateTest::test_create_object_returns_at_least_id_and_last_modified", "tests/core/resource/test_sync.py::SinceModifiedTest::test_filter_from_last_modified_is_exclusive", "tests/core/resource/test_model.py::CreateTest::test_new_objects_are_linked_to_owner", "tests/core/resource/test_sync.py::SinceModifiedTest::test_delete_timestamp_header_is_equal_to_last_deleted", "tests/core/resource/test_sync.py::SinceModifiedTest::test_objects_created_during_fetch_are_above_fetch_timestamp"], "indent": 8}
{"namespace": "mrjob.job.MRJob.run_mapper", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [754, 754], "body_position": [764, 767], "dependency": {"intra_class": ["mrjob.job.MRJob._wrap_protocols", "mrjob.job.MRJob.map_pairs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function runs the mapper and final mapper action for the given step in the MRJob class. It picks the input and output protocol, reads lines, and writes the key-value pairs.\nUses a method to pick the input and output protocol. It then iterates over the key-value pairs from its map pairs and writes each pair using the output protocol.\n", "Arguments": ":param step_num: int. Specifies which step to run (0-indexed).\n:return: no return values.\n"}, "tests": ["tests/test_job.py::StepNumTestCase::test_nonexistent_steps", "tests/test_job.py::StepNumTestCase::test_wrong_type_of_step", "tests/test_job.py::ProtocolsTestCase::test_mapper_raw_value_to_json"], "indent": 8}
{"namespace": "boltons.cacheutils.CachedFunction.__repr__", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [479, 479], "body_position": [480, 484], "dependency": {"intra_class": ["boltons.cacheutils.CachedFunction.func", "boltons.cacheutils.CachedFunction.scoped", "boltons.cacheutils.CachedFunction.typed"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the CachedFunction instance. If it is typed or not scoped, it returns '{type name}(func={func!r}, scoped={scoped!r}, typed={typed!r})'. Otherwise, it returns '{type name}(func={func!r})'.", "Arguments": ":param self: CachedFunction. An instance of the CachedFunction class.\n:return: str. The string representation of the CachedFunction instance."}, "tests": ["tests/test_cacheutils.py::test_callable_cached_dec"], "indent": 8}
{"namespace": "mingus.core.chords.determine", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/chords.py", "signature_position": [920, 920], "body_position": [925, 942], "dependency": {"intra_class": [], "intra_file": ["mingus.core.chords.determine_extended_chord5", "mingus.core.chords.determine_extended_chord6", "mingus.core.chords.determine_extended_chord7", "mingus.core.chords.determine_polychords", "mingus.core.chords.determine_seventh", "mingus.core.chords.determine_triad"], "cross_file": ["mingus.core.intervals", "mingus.core.intervals.determine"]}, "requirement": {"Functionality": "This function determines the name of a chord based on the number of notes in the chord.\nUse a series of conditional statements to determine the chord name based on the chord length.\n", "Arguments": ":param chord: List of strings. The list of notes in the chord.\n:param shorthand: Bool. Whether to use shorthand notation for chord names.\n:param no_inversions: Bool. Whether to exclude inversions from the chord name.\n:param no_polychords: Bool. Whether to exclude polychords from the chord name.\n:return: List of strings. The determined chord name.\n"}, "tests": ["tests/unit/core/test_chords.py::test_chords::test_determine"], "indent": 4}
{"namespace": "sacred.config.config_scope.dedent_function_body", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/config_scope.py", "signature_position": [167, 167], "body_position": [168, 179], "dependency": {"intra_class": [], "intra_file": ["sacred.config.config_scope.is_empty_or_comment"], "cross_file": []}, "requirement": {"Functionality": "This function dedents the body of a function. It first splits the body into individual lines, then finds the common indentation by examining the first non-empty and non-comment line. After that, it dedents each line by removing the common indentation, and finally joins the dedented lines back together.", "Arguments": ":param body: str. The body of the function to be dedented.\n:return: str. The dedented body of the function."}, "tests": ["tests/test_config/test_config_scope.py::test_dedent_body"], "indent": 4}
{"namespace": "telethon.crypto.rsa.encrypt", "type": "function", "project_path": "Communications/Telethon", "completion_path": "Communications/Telethon/telethon/crypto/rsa.py", "signature_position": [57, 57], "body_position": [68, 82], "dependency": {"intra_class": [], "intra_file": ["telethon.crypto.rsa._server_keys"], "cross_file": []}, "requirement": {"Functionality": "This function encrypts the given data using the specified fingerprint and the encryption method required by Telegram. It first checks if a key matching the fingerprint is available. If not, it returns None. If a key is found, it performs the encryption process by appending the SHA1 hash of the data, the data itself, and padding to the data. It then encrypts the resulting data using RSA encryption and returns the encrypted cipher text.", "Arguments": ":param fingerprint: The fingerprint of the RSA key.\n:param data: The data to be encrypted.\n:param use_old: Bool. Whether to use old keys for encryption.\n:return: The encrypted cipher text, or None if no key matching the fingerprint is found."}, "tests": ["tests/telethon/crypto/test_rsa.py::test_encryption_allowed_old_key", "tests/telethon/crypto/test_rsa.py::test_encryption_current_key"], "indent": 4}
{"namespace": "authlib.oauth2.rfc6749.util.list_to_scope", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/oauth2/rfc6749/util.py", "signature_position": [6, 6], "body_position": [8, 12], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["authlib.common.encoding.to_unicode"]}, "requirement": {"Functionality": "This function converts a list of scopes into a space-separated string. It checks if the input scope is of type set, tuple, or list, and then joins the elements of the scope with a space separator. If the scope is None, it returns None. Otherwise, it converts the scope to Unicode and returns it.", "Arguments": ":param scope: The input scope to be converted.\n:return: str. The converted space-separated string representation of the scope."}, "tests": ["tests/core/test_oauth2/test_rfc6749_misc.py::OAuth2UtilTest::test_list_to_scope"], "indent": 4}
{"namespace": "wal_e.worker.pg.wal_transfer.WalTransferGroup.join", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/worker/pg/wal_transfer.py", "signature_position": [130, 130], "body_position": [132, 144], "dependency": {"intra_class": ["wal_e.worker.pg.wal_transfer.WalTransferGroup.closed", "wal_e.worker.pg.wal_transfer.WalTransferGroup.expect", "wal_e.worker.pg.wal_transfer.WalTransferGroup.greenlets", "wal_e.worker.pg.wal_transfer.WalTransferGroup.wait_change"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function waits for the transfer to exit and raises any errors that occur during the process. It closes the input WalTransferGroup instance. Then, it waits a while for all running greenlets to exit and attempts to force them to exit so join terminates in a reasonable amount of time (e.g., 30).", "Arguments": ":param self: WalTransferGroup. An instance of the WalTransferGroup class.\n:return: No return values."}, "tests": ["tests/test_wal_transfer.py::test_simple_upload", "tests/test_wal_transfer.py::test_multi_upload", "tests/test_wal_transfer.py::test_multi_pipeline_fail", "tests/test_wal_transfer.py::test_start_after_join", "tests/test_wal_transfer.py::test_multi_explicit_fail"], "indent": 8}
{"namespace": "mrjob.conf.load_opts_from_mrjob_confs", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [306, 306], "body_position": [324, 341], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.load_opts_from_mrjob_conf", "mrjob.conf.log"], "cross_file": []}, "requirement": {"Functionality": "This function loads a list of dictionaries representing the options in a given list of mrjob config files for a specific runner. It returns a list of tuples, where each tuple contains the path of the config file and its corresponding values. If a path is not found, it uses (None, {}) as its value and if the runner alias is also specified, it logs a warning message: 'No config specified for {runner alias} runner'.", "Arguments": ":param runner_alias: str. The identifier of the runner type.\n:param conf_paths: List or None. The locations of the config files to load. If None, it looks for a config file in the default locations.\n:return: List of tuples. Each tuple contains the path of the config file and its corresponding values."}, "tests": ["tests/test_conf.py::MRJobBasicConfTestCase::test_symlink_to_duplicate_conf_path", "tests/test_conf.py::MRJobBasicConfTestCase::test_duplicate_conf_path", "tests/test_conf.py::MRJobBasicConfTestCase::test_conf_path_order_beats_include"], "indent": 4}
{"namespace": "boto.ec2.networkinterface.NetworkInterface.update", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/networkinterface.py", "signature_position": [172, 172], "body_position": [183, 191], "dependency": {"intra_class": ["boto.ec2.networkinterface.NetworkInterface._update", "boto.ec2.networkinterface.NetworkInterface.connection", "boto.ec2.networkinterface.NetworkInterface.id", "boto.ec2.networkinterface.NetworkInterface.status"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.get_all_network_interfaces"]}, "requirement": {"Functionality": "This function updates the data associated with a NetworkInterface instance by querying EC2. It retrieves the data for the specified ENI ID from EC2 and updates the instance with the new data.", "Arguments": ":param self: NetworkInterface. An instance of the NetworkInterface class.\n:param validate: bool. By default, if EC2 returns no data about the ENI, the update method returns quietly. If the validate parameter is set to True, it will raise a ValueError exception if no data is returned from EC2.\n:param dry_run: bool. Whether to perform a dry run of the update operation. Defaults to False.\n:return: str. The status of the NetworkInterface after the update."}, "tests": ["tests/unit/ec2/test_networkinterface.py::NetworkInterfaceTests::test_update_with_result_set_greater_than_0_updates_dict", "tests/unit/ec2/test_networkinterface.py::NetworkInterfaceTests::test_update_returns_status", "tests/unit/ec2/test_networkinterface.py::NetworkInterfaceTests::test_update_with_validate_true_raises_value_error"], "indent": 8}
{"namespace": "alembic.util.sqla_compat._get_constraint_final_name", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/util/sqla_compat.py", "signature_position": [542, 544], "body_position": [545, 578], "dependency": {"intra_class": [], "intra_file": ["alembic.util.sqla_compat.sqla_14"], "cross_file": []}, "requirement": {"Functionality": "This function returns the final name of a constraint based on the given constraint and dialect. It checks if the constraint has a name, and if not, returns None. If SQLAlchemy version is 1.4 or above, it uses the new API to format the constraint name for the given dialect. Otherwise, it works around the quoting logic to get the final compiled name without quotes.", "Arguments": ":param constraint: Union[Index, Constraint]. The constraint for which the final name is to be determined.\n:param dialect: Optional[Dialect]. The dialect for which the constraint name is to be formatted.\n:return: Optional[str]. The final compiled form of the constraint name for the given dialect, or None if the constraint has no name."}, "tests": ["tests/test_autogen_indexes.py::AutogenerateIndexTest::test_new_table_added"], "indent": 4}
{"namespace": "pyramid.registry.Introspector.get_category", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [136, 136], "body_position": [137, 147], "dependency": {"intra_class": ["pyramid.registry.Introspector._categories", "pyramid.registry.Introspector.related"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a category from the Introspector instance based on the given category name. It then sorts the values in the category based on the sort key and returns a list of dictionaries containing the introspectable values and their related values.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param category_name: str. The name of the category to retrieve.\n:param default: Any. The default value to return if the category is not found. Defaults to None.\n:param sort_key: Callable. The key function used for sorting the values in the category. Defaults to None. If it is None, the order of the values will be used for sorting.\n:return: List[dict]. A list of dictionaries containing the introspectable values (with the key 'introspectable') and their related values (with the key 'related')."}, "tests": ["tests/test_registry.py::TestIntrospector::test_get_category_returns_default_on_miss", "tests/test_registry.py::TestIntrospector::test_get_category", "tests/test_registry.py::TestIntrospector::test_get_category_with_sortkey"], "indent": 8}
{"namespace": "twilio.base.serialize.iso8601_date", "type": "function", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/base/serialize.py", "signature_position": [7, 7], "body_position": [12, 19], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["twilio.base.values", "twilio.base.values.unset"]}, "requirement": {"Functionality": "This function takes a date object and returns a string representation of the date in the format \"YYYY-MM-DD\". If the input is not a string, datetime, or date object, it returns None.", "Arguments": ":param d: The date object to be converted to a string representation.\n:return: str or None. The string representation of the date in the format \"YYYY-MM-DD\", or None if the input is not a string, datetime, or date object."}, "tests": ["tests/unit/base/test_serialize.py::Iso8601DateTestCase::test_str", "tests/unit/base/test_serialize.py::Iso8601DateTestCase::test_unset", "tests/unit/base/test_serialize.py::Iso8601DateTestCase::test_datetime_without_time", "tests/unit/base/test_serialize.py::Iso8601DateTestCase::test_date", "tests/unit/base/test_serialize.py::Iso8601DateTestCase::test_datetime"], "indent": 4}
{"namespace": "asyncssh.mac.get_mac", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/mac.py", "signature_position": [158, 158], "body_position": [166, 167], "dependency": {"intra_class": [], "intra_file": ["asyncssh.mac.MAC", "asyncssh.mac._mac_handler"], "cross_file": []}, "requirement": {"Functionality": "This function returns a MAC (Message Authentication Code) handler object that is initialized with the specified key. The MAC handler can be used for data signing and verification.", "Arguments": ":param mac_alg: bytes. The algorithm used for the MAC.\n:param key: bytes. The key used to initialize the MAC handler.\n:return: MAC. The MAC handler object."}, "tests": ["tests/test_mac.py::_TestMAC::test_mac_algs"], "indent": 4}
{"namespace": "kinto.core.resource.Resource.get", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/resource/__init__.py", "signature_position": [497, 497], "body_position": [512, 524], "dependency": {"intra_class": ["kinto.core.resource.Resource._add_cache_header", "kinto.core.resource.Resource._add_timestamp_header", "kinto.core.resource.Resource._extract_partial_fields", "kinto.core.resource.Resource._get_object_or_404", "kinto.core.resource.Resource._raise_304_if_not_modified", "kinto.core.resource.Resource._raise_400_if_invalid_id", "kinto.core.resource.Resource._raise_412_if_modified", "kinto.core.resource.Resource.model", "kinto.core.resource.Resource.object_id", "kinto.core.resource.Resource.postprocess", "kinto.core.resource.Resource.request"], "intra_file": [], "cross_file": ["kinto.core.utils.dict_subset"]}, "requirement": {"Functionality": "This function is the \"GET\" endpoint for retrieving an object. It performs several checks and operations before returning the object. It checks if the object is found, if it has been modified, and if any partial fields need to be extracted. It then adds a timestamp header and a cache header to the response and returns the object. If have partial fields, it extracts them from the object as the result object. Depending on the situation, different error labels may be raised.", "Arguments": ":param self: Resource. An instance of the Resource class.\n:return: The retrieved object."}, "tests": ["tests/core/resource/test_object.py::GetTest::test_etag_contains_object_timestamp", "tests/core/resource/test_object.py::MergePatchTest::test_merge_patch_removes_attribute_if_none", "tests/core/resource/test_object.py::MergePatchTest::test_patch_doesnt_remove_attribute_if_not_merge_header", "tests/core/resource/test_object.py::UnknownObjectTest::test_get_object_unknown_raises_404", "tests/core/resource/test_object.py::GetTest::test_get_object_returns_all_fields"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage.__repr__", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [1068, 1068], "body_position": [1069, 1071], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage.pageid", "wikipediaapi.WikipediaPage.title"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of a WikipediaPage object. It checks if any recorded methods have been called, and if so, it includes the title, pageid, and ns in the string: \"{title} (id: {page id}, ns: {ns})\". Otherwise, it includes only the title and ns attributes in the string: \"{title} (id: ??, ns: {ns})\"", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: String. The string representation of the WikipediaPage object."}, "tests": ["tests/wikipedia_page_test.py::TestWikipediaPage::test_repr_after_fetching", "tests/wikipedia_page_test.py::TestWikipediaPage::test_repr_before_fetching"], "indent": 8}
{"namespace": "jc.cli.JcCli.about_jc", "type": "method", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/cli.py", "signature_position": [262, 262], "body_position": [264, 284], "dependency": {"intra_class": [], "intra_file": ["jc.cli.info", "jc.cli.info.author", "jc.cli.info.author_email", "jc.cli.info.copyright", "jc.cli.info.description", "jc.cli.info.license", "jc.cli.info.version", "jc.cli.info.website"], "cross_file": ["jc.jc_types.JSONDictType", "jc.lib.all_parser_info", "jc.lib.parser_mod_list", "jc.lib.plugin_parser_mod_list", "jc.lib.standard_parser_mod_list", "jc.lib.streaming_parser_mod_list"]}, "requirement": {"Functionality": "This function returns a dictionary containing information about the jc library and the contents of each parser.info. It includes details such as the library name, version, description, author, author email, website, copyright, license, Python version, Python path, parser count, standard parser count, streaming parser count, plugin parser count, and all parser information.", "Arguments": ":param: No input parameters.\n:return: JSONDictType. A dictionary containing information about the jc library and parser.info."}, "tests": ["tests/test_jc_cli.py::MyTests::test_cli_about_jc"], "indent": 8}
{"namespace": "pyramid.i18n.LocalizerRequestMixin.locale_name", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/i18n.py", "signature_position": [376, 376], "body_position": [377, 378], "dependency": {"intra_class": [], "intra_file": ["pyramid.i18n.negotiate_locale_name"], "cross_file": []}, "requirement": {"Functionality": "This function returns the name of the locale based on the negotiation with the client.", "Arguments": ":param self: LocalizerRequestMixin. An instance of the LocalizerRequestMixin class.\n:return: String. The name of the locale."}, "tests": ["tests/test_i18n.py::TestLocalizerRequestMixin::test_default_localizer"], "indent": 8}
{"namespace": "pyramid.urldispatch.RoutesMapper.get_routes", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/urldispatch.py", "signature_position": [37, 37], "body_position": [38, 41], "dependency": {"intra_class": ["pyramid.urldispatch.RoutesMapper.routelist", "pyramid.urldispatch.RoutesMapper.static_routes"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the list of routes in a RoutesMapper instance. If the include_static parameter is set to True, it also includes the static routes in the returned list.", "Arguments": ":param self: RoutesMapper. An instance of the RoutesMapper class.\n:param include_static: Bool. Whether to include static routes in the returned list. Defaults to False.\n:return: List. The list of routes, including static routes if include_static is True."}, "tests": ["tests/test_urldispatch.py::RoutesMapperTests::test_get_routes"], "indent": 8}
{"namespace": "rest_framework.fields.Field.run_validation", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [534, 534], "body_position": [544, 549], "dependency": {"intra_class": ["rest_framework.fields.Field.run_validators", "rest_framework.fields.Field.to_internal_value", "rest_framework.fields.Field.validate_empty_values"], "intra_file": ["rest_framework.fields.empty"], "cross_file": []}, "requirement": {"Functionality": "This function is used to validate a simple representation and return the internal value. It first checks if the provided data is empty. If it is empty, it returns the data as is. If not, it converts the data to the internal value and runs validators on the value. Finally, it returns the validated value.", "Arguments": ":param self: Field. An instance of the Field class.\n:param data: Any. The data to be validated. It may be empty if no representation was included in the input.\n:return: Any. The validated internal value."}, "tests": ["tests/test_fields.py::TestEmpty::test_not_required", "tests/test_fields.py::TestEmpty::test_required", "tests/test_fields.py::TestDictField::test_allow_empty_disallowed", "tests/test_fields.py::TestEmpty::test_default", "tests/test_fields.py::TestBooleanField::test_disallow_unhashable_collection_types"], "indent": 8}
{"namespace": "boto.ec2.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/__init__.py", "signature_position": [47, 47], "body_position": [61, 68], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection", "boto.regioninfo.RegionInfo", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns an EC2Connection object.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param **kw_params: Additional parameters that are passed on to the connect method of the region object.\n:return: EC2Connection or None. A connection to the given region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestEC2Connection::test_connect_to_region"], "indent": 4}
{"namespace": "pyramid.request.Request.session", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/request.py", "signature_position": [185, 185], "body_position": [190, 197], "dependency": {"intra_class": ["pyramid.request.Request.registry"], "intra_file": [], "cross_file": ["pyramid.interfaces.ISessionFactory"]}, "requirement": {"Functionality": "This function is to obtain the session object associated with the input request instance. If a session factory has not been registered, it raises a ConfigurationError.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: The session object associated with the request."}, "tests": ["tests/test_request.py::TestRequest::test_session_configured"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.expunge", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1488, 1488], "body_position": [1521, 1528], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._consume_until_tagged_response", "imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient.use_uid"], "intra_file": ["imapclient.imapclient.join_message_ids"], "cross_file": []}, "requirement": {"Functionality": "This function is used to expunge messages from the selected folder in an IMAP client. If no messages are specified, it removes all messages with the \"\\Deleted\" flag set. If messages are specified, it removes the specified messages with the \"\\Deleted\" flag set. The function returns the server response message followed by a list of expunge responses. The implementation takes into account whether the client is using UIDs or not.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param messages: List of int or str. The messages to be expunged. Defaults to None.\n:return: Tuple. The server response message followed by a list of expunge responses if no messages are specified. None if messages are specified."}, "tests": ["tests/test_imapclient.py::TestExpunge::test_expunge", "tests/test_imapclient.py::TestExpunge::test_id_expunge"], "indent": 8}
{"namespace": "mingus.core.progressions.substitute", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/progressions.py", "signature_position": [426, 426], "body_position": [436, 504], "dependency": {"intra_class": [], "intra_file": ["mingus.core.progressions.interval_diff", "mingus.core.progressions.parse_string", "mingus.core.progressions.skip", "mingus.core.progressions.substitute", "mingus.core.progressions.tuple_to_string"], "cross_file": []}, "requirement": {"Functionality": "This function generates a list of possible substitutions for the element at index `substitute_index` in the given `progression`. It considers different harmonic substitutions and recursively adds substitutions if `depth` is greater than 0.\nUsing a set of predefined harmonic substitutions. It checks the suffix of the element and applies the corresponding substitutions based on the suffix.\n", "Arguments": ":param progression: List of strings. The given musical progression.\n:param substitute_index: Int. The index of the element in the progression to be substituted.\n:param depth: Int. The depth of recursion. It determines how many levels of substitutions are applied. Defaults to 0.\n:return: List of strings. The list of possible substitutions for the element at `substitute_index`.\n"}, "tests": ["tests/unit/core/test_progressions.py::test_progressions::test_substitute"], "indent": 4}
{"namespace": "boltons.cacheutils.LRI.popitem", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [281, 281], "body_position": [282, 285], "dependency": {"intra_class": ["boltons.cacheutils.LRI._lock", "boltons.cacheutils.LRI._remove_from_ll"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes and returns a (key, value) pair from the LRI class instance.\n", "Arguments": ":param self: LRI, an instance of the LRI class.\n:return: tuple. The removed (key, value) pair from the LRI instance.\n"}, "tests": ["tests/test_cacheutils.py::test_lru_basic"], "indent": 8}
{"namespace": "alembic.script.revision.RevisionMap.get_revision", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [558, 558], "body_position": [572, 577], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._resolve_revision_number", "alembic.script.revision.RevisionMap._revision_for_ident"], "intra_file": ["alembic.script.revision.MultipleHeads", "alembic.script.revision.MultipleHeads.__init__", "alembic.script.revision.Revision"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a specific revision from the RevisionMap instance with the given revision id. It first resolves the given id to the current head or base revision if a symbolic name is provided. If the id matches multiple revisions, it raises a multiple heads exception. It then returns the Revision instance corresponding to the resolved id.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param id_: Optional[str]. The revision id or symbolic name to retrieve. Defaults to None.\n:return: Optional[Revision]. The Revision instance corresponding to the given id, or None if the id is not found."}, "tests": ["tests/test_revision.py::LabeledBranchTest::test_retrieve_branch_revision", "tests/test_revision.py::BranchTravellingTest::test_ancestor_nodes", "tests/test_revision.py::APITest::test_invalid_datatype", "tests/test_revision.py::APITest::test_get_revision_head_multiple", "tests/test_revision.py::APITest::test_get_revision_heads_multiple"], "indent": 8}
{"namespace": "mingus.core.intervals.major_seventh", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [231, 231], "body_position": [232, 233], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.seventh"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the major seventh interval for a given note. It first determines the seventh interval based on the note's root and the root \"C\". Then, it adjusts the note by augmenting or diminishing it until the interval is equal to 11.", "Arguments": ":param note: String. The note for which the major seventh interval is calculated.\n:return: String. The note with the major seventh interval."}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_major_seventh"], "indent": 4}
{"namespace": "kinto.plugins.openid.OpenIDConnectPolicy._verify_token", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/openid/__init__.py", "signature_position": [68, 68], "body_position": [69, 80], "dependency": {"intra_class": ["kinto.plugins.openid.OpenIDConnectPolicy.oid_config"], "intra_file": [], "cross_file": ["kinto.core.logger"]}, "requirement": {"Functionality": "This function verifies the access token by fetching the user information from the profile endpoint. It sends a GET request to the userinfo endpoint with the access token in the Authorization header. If the request is successful, it returns the user profile information. If there is an error during the request or parsing the response, it logs a debug message and returns None.", "Arguments": ":param self: OpenIDConnectPolicy. An instance of the OpenIDConnectPolicy class.\n:param access_token: String. The access token to verify.\n:return: Dictionary. The user profile information if the access token is valid, otherwise None."}, "tests": ["tests/plugins/test_openid.py::VerifyTokenTest::test_fetches_userinfo_if_id_token_is_none"], "indent": 8}
{"namespace": "boto.dynamodb2.fields.GlobalBaseIndexField.schema", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/fields.py", "signature_position": [235, 235], "body_position": [260, 265], "dependency": {"intra_class": ["boto.dynamodb2.fields.GlobalBaseIndexField.throughput"], "intra_file": ["boto.dynamodb2.fields.BaseIndexField", "boto.dynamodb2.fields.BaseIndexField.schema"], "cross_file": []}, "requirement": {"Functionality": "This function returns the schema structure that DynamoDB expects for a global base index field. It first gets a base schema structure from its parent class, and then adds the provisioned throughput information to the base schema.", "Arguments": ":param self: GlobalBaseIndexField. An instance of the GlobalBaseIndexField class.\n:return: Dictionary. The schema structure that DynamoDB expects for the global base index field."}, "tests": ["tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_all_index", "tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_keys_only_index"], "indent": 8}
{"namespace": "boto.dynamodb2.items.Item.get_raw_keys", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [240, 240], "body_position": [246, 251], "dependency": {"intra_class": ["boto.dynamodb2.items.Item._dynamizer", "boto.dynamodb2.items.Item.get_keys"], "intra_file": [], "cross_file": ["boto.dynamodb.types.Dynamizer.encode"]}, "requirement": {"Functionality": "This function returns a dictionary of the keys and their corresponding values in DynamoDB-style format. It iterates over the keys and values and encodes the values before adding them to the dictionary.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: Dict. A dictionary containing the keys and their corresponding encoded values in DynamoDB-style format."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_get_raw_keys"], "indent": 8}
{"namespace": "twtxt.config.Config.following", "type": "method", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/config.py", "signature_position": [101, 101], "body_position": [103, 111], "dependency": {"intra_class": ["twtxt.config.Config.cfg"], "intra_file": ["twtxt.config.logger"], "cross_file": ["twtxt.models.Source"]}, "requirement": {"Functionality": "This function retrieves a list of all Source objects that are stored in the \"following\" section of the Config instance. It iterates over the items in the \"following\" section, creates a Source object for each item, and appends it to the \"following\" list. If the \"following\" section does not exist, it logs a debug message and returns an empty list.", "Arguments": ":param self: Config. An instance of the Config class.\n:return: list. A list of Source objects that are stored in the \"following\" section of the Config instance."}, "tests": ["tests/test_config.py::test_create_config"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.delete", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [610, 610], "body_position": [624, 625], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.delete_table"]}, "requirement": {"Functionality": "This function deletes a table in DynamoDB. It uses the connection object to delete the table with the specified table name.", "Arguments": ":param self: Table. An instance of the Table class.\n:return: Bool. Returns True on success."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_delete"], "indent": 8}
{"namespace": "asyncssh.kex.register_kex_alg", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/kex.py", "signature_position": [92, 93], "body_position": [96, 101], "dependency": {"intra_class": [], "intra_file": ["asyncssh.kex.Kex", "asyncssh.kex._default_kex_algs", "asyncssh.kex._kex_algs", "asyncssh.kex._kex_handlers"], "cross_file": ["asyncssh.misc.HashType"]}, "requirement": {"Functionality": "This function is used to register a key exchange algorithm. It adds the algorithm to the list of supported key exchange algorithms, and if specified as default, adds it to the list of default key exchange algorithms. It also associates the algorithm with its corresponding handler, hash algorithm, and arguments.", "Arguments": ":param alg: bytes. The key exchange algorithm to register.\n:param handler: Type[Kex]. The handler class for the key exchange algorithm.\n:param hash_alg: HashType. The hash algorithm to be used with the key exchange algorithm.\n:param args: Tuple. Additional arguments required for the key exchange algorithm.\n:param default: bool. Whether the key exchange algorithm should be set as the default.\n:return: No return values."}, "tests": ["tests/test_kex.py::_TestKex::test_dh_gex", "tests/test_kex.py::_TestKex::test_dh_gex_old"], "indent": 4}
{"namespace": "googleapiclient._helpers.update_query_params", "type": "function", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/_helpers.py", "signature_position": [166, 166], "body_position": [183, 188], "dependency": {"intra_class": [], "intra_file": ["googleapiclient._helpers.parse_unique_urlencoded"], "cross_file": []}, "requirement": {"Functionality": "This function updates a URI with new query parameters. It takes a URI and a dictionary of query parameters as input. If a key from the dictionary is repeated in the URI, the URI is considered invalid and an error occurs. If the URI is valid, each value from the dictionary will replace the corresponding value in the query parameters (if it exists).", "Arguments": ":param uri: string. A valid URI, with potential existing query parameters.\n:param params: dict. A dictionary of query parameters.\n:return: string. The same URI but with the new query parameters added."}, "tests": ["tests/test__helpers.py::Test_update_query_params::test_update_query_params_no_params", "tests/test__helpers.py::Test_update_query_params::test_update_query_params_replace_param", "tests/test__helpers.py::Test_update_query_params::test_update_query_params_repeated_params", "tests/test__helpers.py::Test_update_query_params::test_update_query_params_existing_params"], "indent": 4}
{"namespace": "boto.rds2.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/rds2/__init__.py", "signature_position": [37, 37], "body_position": [51, 54], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.rds2.layer1.RDSConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns a RDSConnection object to that region. It uses the region name to create a RDSConnection object and returns it.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param **kw_params: Additional parameters that are passed on to the connect method of the region object.\n:return: boto.rds2.layer1.RDSConnection or None. A connection to the given region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestRds2Connection::test_connect_to_region"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledStringIO.write", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [411, 411], "body_position": [412, 422], "dependency": {"intra_class": ["boltons.ioutils.SpooledStringIO._tell", "boltons.ioutils.SpooledStringIO.buffer", "boltons.ioutils.SpooledStringIO.len", "boltons.ioutils.SpooledStringIO.rollover", "boltons.ioutils.SpooledStringIO.tell"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed", "boltons.ioutils.SpooledIOBase._max_size", "boltons.ioutils.text_type"], "cross_file": []}, "requirement": {"Functionality": "This function writes a string to the SpooledStringIO instance. It first checks if the instance is closed. Then, it checks if the input string is of type text_type. If not, it raises a TypeError: 'str expected, got {type of s}'. It then checks if writing the string will exceed the maximum size of the instance. If so, it rolls over the instance to a temp file. Finally, it writes the string to the buffer and updates the current position.", "Arguments": ":param self: SpooledStringIO. An instance of the SpooledStringIO class.\n:param s: String. The string to be written to the instance.\n:return: No return value."}, "tests": ["tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_large_SEEK_END", "tests/test_ioutils.py::TestSpooledStringIO::test_compare_not_equal_instances", "tests/test_ioutils.py::TestSpooledStringIO::test_len_no_rollover", "tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_SEEK_END", "tests/test_ioutils.py::TestSpooledStringIO::test_iter"], "indent": 8}
{"namespace": "alembic.testing.env.multi_heads_fixture", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/env.py", "signature_position": [382, 382], "body_position": [388, 468], "dependency": {"intra_class": [], "intra_file": ["alembic.testing.env.write_script"], "cross_file": ["alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.generate_revision", "alembic.util", "alembic.util.rev_id"]}, "requirement": {"Functionality": "This function creates a multiple head fixture from the three-revs fixture. It generates three new revisions (d, e, f) based on the existing revisions (a, b, c) and writes the corresponding scripts for each revision.", "Arguments": ":param cfg: The configuration object.\n:param a: The head revision.\n:param b: The base revision.\n:param c: The other revision.\n:return: The generated revisions (d, e, f)."}, "tests": ["tests/test_command.py::RevisionEnvironmentTest::test_merge_cmd_revision_environment", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_head_rev_post_context_multihead", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_destination_rev_pre_context_multihead", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_destination_rev_post_context_multihead", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_head_rev_pre_context_multihead"], "indent": 4}
{"namespace": "kinto.config.render_template", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/config/__init__.py", "signature_position": [14, 14], "body_position": [15, 27], "dependency": {"intra_class": [], "intra_file": ["kinto.config.HERE", "kinto.config.logger"], "cross_file": []}, "requirement": {"Functionality": "This function renders a template file by replacing placeholders with values from the provided keyword arguments and saves the rendered template to a destination file.", "Arguments": ":param template: String. The path to the template file.\n:param destination: String. The path to the destination file where the rendered template will be saved.\n:param **kwargs: Keyword arguments. The values to replace the placeholders in the template.\n:return: No return values."}, "tests": ["tests/test_config.py::ConfigTest::test_transpose_parameters_into_template", "tests/test_config.py::ConfigTest::test_create_destination_directory", "tests/test_config.py::ConfigTest::test_render_template_works_with_file_in_cwd"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_HASH256", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [131, 131], "body_position": [132, 133], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pycoin.encoding.hash.double_sha256"]}, "requirement": {"Functionality": "Pop the top item from the stack, calculate its sha256 value, and append the result back to the stack.\n", "Arguments": ":param stack: List, a stack where the operation is performed.\n:return: No return values.\n"}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_HASH256"], "indent": 4}
{"namespace": "pyramid.url.URLMethodsMixin.route_url", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/url.py", "signature_position": [112, 112], "body_position": [245, 270], "dependency": {"intra_class": [], "intra_file": ["pyramid.url._join_elements", "pyramid.url.parse_url_overrides"], "cross_file": ["pyramid.interfaces.IRoutesMapper", "pyramid.threadlocal.get_current_registry", "pyramid.interfaces.IRoutesMapper.get_route", "pyramid.interfaces.IRoute.generate", "pyramid.interfaces.IRoute.pregenerator", "pyramid.registry"]}, "requirement": {"Functionality": "This function generates a fully qualified URL for a named route configuration in a Pyramid application. It takes the route name as the first positional argument and additional positional arguments as path segments. It uses keyword arguments to supply values for dynamic path elements in the route definition. It raises a KeyError exception if the URL cannot be generated for any reason.", "Arguments": ":param self: URLMethodsMixin. An instance of the URLMethodsMixin class.\n:param route_name: String. The name of the route configuration.\n:param *elements: Tuple of strings. Additional positional arguments that are appended to the URL as path segments.\n:param **kw: Keyword arguments. Values that match dynamic path elements in the route definition.\n:return: String. The generated fully qualified URL for the named route configuration."}, "tests": ["tests/test_url.py::TestURLMethodsMixin::test_route_url_with_host", "tests/test_url.py::TestURLMethodsMixin::test_route_url_with_scheme", "tests/test_url.py::TestURLMethodsMixin::test_route_url_with_elements", "tests/test_url.py::TestURLMethodsMixin::test_route_url_with_query", "tests/test_url.py::TestURLMethodsMixin::test_route_url_with_anchor_app_url_elements_and_query"], "indent": 8}
{"namespace": "mrjob.conf.combine_lists", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [390, 390], "body_position": [399, 413], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.py2.string_types"]}, "requirement": {"Functionality": "This function combines multiple sequences into a single list. It ignores any `None` values in the input sequences. It treats strings, bytes, and non-sequence objects as single-item lists.", "Arguments": ":param seqs: Variable number of sequences to be combined into a list.\n:return: List. The combined list of all non-None values from the input sequences."}, "tests": ["tests/test_conf.py::CombineListsTestCase::test_concatenation", "tests/test_conf.py::CombineListsTestCase::test_strings", "tests/test_conf.py::CombineOptsTestCase::test_combine_opts", "tests/test_conf.py::CombineListsTestCase::test_scalars", "tests/test_conf.py::CombineOptsTestCase::test_cleared_opt_values"], "indent": 4}
{"namespace": "msticpy.config.query_editor.QueryParameterEditWidget.delete_parameter", "type": "method", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/config/query_editor.py", "signature_position": [299, 299], "body_position": [301, 305], "dependency": {"intra_class": ["msticpy.config.query_editor.QueryParameterEditWidget._blank_parameter", "msticpy.config.query_editor.QueryParameterEditWidget._changed_data", "msticpy.config.query_editor.QueryParameterEditWidget.param_container", "msticpy.config.query_editor.QueryParameterEditWidget.parameter_dropdown"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function deletes a parameter item from the QueryParameterEditWidget instance. It removes the parameter from the parameters dictionary and clears the input widgets. It also sets the changed data flag to True.", "Arguments": ":param self: QueryParameterEditWidget. An instance of the QueryParameterEditWidget class.\n:param button: The button that triggered the delete action. It is not used in the function.\n:return: No return values."}, "tests": ["tests/config/test_query_editor.py::test_remove_parameter"], "indent": 8}
{"namespace": "sslyze.plugins.heartbleed_plugin._HeartbleedCliConnector.result_to_console_output", "type": "method", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/heartbleed_plugin.py", "signature_position": [54, 54], "body_position": [55, 62], "dependency": {"intra_class": [], "intra_file": ["sslyze.plugins.heartbleed_plugin.HeartbleedScanResult", "sslyze.plugins.heartbleed_plugin.HeartbleedScanResult.is_vulnerable_to_heartbleed", "sslyze.plugins.plugin_base.ScanCommandCliConnector._format_field"], "cross_file": []}, "requirement": {"Functionality": "This function takes a HeartbleedScanResult object as input and converts it into a list of strings that represent the result in a console output format. It formats the title and the vulnerability status of the Heartbleed scan result.", "Arguments": ":param cls: The class object of _HeartbleedCliConnector.\n:param result: HeartbleedScanResult. The Heartbleed scan result object.\n:return: List of strings. The console output representation of the Heartbleed scan result."}, "tests": ["tests/plugins_tests/test_heartbleed_plugin.py::TestHeartbleedPlugin::test_vulnerable"], "indent": 8}
{"namespace": "sacred.ingredient.Ingredient.gather_commands", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/ingredient.py", "signature_position": [300, 300], "body_position": [310, 314], "dependency": {"intra_class": ["sacred.ingredient.Ingredient.post_process_name", "sacred.ingredient.Ingredient.traverse_ingredients", "sacred.ingredient.Ingredient.commands"], "intra_file": [], "cross_file": ["sacred.utils.join_paths"]}, "requirement": {"Functionality": "This function collects all commands from the Ingredient instance and its sub-ingredients. It iterates through each ingredient and its commands, and yields the full name of the command and the corresponding captured function.", "Arguments": ":param self: Ingredient. An instance of the Ingredient class.\n:return: Yields a tuple containing the full name of the command (cmd_name) and the corresponding captured function (cmd)."}, "tests": ["tests/test_ingredients.py::test_gather_commands"], "indent": 8}
{"namespace": "mingus.core.notes.remove_redundant_accidentals", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/notes.py", "signature_position": [122, 122], "body_position": [131, 144], "dependency": {"intra_class": [], "intra_file": ["mingus.core.notes.augment", "mingus.core.notes.diminish"], "cross_file": []}, "requirement": {"Functionality": "Remove redundant sharps and flats from the given note.\n", "Arguments": ":param note: str. The musical note with possible redundant sharps and flats.\n:return: str. The note with the redundant sharps and flats removed.\n"}, "tests": ["tests/unit/core/test_notes.py::test_notes::test_remove_redundant_accidentals"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.thread", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1203, 1203], "body_position": [1220, 1230], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._raw_command_untagged", "imapclient.imapclient.IMAPClient.has_capability"], "intra_file": ["imapclient.imapclient._normalise_search_criteria"], "cross_file": ["imapclient.exceptions", "imapclient.exceptions.CapabilityError", "imapclient.response_parser.parse_response", "imapclient.util.to_bytes"]}, "requirement": {"Functionality": "Return a list of message threads from the currently selected folder that match the specified criteria. Each returned thread is a list of message IDs.\n", "Arguments": ":param algorithm: String, the threading algorithm to use. It defaults to \"REFERENCES\" if not specified.\n:param criteria: String, the search criteria to match the messages. It defaults to \"ALL\" if not specified.\n:param charset: String, the character set to be used. It defaults to \"UTF-8\" if not specified.\n:return: List[Tuple], each tuple represents a message thread, where each element of the tuple is a message ID. For example, \"((1, 2), (3,), (4, 5, 6))\".\n"}, "tests": ["tests/test_thread.py::TestThread::test_unsupported_algorithm", "tests/test_thread.py::TestThread::test_no_thread_support", "tests/test_thread.py::TestThread::test_defaults", "tests/test_thread.py::TestThread::test_all_args"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.Gather.say", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [1884, 1884], "body_position": [1896, 1898], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Say", "twilio.twiml.voice_response.Say.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Say>` element with the given parameters. It nests the `<Say>` element within the current `<Gather>` element.", "Arguments": ":param self: Gather. An instance of the Gather class.\n:param message: String. The message to be said.\n:param voice: String. The voice to be used for saying the message.\n:param loop: Integer. The number of times to loop the message.\n:param language: String. The language of the message.\n:param kwargs: Additional attributes for the `<Say>` element.\n:return: `<Say>` element. The created `<Say>` element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestGather::test_gather_say", "tests/unit/twiml/test_voice_response.py::TestGather::test_nested_say_play_pause"], "indent": 8}
{"namespace": "dash.development.base_component.Component._traverse", "type": "method", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/development/base_component.py", "signature_position": [319, 319], "body_position": [321, 322], "dependency": {"intra_class": ["dash.development.base_component.Component._traverse_with_paths"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function traverses the tree structure of a Component instance and yields the second value in each item in the tree.", "Arguments": ":param self: Component. An instance of the Component class.\n:return: Yields each item in the tree."}, "tests": ["tests/unit/development/test_base_component.py::test_debc011_traverse_with_tuples", "tests/unit/development/test_base_component.py::test_debc010_traverse_full_tree"], "indent": 8}
{"namespace": "mopidy.ext.load_extensions", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/ext.py", "signature_position": [210, 210], "body_position": [216, 268], "dependency": {"intra_class": ["mopidy.ext.Extension.dist_name", "mopidy.ext.Extension.ext_name", "mopidy.ext.Extension.get_command", "mopidy.ext.Extension.get_config_schema", "mopidy.ext.Extension.get_default_config", "mopidy.ext.Extension.version"], "intra_file": ["mopidy.ext.Extension", "mopidy.ext.ExtensionData", "mopidy.ext.logger"], "cross_file": []}, "requirement": {"Functionality": "This function finds all installed extensions by iterating through the entry points of the \"mopidy.ext\" package. It loads each entry point, checks if it is a valid extension class, and creates an ExtensionData object with the necessary attributes. The function then appends the ExtensionData object to a list of installed extensions and returns the list.", "Arguments": ":param: No input parameters.\n:return: List[ExtensionData]. A list of installed extensions, where each extension is represented by an ExtensionData object."}, "tests": ["tests/test_ext.py::TestLoadExtensions::test_gets_instance", "tests/test_ext.py::TestLoadExtensions::test_no_extensions", "tests/test_ext.py::TestLoadExtensions::test_gets_wrong_class", "tests/test_ext.py::TestLoadExtensions::test_creating_instance_fails", "tests/test_ext.py::TestLoadExtensions::test_get_default_config_fails"], "indent": 4}
{"namespace": "rest_framework.fields.DateTimeField.to_representation", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [1178, 1178], "body_position": [1179, 1194], "dependency": {"intra_class": ["rest_framework.fields.DateTimeField.enforce_timezone"], "intra_file": [], "cross_file": ["rest_framework.ISO_8601", "rest_framework.settings.api_settings"]}, "requirement": {"Functionality": "This function converts a datetime value to its representation based on the specified format. It first checks if the value is empty, and if so, returns None. Then, it checks the output format and if it is None or the value is already a string, it returns the value as is. Otherwise, it enforces the timezone on the value and formats it based on the output format.", "Arguments": ":param self: DateTimeField. An instance of the DateTimeField class.\n:param value: The datetime value to be converted.\n:return: The representation of the datetime value based on the specified format."}, "tests": ["tests/test_fields.py::TestCustomTimezoneForDateTimeField::test_should_render_date_time_in_default_timezone"], "indent": 8}
{"namespace": "pycoin.blockchain.BlockChain.BlockChain.tuple_for_index", "type": "method", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/blockchain/BlockChain.py", "signature_position": [61, 61], "body_position": [62, 73], "dependency": {"intra_class": ["pycoin.blockchain.BlockChain.BlockChain._locked_chain", "pycoin.blockchain.BlockChain.BlockChain._longest_chain_cache", "pycoin.blockchain.BlockChain.BlockChain._longest_local_block_chain", "pycoin.blockchain.BlockChain.BlockChain.length", "pycoin.blockchain.BlockChain.BlockChain.parent_hash", "pycoin.blockchain.BlockChain.BlockChain.weight_lookup"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a tuple containing information about a block in the blockchain at the given index. It first checks if the index is negative, and if so, it adjusts it to be a positive index relative to the end of the blockchain. Then, it checks if the index is within the range of the locked chain. If it is, it returns the corresponding block from the locked chain. If the index is outside the range of the locked chain, it retrieves the block from the longest local block chain or the longest chain cache, depending on the index value. Finally, it looks up the weight of the block using the weight lookup dictionary and returns a tuple containing the block's hash, parent hash, and weight.", "Arguments": ":param self: BlockChain. An instance of the BlockChain class.\n:param index: Integer. The index of the block to retrieve.\n:return: Tuple. A tuple containing the block's hash, parent hash, and weight."}, "tests": ["tests/blockchain_test.py::BlockchainTestCase::test_large", "tests/blockchain_test.py::BlockchainTestCase::test_chain_locking", "tests/blockchain_test.py::BlockchainTestCase::test_basic"], "indent": 8}
{"namespace": "bplustree.memory.FileMemory.get_node", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [125, 125], "body_position": [137, 147], "dependency": {"intra_class": ["bplustree.memory.FileMemory._cache", "bplustree.memory.FileMemory._read_page", "bplustree.memory.FileMemory._tree_conf", "bplustree.memory.FileMemory._wal"], "intra_file": ["bplustree.memory.WAL.get_page"], "cross_file": ["bplustree.node.Node", "bplustree.node.Node.from_page_data", "bplustree.node.Node.page"]}, "requirement": {"Functionality": "This function retrieves a node from storage. It first checks if the node is present in the cache. If not, it retrieves the data from the storage and creates a Node object using the data. The created node is then added to the cache for future use.", "Arguments": ":param self: FileMemory. An instance of the FileMemory class.\n:param page: int. The page number of the node to retrieve.\n:return: Node. The retrieved node."}, "tests": ["tests/test_memory.py::test_file_memory_write_transaction", "tests/test_memory.py::test_file_memory_node"], "indent": 8}
{"namespace": "fs.permissions.Permissions.create", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/permissions.py", "signature_position": [189, 190], "body_position": [209, 217], "dependency": {"intra_class": ["fs.permissions.Permissions.__init__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a Permissions object based on the given initial value. The initial value can be an integer, a list of permission names, or None. It returns a mode integer that can be used, for example, by the `os.makedir` function.", "Arguments": ":param cls: Permissions. The class object.\n:param init: Union[int, Iterable[Text], None]. The initial value for creating the Permissions object. It can be an integer, a list of permission names, or None. For example, ['u_r', 'u_w', 'u_x'], None, 0o700 are all legal inputs.\n:return: Permissions. The created Permissions object."}, "tests": ["tests/test_permissions.py::TestPermissions::test_create"], "indent": 8}
{"namespace": "alembic.operations.ops.DropColumnOp.to_column", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [2215, 2217], "body_position": [2218, 2221], "dependency": {"intra_class": ["alembic.operations.ops.DropColumnOp._reverse", "alembic.operations.ops.DropColumnOp.column_name"], "intra_file": [], "cross_file": ["alembic.operations.ops.AddColumnOp.column", "alembic.operations.schemaobj", "alembic.operations.schemaobj.SchemaObjects", "alembic.operations.schemaobj.SchemaObjects.column", "alembic.runtime.migration.MigrationContext"]}, "requirement": {"Functionality": "This function converts the DropColumnOp instance into a Column object. If the reverse option is available, it returns the column of the reverse. Otherwise, it creates a schema based on the `migration_context` parameter and uses its method to create a column object with the specified column name and NULLTYPE.", "Arguments": ":param self: DropColumnOp. An instance of the DropColumnOp class.\n:param migration_context: Optional. An instance of the MigrationContext class. It represents the current migration context. Defaults to None.\n:return: Column."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_add_column", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_column"], "indent": 8}
{"namespace": "pyinfra.api.facts.get_facts", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/facts.py", "signature_position": [161, 161], "body_position": [162, 181], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra.api.inventory.Inventory.iter_active_hosts", "pyinfra.api.state.State.inventory", "pyinfra.progress.progress_spinner"]}, "requirement": {"Functionality": "This function retrieves facts for a given state. It iterates over the active hosts in the state's inventory and spawns a greenlet for each host to retrieve the facts. It then waits for the greenlets to complete and stores the results in a dictionary.", "Arguments": ":param state: State. An instance of the State class. The state for which to retrieve the facts.\n:param *args: Variable length argument list. Additional arguments to pass to the get_fact function.\n:param **kwargs: Arbitrary keyword arguments. Additional keyword arguments to pass to the get_fact function.\n:return: dict. A dictionary containing the retrieved facts, with the host as the key and the facts as the value."}, "tests": ["tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact_executor_mixed_arguments", "tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact_current_op_global_arguments", "tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact_error_ignore", "tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact_executor_host_data_arguments", "tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact"], "indent": 4}
{"namespace": "mingus.core.intervals.major_second", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [173, 173], "body_position": [174, 175], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.second"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the major second interval for a given note. It first determines the second interval between the given note and \"C\". Then, it adjusts the interval by augmenting or diminishing it until it becomes a major second.", "Arguments": ":param note: String. The note for which the major second interval is to be calculated.\n:return: The adjusted major second interval for the given note."}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_major_seconds"], "indent": 4}
{"namespace": "jwt.algorithms.HMACAlgorithm.to_jwk", "type": "method", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/algorithms.py", "signature_position": [278, 278], "body_position": [279, 287], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["jwt.types.JWKDict", "jwt.utils.base64url_encode", "jwt.utils.force_bytes"]}, "requirement": {"Functionality": "This function converts a key object to a JSON Web Key (JWK) representation. It creates a JWK dictionary with the key value and key type, and returns it as a JSON string or dictionary based on the value of the `as_dict` parameter.", "Arguments": ":param key_obj: str or bytes. The key object to be converted to JWK.\n:param as_dict: bool. Optional parameter to specify whether to return the JWK as a dictionary or JSON string. Defaults to False.\n:return: Union[JWKDict, str]. The JWK representation of the key object. If `as_dict` is True, it returns a dictionary. Otherwise, it returns a JSON string."}, "tests": ["tests/test_algorithms.py::TestAlgorithms::test_hmac_to_jwk_returns_correct_values"], "indent": 8}
{"namespace": "discord.utils.time_snowflake", "type": "function", "project_path": "Software-Development/discord-py", "completion_path": "Software-Development/discord-py/discord/utils.py", "signature_position": [395, 395], "body_position": [421, 422], "dependency": {"intra_class": [], "intra_file": ["discord.utils.DISCORD_EPOCH"], "cross_file": []}, "requirement": {"Functionality": "This function takes a datetime object and returns a numeric snowflake that pretends to be created at the given date. The snowflake is calculated based on the timestamp of the datetime object and the Discord epoch.", "Arguments": ":param dt: datetime.datetime. A datetime object to convert to a snowflake. If the datetime object is naive, the timezone is assumed to be local time.\n:param high: bool. Whether or not to set the lower 22 bits of the snowflake to high or low. It defaults to False.\n:return: int. The snowflake representing the time given."}, "tests": ["tests/test_utils.py::test_snowflake_time"], "indent": 4}
{"namespace": "mrjob.conf.combine_dicts", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [435, 435], "body_position": [441, 454], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.ClearedValue", "mrjob.conf._strip_clear_tag"], "cross_file": []}, "requirement": {"Functionality": "This function combines zero or more dictionaries into a single dictionary. Values from dictionaries later in the list take precedence over values earlier in the list. If a dictionary is passed as None, it will be ignored. If the value is specified to be a cleared value whose value is None, it will be removed from the dictionary.", "Arguments": ":param dicts: Variable number of dictionaries to be combined.\n:return: dict. The combined dictionary."}, "tests": ["tests/test_conf.py::CombineDictsTestCase::test_later_values_take_precedence", "tests/test_conf.py::CombineDictsTestCase::test_None_value", "tests/test_conf.py::CombineDictsTestCase::test_dont_accept_wrapped_dicts", "tests/test_hadoop.py::EnvForStepTestCase::test_spark_step", "tests/test_conf.py::CombineDictsTestCase::test_deleted_value"], "indent": 4}
{"namespace": "falcon.inspect.inspect_middleware", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [160, 160], "body_position": [170, 200], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect.MiddlewareClassInfo", "falcon.inspect.MiddlewareClassInfo.__init__", "falcon.inspect.MiddlewareInfo", "falcon.inspect.MiddlewareInfo.__init__", "falcon.inspect.MiddlewareMethodInfo", "falcon.inspect.MiddlewareMethodInfo.__init__", "falcon.inspect.MiddlewareTreeInfo", "falcon.inspect.MiddlewareTreeInfo.__init__", "falcon.inspect.MiddlewareTreeItemInfo", "falcon.inspect.MiddlewareTreeItemInfo.__init__", "falcon.inspect._get_source_info", "falcon.inspect._get_source_info_and_name"], "cross_file": ["falcon.app.App", "falcon.app_helpers.prepare_middleware", "falcon.app.App._ASGI", "falcon.app.App._independent_middleware", "falcon.app.App._unprepared_middleware", "falcon.app_helpers"]}, "requirement": {"Functionality": "This function inspects the middleware components of an application. It prepares the middleware components and gathers information about them, including the middleware tree and the middleware classes.", "Arguments": ":param app: falcon.App. The application to inspect. Works with both falcon.App and falcon.asgi.App.\n:return: MiddlewareInfo. Information about the app's middleware components."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_middleware_tree_item", "tests/test_inspect.py::TestStringVisitor::test_middleware_class_no_methods", "tests/test_inspect.py::TestStringVisitor::test_middleware_tree_no_resource", "tests/test_inspect.py::TestInspectApp::test_middleware", "tests/test_inspect.py::TestStringVisitor::test_middleware_tree_response_only"], "indent": 4}
{"namespace": "rq.serializers.resolve_serializer", "type": "function", "project_path": "Scientific-Engineering/rq", "completion_path": "Scientific-Engineering/rq/rq/serializers.py", "signature_position": [24, 24], "body_position": [36, 49], "dependency": {"intra_class": [], "intra_file": ["rq.serializers.DefaultSerializer"], "cross_file": ["rq.utils.import_attribute"]}, "requirement": {"Functionality": "This function checks the user-defined serializer for the presence of 'dumps' and 'loads' methods. If these methods are not found, it raises a NotImplementedError. If the serializer is not provided, it returns the default pickle serializer. If a string path to a serializer is provided, it loads and returns that serializer. The returned serializer objects implement the 'dumps' and 'loads' methods.", "Arguments": ":param serializer: Optional. Union of Type[DefaultSerializer] and str. The serializer to resolve. Defaults to None.\n:return: Type[DefaultSerializer]. An object that implements the SerializerProtocol."}, "tests": ["tests/test_serializers.py::TestSerializers::test_resolve_serializer"], "indent": 4}
{"namespace": "alembic.command.upgrade", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [358, 363], "body_position": [378, 398], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.runtime.environment.EnvironmentContext", "alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.run_env", "alembic.util", "alembic.util.CommandError"]}, "requirement": {"Functionality": "Upgrade the database to a later version. It creates a script directory based on the given configuration and then runs the upgrade process using the specified revision, SQL mode, and tag.", "Arguments": ":param config: Config. An instance of the Config class.\n:param revision: str. The target revision or range for SQL mode.\n:param sql: bool. If True, use SQL mode.\n:param tag: Optional[str]. An arbitrary tag that can be intercepted by custom env.py scripts.\n:return: None."}, "tests": ["tests/test_postgresql.py::PGOfflineEnumTest::test_offline_inline_enum_create", "tests/test_script_consumption.py::EncodingTest::test_encode", "tests/test_environment.py::EnvironmentTest::test_sql_mode_parameters", "tests/test_postgresql.py::PGOfflineEnumTest::test_offline_distinct_enum_create", "tests/test_command.py::UpgradeDowngradeStampTest::test_version_from_middle_update"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.append", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1395, 1395], "body_position": [1412, 1424], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._normalise_folder"], "intra_file": ["imapclient.imapclient.seq_to_parenstr"], "cross_file": ["imapclient.datetime_util.datetime_to_INTERNALDATE", "imapclient.util.to_bytes", "imapclient.util.to_unicode"]}, "requirement": {"Functionality": "Append a message to the specified folder in the IMAP server. \n", "Arguments": ":param self: IMAPClient, an instance of IMAPClient class.\n:param folder: String, the name of the folder to which the message should be appended.\n:param msg: String, a string contains the full message including header.\n:param flags: Tuple, a sequence of message flags to set. Defaults to an empty tuple if not specified.\n:param msg_time: Datetime, an instance of datatime class. The date and time to set on the message. Defaults to None if not specified. If msg_time contains timezone information (tzinfo), this will be honoured. Otherwise the local machine's time zone sent to the server.\n:return: The APPEND response returned by the server.\n"}, "tests": ["tests/test_imapclient.py::TestAppend::test_with_msg_time", "tests/test_imapclient.py::TestAppend::test_without_msg_time"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.buttons.TopButton.keypress", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [91, 91], "body_position": [92, 96], "dependency": {"intra_class": ["zulipterminal.ui_tools.buttons.TopButton.activate"], "intra_file": [], "cross_file": ["zulipterminal.config.keys.is_command_key", "zulipterminal.urwid_types.urwid_Size"]}, "requirement": {"Functionality": "Handle keypress events for the TopButton class. If the key is the \"ENTER\" key, it activates the button. Otherwise, it calls the keypress method of the superclass to handle the keypress event.", "Arguments": ":param self: TopButton. An instance of the TopButton class.\n:param size: urwid_Size. The size of the widget.\n:param key: str. The key that was pressed.\n:return: Optional[str]. If the key is the \"ENTER\" key, it returns None. Otherwise, it returns the result of the keypress method of the superclass."}, "tests": ["tests/ui_tools/test_buttons.py::TestEmojiButton::test_keypress_emoji_button"], "indent": 8}
{"namespace": "boltons.strutils.indent", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/strutils.py", "signature_position": [729, 729], "body_position": [740, 742], "dependency": {"intra_class": [], "intra_file": ["boltons.strutils.iter_splitlines"], "cross_file": []}, "requirement": {"Functionality": "This function indents each line of the given text with the specified margin string. It allows for selectively applying indentation based on a condition for each line. \n", "Arguments": ":param text: str. The text to be indented.\n:param margin: str. The string to prepend to each line as indentation.\n:param newline: str. The newline character used to rejoin the lines. It defaults to \"\\n\".\n:param key: callable. A function called on each line to determine whether to indent it. It defaults to bool, which ensures that empty lines do not get whitespace added.\n:return: str. The indented text.\n"}, "tests": ["tests/test_strutils.py::test_indent"], "indent": 4}
{"namespace": "pyramid.registry.Introspector.categorized", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [149, 149], "body_position": [150, 158], "dependency": {"intra_class": ["pyramid.registry.Introspector.categories", "pyramid.registry.Introspector.get_category"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function categorizes the data in the Introspector instance based on the categories. It returns the name and introspectables (sorted by the sort key) of each category as a list of tuples.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param sort_key: Optional. The key to sort the categories. Defaults to None.\n:return: List[Tuple[str, List[Dict[str, Any]]]]. Each tuple contains the category name and the corresponding data for that category."}, "tests": ["tests/test_registry.py::TestIntrospector::test_categorized"], "indent": 8}
{"namespace": "datasette.utils.asgi.Response.redirect", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/asgi.py", "signature_position": [411, 411], "body_position": [412, 414], "dependency": {"intra_class": ["datasette.utils.asgi.Response.__init__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a redirect response. It sets the \"Location\" header to the specified path and returns a Response instance with the given status code and headers.", "Arguments": ":param cls: Class. The class of the Response instance.\n:param path: String. The path to redirect to.\n:param status: Integer. The status code for the response. It defaults to 302 if not specified.\n:param headers: Dictionary. Additional headers to include in the response. It defaults to an empty dictionary if not specified.\n:return: Response. The created redirect response instance."}, "tests": ["tests/test_internals_response.py::test_response_redirect", "tests/test_internals_response.py::test_response_set_cookie"], "indent": 8}
{"namespace": "rest_framework.fields.is_simple_callable", "type": "function", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [58, 58], "body_position": [62, 81], "dependency": {"intra_class": [], "intra_file": ["rest_framework.fields.BuiltinSignatureError"], "cross_file": []}, "requirement": {"Functionality": "Check if the given object is a callable that takes no arguments. It first checks if the object is callable. If it is a built-in function, it raises a builtin signature error. Then it checks if the object is a function, method, or a functools.partial object. Finally, it inspects the signature of the object and checks if all the parameters have a default value or are variable positional or keyword parameters.", "Arguments": ":param obj: Any. The object to be checked.\n:return: Bool. True if the object is a callable that takes no arguments, False otherwise."}, "tests": ["tests/test_fields.py::TestIsSimpleCallable::test_function", "tests/test_fields.py::TestIsSimpleCallable::test_method", "tests/test_fields.py::TestIsSimpleCallable::test_type_annotation", "tests/test_fields.py::TestIsSimpleCallable::test_builtin_function", "tests/test_fields.py::TestIsSimpleCallable::test_4602_regression"], "indent": 4}
{"namespace": "falcon.util.uri.decode", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/util/uri.py", "signature_position": [271, 271], "body_position": [293, 328], "dependency": {"intra_class": [], "intra_file": ["falcon.util.uri._HEX_TO_BYTE", "falcon.util.uri._join_tokens"], "cross_file": []}, "requirement": {"Functionality": "This function decodes percent-encoded characters in a URI or query string. It replaces the encoded characters with their corresponding decoded values.", "Arguments": ":param encoded_uri: String. The encoded URI or query string to be decoded.\n:param unquote_plus: Bool. Set to False to retain any plus ('+') characters in the given string, rather than converting them to spaces (default True). Typically you should set this to False when decoding any part of a URI other than the query string.\n:return: String. The decoded URL. If the URL contains escaped non-ASCII characters, UTF-8 is assumed per RFC 3986."}, "tests": ["tests/test_utils.py::TestFalconUtils::test_uri_encode_value", "tests/test_utils.py::TestFalconUtils::test_uri_encode", "tests/test_utils.py::TestFalconUtils::test_prop_uri_decode_models_stdlib_unquote_plus", "tests/test_utils.py::TestFalconUtils::test_uri_decode_bad_coding", "tests/test_utils.py::TestFalconUtils::test_uri_decode_bad_unicode"], "indent": 4}
{"namespace": "rest_framework.exceptions._get_error_details", "type": "function", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/exceptions.py", "signature_position": [18, 18], "body_position": [23, 43], "dependency": {"intra_class": [], "intra_file": ["rest_framework.exceptions.ErrorDetail"], "cross_file": ["rest_framework.utils.serializer_helpers.ReturnDict", "rest_framework.utils.serializer_helpers.ReturnList"]}, "requirement": {"Functionality": "This function takes a nested data structure as input and recursively converts any lazy translation strings or regular strings into `ErrorDetail` objects. It returns the modified data structure with all the strings converted.", "Arguments": ":param data: Any. The nested data structure to be processed.\n:param default_code: Any. The default error code to be used if not specified in the data structure.\n:return: Any. The modified data structure with all the strings converted to `ErrorDetail` objects."}, "tests": ["tests/test_exceptions.py::ExceptionTestCase::test_get_error_details"], "indent": 4}
{"namespace": "boto.directconnect.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/directconnect/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.directconnect.layer1.DirectConnectConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the DirectConnectConnection class from the boto library. It creates the connection with the specified parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: The connection object for the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestDirectconnectConnection::test_connect_to_region"], "indent": 4}
{"namespace": "kinto.core.utils.recursive_update_dict", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [89, 89], "body_position": [96, 106], "dependency": {"intra_class": [], "intra_file": ["kinto.core.utils.recursive_update_dict"], "cross_file": []}, "requirement": {"Functionality": "This function recursively updates all the entries from a dictionary and its children dictionaries. It iterates through the keys and values of the changes dictionary. If a value is a dictionary, it checks if the corresponding key exists in the root dictionary. If not, it creates a new empty dictionary in the root dictionary. Then, it recursively calls the function with the nested dictionaries as the root and changes parameters. If a value is in the ignores list, it removes the corresponding key from the root dictionary. Otherwise, it updates the value in the root dictionary.", "Arguments": ":param root: Dictionary. The root dictionary to be updated.\n:param changes: Dictionary. The dictionary containing the changes to be made. Defaults to the root dictionary.\n:param ignores: Tuple. A tuple of values to be ignored. If a value in the changes dictionary is in the ignores tuple, the corresponding key will be removed from the root dictionary.\n:return: No return values."}, "tests": ["tests/core/test_utils.py::RecursiveUpdateDictTest::test_merge"], "indent": 4}
{"namespace": "pyramid.util.InstancePropertyHelper.add_property", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [175, 175], "body_position": [181, 182], "dependency": {"intra_class": ["pyramid.util.InstancePropertyHelper.make_property", "pyramid.util.InstancePropertyHelper.properties"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds a new property configuration to the InstancePropertyHelper instance. It creates a property based on the given callable and adds it to the property dictionary of the class.", "Arguments": ":param self: InstancePropertyHelper. An instance of the InstancePropertyHelper class.\n:param callable: The callable object that will be used to create the property.\n:param name: str. The name of the property. If not specified, it will be generated based on the callable. Defaults to None.\n:param reify: bool. Whether the property should be reified. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_util.py::Test_InstancePropertyHelper::test_add_property", "tests/test_util.py::Test_InstancePropertyHelper::test_apply_multiple_times"], "indent": 8}
{"namespace": "pyramid.authentication.BasicAuthAuthenticationPolicy.unauthenticated_userid", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [1334, 1334], "body_position": [1336, 1338], "dependency": {"intra_class": [], "intra_file": ["pyramid.authentication.extract_http_basic_credentials", "pyramid.authentication.extract_http_basic_credentials.username"], "cross_file": []}, "requirement": {"Functionality": "This function extracts the username from the authorization request header and returns it as the unauthenticated user ID.", "Arguments": ":param self: BasicAuthAuthenticationPolicy. An instance of the BasicAuthAuthenticationPolicy class.\n:param request: The HTTP request object.\n:return: String. The username extracted from the \"Authorization\" request header."}, "tests": ["tests/test_authentication.py::TestBasicAuthAuthenticationPolicy::test_unauthenticated_userid"], "indent": 8}
{"namespace": "kinto.core.permission.memory.Permission.add_principal_to_ace", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/permission/memory.py", "signature_position": [69, 69], "body_position": [70, 73], "dependency": {"intra_class": ["kinto.core.permission.memory.Permission._store"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Add a principal to the Access Control Entry (ACE) for a specific object and permission. It retrieves the set of principals associated with the given object and permission from the store, adds the new principal to the set, and updates the store with the modified set.", "Arguments": ":param self: Permission. An instance of the Permission class.\n:param object_id: The ID of the object.\n:param permission: The permission for which the principal is being added.\n:param principal: The principal to add to the ACE.\n:return: No return values."}, "tests": ["tests/core/resource/test_object_permissions.py::SpecifyObjectPermissionTest::test_permissions_can_be_removed_with_patch_but_keep_current_user", "tests/core/resource/test_object_permissions.py::SpecifyObjectPermissionTest::test_permissions_can_be_removed_with_patch"], "indent": 8}
{"namespace": "chatette.parsing.SlotDefBuilder.create_concrete", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [148, 148], "body_position": [149, 155], "dependency": {"intra_class": [], "intra_file": ["chatette.parsing.UnitDefBuilder._build_modifiers_repr", "chatette.parsing.UnitDefBuilder._check_information", "chatette.parsing.UnitDefBuilder.identifier", "chatette.parsing.UnitDefBuilder.variation"], "cross_file": ["chatette.units.ast.AST", "chatette.units.modifiable.definitions.slot.SlotDefinition", "chatette.utils.Singleton.get_or_create", "chatette.utils.UnitType", "chatette.utils.UnitType.slot"]}, "requirement": {"Functionality": "This function creates a concrete SlotDefinition object based on the given conditions. It first checks if the necessary information is provided. If a variation is specified, it retrieves the definitions from the AST and checks if the identifier exists. If it does, it returns the corresponding SlotDefinition object. Otherwise, it creates a new SlotDefinition object with the identifier and the modifiers representation.", "Arguments": ":param self: SlotDefBuilder. An instance of the SlotDefBuilder class.\n:return: SlotDefinition. The created SlotDefinition object."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestSlotDefBuilder::test_create_concrete", "tests/unit-testing/parsing/test_init.py::TestSlotDefBuilder::test_new_variation"], "indent": 8}
{"namespace": "zulipterminal.helper.open_media", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/helper.py", "signature_position": [807, 807], "body_position": [811, 830], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["zulipterminal.platform_code.successful_GUI_return_code", "zulipterminal.core.Controller.report_error"]}, "requirement": {"Functionality": "This function is a helper function that opens a media file using a specified tool. It creates a command to run the tool with the given media file path, and then executes the command using the `subprocess.run()` function. It checks the exit status of the process and reports any errors to the controller.", "Arguments": ":param controller: Any. The controller object that handles error reporting.\n:param tool: str. The name or path of the tool to be used to open the media file.\n:param media_path: str. The path of the media file to be opened.\n:return: No return values."}, "tests": ["tests/helper/test_helper.py::test_open_media", "tests/helper/test_helper.py::test_open_media_tool_exception"], "indent": 4}
{"namespace": "boto.s3.website.RoutingRule.then_redirect", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/website.py", "signature_position": [216, 217], "body_position": [218, 223], "dependency": {"intra_class": ["boto.s3.website.RoutingRule.redirect"], "intra_file": ["boto.s3.website.Redirect", "boto.s3.website.Redirect.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function sets the redirect of a RoutingRule instance with the given parameters and returns the updated instance.", "Arguments": ":param self: RoutingRule. An instance of the RoutingRule class.\n:param hostname: String. The hostname to redirect to.\n:param protocol: String. The protocol to use for the redirect.\n:param replace_key: String. The key to replace in the redirect.\n:param replace_key_prefix: String. The prefix to add to the replaced key in the redirect.\n:param http_redirect_code: Integer. The HTTP redirect code to use.\n:return: RoutingRule. The updated RoutingRule instance."}, "tests": ["tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_builders"], "indent": 8}
{"namespace": "sqlitedict.SqliteDict.update", "type": "method", "project_path": "Database/sqlitedict", "completion_path": "Database/sqlitedict/sqlitedict.py", "signature_position": [328, 328], "body_position": [329, 343], "dependency": {"intra_class": ["sqlitedict.SqliteDict.autocommit", "sqlitedict.SqliteDict.commit", "sqlitedict.SqliteDict.conn", "sqlitedict.SqliteDict.flag", "sqlitedict.SqliteDict.tablename", "sqlitedict.SqliteDict.update"], "intra_file": ["sqlitedict.SqliteMultithread.executemany"], "cross_file": []}, "requirement": {"Functionality": "Update the SqliteDict instance with the given items and keyword arguments. It first checks if the instance is read-only, and if so, raises a RuntimeError. Then it encodes the keys and values of the items, and executes a SQL statement to update the items in the database. If there are any keyword arguments, it recursively calls the update function with those arguments. Finally, if the autocommit flag is set, it commits the changes to the database.", "Arguments": ":param self: SqliteDict. An instance of the SqliteDict class.\n:param items: Tuple or dictionary. The items to update in the instance. Defaults to an empty tuple.\n:param kwds: Keyword arguments. Additional items to update in the instance.\n:return: No return values."}, "tests": ["tests/test_temp_db.py::TempSqliteDictTest::test_clear_data", "tests/test_temp_db.py::TempSqliteDictTest::test_update_records"], "indent": 8}
{"namespace": "boto.route53.zone.Zone.find_records", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/route53/zone.py", "signature_position": [201, 201], "body_position": [230, 273], "dependency": {"intra_class": ["boto.route53.zone.Zone.id", "boto.route53.zone.Zone.route53connection"], "intra_file": [], "cross_file": ["boto.exception.TooManyRecordsException", "boto.route53.connection.Route53Connection._make_qualified", "boto.route53.connection.Route53Connection.get_all_rrsets", "boto.route53.connection.Route53Connection.get_all_rrsets.name"]}, "requirement": {"Functionality": "This function searches for records in a Zone that match the given parameters. It returns the matching records based on the specified conditions.", "Arguments": ":param self: Zone. An instance of the Zone class.\n:param name: str. The name of the records that should match this parameter.\n:param type: str. The type of the records that should match this parameter.\n:param desired: int. The number of desired results. If the number of matching records in the Zone exceeds the value of this parameter, a TooManyRecordsException is thrown.\n:param all: bool. If True, return all records that match the name, type, and identifier parameters.\n:param identifier: tuple. A tuple specifying WRR or LBR attributes. Valid forms are: (str, int) for WRR record, and (str, str) for LBR record.\n:return: None if no results, a ResourceRecord if one result, or a ResourceRecordSets if more than one result."}, "tests": ["tests/unit/route53/test_zone.py::TestZone::test_find_records"], "indent": 8}
{"namespace": "pyramid.authentication.RepozeWho1AuthenticationPolicy.authenticated_userid", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [220, 220], "body_position": [230, 265], "dependency": {"intra_class": ["pyramid.authentication.RepozeWho1AuthenticationPolicy._get_identity", "pyramid.authentication.RepozeWho1AuthenticationPolicy.callback"], "intra_file": ["pyramid.authentication.CallbackAuthenticationPolicy._clean_principal", "pyramid.authentication.CallbackAuthenticationPolicy._log", "pyramid.authentication.CallbackAuthenticationPolicy.debug"], "cross_file": []}, "requirement": {"Functionality": "This function returns the authenticated user ID based on the provided request. It checks if the identity is None, if the user ID is None, and if the user ID is allowed by the security policy. If a callback is registered, it only returns the user ID if the callback returns a non-None value.", "Arguments": ":param self: RepozeWho1AuthenticationPolicy. An instance of the RepozeWho1AuthenticationPolicy class.\n:param request: The request object.\n:return: The authenticated user ID or None."}, "tests": ["tests/test_authentication.py::TestRepozeWho1AuthenticationPolicy::test_authenticated_userid_with_callback_returns_something", "tests/test_authentication.py::TestRepozeWho1AuthenticationPolicy::test_authenticated_userid"], "indent": 8}
{"namespace": "mrjob.setup.WorkingDirManager.name_to_path", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/setup.py", "signature_position": [470, 470], "body_position": [478, 488], "dependency": {"intra_class": ["mrjob.setup.WorkingDirManager._check_type", "mrjob.setup.WorkingDirManager._name_to_typed_path", "mrjob.setup.WorkingDirManager._typed_path_to_auto_name", "mrjob.setup.WorkingDirManager.name"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a map that maps the name of files/archives in the setup directory to their corresponding paths. It can be used to build options for Hadoop or to fake them in a bootstrap script.", "Arguments": ":param self: WorkingDirManager. An instance of the WorkingDirManager class.\n:param type: str. The type of files/archives to include in the map. It can be either \"archive\" or \"file\". If not specified, all files/archives will be included.\n:return: Dictionary. A dictionary that maps the name of files/archives to their corresponding paths."}, "tests": ["tests/test_setup.py::WorkingDirManagerTestCase::test_auto_names_are_different_from_assigned_names", "tests/test_setup.py::WorkingDirManagerTestCase::test_empty", "tests/test_setup.py::WorkingDirManagerTestCase::test_okay_to_give_same_path_same_name", "tests/test_setup.py::WorkingDirManagerTestCase::test_bad_path_type", "tests/test_setup.py::WorkingDirManagerTestCase::test_basic"], "indent": 8}
{"namespace": "pythonforandroid.pythonpackage.parse_as_folder_reference", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/pythonpackage.py", "signature_position": [475, 475], "body_position": [482, 497], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.pythonpackage.parse_as_folder_reference"], "cross_file": []}, "requirement": {"Functionality": "This function checks if a dependency reference refers to a folder path. If it does, it returns the folder path after parsing and resolving file:// URLs. If it doesn't refer to a folder path, it returns None.", "Arguments": ":param dep: String. The dependency reference to be checked.\n:return: String or None. The folder path if the dependency reference refers to a folder path, otherwise None."}, "tests": ["tests/test_pythonpackage_basic.py::test_parse_as_folder_reference"], "indent": 4}
{"namespace": "alembic.script.revision.Revision._all_down_revisions", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [1604, 1604], "body_position": [1605, 1608], "dependency": {"intra_class": ["alembic.script.revision.Revision._resolved_dependencies", "alembic.script.revision.Revision.down_revision"], "intra_file": [], "cross_file": ["alembic.util", "alembic.util.langhelpers.dedupe_tuple", "alembic.util.langhelpers.to_tuple"]}, "requirement": {"Functionality": "This function combines the down revision and the resolved dependencies as a tuple and removes any duplicates.", "Arguments": ":param self: Revision. An instance of the Revision class.\n:return: Tuple[str, ...]. A tuple containing all the down revisions."}, "tests": ["tests/test_revision.py::NormalizedDownRevTest::test_normalized_down_revisions", "tests/test_revision.py::NormalizedDownRevTest::test_dupe_dependency"], "indent": 8}
{"namespace": "diffprivlib.accountant.BudgetAccountant.set_default", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/accountant.py", "signature_position": [447, 447], "body_position": [455, 456], "dependency": {"intra_class": ["diffprivlib.accountant.BudgetAccountant._default"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets the current accountant as the default accountant to be used when running functions and queries with diffprivlib.", "Arguments": ":param self: BudgetAccountant. An instance of the BudgetAccountant class.\n:return: BudgetAccountant. The current accountant instance."}, "tests": ["tests/test_BudgetAccountant.py::TestBudgetAccountant::test_default", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_set_default", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_with_statement"], "indent": 8}
{"namespace": "boto.ec2.address.Address.release", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/address.py", "signature_position": [75, 75], "body_position": [80, 88], "dependency": {"intra_class": ["boto.ec2.address.Address.allocation_id", "boto.ec2.address.Address.connection", "boto.ec2.address.Address.public_ip"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.release_address"]}, "requirement": {"Functionality": "Free up this Elastic IP address. If the address has an allocation ID, it releases the address using the allocation ID. Otherwise, it releases the address using the public IP.", "Arguments": ":param self: Address. An instance of the Address class.\n:param dry_run: Bool. Whether to perform a dry run (no changes are made). Defaults to False.\n:return: The result of the release operation."}, "tests": ["tests/unit/ec2/test_address.py::AddressTest::test_release_calls_connection_release_address_with_correct_args", "tests/unit/ec2/test_address.py::AddressWithNetworkInterfaceTest::test_release_calls_connection_release_address_with_correct_args", "tests/unit/ec2/test_address.py::AddressWithAllocationTest::test_release_calls_connection_release_address_with_correct_args"], "indent": 8}
{"namespace": "diffprivlib.tools.utils.nanstd", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [522, 523], "body_position": [578, 581], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._std"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the standard deviation of an array along the specified axis, while ignoring NaN values. It adds noise to the computation to satisfy differential privacy. The sensitivity of the computation is calculated using the specified bounds. The function closely follows the behavior of the numpy.std function.", "Arguments": ":param array: array_like. The array for which the standard deviation is calculated.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values in the array.\n:param axis: int or tuple of ints, optional. The axis or axes along which the standard deviation is computed. If not specified, the standard deviation is computed for the flattened array.\n:param dtype: dtype, optional. The type to use in computing the standard deviation.\n:param keepdims: bool, default: False. If True, the reduced axes are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. The accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. A new array containing the standard deviation."}, "tests": ["tests/tools/test_nanstd.py::TestNanStd::test_no_epsilon", "tests/tools/test_nanstd.py::TestNanStd::test_no_params", "tests/tools/test_nanstd.py::TestNanStd::test_missing_bounds", "tests/tools/test_nanstd.py::TestNanStd::test_no_bounds", "tests/tools/test_nanstd.py::TestNanStd::test_nan"], "indent": 4}
{"namespace": "mrjob.logs.ids._sort_for_spark", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/ids.py", "signature_position": [27, 27], "body_position": [32, 38], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.ids._attempt_num", "mrjob.logs.ids._container_num", "mrjob.logs.ids._step_sort_key"], "cross_file": []}, "requirement": {"Functionality": "Sorts a given list of dictionaries in a specific order.\nThe function uses nested sorts with different sorting keys to achieve the desired sorting order.\n", "Arguments": ":param ds: list or sequence of dictionaries. The list of dictionaries to be sorted.\n:return: list. The sorted list of dictionaries in the specified order.\n"}, "tests": ["tests/logs/test_ids.py::SortForSparkTestCase::test_sort_by_container_id", "tests/logs/test_ids.py::SortForSparkTestCase::test_empty", "tests/logs/test_ids.py::SortForSparkTestCase::test_sort_by_timestamp_and_step_num"], "indent": 4}
{"namespace": "mrjob.compat.jobconf_from_env", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/compat.py", "signature_position": [571, 571], "body_position": [586, 596], "dependency": {"intra_class": [], "intra_file": ["mrjob.compat._JOBCONF_MAP"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the value of a jobconf variable from the runtime environment. It first checks if the variable exists in the environment using the variable name as is. If not found, it tries alternative variable names based on a mapping dictionary. If the variable is still not found, it returns the default value.", "Arguments": ":param variable: str. The name of the jobconf variable to retrieve.\n:param default: str. The default value to return if the jobconf variable is not set. Defaults to None.\n:return: str. The value of the jobconf variable if found, otherwise the default value."}, "tests": ["tests/test_compat.py::JobConfFromEnvTestCase::test_get_new_hadoop_jobconf", "tests/test_compat.py::JobConfFromEnvTestCase::test_get_old_hadoop_jobconf", "tests/test_compat.py::JobConfFromEnvTestCase::test_get_missing_jobconf_not_in_table", "tests/test_compat.py::JobConfFromEnvTestCase::test_default"], "indent": 4}
{"namespace": "exodus_bundler.bundling.resolve_binary", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [187, 187], "body_position": [189, 197], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["exodus_bundler.errors.MissingFileError"]}, "requirement": {"Functionality": "This function attempts to find the absolute path to a binary file. It first checks if the given binary file exists in the current directory. If not, it searches for the binary file in the directories specified in the PATH environment variable. If the binary file is found, it returns the absolute path to the binary file. If the binary file is not found in any of the directories, it raises a missing file error 'The \"%s\" binary could not be found in $PATH.'", "Arguments": ":param binary: String. The name of the binary file.\n:return: String. The absolute path to the binary file."}, "tests": ["tests/test_bundling.py::test_resolve_binary"], "indent": 4}
{"namespace": "wikipediaapi.WikipediaPage.section_by_title", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [934, 937], "body_position": [944, 949], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch", "wikipediaapi.WikipediaPage._section_mapping"], "intra_file": ["wikipediaapi.WikipediaPageSection"], "cross_file": []}, "requirement": {"Functionality": "This function returns the last section of the current Wikipedia page with the given title. It first checks if the \"extracts\" data has been fetched for the page. If not, it fetches the \"extracts\" data. Then, it retrieves the sections with the given title from the section mapping. If there are sections with the given title, it returns the last section. Otherwise, it returns None.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:param title: str. The title of the section to retrieve.\n:return: Optional[WikipediaPageSection]. The last section of the current page with the given title."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_subsubsection", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_subsection_by_title_return_last", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_with_erroneous_edit", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_subsection_by_title_with_multiple_spans", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_subsection_by_title"], "indent": 8}
{"namespace": "falcon.request.Request.forwarded_uri", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [789, 789], "body_position": [790, 800], "dependency": {"intra_class": ["falcon.request.Request._cached_forwarded_uri", "falcon.request.Request.forwarded_host", "falcon.request.Request.forwarded_scheme", "falcon.request.Request.relative_uri"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the forwarded URI of a Request instance. It first checks if the cached forwarded URI is None. If it is, it concatenates the forwarded scheme, forwarded host, and relative URI to form the forwarded URI and assigns it to the cached forwarded URI. Finally, it returns the cached forwarded URI. The format of the concatenation is \"{forwarded scheme}://{forwarded host}{relative uri}\".", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The forwarded URI of the Request instance."}, "tests": ["tests/test_request_forwarded.py::test_x_forwarded_proto", "tests/test_request_forwarded.py::test_no_forwarded_headers_with_port", "tests/test_request_forwarded.py::test_x_forwarded_host_with_port", "tests/test_request_forwarded.py::test_no_forwarded_headers", "tests/test_request_forwarded.py::test_x_forwarded_host"], "indent": 8}
{"namespace": "pycorrector.en_spell.EnSpell.correct", "type": "method", "project_path": "Text-Processing/pycorrector", "completion_path": "Text-Processing/pycorrector/pycorrector/en_spell.py", "signature_position": [143, 143], "body_position": [152, 174], "dependency": {"intra_class": ["pycorrector.en_spell.EnSpell.check_init", "pycorrector.en_spell.EnSpell.correct_word", "pycorrector.en_spell.EnSpell.custom_confusion"], "intra_file": [], "cross_file": ["pycorrector.utils.text_utils.is_alphabet_string", "pycorrector.utils.tokenizer.split_2_short_text"]}, "requirement": {"Functionality": "This function corrects the spelling of a given text by replacing incorrect words with their most probable correct versions. It also provides details about the corrections made, such as the wrong word, the correct word, and the indices of the correction within the text. The function first ensure that necessary data is initialized. Then, it split the input text into blocks of words. The include_symbol parameter determines whether punctuations are included in the split blocks.\nThe function then iterates over each block of words and their corresponding indices. If a word is more than one character long and consists of alphabetical characters, it checks if the word is confusion. If it does, the corrected item is retrieved from the dictionary. Otherwise, it parse the word to obtain the corrected item.\nIf the corrected item is different from the original word, the beginning and ending indices of the word are calculated, and a detail tuple is created containing the original word, the corrected item, and the indices and saved in a list. The word is then replaced with the corrected item. Finally, the details list is sorted based on the beginning indices of the words, and the corrected text and details list are returned as a tuple.", "Arguments": ":param self: EnSpell. An instance of the EnSpell class.\n:param text: String. The input query to be corrected.\n:param include_symbol: Bool. Whether to include symbols in the correction process. Defaults to True.\n:return: Tuple. The corrected text and a list of details about the corrections made. Each detail is represented as a list containing the wrong word, the correct word, the beginning index, and the ending index of the correction within the text."}, "tests": ["tests/en_spell_bug_fix_test.py::EnBugTestCase::test_en_bug_correct2", "tests/en_spell_bug_fix_test.py::EnBugTestCase::test_en_bug_correct1"], "indent": 8}
{"namespace": "pyramid.config.views.MultiView.add", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/views.py", "signature_position": [88, 88], "body_position": [89, 113], "dependency": {"intra_class": ["pyramid.config.views.MultiView.accepts", "pyramid.config.views.MultiView.media_views", "pyramid.config.views.MultiView.views"], "intra_file": [], "cross_file": ["pyramid.config.predicates.sort_accept_offers"]}, "requirement": {"Functionality": "This function adds a view to the MultiView instance based on the given conditions. If a view with the same phash value already exists, it updates the existing view. If accept is not specified, it adds the view to the main views list and sorts it based on the order. If accept is specified, it updates the existing view or adds the view to the subset of views for that accept value and sorts it based on the order. It also updates the accept values and sorts them based on the custom order.", "Arguments": ":param self: MultiView. An instance of the MultiView class.\n:param view: The view to be added.\n:param order: The order of the view.\n:param phash: The phash value of the view. Defaults to None.\n:param accept: The accept value for the view. Defaults to None.\n:param accept_order: The order of the accept values. Defaults to None.\n:return: No return values."}, "tests": ["tests/test_config/test_views.py::TestMultiView::test_multiple_with_functions_as_views", "tests/test_config/test_views.py::TestMultiView::test_add_with_phash", "tests/test_config/test_views.py::TestMultiView::test_add_with_phash_override_accept2", "tests/test_config/test_views.py::TestMultiView::test_add_with_phash_override_accept", "tests/test_config/test_views.py::TestMultiView::test_add"], "indent": 8}
{"namespace": "praw.models.util.BoundedSet.add", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/models/util.py", "signature_position": [185, 185], "body_position": [187, 190], "dependency": {"intra_class": ["praw.models.util.BoundedSet._access", "praw.models.util.BoundedSet._set", "praw.models.util.BoundedSet.max_items"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds an item to the set and assigns the value \"None\" to the new item in the set. If an item already exists in the set, place the item at the latest location. Then discards the oldest item if the set is already full. It keeps track of the access order of the items in the set.", "Arguments": ":param self: BoundedSet. An instance of the BoundedSet class.\n:param item: Any. The item to be added to the set.\n:return: No return values."}, "tests": ["tests/unit/models/test_util.py::TestBoundedSet::test_contains", "tests/unit/models/test_util.py::TestBoundedSet::test_lru_add", "tests/unit/models/test_util.py::TestBoundedSet::test_lru_contains"], "indent": 8}
{"namespace": "boto.s3.connection.S3Connection.generate_url_sigv4", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/connection.py", "signature_position": [357, 360], "body_position": [361, 381], "dependency": {"intra_class": ["boto.s3.connection.S3Connection.calling_format"], "intra_file": ["boto.s3.connection._CallingFormat.build_auth_path", "boto.s3.connection._CallingFormat.build_host", "boto.s3.connection._CallingFormat.build_path_base"], "cross_file": ["boto.connection.AWSAuthConnection._auth_handler", "boto.connection.AWSAuthConnection.build_base_http_request", "boto.connection.AWSAuthConnection.server_name", "boto.auth.S3HmacAuthV4Handler.presign"]}, "requirement": {"Functionality": "Generate a presigned URL with Signature Version 4 for accessing an S3 object. It constructs the necessary parameters and builds an HTTP request. Then, it uses the authentication handler to generate the presigned URL. For presigned URLs we should ignore the port if it's HTTPS", "Arguments": ":param self: S3Connection. An instance of S3Connection class\n:param expires_in: Integer. The number of seconds until the presigned URL expires.\n:param method: String. The HTTP method to be used for the request.\n:param bucket: String. The name of the S3 bucket.\n:param key: String. The key of the S3 object.\n:param headers: Dictionary. Additional headers to include in the request.\n:param force_http: Bool. Whether to force the use of HTTP instead of HTTPS.\n:param response_headers: Dictionary. Additional response headers to include in the presigned URL.\n:param version_id: String. The version ID of the S3 object.\n:param iso_date: String. The ISO-formatted date to be used for signing the request.\n:return: String. The generated presigned URL."}, "tests": ["tests/unit/s3/test_connection.py::TestSigV4Presigned::test_sigv4_presign_headers", "tests/unit/s3/test_connection.py::TestSigV4Presigned::test_sigv4_presign_respects_is_secure", "tests/unit/s3/test_connection.py::TestSigV4Presigned::test_sigv4_presign_optional_params", "tests/unit/s3/test_connection.py::TestSigV4Presigned::test_sigv4_presign_response_headers", "tests/unit/s3/test_connection.py::TestSigV4Presigned::test_sigv4_presign"], "indent": 8}
{"namespace": "onlinejudge_command.pretty_printers._tokenize_line", "type": "function", "project_path": "Text-Processing/online-judge-tools", "completion_path": "Text-Processing/online-judge-tools/onlinejudge_command/pretty_printers.py", "signature_position": [56, 56], "body_position": [57, 78], "dependency": {"intra_class": [], "intra_file": ["onlinejudge_command.pretty_printers._PrettyToken.__init__", "onlinejudge_command.pretty_printers._PrettyTokenType", "onlinejudge_command.pretty_printers._PrettyTokenType.HINT", "onlinejudge_command.pretty_printers._PrettyTokenType.NEWLINE", "onlinejudge_command.pretty_printers._PrettyTokenType.WHITESPACE", "onlinejudge_command.pretty_printers._tokenize_str"], "cross_file": []}, "requirement": {"Functionality": "Tokenize a line of text into a list of _PrettyToken instances. It separates the body of the line from any trailing whitespace or newlines and creates tokens for each part.", "Arguments": ":param line: String. The line of text to be tokenized.\n:return: List[_PrettyToken]. A list of _PrettyToken objects representing the tokens of the line."}, "tests": ["tests/pretty_printers.py::TokenizeLineTest::test_trailing_whitespace", "tests/pretty_printers.py::TokenizeLineTest::test_only_newline", "tests/pretty_printers.py::TokenizeLineTest::test_with_whitespace", "tests/pretty_printers.py::TokenizeLineTest::test_simple", "tests/pretty_printers.py::TokenizeLineTest::test_without_newline"], "indent": 4}
{"namespace": "telethon.extensions.html.unparse", "type": "function", "project_path": "Communications/Telethon", "completion_path": "Communications/Telethon/telethon/extensions/html.py", "signature_position": [152, 152], "body_position": [161, 195], "dependency": {"intra_class": [], "intra_file": ["telethon.extensions.html.ENTITY_TO_FORMATTER"], "cross_file": ["telethon.helpers.add_surrogate", "telethon.helpers.del_surrogate", "telethon.helpers.within_surrogate"]}, "requirement": {"Functionality": "This function takes a normal text and a list of MessageEntity objects and converts them into HTML representation. It checks for special cases, such as empty text or the absence of entities, and utilizes a dictionary to determine HTML formatting for different message entity types. The function handles surrogate pairs and generates the final HTML output by combining formatted text and escaped portions. The goal is to reverse the operation of a parser, producing HTML from plain text and associated entities.", "Arguments": ":param text: str. The text to be converted into HTML.\n:param entities: Iterable[TypeMessageEntity]. The list of MessageEntity objects applied to the text.\n:return: str. The HTML representation of the text with applied formatting based on the entities."}, "tests": ["tests/telethon/extensions/test_html.py::test_malformed_entities", "tests/telethon/extensions/test_html.py::test_trailing_malformed_entities", "tests/telethon/extensions/test_html.py::test_entity_edges", "tests/telethon/extensions/test_html.py::test_offset_at_emoji"], "indent": 4}
{"namespace": "boto.glacier.concurrent.ConcurrentTransferer._calculate_required_part_size", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/glacier/concurrent.py", "signature_position": [47, 47], "body_position": [48, 58], "dependency": {"intra_class": ["boto.glacier.concurrent.ConcurrentTransferer._part_size"], "intra_file": ["boto.glacier.concurrent.log"], "cross_file": ["boto.glacier.utils.minimum_part_size"]}, "requirement": {"Functionality": "Calculate the required part size for concurrent transfer based on the total size of the data. It compares the specified part size with the minimum required part size and returns the total number of parts and the final part size to be used for concurrent transfer.", "Arguments": ":param self: ConcurrentTransferer. An instance of the ConcurrentTransferer class.\n:param total_size: Integer. The total size of the data to be transferred.\n:return: Tuple. The total number of parts and the final part size to be used for concurrent transfer."}, "tests": ["tests/unit/glacier/test_concurrent.py::TestConcurrentUploader::test_calculate_required_part_size_too_small", "tests/unit/glacier/test_concurrent.py::TestConcurrentUploader::test_calculate_required_part_size"], "indent": 8}
{"namespace": "rest_framework.relations.SlugRelatedField.to_internal_value", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/relations.py", "signature_position": [497, 497], "body_position": [498, 504], "dependency": {"intra_class": ["rest_framework.relations.SlugRelatedField.slug_field"], "intra_file": ["rest_framework.relations.RelatedField.get_queryset"], "cross_file": ["rest_framework.fields.Field.fail"]}, "requirement": {"Functionality": "This function converts the given data into its internal representation. It retrieves the queryset based on the field and tries to get the corresponding object using the slug field and the given data. If the object is not found, it raises an exception. If there are any type or value errors, it also raises an exception.", "Arguments": ":param self: SlugRelatedField. An instance of the SlugRelatedField class.\n:param data: The data to be converted to its internal representation.\n:return: No return values."}, "tests": ["tests/test_relations.py::TestSlugRelatedField::test_slug_related_lookup_exists", "tests/test_relations.py::TestSlugRelatedField::test_slug_related_lookup_invalid_type", "tests/test_relations.py::TestSlugRelatedField::test_slug_related_lookup_does_not_exist"], "indent": 8}
{"namespace": "sqlitedict.SqliteDict.clear", "type": "method", "project_path": "Database/sqlitedict", "completion_path": "Database/sqlitedict/sqlitedict.py", "signature_position": [348, 348], "body_position": [349, 356], "dependency": {"intra_class": ["sqlitedict.SqliteDict.conn", "sqlitedict.SqliteDict.flag", "sqlitedict.SqliteDict.tablename"], "intra_file": ["sqlitedict.SqliteMultithread.commit", "sqlitedict.SqliteMultithread.execute"], "cross_file": []}, "requirement": {"Functionality": "Clear all the data in the SqliteDict instance. It raises a RuntimeError if the instance is read-only. It deletes all the rows in the table associated with the instance.", "Arguments": ":param self: SqliteDict. An instance of the SqliteDict class.\n:return: No return values."}, "tests": ["tests/test_temp_db.py::TempSqliteDictTest::test_clear_data"], "indent": 8}
{"namespace": "gunicorn.config.Config.logger_class", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [148, 148], "body_position": [149, 167], "dependency": {"intra_class": ["gunicorn.config.Config.settings"], "intra_file": ["gunicorn.config.LoggerClass", "gunicorn.config.LoggerClass.default"], "cross_file": ["gunicorn.util", "gunicorn.util.load_class"]}, "requirement": {"Functionality": "This function retrieves the logger class based on the configuration settings. It first checks the 'logger_class' setting and if it is \"simple\", it uses the default logger class. If the default logger class is being used andstatsd is on, it automatically switches to the gunicorn.instrument.statsd.Statsd class. Then, it loads the logger class (with default: \"gunicorn.glogging.Logger\" and section: \"gunicorn.loggers\") and install it if can, finally returns it.", "Arguments": ":param self: Config. An instance of the Config class.\n:return: The logger class based on the configuration settings."}, "tests": ["tests/test_config.py::test_statsd_changes_logger", "tests/test_config.py::test_property_access", "tests/test_config.py::test_always_use_configured_logger"], "indent": 8}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.du", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [190, 190], "body_position": [193, 206], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem.invoke_hadoop"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the size of a file or directory (recursively) in the Hadoop filesystem. If the file or directory doesn't exist, it returns 0. It uses the Hadoop binary to execute the \"fs -du\" command and parses the output to calculate the size. If the return value is in 0, 1, or 255, but the output cannot be parsed, it raises an IOError: 'Unexpected output from Hadoop fs -du: {output!r}'.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:param path_glob: str. The path of the file or directory to calculate the size of.\n:return: int. The size of the file or directory, or 0 if it doesn't exist."}, "tests": ["tests/fs/test_hadoop.py::HadoopFSTestCase::test_du", "tests/fs/test_hadoop.py::HadoopFSTestCase::test_du_non_existent"], "indent": 8}
{"namespace": "pysimplesoap.simplexml.SimpleXMLElement.as_xml", "type": "method", "project_path": "Communications/PySimpleSOAP", "completion_path": "Communications/PySimpleSOAP/pysimplesoap/simplexml.py", "signature_position": [116, 116], "body_position": [118, 121], "dependency": {"intra_class": ["pysimplesoap.simplexml.SimpleXMLElement.__document"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the XML representation of the document. If the \"pretty\" parameter is set to False, it returns the XML representation without any formatting. If \"pretty\" is set to True, it returns the XML representation with indentation and line breaks for better readability.", "Arguments": ":param self: SimpleXMLElement. An instance of the SimpleXMLElement class.\n:param filename: String [optional]. The name of the file to save the XML representation. Defaults to None.\n:param pretty: Bool. Whether to format the XML representation with indentation and line breaks. Defaults to False.\n:return: String. The XML representation of the document."}, "tests": ["tests/simplexmlelement_test.py::TestSimpleXMLElement::test_marshall_cdata", "tests/simplexmlelement_test.py::TestSimpleXMLElement::test_to_xml"], "indent": 8}
{"namespace": "diffprivlib.tools.quantiles.quantile", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/quantiles.py", "signature_position": [32, 33], "body_position": [93, 151], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.quantiles.quantile"], "cross_file": ["diffprivlib.accountant.BudgetAccountant", "diffprivlib.accountant.BudgetAccountant.check", "diffprivlib.accountant.BudgetAccountant.load_default", "diffprivlib.accountant.BudgetAccountant.spend", "diffprivlib.tools.utils._wrap_axis", "diffprivlib.utils.PrivacyLeakWarning", "diffprivlib.utils.check_random_state", "diffprivlib.utils.warn_unused_args", "diffprivlib.validation.check_bounds", "diffprivlib.validation.clip_to_bounds", "diffprivlib.mechanisms.exponential.Exponential.randomise"]}, "requirement": {"Functionality": "This function calculates the differentially private quantile of an array. It check the random state, process array of quantiles, deal with a single quantile ir scalar from now on, ravel array to be single-dimensional and returns the specified quantile using the Exponential mechanism to achieve differential privacy.", "Arguments": ":param array: array_like. The input array containing numbers whose quantile is sought.\n:param quant: float or array-like. The quantile(s) to be calculated. Each quantile must be in the unit interval [0, 1]. If quant is array-like, quantiles are returned over the flattened array.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon. Differential privacy is achieved over the entire output, with epsilon split evenly between each output value.\n:param bounds: tuple, optional. Bounds of the values of the array, of the form (min, max).\n:param axis: None or int or tuple of ints, optional. Axis or axes along which a sum is performed. The default, axis=None, will sum all of the elements of the input array.\n:param keepdims: bool, default: False. If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. Accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. Returns a new array containing the quantile values."}, "tests": ["tests/tools/test_quantile.py::TestQuantile::test_bad_quantile", "tests/tools/test_quantile.py::TestQuantile::test_accountant", "tests/tools/test_quantile.py::TestQuantile::test_no_epsilon", "tests/tools/test_quantile.py::TestQuantile::test_large_epsilon", "tests/tools/test_quantile.py::TestQuantile::test_output_type"], "indent": 4}
{"namespace": "fs.wildcard.match", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/wildcard.py", "signature_position": [21, 22], "body_position": [33, 38], "dependency": {"intra_class": [], "intra_file": ["fs.wildcard._PATTERN_CACHE", "fs.wildcard._translate"], "cross_file": []}, "requirement": {"Functionality": "This function tests whether a given name matches a wildcard pattern. It uses regular expressions to match the pattern against the name.", "Arguments": ":param pattern: Text. A wildcard pattern to match against the name.\n:param name: Text. The name to be tested.\n:return: bool. True if the name matches the pattern, False otherwise."}, "tests": ["tests/test_wildcard.py::TestFNMatch::test_wildcard"], "indent": 4}
{"namespace": "boto.dynamodb2.fields.BaseIndexField.definition", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/fields.py", "signature_position": [103, 103], "body_position": [116, 124], "dependency": {"intra_class": ["boto.dynamodb2.fields.BaseIndexField.parts"], "intra_file": ["boto.dynamodb2.fields.BaseSchemaField.name", "boto.dynamodb2.fields.BaseSchemaField.data_type"], "cross_file": []}, "requirement": {"Functionality": "This function returns the attribute definition structure that DynamoDB expects for the index field. It iterates over the parts of the index field and creates a list of dictionaries, where each dictionary represents an attribute with its name and data type.", "Arguments": ":param self: BaseIndexField. An instance of the BaseIndexField class.\n:return: List of dictionaries. The attribute definition structure that DynamoDB expects. Each dictionary contains the name and data type of an attribute."}, "tests": ["tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_include_index", "tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_all_index", "tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_all_index", "tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_keys_only_index", "tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_include_index"], "indent": 8}
{"namespace": "fs._ftp_parse._parse_time", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/_ftp_parse.py", "signature_position": [86, 86], "body_position": [87, 104], "dependency": {"intra_class": [], "intra_file": ["fs._ftp_parse.EPOCH_DT"], "cross_file": ["fs._tzcompat.timezone", "fs._tzcompat.timezone.utc"]}, "requirement": {"Functionality": "This function parses a given time string using a list of specified formats. It tries each format until it successfully parses the time string or exhausts all formats. If the time string cannot be parsed using any of the formats, it returns None. If the time string is successfully parsed, it converts it to epoch time and returns the epoch time value.", "Arguments": ":param t: String. The time string to be parsed.\n:param formats: List of strings. A list of formats to be used for parsing the time string.\n:return: Float. The epoch time value of the parsed time string. If the time string cannot be parsed, it returns None."}, "tests": ["tests/test_ftp_parse.py::TestFTPParse::test_parse_time"], "indent": 4}
{"namespace": "pythonforandroid.prerequisites.get_required_prerequisites", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [368, 368], "body_position": [369, 381], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.prerequisites.AutoconfPrerequisite", "pythonforandroid.prerequisites.AutomakePrerequisite", "pythonforandroid.prerequisites.CmakePrerequisite", "pythonforandroid.prerequisites.HomebrewPrerequisite", "pythonforandroid.prerequisites.JDKPrerequisite", "pythonforandroid.prerequisites.LibtoolPrerequisite", "pythonforandroid.prerequisites.OpenSSLPrerequisite", "pythonforandroid.prerequisites.PkgConfigPrerequisite"], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of prerequisite instances that are required for the specified platform. It filters out the prerequisite classes based on the platform and creates instances of the remaining classes.", "Arguments": ":param platform: String. The platform for which the prerequisites are required. It defaults to \"linux\" if not specified.\n:return: List of prerequisite instances. The list of prerequisite instances that are required for the specified platform."}, "tests": ["tests/test_prerequisites.py::TestDefaultPrerequisitesCheckandInstall::test_default_linux_prerequisites_set", "tests/test_prerequisites.py::TestDefaultPrerequisitesCheckandInstall::test_default_darwin_prerequisites_set"], "indent": 4}
{"namespace": "mopidy.httpclient.format_user_agent", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/httpclient.py", "signature_position": [36, 36], "body_position": [44, 51], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mopidy.__version__", "mopidy"]}, "requirement": {"Functionality": "This function constructs a User-Agent string that is suitable for use in client code. It includes the provided name, Mopidy version, and Python version.", "Arguments": ":param name: String [optional]. The name to identify the use. It should be in the format \"dist_name/version\".\n:return: String. The constructed User-Agent string."}, "tests": ["tests/test_httpclient.py::test_format_user_agent"], "indent": 4}
{"namespace": "mrjob.step.MRStep.description", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/step.py", "signature_position": [301, 301], "body_position": [302, 321], "dependency": {"intra_class": ["mrjob.step.MRStep._steps", "mrjob.step.MRStep.has_explicit_combiner", "mrjob.step.MRStep.has_explicit_mapper", "mrjob.step.MRStep.has_explicit_reducer", "mrjob.step.MRStep.render_combiner", "mrjob.step.MRStep.render_mapper", "mrjob.step.MRStep.render_reducer"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Generates a description dictionary based on the properties of the MRStep instance.\nCreate a dictionary `desc` with the initial key-value pair where the key is 'type' and the value is 'streaming'. Check if it is necessary to include a mapper in the description:\nIf it is the first step or there is an explicit mapper, or there are explicit combiners, then include the mapper in the description.If there is an explicit combiner, then include the combiner in the description. If there is an explicit reducer, then include the reducer in the description. If mapper_raw is true, set the 'input_manifest' key in the description to True. Check if the 'jobconf' key in steps. If so, assign it to jobconf in the dictionary.\n", "Arguments": ":param self: MRStep. An instance of the MRStep class.\n:param step_num: int. The step number. It defaults to 0 if not specified.\n:return: dict. The description dictionary generated based on the properties of the MRStep instance.\n"}, "tests": ["tests/test_step.py::MRStepDescriptionTestCase::test_render_reducer_cmd_first_mapper_not_implied", "tests/test_step.py::MRStepDescriptionTestCase::test_render_mapper_pre_filter", "tests/test_step.py::MRStepDescriptionTestCase::test_render_mapper", "tests/test_step.py::MRStepDescriptionTestCase::test_render_reducer_cmd_first_mapper_implied", "tests/test_step.py::MRStepDescriptionTestCase::test_render_combiner"], "indent": 8}
{"namespace": "boto.ec2.ec2object.TaggedEC2Object.add_tags", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/ec2object.py", "signature_position": [82, 82], "body_position": [94, 101], "dependency": {"intra_class": ["boto.ec2.ec2object.TaggedEC2Object.id", "boto.ec2.ec2object.TaggedEC2Object.tags"], "intra_file": ["boto.ec2.ec2object.EC2Object.connection"], "cross_file": ["boto.ec2.tag.TagSet", "boto.ec2.connection.EC2Connection.create_tags"]}, "requirement": {"Functionality": "This function adds tags to a TaggedEC2Object instance. Tags are key-value pairs. It also sends a request to the EC2 service.", "Arguments": ":param self: TaggedEC2Object. An instance of the TaggedEC2Object class.\n:param tags: dict. A dictionary of key-value pairs for the tags being stored. If you want to add a tag with only the name and no value, the corresponding value for that tag name should be an empty string.\n:param dry_run: bool. Whether to perform a dry run, which means the tags will not actually be added. Defaults to False.\n:return: No return values."}, "tests": ["tests/unit/ec2/test_ec2object.py::TestAddTags::test_add_tags"], "indent": 8}
{"namespace": "googleapiclient.channel.Channel.body", "type": "method", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/channel.py", "signature_position": [209, 209], "body_position": [218, 233], "dependency": {"intra_class": ["googleapiclient.channel.Channel.address", "googleapiclient.channel.Channel.expiration", "googleapiclient.channel.Channel.id", "googleapiclient.channel.Channel.params", "googleapiclient.channel.Channel.resource_id", "googleapiclient.channel.Channel.resource_uri", "googleapiclient.channel.Channel.token", "googleapiclient.channel.Channel.type"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function builds a dictionary representation of a Channel object. It includes the id, token, type, and address attributes of the Channel object. If the Channel object has additional attributes such as params, resource id, resource uri, or expiration, they are also included in the dictionary.", "Arguments": ":param self: Channel. An instance of the Channel class.\n:return: Dictionary. A dictionary representation of the Channel object."}, "tests": ["tests/test_channel.py::TestChannel::test_basic"], "indent": 8}
{"namespace": "kinto.core.testing.get_user_headers", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/testing.py", "signature_position": [84, 84], "body_position": [90, 93], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["kinto.core.utils.encode64"]}, "requirement": {"Functionality": "This function is a helper function that generates Basic Auth authorization headers based on the specified user and password. It encodes the \"user:password\" string using Base64 encoding and returns the headers as a dictionary {\"Authorization\": encodes result}.", "Arguments": ":param user: String. The username to be used for authentication.\n:param password: String. The password to be used for authentication. It defaults to \"secret\" if not specified.\n:return: dict. The generated authorization headers as a dictionary."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_validation_validates_user", "tests/test_views_objects_permissions.py::CollectionPermissionsTest::test_cannot_read_if_not_allowed", "tests/test_views_buckets.py::BucketReadPermissionTest::test_bucket_collection_endpoint_lists_them_all_for_everyone", "tests/test_views_objects_permissions.py::GroupPermissionsTest::test_cannot_read_if_not_allowed", "tests/plugins/test_accounts.py::AccountUpdateTest::test_changing_metadata_does_not_change_password"], "indent": 4}
{"namespace": "boto.sqs.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/sqs/__init__.py", "signature_position": [43, 43], "body_position": [44, 47], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.regioninfo.connect", "boto.sqs.connection.SQSConnection", "boto.sqs.regioninfo.SQSRegionInfo"]}, "requirement": {"Functionality": "Connect to a specific region using the SQSConnection class. It creates the connection with the specified region name and other optional keyword parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param kw_params: Keyword arguments. Additional parameters that can be passed to the connect function.\n:return: SQSConnection. The connection object for the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestSqsConnection::test_connect_to_region"], "indent": 4}
{"namespace": "bentoml._internal.runner.strategy.DefaultStrategy.get_worker_env", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/strategy.py", "signature_position": [104, 110], "body_position": [117, 182], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.strategy.THREAD_ENVS", "bentoml._internal.runner.strategy.logger"], "cross_file": ["bentoml._internal.resource.get_resource", "bentoml._internal.resource.system_resources", "bentoml._internal.runner.runnable.Runnable"]}, "requirement": {"Functionality": "This function is a method of the DefaultStrategy class. It is used to get the environment variables for a worker process based on the given parameters. It determines whether to use GPU or CPU based on the resource request and the runnable class. It sets the appropriate environment variables accordingly.", "Arguments": ":param cls: DefaultStrategy. The class itself.\n:param runnable_class: Type[Runnable]. The class of the runnable to be executed.\n:param resource_request: dict[str, t.Any] | None. The resource request of the runnable. Defaults to None.\n:param workers_per_resource: int | float. The number of workers per resource. Defaults to None.\n:param worker_index: int. The index of the worker. Starts from 0.\n:return: dict[str, t.Any]. The environment variables for the worker process."}, "tests": ["tests/unit/_internal/runner/test_strategy.py::test_default_gpu_strategy", "tests/unit/_internal/runner/test_strategy.py::test_default_cpu_strategy", "tests/integration/frameworks/test_frameworks.py::test_runner_cpu", "tests/integration/frameworks/test_frameworks.py::test_runner_cpu_multi_threading"], "indent": 8}
{"namespace": "pythonforandroid.recommendations.read_ndk_version", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/recommendations.py", "signature_position": [116, 116], "body_position": [118, 135], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.recommendations.PARSE_ERROR_NDK_MESSAGE", "pythonforandroid.recommendations.UNKNOWN_NDK_MESSAGE"], "cross_file": ["pythonforandroid.logger.info"]}, "requirement": {"Functionality": "This function reads the version of the NDK (Android Native Development Kit) from the specified NDK directory. It opens the 'source.properties' file in the directory and reads its contents. It then searches for the line that starts with 'Pkg.Revision' and extracts the version number from that line.", "Arguments": ":param ndk_dir: String. The path to the NDK directory.\n:return: LooseVersion. The version of the NDK, represented as a LooseVersion object."}, "tests": ["tests/test_recommendations.py::TestRecommendations::test_read_ndk_version_error", "tests/test_recommendations.py::TestRecommendations::test_read_ndk_version"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.buttons.MessageLinkButton._switch_narrow_to", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [582, 582], "body_position": [586, 606], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.ui_tools.buttons.ParsedNarrowLink"], "cross_file": ["zulipterminal.core.Controller.narrow_to_stream", "zulipterminal.core.Controller.narrow_to_topic"]}, "requirement": {"Functionality": "This function switches the narrow view in the MessageLinkButton instance based on the parsed link. It determines the type of narrow view based on the \"narrow\" key in the parsed link and calls the corresponding narrow_to_* method in the controller.", "Arguments": ":param self: MessageLinkButton. An instance of the MessageLinkButton class.\n:param parsed_link: ParsedNarrowLink. The parsed link containing information about the narrow view to switch to.\n:return: No return values."}, "tests": ["tests/ui_tools/test_buttons.py::TestMessageLinkButton::test__switch_narrow_to"], "indent": 8}
{"namespace": "kinto.core.resource.Resource.delete", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/resource/__init__.py", "signature_position": [652, 652], "body_position": [663, 696], "dependency": {"intra_class": ["kinto.core.resource.Resource._404_for_object", "kinto.core.resource.Resource._add_timestamp_header", "kinto.core.resource.Resource._get_object_or_404", "kinto.core.resource.Resource._raise_400_if_invalid_id", "kinto.core.resource.Resource._raise_412_if_modified", "kinto.core.resource.Resource.model", "kinto.core.resource.Resource.object_id", "kinto.core.resource.Resource.postprocess", "kinto.core.resource.Resource.request"], "intra_file": [], "cross_file": ["kinto.core.resource.model.Model.delete_object", "kinto.core.events.ACTIONS", "kinto.core.events.ACTIONS.DELETE", "kinto.core.storage.exceptions", "kinto.core.storage.exceptions.ObjectNotFoundError"]}, "requirement": {"Functionality": "This function deletes an object by sending a DELETE request to the object's endpoint. It performs some checks (like id does not match the format, can not get object, object is modified) and raises exceptions if necessary. Then retreive the last modified information from a querystring if present, if the modified less or equal than current object. Ignore it. After deleting the object, it returns the deleted object.", "Arguments": ":param self: Resource. An instance of the Resource class.\n:return: No return values."}, "tests": ["tests/core/resource/test_object.py::DeleteTest::test_etag_is_provided", "tests/core/resource/test_object.py::DeleteTest::test_delete_object_returns_last_timestamp", "tests/core/resource/test_preconditions.py::ModifiedMeanwhileTest::test_delete_returns_412_if_changed_meanwhile", "tests/core/resource/test_object.py::DeleteTest::test_delete_object_returns_stripped_object", "tests/core/resource/test_object.py::DeleteTest::test_delete_ignores_last_modified_if_equal"], "indent": 8}
{"namespace": "diffprivlib.accountant.BudgetAccountant.load_default", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/accountant.py", "signature_position": [418, 418], "body_position": [436, 445], "dependency": {"intra_class": ["diffprivlib.accountant.BudgetAccountant.__init__", "diffprivlib.accountant.BudgetAccountant._default"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function loads the default privacy budget accountant if none is supplied. It also checks if the supplied accountant is an instance of the BudgetAccountant class.", "Arguments": ":param accountant: BudgetAccountant or None. The supplied budget accountant. If None, the default accountant is returned.\n:return: default: BudgetAccountant. Returns a working BudgetAccountant, either the supplied accountant or the existing default."}, "tests": ["tests/test_BudgetAccountant.py::TestBudgetAccountant::test_load_wrong_type"], "indent": 8}
{"namespace": "hbmqtt.plugins.manager.PluginManager.get_plugin", "type": "method", "project_path": "Communications/hbmqtt", "completion_path": "Communications/hbmqtt/hbmqtt/plugins/manager.py", "signature_position": [81, 81], "body_position": [87, 90], "dependency": {"intra_class": ["hbmqtt.plugins.manager.PluginManager._plugins"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a plugin from the loaded plugins based on its name. It iterates through the list of plugins and returns the plugin with a matching name. If no plugin is found, it returns None.", "Arguments": ":param self: PluginManager. An instance of the PluginManager class.\n:param name: String. The name of the plugin to retrieve.\n:return: Plugin. The plugin with the specified name, or None if no plugin is found."}, "tests": ["tests/plugins/test_manager.py::TestPluginManager::test_map_coro_return", "tests/plugins/test_manager.py::TestPluginManager::test_map_coro", "tests/plugins/test_manager.py::TestPluginManager::test_fire_event", "tests/plugins/test_manager.py::TestPluginManager::test_fire_event_wait"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_values.rarest_window_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_values.py", "signature_position": [545, 557], "body_position": [609, 626], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_values.compute_likelihood_windows_in_session"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix"]}, "requirement": {"Functionality": "This function finds and computes the likelihood of the rarest window of a given length in a session. It uses the input parameters and calculates the likelihoods of all sliding windows in the session. It then returns the rarest window and its corresponding likelihood.", "Arguments": ":param session: List[Cmd]. A list of Cmd objects representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands (length 2).\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the params conditional on the commands.\n:param value_cond_param_probs: Union[StateMatrix, dict]. Computed probabilities of the values conditional on the params.\n:param modellable_params: set. A set of params for which the probabilities of their values will be included in the likelihood calculation.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, the `start_token` and `end_token` will be added to the session before the calculations.\n:param start_token: str. A dummy command to signify the start of the session.\n:param end_token: str. A dummy command to signify the end of the session.\n:param use_geo_mean: bool. If True, each likelihood of the sliding windows will be raised to the power of (1/`window_len`).\n:return: Tuple[List[Cmd], float]. The rarest window part of the session and the likelihood of the rarest window."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_values.py::TestCmdsParamsValues::test_rarest_window_session"], "indent": 4}
{"namespace": "sacred.utils.iterate_flattened", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [442, 442], "body_position": [448, 454], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.iterate_flattened", "sacred.utils.join_paths"], "cross_file": []}, "requirement": {"Functionality": "This function recursively iterates over the items of a dictionary and provides a full dotted path for every leaf.", "Arguments": ":param d: Dictionary. The input dictionary to iterate over.\n:return: Generator. A generator that yields a tuple containing the full dotted path and the corresponding value for every leaf in the dictionary."}, "tests": ["tests/test_utils.py::test_iterate_flattened"], "indent": 4}
{"namespace": "pyramid.i18n.Translations.load", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/i18n.py", "signature_position": [247, 247], "body_position": [259, 269], "dependency": {"intra_class": ["pyramid.i18n.Translations.DEFAULT_DOMAIN", "pyramid.i18n.Translations.__init__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function loads translations from a given directory. It takes the directory name, a list of preferred locales, and the message domain as input parameters. It returns the loaded catalog of translations or a gettext.NullTranslations instance if no matching translations were found.", "Arguments": ":param cls: Translations. The Translations class.\n:param dirname: String. The directory containing the MO files.\n:param locales: List of locales. The list of locales in order of preference. Each item in the list can be either a Locale object or a locale string.\n:param domain: String. The message domain.\n:return: Translations. The loaded catalog of translations or a NullTranslations instance if no matching translations were found."}, "tests": ["tests/test_i18n.py::TestTranslations::test_load_domain_None", "tests/test_i18n.py::TestTranslations::test_load_found_locale_and_domain_locale_is_string", "tests/test_i18n.py::TestTranslations::test_load_found_locale_and_domain", "tests/test_i18n.py::TestTranslations::test_load_locales_None"], "indent": 8}
{"namespace": "pyramid.testing.DummyResource.clone", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [215, 215], "body_position": [222, 230], "dependency": {"intra_class": ["pyramid.testing.DummyResource.__name__", "pyramid.testing.DummyResource.__parent__", "pyramid.testing.DummyResource.kw", "pyramid.testing.DummyResource.subs"], "intra_file": ["pyramid.testing._marker"], "cross_file": []}, "requirement": {"Functionality": "Create a clone of the DummyResource object and return it.", "Arguments": ":param self: DummyResource. An instance of the DummyResource class.\n:param __name__: String. Optional argument to override the existing __name__ attribute of the resource.\n:param __parent__: Object. Optional argument to override the existing __parent__ attribute of the resource.\n:param **kw: Keyword arguments. Extra keyword arguments that can be used to add to or override existing resource keywords (attributes).\n:return: DummyResource. The cloned instance of the DummyResource object."}, "tests": ["tests/test_testing.py::TestDummyResource::test_clone"], "indent": 8}
{"namespace": "mrjob.fs.ssh.SSHFilesystem._cat_file", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/ssh.py", "signature_position": [190, 190], "body_position": [191, 201], "dependency": {"intra_class": ["mrjob.fs.ssh.SSHFilesystem._ssh_finish_run", "mrjob.fs.ssh.SSHFilesystem._ssh_launch"], "intra_file": ["mrjob.fs.ssh._SSH_URI_RE"], "cross_file": ["mrjob.cat.decompress"]}, "requirement": {"Functionality": "This function reads and returns the contents of a file located on a remote SSH filesystem. It uses the SSH protocol to connect to the remote host and execute the \"cat\" command on the specified file path. It then decompresses the output and yields it in chunks.", "Arguments": ":param self: SSHFilesystem. An instance of the SSHFilesystem class.\n:param path: str. The path of the file to read on the remote filesystem.\n:return: Generator. Yields chunks of the file's contents."}, "tests": ["tests/fs/test_ssh.py::SSHFSTestCase::test_cat_gz", "tests/fs/test_ssh.py::SSHFSTestCase::test_cat_without_required_sudo", "tests/fs/test_ssh.py::SSHFSTestCase::test_worker_cat_without_required_sudo", "tests/fs/test_ssh.py::SSHFSTestCase::test_cat_with_required_sudo", "tests/fs/test_ssh.py::SSHFSTestCase::test_worker_cat_with_required_sudo"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.setacl", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1553, 1553], "body_position": [1559, 1561], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._normalise_folder"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set an access control list (ACL) for a given user on a specified folder in IMAPClient. Remove an ACL if the `what` is an empty string. Return the server response string.\n", "Arguments": ":param folder: String, the folder path for which the ACL needs to be set.\n:param who: String, the user for whom the ACL is being set.\n:param what: String, the access control level to be set for the user. Empty string removes the ACL.\n:return: String, the server response string.\n"}, "tests": ["tests/test_imapclient.py::TestAclMethods::test_setacl"], "indent": 8}
{"namespace": "twilio.twiml.TwiML.append", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/__init__.py", "signature_position": [74, 74], "body_position": [82, 83], "dependency": {"intra_class": ["twilio.twiml.TwiML.nest"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds a TwiML document to a TwiML instance. It nests the given TwiML document within the current TwiML instance.", "Arguments": ":param self: TwiML. An instance of the TwiML class.\n:param verb: TwiML Document. The TwiML document to be added to the instance.\n:return: Self."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestDial::test_add_number_status_callback_event", "tests/unit/twiml/test_voice_response.py::TestEnqueue::test_task_dict", "tests/unit/twiml/test_voice_response.py::TestQueue::test_queue", "tests/unit/twiml/test_voice_response.py::TestDial::test_sip", "tests/unit/twiml/test_voice_response.py::TestConference::test_conference"], "indent": 8}
{"namespace": "bplustree.memory.FileMemory.next_available_page", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [201, 201], "body_position": [202, 203], "dependency": {"intra_class": ["bplustree.memory.FileMemory.last_page"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the last available page number in the instance and maintain the attributes properly.", "Arguments": ":param self: FileMemory. An instance of the FileMemory class.\n:return: int."}, "tests": ["tests/test_memory.py::test_file_memory_next_available_page"], "indent": 8}
{"namespace": "datasette.utils.asgi.Response.asgi_send", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/asgi.py", "signature_position": [330, 330], "body_position": [331, 350], "dependency": {"intra_class": ["datasette.utils.asgi.Response._set_cookie_headers", "datasette.utils.asgi.Response.body", "datasette.utils.asgi.Response.content_type", "datasette.utils.asgi.Response.headers", "datasette.utils.asgi.Response.status"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to send an ASGI response. It prepares the headers and body of the Response instance, converts them to the required format, and sends them using the provided `send` function.", "Arguments": ":param self: Response. An instance of the Response class.\n:param send: Function. The function used to send the response.\n:return: No return value."}, "tests": ["tests/test_internals_response.py::test_response_set_cookie"], "indent": 8}
{"namespace": "boto.ec2.volume.Volume.create_snapshot", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/volume.py", "signature_position": [190, 190], "body_position": [201, 205], "dependency": {"intra_class": ["boto.ec2.volume.Volume.connection", "boto.ec2.volume.Volume.id"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.create_snapshot"]}, "requirement": {"Functionality": "Create a snapshot of this EBS Volume.", "Arguments": ":param self: Volume. An instance of the Volume class.\n:param description: str. A description of the snapshot. Limited to 256 characters.\n:param dry_run: bool. Whether to simulate the operation without actually creating a snapshot. Defaults to False.\n:return: Snapshot. The created Snapshot object."}, "tests": ["tests/unit/ec2/test_volume.py::VolumeTests::test_create_snapshot_with_description", "tests/unit/ec2/test_volume.py::VolumeTests::test_create_snapshot_calls_connection_create_snapshot"], "indent": 8}
{"namespace": "pyt.core.project_handler.get_directory_modules", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/core/project_handler.py", "signature_position": [11, 11], "body_position": [15, 31], "dependency": {"intra_class": [], "intra_file": ["pyt.core.project_handler._is_python_file", "pyt.core.project_handler._local_modules"], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of tuples containing the names and paths of the modules in a given directory. It first checks if the list of local modules is already populated and if the directory matches the directory of the first module in the list. If so, it returns the list as is. If not, it checks if the given directory is a valid directory. If it is not, it sets the directory to the parent directory of the given file path. Then, it iterates through the files in the directory and checks if each file is a Python file. If it is, it extracts the module name by removing the file extension and adds a tuple of the module name and the file path to the list of local modules. Finally, it returns the list of local modules.", "Arguments": ":param directory: String. The directory to search for modules.\n:return: List of tuples. A list containing tuples of module names and file paths."}, "tests": ["tests/cfg/import_test.py::ImportTest::test_package_with_folder", "tests/cfg/import_test.py::ImportTest::test_from_package_with_function", "tests/cfg/import_test.py::ImportTest::test_from_package_with_file_and_alias", "tests/cfg/import_test.py::ImportTest::test_import_as", "tests/cfg/import_test.py::ImportTest::test_package_with_folder_and_alias"], "indent": 4}
{"namespace": "pycoin.services.providers.get_default_providers_for_netcode", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/services/providers.py", "signature_position": [135, 135], "body_position": [136, 142], "dependency": {"intra_class": [], "intra_file": ["pycoin.services.providers.THREAD_LOCALS", "pycoin.services.providers.providers_for_netcode_from_env"], "cross_file": ["pycoin.networks.default.get_current_netcode"]}, "requirement": {"Functionality": "This function retrieves the default providers for a given netcode. If the netcode is not provided, it retrieves the current netcode. It then checks if the providers for the netcode are already stored in the thread locals dictionary. If not, it retrieves the providers for the netcode from the environment. Finally, it returns the providers for the given netcode.", "Arguments": ":param netcode: String [optional]. The netcode for which to retrieve the default providers. If not provided, the current netcode is used.\n:return: Dictionary. The default providers for the given netcode."}, "tests": ["tests/services/services_test.py::ServicesTest::test_thread_provider"], "indent": 4}
{"namespace": "csvkit.cli.CSVKitUtility.run", "type": "method", "project_path": "Scientific-Engineering/csvkit", "completion_path": "Scientific-Engineering/csvkit/csvkit/cli.py", "signature_position": [106, 106], "body_position": [111, 122], "dependency": {"intra_class": ["csvkit.cli.CSVKitUtility._open_input_file", "csvkit.cli.CSVKitUtility.args", "csvkit.cli.CSVKitUtility.input_file", "csvkit.cli.CSVKitUtility.main", "csvkit.cli.CSVKitUtility.override_flags"], "intra_file": ["csvkit.cli.LazyFile.close"], "cross_file": []}, "requirement": {"Functionality": "This function is a wrapper around the main loop of a utility. It handles opening and closing files. It first checks if the 'f' flag is not present in the override flags. If not present, it opens the input file. Then, it executes the main loop of the utility, ignoring warnings related to column names if the 'no_header_row' option is present. Finally, it closes the input file if the 'f' flag is not present in the override flags.", "Arguments": ":param self: CSVKitUtility. An instance of the CSVKitUtility class.\n:return: No return values."}, "tests": ["tests/test_utilities/test_csvsql.py::TestCSVSQL::test_before_after_insert", "tests/test_utilities/test_csvjson.py::TestCSVJSON::test_duplicate_keys"], "indent": 8}
{"namespace": "gunicorn.http.unreader.Unreader.unread", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/http/unreader.py", "signature_position": [52, 52], "body_position": [53, 54], "dependency": {"intra_class": ["gunicorn.http.unreader.Unreader.buf"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function appends the given data to the end of the buffer in the Unreader instance.", "Arguments": ":param self: Unreader. An instance of the Unreader class.\n:param data: The data to be appended to the buffer.\n:return: No return values."}, "tests": ["tests/test_http.py::test_unreader_unread"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient._proc_folder_list", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [747, 750], "body_position": [751, 766], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient.folder_encode"], "intra_file": [], "cross_file": ["imapclient.imap_utf7.decode", "imapclient.response_parser.parse_response", "imapclient.util.chunk"]}, "requirement": {"Functionality": "This function processes the folder data returned by the IMAP server and filters out empty strings and None values. It then parses the response and extracts the flags, delimiter, and name of each folder. If the folder name is an integer, it converts it back to a string. If folder encoding is enabled, it decodes the folder name using UTF-7 encoding. Finally, it returns a list of tuples containing the flags, delimiter, and name of each folder.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param folder_data: List of bytes. The folder data returned by the IMAP server.\n:return: List of tuples. Each tuple contains the flags, delimiter, and name of a folder."}, "tests": ["tests/test_imapclient.py::TestListFolders::test_without_quotes", "tests/test_imapclient.py::TestListFolders::test_unquoted_numeric_folder_name_parsed_as_long", "tests/test_imapclient.py::TestListFolders::test_mixed", "tests/test_imapclient.py::TestListFolders::test_quoted_specials", "tests/test_imapclient.py::TestListFolders::test_blanks"], "indent": 8}
{"namespace": "pyramid.request.CallbackMethodsMixin._process_finished_callbacks", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/request.py", "signature_position": [131, 131], "body_position": [132, 135], "dependency": {"intra_class": ["pyramid.request.CallbackMethodsMixin.finished_callbacks"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function processes the finished callbacks in a CallbackMethodsMixin instance. It retrieves the finished callbacks and executes them one by one, passing the input instance as an argument to each callback.", "Arguments": ":param self: CallbackMethodsMixin. An instance of the CallbackMethodsMixin class.\n:return: No return values."}, "tests": ["tests/test_request.py::TestRequest::test__process_finished_callbacks"], "indent": 8}
{"namespace": "datasette.utils.asgi.Response.set_cookie", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/asgi.py", "signature_position": [352, 363], "body_position": [364, 381], "dependency": {"intra_class": ["datasette.utils.asgi.Response._set_cookie_headers"], "intra_file": ["datasette.utils.asgi.SAMESITE_VALUES"], "cross_file": []}, "requirement": {"Functionality": "This function sets a cookie in the Response object. It creates a cookie with the given parameters and adds it to the list of cookie headers in the Response object.", "Arguments": ":param self: Response. An instance of the Response class.\n:param key: String. The name of the cookie.\n:param value: String. The value of the cookie. Defaults to an empty string.\n:param max_age: Integer. The maximum age of the cookie in seconds. Defaults to None.\n:param expires: String. The expiration date of the cookie in the format \"Wdy, DD-Mon-YYYY HH:MM:SS GMT\". Defaults to None.\n:param path: String. The path on the server where the cookie is valid. Defaults to \"/\".\n:param domain: String. The domain where the cookie is valid. Defaults to None.\n:param secure: Bool. Whether the cookie should only be sent over HTTPS. Defaults to False.\n:param httponly: Bool. Whether the cookie should only be accessible via HTTP requests. Defaults to False.\n:param samesite: String. The SameSite attribute of the cookie. It should be one of [\"lax\", \"strict\", \"none\"]. Defaults to \"lax\".\n:return: No return value."}, "tests": ["tests/test_internals_response.py::test_response_set_cookie"], "indent": 8}
{"namespace": "onlinejudge_command.pretty_printers._tokenize_file_content_without_snipping", "type": "function", "project_path": "Text-Processing/online-judge-tools", "completion_path": "Text-Processing/online-judge-tools/onlinejudge_command/pretty_printers.py", "signature_position": [221, 221], "body_position": [222, 226], "dependency": {"intra_class": [], "intra_file": ["onlinejudge_command.pretty_printers._PrettyToken", "onlinejudge_command.pretty_printers._decode_with_recovery", "onlinejudge_command.pretty_printers._tokenize_line", "onlinejudge_command.pretty_printers._warn_if_empty"], "cross_file": []}, "requirement": {"Functionality": "This function tokenizes the content of a file without snipping. It first decodes the content, then splits the decoded text into lines and tokenizes each line. It also checks if the tokens list is empty and warns if it is.", "Arguments": ":param content: Bytes. The content of the file to be tokenized.\n:return: List of _PrettyToken. The list of tokens generated from the file content."}, "tests": ["tests/pretty_printers.py::TokenizeFileContentWithoutSnippingTest::test_empty", "tests/pretty_printers.py::TokenizeFileContentWithoutSnippingTest::test_only_newlines", "tests/pretty_printers.py::TokenizeFileContentWithoutSnippingTest::test_small"], "indent": 4}
{"namespace": "pyramid.authentication.AuthTktAuthenticationPolicy.unauthenticated_userid", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [633, 633], "body_position": [635, 637], "dependency": {"intra_class": ["pyramid.authentication.AuthTktAuthenticationPolicy.cookie"], "intra_file": ["pyramid.authentication.AuthTktCookieHelper.identify"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the user ID from the auth_tkt cookie.", "Arguments": ":param self: AuthTktAuthenticationPolicy. An instance of the AuthTktAuthenticationPolicy class.\n:param request: The request object.\n:return: The user ID extracted from the auth_tkt cookie."}, "tests": ["tests/test_authentication.py::TestAuthTktAuthenticationPolicy::test_unauthenticated_userid"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.exists", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [59, 59], "body_position": [60, 61], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "Check if a file or directory exists in the local filesystem. It converts the input path_glob from a file URI to a local filesystem path and then checks if any files or directories match the given path_glob.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param path_glob: String. The file or directory path to check. It can contain wildcards (*) to match multiple files or directories.\n:return: Bool. True if at least one file or directory matches the path_glob, False otherwise."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_rm_file_by_uri", "tests/fs/test_local.py::LocalFSTestCase::test_exists_no", "tests/fs/test_local.py::LocalFSTestCase::test_rm_file", "tests/fs/test_local.py::LocalFSTestCase::test_rm_dir", "tests/fs/test_local.py::LocalFSTestCase::test_touchz"], "indent": 8}
{"namespace": "sslyze.plugins.certificate_info._cli_connector._CertificateInfoCliConnector.result_to_console_output", "type": "method", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/certificate_info/_cli_connector.py", "signature_position": [69, 69], "body_position": [70, 84], "dependency": {"intra_class": ["sslyze.plugins.certificate_info._cli_connector._CertificateInfoCliConnector._cert_deployment_to_console_output"], "intra_file": ["sslyze.plugins.certificate_info.implementation.CertificateInfoScanResult.certificate_deployments", "sslyze.plugins.certificate_info.implementation.CertificateInfoScanResult.hostname_used_for_server_name_indication"], "cross_file": ["sslyze.plugins.plugin_base.ScanCommandCliConnector._format_field", "sslyze.plugins.plugin_base.ScanCommandCliConnector._format_title"]}, "requirement": {"Functionality": "This function takes a CertificateInfoScanResult object as input and converts the result into a list of strings that can be displayed on the console. It includes information about the hostname sent for SNI and the number of certificates detected. It also iterates through each certificate deployment and adds the formatted information to the result list.", "Arguments": ":param cls: _CertificateInfoCliConnector. The class object of _CertificateInfoCliConnector.\n:param result: CertificateInfoScanResult. The result of a certificate information scan.\n:return: List of strings. The formatted result that can be displayed on the console."}, "tests": ["tests/plugins_tests/certificate_info/test_certificate_algorithms.py::TestCertificateAlgorithms::test_ed25519_certificate", "tests/plugins_tests/certificate_info/test_certificate_algorithms.py::TestCertificateAlgorithms::test_rsa_certificate", "tests/plugins_tests/certificate_info/test_certificate_algorithms.py::TestCertificateAlgorithms::test_invalid_certificate_bad_name", "tests/plugins_tests/certificate_info/test_certificate_algorithms.py::TestCertificateAlgorithms::test_ecdsa_certificate"], "indent": 8}
{"namespace": "boltons.setutils.IndexedSet.index", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/setutils.py", "signature_position": [466, 466], "body_position": [468, 472], "dependency": {"intra_class": ["boltons.setutils.IndexedSet._get_apparent_index", "boltons.setutils.IndexedSet.item_index_map"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the index of a value in the IndexedSet instance. If the value is not present in the instance, it raises a ValueError: '{val!r} is not in {type name}'.", "Arguments": ":param self: IndexedSet. An instance of the IndexedSet class.\n:param val: The value to get the index of.\n:return: The index of the value in the IndexedSet instance."}, "tests": ["tests/test_setutils.py::test_iset_index_method"], "indent": 8}
{"namespace": "faker.utils.checksums.calculate_luhn", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/checksums.py", "signature_position": [18, 18], "body_position": [22, 23], "dependency": {"intra_class": [], "intra_file": ["faker.utils.checksums.luhn_checksum"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the checksum using Luhn's algorithm for a given partial number. It multiplies the partial number by 10, calculates the checksum, and returns the check digit. If the check digit is 0, it returns the check digit itself. Otherwise, it returns 10 minus the check digit.", "Arguments": ":param partial_number: float. The partial number for which the checksum needs to be calculated.\n:return: int. The calculated check digit using Luhn's algorithm."}, "tests": ["tests/utils/test_utils.py::UtilsTestCase::test_luhn_checksum"], "indent": 4}
{"namespace": "tools.cgrep.compare_tokens", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [397, 397], "body_position": [409, 423], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["capirca.lib.nacaddr.IP", "capirca.lib.naming.Naming.GetNet", "capirca.lib.nacaddr"]}, "requirement": {"Functionality": "This function compares two network objects against each other. It retrieves the network and service definitions from the database based on the options provided. It then compares the two network objects and returns the meta information and the differences between the two objects.", "Arguments": ":param options: The options sent to the script.\n:param db: The network and service definitions from the database.\n:return: A tuple containing the meta information (first object, second object, union of those two) and the differences between the two network objects."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_compare_same_token"], "indent": 2}
{"namespace": "dash._get_paths.app_strip_relative_path", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_get_paths.py", "signature_position": [131, 131], "body_position": [132, 151], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["dash.exceptions", "dash.exceptions.UnsupportedRelativePath"]}, "requirement": {"Functionality": "This function strips the relative path from the given path based on the pathname of requests. It checks if the pathname of requests not equal \"/\" and the path don't start with the requests_pathname processed by rstrip with \"/\" before and removes it if it does. It also handles the case where the requests_pathname has a trailing slash and the path does not.", "Arguments": ":param requests_pathname: String. The pathname from the request URL.\n:param path: String. The path to be stripped.\n:return: String. The stripped path."}, "tests": ["tests/unit/test_configs.py::test_invalid_strip_relative_path", "tests/unit/test_configs.py::test_strip_relative_path"], "indent": 4}
{"namespace": "pyramid.authorization.ACLAuthorizationPolicy.principals_allowed_by_permission", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authorization.py", "signature_position": [77, 77], "body_position": [82, 84], "dependency": {"intra_class": ["pyramid.authorization.ACLAuthorizationPolicy.helper"], "intra_file": ["pyramid.authorization.ACLHelper.principals_allowed_by_permission"], "cross_file": []}, "requirement": {"Functionality": "This function returns the set of principals that are explicitly granted the specified permission according to the ACL (Access Control List) attached to the context and any inherited ACLs based on the lineage.", "Arguments": ":param self: ACLAuthorizationPolicy. An instance of the ACLAuthorizationPolicy class.\n:param context: The context object to which the ACL is attached.\n:param permission: The name of the permission.\n:return: Set of principals. The set of principals that are explicitly granted the specified permission."}, "tests": ["tests/test_authorization.py::TestACLAuthorizationPolicy::test_principals_allowed_by_permission", "tests/test_authorization.py::TestACLAuthorizationPolicy::test_principals_allowed_by_permission_deny_permission_in_acl", "tests/test_authorization.py::TestACLAuthorizationPolicy::test_principals_allowed_by_permission_callable_acl", "tests/test_authorization.py::TestACLAuthorizationPolicy::test_principals_allowed_by_permission_direct", "tests/test_authorization.py::TestACLAuthorizationPolicy::test_principals_allowed_by_permission_deny_not_permission_in_acl"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.OpenSSLPrerequisite.darwin_pkg_config_location", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [277, 277], "body_position": [278, 281], "dependency": {"intra_class": ["pythonforandroid.prerequisites.OpenSSLPrerequisite.homebrew_formula_name"], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "This function returns the location of the pkg-config directory for OpenSSL on macOS. It constructs the path by combining the prefix location of the Homebrew formula for OpenSSL and the \"lib/pkgconfig\" directory.", "Arguments": ":param self: OpenSSLPrerequisite. An instance of the OpenSSLPrerequisite class.\n:return: String. The location of the pkg-config directory for OpenSSL on macOS."}, "tests": ["tests/test_prerequisites.py::TestOpenSSLPrerequisite::test_darwin_pkg_config_location"], "indent": 8}
{"namespace": "alembic.autogenerate.compare._compare_server_default", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/compare.py", "signature_position": [1125, 1133], "body_position": [1134, 1209], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.api.AutogenContext.migration_context", "alembic.autogenerate.compare._compare_computed_default", "alembic.autogenerate.compare._compare_identity_default", "alembic.autogenerate.compare._render_server_default_for_compare", "alembic.autogenerate.compare._warn_computed_not_supported", "alembic.autogenerate.compare.log", "alembic.operations.ops.AlterColumnOp.existing_server_default", "alembic.operations.ops.AlterColumnOp.modify_server_default"], "cross_file": ["alembic.autogenerate.api.AutogenContext", "alembic.operations.ops.AlterColumnOp", "alembic.runtime.migration.MigrationContext._compare_server_default", "alembic.util.sqla_compat", "alembic.util.sqla_compat._server_default_is_computed", "alembic.util.sqla_compat._server_default_is_identity", "alembic.util.sqla_compat.has_computed_reflection"]}, "requirement": {"Functionality": "This function compares the server default values of two columns in a database table. It checks if the server default values are different and modifies the alter_column_op object accordingly.", "Arguments": ":param autogen_context: AutogenContext. The autogenerate context.\n:param alter_column_op: AlterColumnOp. The alter column operation object.\n:param schema: Optional string. The schema of the table.\n:param tname: Union[quoted_name, str]. The name of the table.\n:param cname: Union[quoted_name, str]. The name of the column.\n:param conn_col: Column[Any]. The column object from the database connection.\n:param metadata_col: Column[Any]. The column object from the metadata.\n:return: Optional bool. Returns None."}, "tests": ["tests/test_mysql.py::MySQLOpTest::test_alter_column_modify_programmatic_default"], "indent": 4}
{"namespace": "googleapiclient.model.makepatch", "type": "function", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/model.py", "signature_position": [369, 369], "body_position": [390, 410], "dependency": {"intra_class": [], "intra_file": ["googleapiclient.model.makepatch"], "cross_file": []}, "requirement": {"Functionality": "This function creates a patch object that contains only the changes between the original and modified resources. It compares the values of each key in the original and modified dictionaries and constructs a patch object with the differences.", "Arguments": ":param original: object. The original deserialized resource.\n:param modified: object. The modified deserialized resource.\n:return: object. An object that contains only the changes from the original to modified resources, suitable for passing to a PATCH method."}, "tests": ["tests/test_model.py::TestPatch::test_patch"], "indent": 4}
{"namespace": "boto.dynamodb2.table.Table.batch_get", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1504, 1504], "body_position": [1544, 1547], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._batch_get", "boto.dynamodb2.table.Table.max_batch_get"], "intra_file": [], "cross_file": ["boto.dynamodb2.results.BatchGetResultSet", "boto.dynamodb2.results.ResultSet.to_call"]}, "requirement": {"Functionality": "This function fetches multiple specific items in batch from a table. It takes a list of dictionaries as the keys parameter, where each dictionary consists of the key values to specify. It also accepts optional parameters such as consistent (boolean) for specifying whether to use strongly consistent read or not, and attributes (tuple) for specifying the attributes to fetch from DynamoDB. It returns a ResultSet object that handles the pagination of results.", "Arguments": ":param self: Table. An instance of the Table class.\n:param keys: List of dictionaries. The keys values to specify for fetching items.\n:param consistent: Bool. Whether to use strongly consistent read. Defaults to False.\n:param attributes: Tuple. The attributes to fetch from DynamoDB.\n:return: ResultSet. The ResultSet object that handles the pagination of results."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_get"], "indent": 8}
{"namespace": "imapclient.response_lexer.TokenSource.current_literal", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/response_lexer.py", "signature_position": [41, 41], "body_position": [42, 44], "dependency": {"intra_class": ["imapclient.response_lexer.TokenSource.lex"], "intra_file": ["imapclient.response_lexer.Lexer.current_source"], "cross_file": []}, "requirement": {"Functionality": "This function returns the current literal value from the TokenSource instance. It checks if the current source is not None and returns the literal value.", "Arguments": ":param self: TokenSource. An instance of the TokenSource class.\n:return: Optional[bytes]. The current literal value from the TokenSource instance."}, "tests": ["tests/test_response_lexer.py::TestTokenSource::test_literals", "tests/test_response_lexer.py::TestTokenSource::test_literal"], "indent": 8}
{"namespace": "diffprivlib.tools.quantiles.percentile", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/quantiles.py", "signature_position": [154, 155], "body_position": [211, 219], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.quantiles.quantile"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the differentially private percentile of an array. It calls the quantile with the percentile value calculated as percent / 100 and validate the value, ensuring that the calculated percentile values fall within the acceptable range.", "Arguments": ":param array: array_like. An array containing numbers whose percentile is sought.\n:param percent: float or array-like. The percentile or list of percentiles sought. Each percentile must be in the range [0, 100]. If percent is array-like, percentiles are returned over the flattened array.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon. Differential privacy is achieved over the entire output, with epsilon split evenly between each output value.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: None or int or tuple of ints, optional. The axis or axes along which the sum is performed. The default, axis=None, sums all the elements of the input array. If axis is negative, it counts from the last to the first axis. If axis is a tuple of ints, a sum is performed on all the specified axes.\n:param keepdims: bool, default: False. If True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm. To obtain deterministic behavior during randomization, random_state has to be fixed to an integer.\n:param accountant: BudgetAccountant, optional. An accountant to keep track of the privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. Returns a new array containing the percentile values."}, "tests": ["tests/tools/test_percentile.py::TestPercentile::test_bad_percents", "tests/tools/test_percentile.py::TestPercentile::test_random_state", "tests/tools/test_percentile.py::TestPercentile::test_simple", "tests/tools/test_percentile.py::TestPercentile::test_uniform_array"], "indent": 4}
{"namespace": "mrjob.job.MRJob.increment_counter", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [548, 548], "body_position": [562, 585], "dependency": {"intra_class": ["mrjob.job.MRJob.stderr"], "intra_file": [], "cross_file": ["mrjob.py2.integer_types", "mrjob.py2.string_types"]}, "requirement": {"Functionality": "This function is used to increment a counter in Hadoop streaming by printing to stderr. It takes in the counter group, counter description, and the amount by which the counter should be incremented. It replaces commas in the counter group and counter description with semicolons to avoid confusion with Hadoop streaming. Then, it constructs a line using a specified format - \"reporter:counter:{group},{counter},{amount}\\n\". The line is outputted through the standard error stream of the input MRJob instance.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:param group: str. The counter group.\n:param counter: str. The description of the counter.\n:param amount: int. The amount by which the counter should be incremented. Defaults to 1.\n:return: No return values."}, "tests": ["tests/test_job.py::CountersAndStatusTestCase::test_negative_and_zero_counters", "tests/test_job.py::CountersAndStatusTestCase::test_commas_in_counters", "tests/test_job.py::CountersAndStatusTestCase::test_bad_counter_amounts", "tests/test_job.py::CountersAndStatusTestCase::test_counters_and_status"], "indent": 8}
{"namespace": "boto.cognito.sync.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cognito/sync/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cognito.sync.layer1.CognitoSyncConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CognitoSyncConnection class. It calls the connect function with the specified parameters and returns the connection object.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: CognitoSyncConnection. The connection object for the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCognitoSyncConnection::test_connect_to_region"], "indent": 4}
{"namespace": "fs._ftp_parse.parse", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/_ftp_parse.py", "signature_position": [67, 67], "body_position": [68, 75], "dependency": {"intra_class": [], "intra_file": ["fs._ftp_parse.parse_line"], "cross_file": []}, "requirement": {"Functionality": "Parse a list of lines and extract information from each line that is not blank.\n", "Arguments": ":param lines: List[String], the input list of lines to be parsed.\n:return: List, the list of parsed information extracted from the input lines.\n"}, "tests": ["tests/test_ftp_parse.py::TestFTPParse::test_parse", "tests/test_ftp_parse.py::TestFTPParse::test_decode_linux_sticky", "tests/test_ftp_parse.py::TestFTPParse::test_decode_windowsnt", "tests/test_ftp_parse.py::TestFTPParse::test_decode_linux", "tests/test_ftp_parse.py::TestFTPParse::test_decode_linux_suid"], "indent": 4}
{"namespace": "alembic.operations.ops.DropConstraintOp.to_constraint", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [176, 176], "body_position": [177, 189], "dependency": {"intra_class": ["alembic.operations.ops.DropConstraintOp._reverse", "alembic.operations.ops.DropConstraintOp.constraint_name", "alembic.operations.ops.DropConstraintOp.schema", "alembic.operations.ops.DropConstraintOp.table_name"], "intra_file": ["alembic.operations.ops.AddConstraintOp.to_constraint"], "cross_file": ["alembic.util.sqla_compat", "alembic.util.sqla_compat._table_for_constraint"]}, "requirement": {"Functionality": "Converts a DropConstraintOp instance to a Constraint instance. It first checks if the reverse operation is present. If it is, it converts the reverse operation to a Constraint instance and sets the name, table name, and schema of the constraint. Then it returns the constraint. If the reverse operation is not present, it raises a ValueError.", "Arguments": ":param self: DropConstraintOp. An instance of the DropConstraintOp class.\n:return: Constraint. The converted Constraint instance."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_drop_check", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_unique", "tests/test_op.py::ObjectFromToTest::test_create_unique_constraint_add_kw", "tests/test_op.py::ObjectFromToTest::test_drop_unique_constraint_change_name", "tests/test_autogen_diffs.py::OrigObjectTest::test_add_unique"], "indent": 8}
{"namespace": "playhouse.db_url.parse", "type": "function", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/db_url.py", "signature_position": [87, 87], "body_position": [88, 89], "dependency": {"intra_class": [], "intra_file": ["playhouse.db_url.parseresult_to_dict"], "cross_file": []}, "requirement": {"Functionality": "This function takes a URL as input and parses it. It then convert the parsed result into a dictionary using the parsed result and unquote password which determines whether the password in the URL should be unquoted or not.", "Arguments": ":param url: String. The URL to be parsed.\n:param unquote_password: Bool. Whether to unquote the password in the URL. Defaults to False.\n:return: Dictionary. The parsed URL as a dictionary."}, "tests": ["tests/db_url.py::TestDBUrl::test_db_url_quoted_password", "tests/db_url.py::TestDBUrl::test_db_url_parse"], "indent": 4}
{"namespace": "dash._configs.pages_folder_config", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_configs.py", "signature_position": [125, 125], "body_position": [126, 137], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["dash.exceptions.InvalidConfig"]}, "requirement": {"Functionality": "This function configures the pages folder for a Dash application. It checks if the pages folder exists and raises an exception if it doesn't. It returns the path to the pages folder if it exists.", "Arguments": ":param name: String. The name of the Dash application.\n:param pages_folder: String. The name of the pages folder.\n:param use_pages: Bool. Whether to use the pages folder.\n:return: String. The path to the pages folder."}, "tests": ["tests/unit/pages/test_pages_config.py::test_pages_folder_config", "tests/unit/pages/test_pages_config.py::test_pages_missing_path_config"], "indent": 4}
{"namespace": "imapclient.datetime_util.format_criteria_date", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/datetime_util.py", "signature_position": [67, 67], "body_position": [69, 70], "dependency": {"intra_class": [], "intra_file": ["imapclient.datetime_util._SHORT_MONTHS"], "cross_file": []}, "requirement": {"Functionality": "Take a date or datetime instance as input and format it into a string that can be used in IMAP search criteria.\n", "Arguments": ":param dt: Date or datetime, the date or datetime instance to be formatted.\n:return: Bytes, the formatted date as a byte string.\n"}, "tests": ["tests/test_datetime_util.py::TestCriteriaDateFormatting::test_single_digit_day", "tests/test_datetime_util.py::TestCriteriaDateFormatting::test_basic"], "indent": 4}
{"namespace": "csvkit.convert.fixed.fixed2csv", "type": "function", "project_path": "Scientific-Engineering/csvkit", "completion_path": "Scientific-Engineering/csvkit/csvkit/convert/fixed.py", "signature_position": [10, 10], "body_position": [30, 59], "dependency": {"intra_class": [], "intra_file": ["csvkit.convert.fixed.FixedWidthReader", "csvkit.convert.fixed.FixedWidthReader.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function converts a fixed-width file to a CSV file using a CSV-formatted schema description. It reads the fixed-width file, parses it based on the provided schema, and writes the parsed data to a CSV file. If an output file is not specified, the function returns the complete parsed data as a string.", "Arguments": ":param f: File object. The fixed-width file to be converted to CSV.\n:param schema: CSV-formatted schema description. A CSV file that specifies the column names, starting indices, and lengths of each column in the fixed-width file.\n:param output: File object [optional]. The output CSV file where the parsed data will be written. If not specified, the parsed data will be returned as a string.\n:param skip_lines: Integer [optional]. The number of lines to skip from the top of the fixed-width file.\n:param kwargs: Additional keyword arguments [optional]. Additional arguments that can be passed to the function.\n:return: String or None. If an output file is specified, the function returns None. If an output file is not specified, the function returns the complete parsed data as a string."}, "tests": ["tests/test_convert/test_fixed.py::TestFixed::test_fixed", "tests/test_convert/test_fixed.py::TestFixed::test_fixed_skip_lines", "tests/test_convert/test_fixed.py::TestFixed::test_fixed_streaming"], "indent": 4}
{"namespace": "falcon.routing.converters.DateTimeConverter.convert", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/routing/converters.py", "signature_position": [111, 111], "body_position": [112, 115], "dependency": {"intra_class": ["falcon.routing.converters.DateTimeConverter._format_string"], "intra_file": ["falcon.routing.converters.strptime"], "cross_file": []}, "requirement": {"Functionality": "This function converts a given value to a datetime object using the specified format string(default ``'%Y-%m-%dT%H:%M:%SZ'``). If the conversion fails, it returns None.", "Arguments": ":param self: DateTimeConverter. An instance of the DateTimeConverter class.\n:param value: The value to be converted to a datetime object.\n:return: datetime. The converted datetime object, or None if the conversion fails."}, "tests": ["tests/test_uri_converters.py::test_datetime_converter", "tests/test_uri_converters.py::test_datetime_converter_default_format"], "indent": 8}
{"namespace": "boltons.strutils.multi_replace", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/strutils.py", "signature_position": [1266, 1266], "body_position": [1279, 1280], "dependency": {"intra_class": [], "intra_file": ["boltons.strutils.MultiReplace", "boltons.strutils.MultiReplace.__init__", "boltons.strutils.MultiReplace.sub"], "cross_file": []}, "requirement": {"Functionality": "This function is a shortcut to invoke the MultiReplace class in a single call. It creates an instance of MultiReplace with the given substitution map and optional keyword arguments, and then performs the multi-replacement on the input text.", "Arguments": ":param text: String. The input text to perform the multi-replacement on.\n:param sub_map: Dictionary. A dictionary mapping substrings to their corresponding replacements.\n:param kwargs: Additional keyword arguments that can be passed to the MultiReplace class.\n:return: String. The input text after performing the multi-replacement."}, "tests": ["tests/test_strutils.py::TestMultiReplace::test_shortcut_function"], "indent": 4}
{"namespace": "mistune.create_markdown", "type": "function", "project_path": "Text-Processing/mistune", "completion_path": "Text-Processing/mistune/src/mistune/__init__.py", "signature_position": [20, 20], "body_position": [37, 46], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mistune.inline_parser.InlineParser", "mistune.markdown.Markdown", "mistune.renderers.html.HTMLRenderer"]}, "requirement": {"Functionality": "Create a Markdown instance based on the given condition. \n", "Arguments": ":param escape: Bool, whether to escape HTML if the renderer is set to \"html\". \n:param hard_wrap: Bool, whether to break every new line into <br> if the renderer is set to \"html\".\n:param renderer: renderer instance, default is HTMLRenderer.\n:param plugins: List, a list of plugins.\n"}, "tests": ["tests/test_directives.py::TestCustomizeToc::test_fenced_toc", "tests/test_misc.py::TestMiscCases::test_before_parse_hooks", "tests/test_directives.py::TestCustomizeToc::test_rst_toc", "tests/test_hooks.py::TestTocHook::test_customize_heading_id_func", "tests/test_misc.py::TestMiscCases::test_escape_html"], "indent": 4}
{"namespace": "principalmapper.querying.local_policy_simulation._matches_after_expansion", "type": "function", "project_path": "Security/principalmapper", "completion_path": "Security/principalmapper/principalmapper/querying/local_policy_simulation.py", "signature_position": [908, 909], "body_position": [917, 927], "dependency": {"intra_class": [], "intra_file": ["principalmapper.querying.local_policy_simulation._compose_pattern"], "cross_file": ["principalmapper.util.case_insensitive_dict.CaseInsensitiveDict"]}, "requirement": {"Functionality": "This function is a helper function that checks if a given string matches another string based on certain conditions. It handles matching with respect to wildcards, variables, and regular expressions, like replace a '${' + key + '}' pattern to value in condition_keys.", "Arguments": ":param string_to_check: str. The string that needs to be checked.\n:param string_to_check_against: str. The string that the first string is checked against.\n:param condition_keys: Optional[CaseInsensitiveDict]. A dictionary of condition keys and their corresponding values. These values can be used for variable substitution in the second string. Defaults to None.\n:return: bool. True if the first string matches the second string based on the conditions, False otherwise."}, "tests": ["tests/test_local_policy_sim.py::TestLocalPolicyVariableExpansions::test_qmark_expansion", "tests/test_local_policy_sim.py::TestLocalPolicyVariableExpansions::test_asterisk_expansion", "tests/test_local_policy_sim.py::TestLocalPolicyVariableExpansions::test_var_expansion"], "indent": 4}
{"namespace": "mrjob.compat.uses_yarn", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/compat.py", "signature_position": [718, 718], "body_position": [721, 722], "dependency": {"intra_class": [], "intra_file": ["mrjob.compat.version_gte"], "cross_file": []}, "requirement": {"Functionality": "Check if the given version is a YARN version of Hadoop.\n", "Arguments": ":param version: String. The version number to be checked.\n:return: Bool. True if the version is a YARN version, False otherwise.\n"}, "tests": ["tests/test_compat.py::UsesYarnTestCase::test_uses_yarn"], "indent": 4}
{"namespace": "rest_framework.fields.CharField.to_internal_value", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [753, 756], "body_position": [757, 760], "dependency": {"intra_class": ["rest_framework.fields.CharField.trim_whitespace"], "intra_file": ["rest_framework.fields.Field.fail"], "cross_file": []}, "requirement": {"Functionality": "This function converts the input data into an internal value for a CharField instance. It checks if the data is a boolean or not an instance of string, integer, or float. If it is, it raises an exception. Otherwise, it converts the data into a string and strips whitespace if necessary.", "Arguments": ":param self: CharField. An instance of the CharField class.\n:param data: The input data to be converted.\n:return: The internal value of the data."}, "tests": ["tests/test_fields.py::TestCharField::test_trim_whitespace_disabled", "tests/test_fields.py::TestCharField::test_trim_whitespace_default"], "indent": 8}
{"namespace": "bentoml._internal.types.LazyType.get_class", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/types.py", "signature_position": [184, 184], "body_position": [185, 198], "dependency": {"intra_class": ["bentoml._internal.types.LazyType._runtime_class", "bentoml._internal.types.LazyType.module", "bentoml._internal.types.LazyType.qualname"], "intra_file": ["bentoml._internal.types.T"], "cross_file": []}, "requirement": {"Functionality": "This function returns the class object based on the given module and qualname. If the runtime class object is not available, it tries to import the module and retrieve the class object. It caches the runtime class object for future use.", "Arguments": ":param self: LazyType. An instance of the LazyType class.\n:param import_module: Bool. Whether to import the module if it is not already imported. Defaults to True.\n:return: Type[T]. The class object corresponding to the module and qualname."}, "tests": ["tests/unit/_internal/test_utils.py::test_typeref"], "indent": 8}
{"namespace": "boto.glacier.utils.compute_hashes_from_fileobj", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/glacier/utils.py", "signature_position": [110, 110], "body_position": [128, 145], "dependency": {"intra_class": [], "intra_file": ["boto.glacier.utils.bytes_to_hex", "boto.glacier.utils.tree_hash"], "cross_file": []}, "requirement": {"Functionality": "This function computes the linear and tree hash of a file-like object in a single pass. It reads the file in chunks and updates the linear hash and tree hash accordingly.", "Arguments": ":param fileobj: A file-like object that represents the file to compute the hashes from.\n:param chunk_size: Integer. The size of the chunks to use for the tree hash. It also determines the buffer size used to read from the file. Defaults to 1024 * 1024.\n:return: Tuple. A tuple of (linear_hash, tree_hash), where both hashes are returned in hexadecimal format."}, "tests": ["tests/unit/glacier/test_utils.py::TestFileHash::test_compute_hash_tempfile_py3"], "indent": 4}
{"namespace": "datasette.app.Datasette.render_template", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [988, 990], "body_position": [991, 1084], "dependency": {"intra_class": ["datasette.app.Datasette._asset_urls", "datasette.app.Datasette._crumb_items", "datasette.app.Datasette._startup_invoked", "datasette.app.Datasette.app_css_hash", "datasette.app.Datasette.jinja_env", "datasette.app.Datasette.setting", "datasette.app.Datasette.urls"], "intra_file": [], "cross_file": ["datasette.plugins.pm", "datasette.utils.await_me_maybe", "datasette.utils.display_actor", "datasette.utils.format_bytes", "datasette.utils.asgi.Request.actor", "datasette.utils.asgi.Request.args", "datasette.utils.asgi.Request.cookies"]}, "requirement": {"Functionality": "This function renders a template using the Datasette instance. It first checks if the startup has been invoked, and if not, raises an exception. Then, it prepares the context for the template by adding various variables and values. It also calls hooks to get any extra body scripts and template variables. Finally, it renders the template with the prepared context and returns the result.", "Arguments": ":param self: Datasette. An instance of the Datasette class.\n:param templates: Template or str. The template(s) to render. It can be a Template instance or a string representing the template name.\n:param context: dict. The context variables to be passed to the template. Defaults to None.\n:param request: Request. The request object associated with the rendering. Defaults to None.\n:param view_name: str. The name of the view being rendered. Defaults to None.\n:return: str. The rendered template as a string."}, "tests": ["tests/test_internals_datasette.py::test_datasette_render_template_no_request"], "indent": 8}
{"namespace": "boltons.socketutils.NetstringSocket.write_ns", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [701, 701], "body_position": [702, 706], "dependency": {"intra_class": ["boltons.socketutils.NetstringSocket.bsock", "boltons.socketutils.NetstringSocket.maxsize"], "intra_file": ["boltons.socketutils.BufferedSocket.send", "boltons.socketutils.NetstringMessageTooLong", "boltons.socketutils.NetstringMessageTooLong.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function writes a netstring payload to the socket. It first checks if the payload size exceeds the maximum size allowed. If it does, it raises a netstring message too-long exception. Otherwise, it encodes the payload size as a string in ASCII, appends it with a colon and the payload, and appends a comma at the end. Finally, it sends the resulting data through the socket.", "Arguments": ":param self: NetstringSocket. An instance of the NetstringSocket class.\n:param payload: The payload to be written to the socket.\n:return: No return value."}, "tests": ["tests/test_socketutils.py::test_socketutils_netstring", "tests/test_socketutils.py::test_socketutils_netstring_timeout"], "indent": 8}
{"namespace": "exodus_bundler.bundling.File.hash", "type": "method", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [649, 649], "body_position": [651, 652], "dependency": {"intra_class": ["exodus_bundler.bundling.File.path"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function computes a hash based on the content of the file. It opens the file in binary mode, reads its content, and computes the SHA256 hash value.", "Arguments": ":param self: File. An instance of the File class.\n:return: str. The computed hash value as a hexadecimal string."}, "tests": ["tests/test_bundling.py::test_file_hash"], "indent": 8}
{"namespace": "alembic.operations.ops.DropTableOp.from_table", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [1333, 1335], "body_position": [1336, 1348], "dependency": {"intra_class": ["alembic.operations.ops.DropTableOp.__init__"], "intra_file": ["alembic.operations.ops.CreateTableOp", "alembic.operations.ops.CreateTableOp.from_table"], "cross_file": []}, "requirement": {"Functionality": "This function creates a DropTableOp instance based on the given table. It extracts the necessary information from the table object and uses it to initialize the DropTableOp instance.", "Arguments": ":param cls: Class. The class of the DropTableOp instance.\n:param table: Table. The table object from which the DropTableOp instance is created.\n:param _namespace_metadata: Optional MetaData. The metadata associated with the table. Defaults to None.\n:return: DropTableOp. The created DropTableOp instance."}, "tests": ["tests/test_op.py::ObjectFromToTest::test_drop_table_add_kw", "tests/test_autogen_render.py::AutogenRenderTest::test_render_drop_table", "tests/test_op.py::ObjectFromToTest::test_drop_table", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_table", "tests/test_autogen_render.py::AutogenRenderTest::test_render_drop_table_w_schema"], "indent": 8}
{"namespace": "jinja2.utils.generate_lorem_ipsum", "type": "function", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/utils.py", "signature_position": [342, 344], "body_position": [346, 394], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["jinja2.constants.LOREM_IPSUM_WORDS"]}, "requirement": {"Functionality": "This function generates Lorem Ipsum text based on the given parameters. It creates a specified number of paragraphs, each containing a random number of words within a given range. The generated text can be returned as plain text or as HTML paragraphs. It adds a comma after every 3 to 8 words, and a period after every 10 to 20 words. Every paragraph ends with a period. It also automatically capitalizes the first word of each sentence. If the text is rendered as HTML, it also adds a \"\\n\" between each paragraph. Otherwise, it adds a \"\\n\\n\" between each paragraph.", "Arguments": ":param n: int. The number of paragraphs to generate. Defaults to 5.\n:param html: bool. Whether to return the generated text as HTML paragraphs. Defaults to True.\n:param min: int. The minimum number of words in each paragraph. Defaults to 20.\n:param max: int. The maximum number of words in each paragraph. Defaults to 100.\n:return: str. The generated Lorem Ipsum text. If html is True, the text is returned as HTML paragraphs. Otherwise, it is returned as plain text."}, "tests": ["tests/test_utils.py::TestLoremIpsum::test_lorem_ipsum_max", "tests/test_utils.py::TestLoremIpsum::test_lorem_ipsum_markup", "tests/test_utils.py::TestLoremIpsum::test_lorem_ipsum_min", "tests/test_utils.py::TestLoremIpsum::test_lorem_ipsum_n", "tests/test_utils.py::TestLoremIpsum::test_lorem_ipsum_html"], "indent": 4}
{"namespace": "exodus_bundler.bundling.Bundle.add_file", "type": "method", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [718, 718], "body_position": [734, 763], "dependency": {"intra_class": ["exodus_bundler.bundling.Bundle.add_file", "exodus_bundler.bundling.Bundle.chroot", "exodus_bundler.bundling.Bundle.file_factory", "exodus_bundler.bundling.Bundle.files", "exodus_bundler.bundling.Bundle.linker_files"], "intra_file": ["exodus_bundler.bundling.logger"], "cross_file": ["exodus_bundler.errors.UnexpectedDirectoryError"]}, "requirement": {"Functionality": "This function adds an additional file to the bundle. If the file corresponds to an ELF binary, all of its dependencies will also be pulled into the bundle. The function handles both absolute and relative paths, as well as binary names in `PATH`. Directories will be included recursively for non-entry point dependencies.", "Arguments": ":param self: Bundle. An instance of the Bundle class.\n:param path: str. The path of the file to be added. It can be an absolute path, relative path, or a binary name in `PATH`.\n:param entry_point: str, optional. The name of the bundle entry point for an executable. If `True`, the executable's basename will be used.\n:return: The `File` that was added, or `None` if it was a directory that was added recursively."}, "tests": ["tests/test_bundling.py::test_file_symlink", "tests/test_bundling.py::test_bundle_add_file", "tests/test_bundling.py::test_bundle_hash", "tests/test_bundling.py::test_bundle_file_factory"], "indent": 8}
{"namespace": "pyinfra.operations.files.rsync", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/files.py", "signature_position": [670, 670], "body_position": [685, 692], "dependency": {"intra_class": [], "intra_file": ["pyinfra.operations.files.show_rsync_warning"], "cross_file": ["pyinfra.api.host.Host.check_can_rsync"]}, "requirement": {"Functionality": "This function uses the \"rsync\" command to synchronize a local directory to a remote system. It calls the \"rsync\" binary on the system to perform the synchronization.", "Arguments": ":param src: String. The source directory to sync.\n:param dest: String. The destination directory to sync to.\n:param flags: List of strings. Optional. The flags to pass to the \"rsync\" command. Defaults to [\"-ax\", \"--delete\"].\n:return: Generator. Yields an instance of the RsyncCommand class."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_failure", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_with_strict_host_key_checking_disabled_and_custom_config_file", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_with_sanitized_custom_config_file", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_with_strict_host_key_checking_disabled"], "indent": 4}
{"namespace": "pythonforandroid.prerequisites.LibtoolPrerequisite.darwin_checker", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [325, 325], "body_position": [326, 329], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "Check if the libtool formula is installed on a Darwin system. It gets the location prefix of the libtool formula and returns True if it is not None.", "Arguments": ":param self: LibtoolPrerequisite. An instance of the LibtoolPrerequisite class.\n:return: Bool. True if the libtool formula is installed, False otherwise."}, "tests": ["tests/test_prerequisites.py::TestLibtoolPrerequisite::test_darwin_checker"], "indent": 8}
{"namespace": "dash.development._py_components_generation.js_to_py_type", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/development/_py_components_generation.py", "signature_position": [655, 655], "body_position": [671, 691], "dependency": {"intra_class": [], "intra_file": ["dash.development._py_components_generation.map_js_to_py_types_flow_types", "dash.development._py_components_generation.map_js_to_py_types_prop_types"], "cross_file": []}, "requirement": {"Functionality": "This function converts JavaScript types to Python types for the component definition. It takes a type object as input and determines whether to use Flow types or PropTypes. It then maps the JavaScript types to the corresponding Python types and returns the Python type string.", "Arguments": ":param type_object: dict. The react-docgen-generated prop type dictionary.\n:param is_flow_type: bool. Indicates whether the prop uses Flow types. If False, PropTypes are used.\n:param indent_num: int. The number of indents to use for the docstring for the prop.\n:return: str. The Python type string."}, "tests": ["tests/unit/development/test_flow_metadata_conversions.py::test_docgen_to_python_args", "tests/unit/development/test_metadata_conversions.py::test_docgen_to_python_args"], "indent": 4}
{"namespace": "mingus.containers.note.Note.from_hertz", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note.py", "signature_position": [236, 236], "body_position": [242, 247], "dependency": {"intra_class": ["mingus.containers.note.Note.name", "mingus.containers.note.Note.octave"], "intra_file": [], "cross_file": ["mingus.core.notes", "mingus.core.notes.int_to_note"]}, "requirement": {"Functionality": "This function sets the Note name and pitch by calculating them from the hertz value. It uses the standard_pitch argument to set the pitch of A-4, from which the rest of the notes are calculated.\n", "Arguments": ":param self: Note, an instance of the Note class.\n:param hertz: float, the hertz value, representing the frequency of the Note.\n:param standard_pitch: float, representing the pitch of A-4. It defaults to 440 if not specified.\n:return: Note, the instance of the Note class with the name and octave set based on the hertz value.\n"}, "tests": ["tests/unit/containers/test_note.py::test_Note::test_from_hertz"], "indent": 8}
{"namespace": "asyncssh.auth_keys.SSHAuthorizedKeys.validate", "type": "method", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/auth_keys.py", "signature_position": [278, 280], "body_position": [283, 289], "dependency": {"intra_class": ["asyncssh.auth_keys.SSHAuthorizedKeys._ca_entries", "asyncssh.auth_keys.SSHAuthorizedKeys._user_entries", "asyncssh.auth_keys._SSHAuthorizedKeyEntry.match_options"], "intra_file": [], "cross_file": ["asyncssh.public_key.SSHKey"]}, "requirement": {"Functionality": "This function validates whether a public key or certificate authority (CA) is valid for authentication. It checks if the provided key matches any of the entries in the SSHAuthorizedKeys instance and if the match options (client host, client address, and certificate principals) are satisfied.", "Arguments": ":param self: SSHAuthorizedKeys. An instance of the SSHAuthorizedKeys class.\n:param key: SSHKey. The public key or CA to validate.\n:param client_host: str. The hostname of the client.\n:param client_addr: str. The IP address of the client.\n:param cert_principals: Optional[Sequence[str]]. A sequence of certificate principals.\n:param ca: bool. Whether the key is a CA or not. Defaults to False.\n:return: Optional[Mapping[str, object]]. The options associated with the matching entry, or None if no match is found."}, "tests": ["tests/test_auth_keys.py::_TestAuthorizedKeys::test_options"], "indent": 8}
{"namespace": "rest_framework.relations.PrimaryKeyRelatedField.to_representation", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/relations.py", "signature_position": [308, 308], "body_position": [309, 311], "dependency": {"intra_class": ["rest_framework.relations.PrimaryKeyRelatedField.pk_field"], "intra_file": [], "cross_file": ["rest_framework.fields.Field.to_representation", "rest_framework.authtoken.models.TokenProxy.pk"]}, "requirement": {"Functionality": "This function converts the given value into its representation for serialization. If the primary key field is not None, it uses the primary key field to convert the primary key value. Otherwise, it directly returns the primary key value.", "Arguments": ":param self: PrimaryKeyRelatedField. An instance of the PrimaryKeyRelatedField class.\n:param value: The value to be converted into its representation.\n:return: The representation of the given value."}, "tests": ["tests/test_relations.py::TestProxiedPrimaryKeyRelatedField::test_pk_representation", "tests/test_relations.py::TestPrimaryKeyRelatedField::test_pk_representation"], "indent": 8}
{"namespace": "prometheus_client.multiprocess.MultiProcessCollector.merge", "type": "method", "project_path": "System/prometheus-client", "completion_path": "System/prometheus-client/prometheus_client/multiprocess.py", "signature_position": [36, 36], "body_position": [43, 44], "dependency": {"intra_class": ["prometheus_client.multiprocess.MultiProcessCollector._accumulate_metrics", "prometheus_client.multiprocess.MultiProcessCollector._read_metrics"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Merge metrics from given mmap files. By default, histograms are accumulated, but if writing the merged data back to mmap files, use accumulate=False to avoid compound accumulation.", "Arguments": ":param files: List of str. The mmap files to merge metrics from.\n:param accumulate: Bool. Whether to accumulate histograms. Defaults to True.\n:return: The merged metrics."}, "tests": ["tests/test_multiprocess.py::TestMultiProcess::test_merge_no_accumulate"], "indent": 8}
{"namespace": "mingus.containers.note_container.NoteContainer.get_note_names", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note_container.py", "signature_position": [293, 293], "body_position": [298, 302], "dependency": {"intra_class": ["mingus.containers.note_container.NoteContainer.notes"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of unique note names from the current note container.\n", "Arguments": ":param self: NoteContainer, an instance of the NoteContainer class.\n:return: List. A list containing the unique note names from the current note container.\n"}, "tests": ["tests/unit/containers/test_note_containers.py::test_NoteContainers::test_get_note_names"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.CmakePrerequisite.darwin_installer", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [363, 363], "body_position": [364, 365], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pythonforandroid.logger.info"]}, "requirement": {"Functionality": "This function installs cmake on a macOS system using the Homebrew package manager.", "Arguments": ":param self: CmakePrerequisite. An instance of the CmakePrerequisite class.\n:return: No return values."}, "tests": ["tests/test_prerequisites.py::TestCmakePrerequisite::test_darwin_installer"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.NdarrayContainer.from_batch_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [335, 339], "body_position": [340, 341], "dependency": {"intra_class": ["bentoml._internal.runner.container.NdarrayContainer.batches_to_batch", "bentoml._internal.runner.container.NdarrayContainer.from_payload"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": []}, "requirement": {"Functionality": "This function takes a sequence of payloads and a batch dimension as input and returns a tuple containing an NdarrayContainer object and a list of integers. It first creates a list of NdarrayContainer objects for each payload in the input sequence. Then, it converts the list of batches into a single batch with the specified batch dimension.", "Arguments": ":param cls: NdarrayContainer. The class itself.\n:param payloads: Sequence of Payload objects. The payloads to be processed.\n:param batch_dim: Integer. The dimension along which the batches should be combined. Defaults to 0.\n:return: Tuple containing an NdarrayContainer object and a list of integers. The NdarrayContainer object represents the combined batch, and the list of integers represents the shape of the combined batch."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_ndarray_container"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage.sections_by_title", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [951, 954], "body_position": [961, 966], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch", "wikipediaapi.WikipediaPage._section_mapping"], "intra_file": ["wikipediaapi.WikipediaPageSection"], "cross_file": []}, "requirement": {"Functionality": "This function returns all sections of the current Wikipedia page with a given title. It first checks if the \"extracts\" data has been fetched for the page. If not, it fetches the \"extracts\" data. Then, it retrieves the sections with the given title from the section mapping. If no sections are found, an empty list is returned.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:param title: str. The title of the section to retrieve.\n:return: List[WikipediaPageSection]. A list of WikipediaPageSection objects representing the sections with the given title."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_subsections_by_title"], "indent": 8}
{"namespace": "alembic.command.ensure_version", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [721, 721], "body_position": [732, 744], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.runtime.environment.EnvironmentContext", "alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.run_env"]}, "requirement": {"Functionality": "This function ensures that the alembic version table exists. It creates the version table if it doesn't already exist.", "Arguments": ":param config: Config. An instance of the Config class.\n:param sql: Bool. Whether to use \"--sql\" mode. Defaults to False.\n:return: None."}, "tests": ["tests/test_command.py::EnureVersionTest::test_ensure_version", "tests/test_command.py::EnureVersionTest::test_ensure_version_called_twice", "tests/test_command.py::EnureVersionTest::test_sql_ensure_version"], "indent": 4}
{"namespace": "alembic.testing.fixtures.capture_engine_context_buffer", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/fixtures.py", "signature_position": [106, 106], "body_position": [107, 128], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.testing.env._sqlite_file_db", "alembic.environment.EnvironmentContext", "alembic.environment.EnvironmentContext.configure"]}, "requirement": {"Functionality": "This function captures the engine context buffer by writing the executed SQL statements into a buffer. It creates a SQLite database engine, connects to it, and sets up a listener to write the executed statements into the buffer. It also updates the input parameters and configures the environment context. Finally, it yields the buffer.", "Arguments": ":param **kw: Keyword arguments. Additional parameters that can be passed to the function.\n:return: A buffer object that contains the executed SQL statements."}, "tests": ["tests/test_command.py::StampMultipleHeadsTest::test_online_stamp_multi_rev_from_real_ancestor", "tests/test_command.py::StampMultipleHeadsTest::test_online_stamp_version_already_there", "tests/test_command.py::StampMultipleHeadsTest::test_online_stamp_multi_rev_nonsensical", "tests/test_command.py::StampMultipleHeadsTest::test_stamp_purge"], "indent": 4}
{"namespace": "sslyze.plugins.certificate_info._certificate_utils.parse_subject_alternative_name_extension", "type": "function", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/certificate_info/_certificate_utils.py", "signature_position": [25, 25], "body_position": [26, 47], "dependency": {"intra_class": [], "intra_file": ["sslyze.plugins.certificate_info._certificate_utils.SubjectAlternativeNameExtension"], "cross_file": []}, "requirement": {"Functionality": "This function parses the Subject Alternative Name (SAN) extension of a certificate. It retrieves the SAN extension from the certificate and extracts the DNS names and IP addresses from it. It then returns a SubjectAlternativeNameExtension object containing the extracted DNS names and IP addresses.", "Arguments": ":param certificate: Certificate. The certificate from which to parse the SAN extension.\n:return: SubjectAlternativeNameExtension. An object containing the extracted DNS names and IP addresses from the SAN extension."}, "tests": ["tests/plugins_tests/certificate_info/test_certificate_utils.py::TestCertificateUtils::test_parse_subject_alternative_name_extension"], "indent": 4}
{"namespace": "jinja2.environment.Template.render", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/environment.py", "signature_position": [1269, 1269], "body_position": [1279, 1301], "dependency": {"intra_class": ["jinja2.environment.Template.environment", "jinja2.environment.Template.new_context", "jinja2.environment.Template.render_async", "jinja2.environment.Template.root_render_func"], "intra_file": ["jinja2.environment.Environment.is_async", "jinja2.environment.Environment.concat", "jinja2.environment.Environment.handle_exception"], "cross_file": []}, "requirement": {"Functionality": "This method renders a template with the given context. It can also render the template asynchronously if the environment is set to async. The rendered template is returned as a string.", "Arguments": ":param self: Template. An instance of the Template class.\n:param args: Any. Variable length arguments that can be passed to a dict constructor.\n:param kwargs: Any. Variable length keyword arguments that can be passed to a dict constructor.\n:return: str. The rendered template as a string."}, "tests": ["tests/test_security.py::TestSandbox::test_attr_filter", "tests/test_security.py::TestSandbox::test_unary_operator_intercepting", "tests/test_security.py::TestStringFormat::test_basic_format_safety", "tests/test_imports.py::TestIncludes::test_context_include_with_overrides", "tests/test_security.py::TestStringFormat::test_empty_braces_format"], "indent": 8}
{"namespace": "diffprivlib.accountant.BudgetAccountant.pop_default", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/accountant.py", "signature_position": [459, 459], "body_position": [468, 470], "dependency": {"intra_class": ["diffprivlib.accountant.BudgetAccountant._default"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function pops the default BudgetAccountant instance from the class and returns it to the user.", "Arguments": ":param: No input parameters.\n:return: BudgetAccountant. The existing default BudgetAccountant instance."}, "tests": ["tests/test_BudgetAccountant.py::TestBudgetAccountant::test_default", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_pop_default", "tests/tools/test_histogram.py::TestHistogram::test_default_accountant", "tests/tools/test_histogramdd.py::TestHistogramdd::test_default_accountant"], "indent": 8}
{"namespace": "pyramid.registry.Registry.registerHandler", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [95, 95], "body_position": [96, 98], "dependency": {"intra_class": ["pyramid.registry.Registry.has_listeners"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function registers a handler in the Registry instance. It also sets the flag of the Registry instance to indicate that it has listeners.", "Arguments": ":param self: Registry. An instance of the Registry class.\n:param *arg: Variable length arguments. The arguments for the superclass method.\n:param **kw: Keyword arguments. The keyword arguments for the superclass method.\n:return: The result of the superclass method."}, "tests": ["tests/test_router.py::TestRouter::test_call_newrequest_evllist_exc_can_be_caught_by_exceptionview", "tests/test_registry.py::TestRegistry::test_registerHandler_and_notify", "tests/test_router.py::TestRouter::test_call_route_matches_doesnt_overwrite_subscriber_iface"], "indent": 8}
{"namespace": "chatette.cli.interactive_commands.command_strategy.CommandStrategy.find_redirection_file_path", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/cli/interactive_commands/command_strategy.py", "signature_position": [95, 95], "body_position": [108, 119], "dependency": {"intra_class": [], "intra_file": ["chatette.cli.interactive_commands.command_strategy.REDIRECTION_APPEND_SYM", "chatette.cli.interactive_commands.command_strategy.REDIRECTION_SYM"], "cross_file": ["chatette.cli.terminal_writer.RedirectionType", "chatette.cli.terminal_writer.RedirectionType.append", "chatette.cli.terminal_writer.RedirectionType.quiet", "chatette.cli.terminal_writer.RedirectionType.truncate"]}, "requirement": {"Functionality": "This function finds the path of the file to which the output of a command should be redirected. It checks the tokens list to determine the type of redirection and returns a 2-tuple containing the redirection type and the file path. If no redirection is found, it returns None. If the redirection should be done to nowhere, it returns a 2-tuple with the redirection type set to \"quiet\" and the file path set to None.", "Arguments": ":param tokens: List of strings. The tokens representing the command and redirection symbols.\n:return: 2-tuple. The first element is the redirection type, an enumeration item of type \"RedirectionType\". The second element is the file path to which the output should be redirected. Returns None if no redirection is found. Returns (RedirectionType.quiet, None) if the redirection should be done to nowhere."}, "tests": ["tests/unit-testing/cli/interactive_commands/test_command_strategy.py::TestFindRedirectionFilePath::test_quiet", "tests/unit-testing/cli/interactive_commands/test_command_strategy.py::TestFindRedirectionFilePath::test_append_redirection", "tests/unit-testing/cli/interactive_commands/test_command_strategy.py::TestFindRedirectionFilePath::test_truncate_redirection"], "indent": 8}
{"namespace": "pyt.vulnerabilities.vulnerabilities.label_contains", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/vulnerabilities/vulnerabilities.py", "signature_position": [151, 154], "body_position": [165, 167], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyt.vulnerabilities.vulnerability_helper.TriggerNode", "pyt.vulnerabilities.trigger_definitions_parser.Sink.trigger_word"]}, "requirement": {"Functionality": "This function checks if a given node contains any of the trigger words provided. It iterates through the list of trigger words and checks if each trigger word is present in the label of the node. If a trigger word is found, it yields a TriggerNode object.", "Arguments": ":param node: Node. The CFG node to check.\n:param triggers: List of Union[Sink, Source]. The list of trigger words to look for.\n:return: Iterable of TriggerNodes. It can contain multiple TriggerNodes if multiple trigger words are found in the node's label."}, "tests": ["tests/vulnerabilities/vulnerabilities_test.py::EngineTest::test_label_contains"], "indent": 4}
{"namespace": "benedict.dicts.keypath.keypath_util._split_key_indexes", "type": "function", "project_path": "Text-Processing/python-benedict", "completion_path": "Text-Processing/python-benedict/benedict/dicts/keypath/keypath_util.py", "signature_position": [37, 37], "body_position": [42, 55], "dependency": {"intra_class": [], "intra_file": ["benedict.dicts.keypath.keypath_util.KEY_INDEX_RE"], "cross_file": []}, "requirement": {"Functionality": "This function splits key indexes in a string and returns a list of the split indexes. It checks if the key contains square brackets and ends with a closing bracket. If it does, it extracts the indexes and adds them to the list. If not, it simply returns the key as a list with a single element.", "Arguments": ":param key: String. The key containing indexes to be split.\n:return: List. A list of split indexes."}, "tests": ["tests/dicts/keypath/test_keypath_util.py::keypath_util_test_case::test_split_key_indexes_with_invalid_indexes", "tests/dicts/keypath/test_keypath_util.py::keypath_util_test_case::test_split_key_indexes_with_valid_indexes"], "indent": 4}
{"namespace": "boto.support.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/support/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.regioninfo.connect", "boto.support.layer1.SupportConnection"]}, "requirement": {"Functionality": "Connect to a specific region using the SupportConnection class from the boto library. It creates a connection to the \"support\" service in the specified region.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: SupportConnection. The connection object to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestSupportConnection::test_connect_to_region"], "indent": 4}
{"namespace": "imapclient.imap_utf7.decode", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imap_utf7.py", "signature_position": [62, 62], "body_position": [69, 98], "dependency": {"intra_class": [], "intra_file": ["imapclient.imap_utf7.AMPERSAND_ORD", "imapclient.imap_utf7.DASH_ORD", "imapclient.imap_utf7.base64_utf7_decode"], "cross_file": []}, "requirement": {"Functionality": "This function decodes a folder name from IMAP modified UTF-7 encoding to Unicode. It takes a string or bytes as input and always returns a Unicode string. If the input is not of type bytes or str, it is returned unchanged.", "Arguments": ":param s: Union[bytes, str]. The input string or bytes to be decoded.\n:return: str. The decoded folder name in Unicode."}, "tests": ["tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_printable_singletons", "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_decode"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.folder_status", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1002, 1002], "body_position": [1012, 1022], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._normalise_folder"], "intra_file": ["imapclient.imapclient.as_pairs", "imapclient.imapclient.normalise_text_list"], "cross_file": ["imapclient.response_parser.parse_response"]}, "requirement": {"Functionality": "This function returns the status of a specified folder in an IMAPClient instance. It queries the specified status items \"(\"MESSAGES\", \"RECENT\", \"UIDNEXT\", \"UIDVALIDITY\", \"UNSEEN\")\" for the folder and returns a dictionary with keys matching the queried items.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param folder: String. The name of the folder to query the status for.\n:param what: List of strings. A sequence of status items to query. It defaults to ['MESSAGES', 'RECENT', 'UIDNEXT', 'UIDVALIDITY', 'UNSEEN'] if not specified.\n:return: Dictionary. A dictionary of the status items for the folder with keys matching the queried items."}, "tests": ["tests/test_folder_status.py::TestFolderStatus::test_basic", "tests/test_folder_status.py::TestFolderStatus::test_literal", "tests/test_folder_status.py::TestFolderStatus::test_extra_response"], "indent": 8}
{"namespace": "pyramid.path.Resolver.get_package_name", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/path.py", "signature_position": [106, 106], "body_position": [107, 111], "dependency": {"intra_class": ["pyramid.path.Resolver.package"], "intra_file": ["pyramid.path.CALLER_PACKAGE", "pyramid.path.caller_package"], "cross_file": []}, "requirement": {"Functionality": "This function returns the name of the package based on the package in a Resolver instance. If the package value is set to CALLER_PACKAGE, it retrieves the name of the caller package. Otherwise, it retrieves the name of the package specified in the package of the Resolver instance.", "Arguments": ":param self: Resolver. An instance of the Resolver class.\n:return: String. The name of the package."}, "tests": ["tests/test_path.py::TestResolver::test_get_package_name_caller_package", "tests/test_path.py::TestResolver::test_get_package_name_string"], "indent": 8}
{"namespace": "bentoml._internal.models.model.Model.create", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/models/model.py", "signature_position": [138, 150], "body_position": [174, 198], "dependency": {"intra_class": ["bentoml._internal.models.model.Model.__init__"], "intra_file": ["bentoml._internal.models.model.ModelInfo", "bentoml._internal.models.model.ModelInfo.__init__", "bentoml._internal.models.model.ModelOptions"], "cross_file": ["bentoml._internal.tag.Tag", "bentoml._internal.tag.Tag.from_taglike", "bentoml._internal.tag.Tag.make_new_version", "bentoml._internal.tag.Tag.name", "bentoml._internal.tag.Tag.version"]}, "requirement": {"Functionality": "This function creates a new instance of the Model class and saves it to the model store. It takes various input parameters to configure the model instance and its associated metadata.", "Arguments": ":param cls: Type[Model]. The class object of the Model class.\n:param name: Union[Tag, str]. The name of the model in the target model store. If a Tag object is provided, the version will be automatically generated.\n:param module: str. The import path of the module used for saving/loading this model.\n:param api_version: str. The version of the API associated with this model.\n:param signatures: ModelSignaturesType. The signatures of the model, specifying the input and output types.\n:param labels: Optional[Dict[str, str]]. User-defined labels for managing models.\n:param options: Optional[ModelOptions]. Default options for loading this model, defined by the runner implementation.\n:param custom_objects: Optional[Dict[str, Any]]. User-defined additional Python objects to be saved alongside the model.\n:param metadata: Optional[Dict[str, Any]]. User-defined metadata for storing model training context information or model evaluation metrics.\n:param context: ModelContext. The environment context managed by BentoML for loading the model.\n:return: Model. The created Model instance in the temporary filesystem."}, "tests": ["tests/unit/_internal/models/test_model.py::test_model_creationtime", "tests/unit/_internal/models/test_model.py::test_model_version", "tests/unit/_internal/models/test_model.py::test_model_equal"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.unselect_folder", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [824, 824], "body_position": [832, 835], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._imap"], "intra_file": ["imapclient.imapclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function unselects the current folder in the IMAPClient instance and releases any associated resources. It sends the \"UNSELECT\" command to the server and returns the UNSELECT response string.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:return: String. The UNSELECT response string returned by the server."}, "tests": ["tests/test_imapclient.py::TestSelectFolder::test_unselect"], "indent": 8}
{"namespace": "mrjob.compat.jobconf_from_dict", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/compat.py", "signature_position": [599, 599], "body_position": [612, 620], "dependency": {"intra_class": [], "intra_file": ["mrjob.compat._JOBCONF_MAP"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the value of a jobconf variable from a given dictionary. It first checks if the variable exists in the dictionary. If not, it tries different variants of the variable name based on a mapping dictionary before giving up and returning the default value.", "Arguments": ":param jobconf: dict. The jobconf dictionary containing the variables.\n:param name: str. The name of the jobconf variable.\n:param default: Any. The fallback value to return if the variable is not found. Defaults to None.\n:return: Any. The value of the jobconf variable if found, otherwise the default value."}, "tests": ["tests/test_compat.py::JobConfFromDictTestCase::test_get_old_hadoop_jobconf", "tests/test_compat.py::JobConfFromDictTestCase::test_get_missing_jobconf_not_in_table", "tests/test_compat.py::JobConfFromDictTestCase::test_default", "tests/test_compat.py::JobConfFromDictTestCase::test_get_new_hadoop_jobconf"], "indent": 4}
{"namespace": "pyramid.scripts.proutes.PRoutesCommand._get_mapper", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/scripts/proutes.py", "signature_position": [306, 306], "body_position": [307, 310], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyramid.config.Configurator", "pyramid.config.routes.RoutesConfiguratorMixin.get_routes_mapper"]}, "requirement": {"Functionality": "This function returns the routes mapper object associated with the given registry.", "Arguments": ":param self: PRoutesCommand. An instance of the PRoutesCommand class.\n:param registry: The registry object.\n:return: The routes mapper object associated with the given registry."}, "tests": ["tests/test_scripts/test_proutes.py::TestPRoutesCommand::test__get_mapper"], "indent": 8}
{"namespace": "mssqlcli.packages.parseutils.tables.extract_tables", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/packages/parseutils/tables.py", "signature_position": [121, 121], "body_position": [127, 146], "dependency": {"intra_class": [], "intra_file": ["mssqlcli.packages.parseutils.tables.extract_from_part", "mssqlcli.packages.parseutils.tables.extract_table_identifiers"], "cross_file": []}, "requirement": {"Functionality": "This function extracts the table names from an SQL statement. It uses the sqlparse library to parse the SQL statement and then extracts the table names from the parsed result.", "Arguments": ":param sql: String. The SQL statement to extract table names from.\n:return: Tuple of TableReference namedtuples. The extracted table names from the SQL statement."}, "tests": ["tests/parseutils/test_parseutils.py::test_simple_select_with_cols_multiple_qualified_tables", "tests/parseutils/test_parseutils.py::test_simple_function_as_table", "tests/parseutils/test_parseutils.py::test_incomplete_join_clause", "tests/parseutils/test_parseutils.py::test_complex_table_and_function", "tests/parseutils/test_parseutils.py::test_simple_schema_qualified_function_as_table"], "indent": 4}
{"namespace": "mopidy.internal.validation.check_instance", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/validation.py", "signature_position": [64, 64], "body_position": [65, 66], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mopidy.exceptions.ValidationError", "mopidy.exceptions"]}, "requirement": {"Functionality": "Check if the given argument is an instance of a specified class. If not, raise a validation error with a customizable error message.", "Arguments": ":param arg: Any. The argument to be checked.\n:param cls: Class. The class to check against.\n:param msg: String. The error message to be displayed if the argument is not an instance of the class. It defaults to \"Expected a {name} instance, not {arg!r}\".\n:return: No return values."}, "tests": ["tests/internal/test_validation.py::test_check_instance_error_message", "tests/internal/test_validation.py::test_check_instance_with_invalid_values"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.get_gmail_labels", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1274, 1274], "body_position": [1284, 1286], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._filter_fetch_dict", "imapclient.imapclient.IMAPClient.fetch"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the label set for each message in the currently selected folder. It fetches the X-GM-LABELS attribute for the given messages from the IMAP server and filters the response to get the label information. It then decodes the labels using UTF-7 encoding and returns a dictionary with message IDs as keys and label sets as values.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param messages: List of bytes. The messages for which to retrieve the labels.\n:return: Dictionary. A dictionary mapping message IDs to label sets."}, "tests": ["tests/test_store.py::TestGmailLabels::test_get"], "indent": 8}
{"namespace": "datasette.utils.validate_sql_select", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [256, 256], "body_position": [257, 265], "dependency": {"intra_class": [], "intra_file": ["datasette.utils.InvalidSql", "datasette.utils.allowed_sql_res", "datasette.utils.disallawed_sql_res"], "cross_file": []}, "requirement": {"Functionality": "This function validates a SQL SELECT statement. It removes any comments from the SQL statement, converts it to lowercase, and checks if it matches any of the allowed SQL patterns. If it does not match any allowed patterns, it raises an invalid sql exception. It also checks if the SQL statement matches any of the disallowed SQL patterns, and if it does, it raises an invalid sql exception with the corresponding error message.", "Arguments": ":param sql: String. The SQL statement to be validated.\n:return: No return value."}, "tests": ["tests/test_utils.py::test_validate_sql_select_bad"], "indent": 4}
{"namespace": "boto.s3.website.RoutingRule.when", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/website.py", "signature_position": [212, 212], "body_position": [213, 214], "dependency": {"intra_class": ["boto.s3.website.RoutingRule.__init__"], "intra_file": ["boto.s3.website.Condition", "boto.s3.website.Condition.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function is a class method that creates a new instance of the RoutingRule class with a specified condition. It sets the key prefix and HTTP error code for the condition and returns the new instance.", "Arguments": ":param cls: The class object.\n:param key_prefix: Optional. The key prefix for the condition.\n:param http_error_code: Optional. The HTTP error code for the condition.\n:return: The new instance of the RoutingRule class with the specified condition."}, "tests": ["tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_builders"], "indent": 8}
{"namespace": "mingus.containers.note_container.NoteContainer.from_progression_shorthand", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note_container.py", "signature_position": [155, 155], "body_position": [165, 174], "dependency": {"intra_class": ["mingus.containers.note_container.NoteContainer.add_notes", "mingus.containers.note_container.NoteContainer.empty"], "intra_file": [], "cross_file": ["mingus.core.progressions", "mingus.core.progressions.to_chords"]}, "requirement": {"Functionality": "This function clears the NoteContainer and adds notes to it based on the given progression shorthand.\n", "Arguments": ":param self: NoteContainer. An instance of the NoteContainer class.\n:param shorthand: str. The progression shorthand describing the notes to be added.\n:param key: str. The key to be used for the progression shorthand. It defaults to \"C\" if not specified.\n:return: NoteContainer. The modified instance of the NoteContainer.\n"}, "tests": ["tests/unit/containers/test_note_containers.py::test_NoteContainers::test_from_progression_shorthand"], "indent": 8}
{"namespace": "mrjob.logs.errors._merge_and_sort_errors", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/errors.py", "signature_position": [101, 101], "body_position": [107, 136], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.logs.ids._time_sort_key"]}, "requirement": {"Functionality": "This function merges errors from one or more lists of errors and returns them sorted by recency.\nThis function first initializes a dictionary to save errors. Then, it iterates through each error in the given list of errors and merge them by container id. If an error does not have container id, it generates a key based on the error's time. Finally it uses a custom key sort function to prioritize task errors and sort the errors based on their keys.\n", "Arguments": ":param errors: List of dictionaries. One or more lists of errors to be merged and sorted.\n:param attempt_to_container_id: Dictionary. A dictionary mapping attempt_id to container_id.\n:return: List of dictionaries. The merged and sorted list of errors.\n"}, "tests": ["tests/logs/test_errors.py::MergeAndSortErrorsTestCase::test_merge_errors", "tests/logs/test_errors.py::MergeAndSortErrorsTestCase::test_can_merge_with_incomplete_ids", "tests/logs/test_errors.py::MergeAndSortErrorsTestCase::test_attempt_to_container_id", "tests/logs/test_errors.py::MergeAndSortErrorsTestCase::test_single_error", "tests/logs/test_errors.py::MergeAndSortErrorsTestCase::test_empty"], "indent": 4}
{"namespace": "pyramid.testing.DummySession.get_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [265, 265], "body_position": [266, 269], "dependency": {"intra_class": ["pyramid.testing.DummySession.new_csrf_token"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the CSRF token from the session. If the token is not found in the session, a new CSRF token is generated and returned.", "Arguments": ":param self: DummySession. An instance of the DummySession class.\n:return: The CSRF token."}, "tests": ["tests/test_testing.py::TestDummySession::test_get_csrf_token", "tests/test_csrf.py::Test_check_csrf_token::test_success_header", "tests/test_testing.py::TestDummySession::test_get_csrf_token_generates_token", "tests/test_csrf.py::Test_check_csrf_token::test_success_default_header", "tests/test_csrf.py::Test_check_csrf_token_without_defaults_configured::test_success_token"], "indent": 8}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.close", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [436, 436], "body_position": [440, 443], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.stream"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Close the stream associated with the JsonRpcReader instance. Raise an AttributeError if failed.", "Arguments": ":param self: JsonRpcReader. An instance of the JsonRpcReader class.\n:return: No return values."}, "tests": ["tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_nested_request", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_basic_response", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_response_multiple_headers", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_incorrect_header_formats", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_basic_request"], "indent": 8}
{"namespace": "boto.glacier.utils.minimum_part_size", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/glacier/utils.py", "signature_position": [34, 34], "body_position": [59, 71], "dependency": {"intra_class": [], "intra_file": ["boto.glacier.utils.DEFAULT_PART_SIZE", "boto.glacier.utils.MAXIMUM_NUMBER_OF_PARTS", "boto.glacier.utils._MEGABYTE"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the minimum part size needed for a multipart upload in Glacier. It checks if the default part size is sufficient for the given file size. If not, it calculates the smallest part size that can accommodate the file size. If the file size exceeds the maximum allowed archive size (10,000 * 4GB), a ValueError is raised.", "Arguments": ":param size_in_bytes: Integer. The size of the file in bytes.\n:param default_part_size: Integer. The default part size in bytes. Defaults to DEFAULT_PART_SIZE.\n:return: Integer. The minimum part size needed for the multipart upload."}, "tests": ["tests/unit/glacier/test_utils.py::TestPartSizeCalculations::test_file_size_too_large", "tests/unit/glacier/test_utils.py::TestPartSizeCalculations::test_under_the_maximum_value", "tests/unit/glacier/test_utils.py::TestPartSizeCalculations::test_small_values_still_use_default_part_size", "tests/unit/glacier/test_utils.py::TestPartSizeCalculations::test_gigabyte_size", "tests/unit/glacier/test_utils.py::TestPartSizeCalculations::test_default_part_size_can_be_specified"], "indent": 4}
{"namespace": "rows.fields.DateField.serialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [360, 360], "body_position": [361, 364], "dependency": {"intra_class": ["rows.fields.DateField.OUTPUT_FORMAT"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function serializes a given date value into a string format. If the value is None, it returns an empty string. Otherwise, it converts the date value into a string using the specified output format.", "Arguments": ":param cls: Class. The DateField class.\n:param value: Date. The date value to be serialized.\n:param *args: Additional positional arguments.\n:param **kwargs: Additional keyword arguments.\n:return: String. The serialized date value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_DateField"], "indent": 8}
{"namespace": "boto.cloudsearchdomain.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudsearchdomain/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudsearchdomain.layer1.CloudSearchDomainConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the cloud search domain. It creates a connection to the cloud search domain in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: CloudSearchDomainConnection. The connection to the cloud search domain in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCloudsearchDomainConnection::test_connect_to_region"], "indent": 4}
{"namespace": "boltons.listutils.BarrelList.pop", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/listutils.py", "signature_position": [162, 162], "body_position": [163, 177], "dependency": {"intra_class": ["boltons.listutils.BarrelList._balance_list", "boltons.listutils.BarrelList._translate_index", "boltons.listutils.BarrelList.lists"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Remove and return an item from the BarrelList based on the specified indexes.\n", "Arguments": ":param self: BarrelList, an instance of BarrelList class.\n:param *a: Tuple, the index of the item to be popped. Default is an empty tuple.\n:return: The item that is removed and returned from the BarrelList. No return values if the list is empty or the index is invalid.\n"}, "tests": ["tests/test_listutils.py::test_barrel_list"], "indent": 8}
{"namespace": "bentoml._internal.configuration.helpers.expand_env_var_in_values", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/configuration/helpers.py", "signature_position": [186, 186], "body_position": [187, 193], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.configuration.helpers.expand_env_var", "bentoml._internal.configuration.helpers.expand_env_var_in_values"], "cross_file": []}, "requirement": {"Functionality": "This function expands environment variables in the values of a given dictionary. It iterates through each key-value pair in the dictionary and checks the type of the value including \"mutable mapping\", \"string\" and \"sequence\". Then it calls the corresponding functions.", "Arguments": ":param d: MutableMapping[str, Any]. A dictionary-like object with string keys and arbitrary values.\n:return: No return values."}, "tests": ["tests/unit/_internal/configuration/test_helpers.py::test_expand_env_in_values"], "indent": 4}
{"namespace": "telethon.utils.get_inner_text", "type": "function", "project_path": "Communications/Telethon", "completion_path": "Communications/Telethon/telethon/utils.py", "signature_position": [937, 937], "body_position": [946, 953], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["telethon.helpers.add_surrogate", "telethon.helpers.del_surrogate"]}, "requirement": {"Functionality": "This function takes in a text and a list of entities and returns the inner text that is surrounded by the given entities. It iterates through each entity, extracts the corresponding inner text, and appends it to the result list.", "Arguments": ":param text: String. The original text.\n:param entities: List of entities. The entity or entities that must be matched.\n:return: List of strings. A list of the text surrounded by the entities."}, "tests": ["tests/telethon/test_helpers.py::test_strip_text"], "indent": 4}
{"namespace": "datasette.facets.ArrayFacet.suggest", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/facets.py", "signature_position": [303, 303], "body_position": [304, 368], "dependency": {"intra_class": [], "intra_file": ["datasette.facets.Facet.database", "datasette.facets.Facet.ds", "datasette.facets.Facet.get_columns", "datasette.facets.Facet.get_configs", "datasette.facets.Facet.params", "datasette.facets.Facet.request", "datasette.facets.Facet.sql"], "cross_file": ["datasette.database.QueryInterrupted", "datasette.utils.escape_sqlite", "datasette.utils.path_with_added_args", "datasette.app.Datasette.absolute_url", "datasette.app.Datasette.execute", "datasette.app.Datasette.setting", "datasette.app.Datasette.urls", "datasette.url_builder.Urls.path"]}, "requirement": {"Functionality": "This function suggests array facets based on the given SQL query and parameters. It retrieves the columns from the query, checks if each column is already enabled as a facet, and then checks if every value in the column is either null or a JSON array. If these conditions are met, it further checks that the first 100 arrays in the column contain only strings. If all these conditions are satisfied, it adds the column as a suggested array facet to the list of suggested facets.", "Arguments": ":param self: ArrayFacet. An instance of the ArrayFacet class.\n:return: List of dictionaries. A list of suggested array facets, where each dictionary contains the name of the facet, its type, and a toggle URL."}, "tests": ["tests/test_facets.py::test_array_facet_suggest_not_if_all_empty_arrays", "tests/test_facets.py::test_array_facet_suggest"], "indent": 8}
{"namespace": "falcon.cmd.inspect_app.route_main", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/cmd/inspect_app.py", "signature_position": [89, 89], "body_position": [90, 94], "dependency": {"intra_class": [], "intra_file": ["falcon.cmd.inspect_app.main"], "cross_file": []}, "requirement": {"Functionality": "This function is the main entry point for routing. It prints two deprecation messages ('The \"falcon-print-routes\" command is deprecated. ', 'Please use \"falcon-inspect-app\"') and then calls the main function.", "Arguments": ":param: No input parameters.\n:return: No return values."}, "tests": ["tests/test_cmd_inspect_app.py::test_route_main"], "indent": 4}
{"namespace": "mssqlcli.localized_strings.translation", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/localized_strings.py", "signature_position": [10, 10], "body_position": [11, 12], "dependency": {"intra_class": [], "intra_file": ["mssqlcli.localized_strings.DOMAIN", "mssqlcli.localized_strings.LANGUAGES", "mssqlcli.localized_strings.LOCALE_DIR"], "cross_file": []}, "requirement": {"Functionality": "This function creates a translation object based on the given parameters. It uses the gettext module to load translations from the specified domain and localedir for the specified languages. If languages is not provided, it uses the default LANGUAGES.", "Arguments": ":param domain: String. The translation domain to load translations from. It defaults to DOMAIN if not specified.\n:param localedir: String. The directory where translation files are located. It defaults to LOCALE_DIR if not specified.\n:param languages: List of strings. The languages for which translations should be loaded. It defaults to LANGUAGES if not specified.\n:return: Translation object. The created translation object."}, "tests": ["tests/test_localization.py::LocalizationTests::test_product"], "indent": 4}
{"namespace": "jc.cli.JcCli.yaml_out", "type": "method", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/cli.py", "signature_position": [340, 340], "body_position": [346, 380], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["jc.utils.warning_message", "jc.utils"]}, "requirement": {"Functionality": "This function returns a YAML formatted string. If the ruamel.yaml library is installed, it uses it to format the string with color codes. If the library is not installed, it falls back to JSON formatting with a warning message.", "Arguments": ":param self: JcCli. An instance of the JcCli class.\n:return: str. The YAML formatted string."}, "tests": ["tests/test_jc_cli.py::MyTests::test_cli_yaml_out", "tests/test_jc_cli.py::MyTests::test_cli_yaml_out_mono"], "indent": 8}
{"namespace": "kinto.core.views.batch.BatchPayloadSchema.deserialize", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/views/batch.py", "signature_position": [59, 59], "body_position": [61, 69], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["kinto.core.utils.merge_dicts"]}, "requirement": {"Functionality": "This function is a method of the BatchPayloadSchema class. It deserializes the received data and merges the defaults with the requests. It then returns the deserialized data.", "Arguments": ":param self: BatchPayloadSchema. An instance of the BatchPayloadSchema class.\n:param cstruct: dict. The data to be deserialized. Defaults to colander.null.\n:return: The deserialized data after merging the defaults with the requests."}, "tests": ["tests/core/test_views_batch.py::BatchSchemaTest::test_defaults_path_is_applied_to_requests", "tests/core/test_views_batch.py::BatchSchemaTest::test_body_is_an_arbitrary_mapping", "tests/core/test_views_batch.py::BatchSchemaTest::test_request_headers_are_preserved", "tests/core/test_views_batch.py::BatchSchemaTest::test_defaults_body_is_applied_to_requests", "tests/core/test_views_batch.py::BatchSchemaTest::test_defaults_values_do_not_overwrite_requests_values"], "indent": 8}
{"namespace": "datasette.app.Datasette.ensure_permissions", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [691, 695], "body_position": [701, 724], "dependency": {"intra_class": ["datasette.app.Datasette.permission_allowed"], "intra_file": [], "cross_file": ["datasette.utils.asgi.Forbidden"]}, "requirement": {"Functionality": "This function ensures that the given actor has the required permissions to perform certain actions on specified resources. It iterates through the list of permissions and checks if each permission is allowed for the actor. If any of the checks fail, it raises a forbidden exception.", "Arguments": ":param self: Datasette. An instance of the Datasette class.\n:param actor: Dict. The actor for whom the permissions are being checked. It can be None or a dictionary.\n:param permissions: Sequence. A sequence of permissions to be checked. Each permission can be a string representing an action or a tuple/list of two items representing an action and a resource.\n:return: No return values."}, "tests": ["tests/test_internals_datasette.py::test_datasette_ensure_permissions_check_visibility"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.describe", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [332, 332], "body_position": [355, 379], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._introspect_global_indexes", "boto.dynamodb2.table.Table._introspect_indexes", "boto.dynamodb2.table.Table._introspect_schema", "boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.global_indexes", "boto.dynamodb2.table.Table.indexes", "boto.dynamodb2.table.Table.schema", "boto.dynamodb2.table.Table.table_name", "boto.dynamodb2.table.Table.throughput"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.describe_table"]}, "requirement": {"Functionality": "This function describes the current structure of a table in DynamoDB. It retrieves information about the table's schema, indexes, throughput, and other details from DynamoDB. The function also updates the corresponding attributes of the Table instance. The function returns the full raw data structure from DynamoDB.", "Arguments": ":param self: Table. An instance of the Table class.\n:return: The full raw data structure of the table from DynamoDB."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_describe"], "indent": 8}
{"namespace": "kinto.core.utils.find_nested_value", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [197, 197], "body_position": [204, 224], "dependency": {"intra_class": [], "intra_file": ["kinto.core.utils.find_nested_value"], "cross_file": []}, "requirement": {"Functionality": "This function finds a nested value in a dictionary based on a given dotted path key string. It first checks if the path itself exists as a key in the dictionary and returns the corresponding value if found. If not, it splits the path into parts and creates a list of all possible root keys. It then iterates through the list in reverse order and checks if each root key exists in the dictionary. The longest root key that exists is considered as the actual root key. If no valid root key is found or if the value corresponding to the root key is not a dictionary, it returns the default value. Otherwise, it extracts the subpath from the original path by removing the root key and recursively calls the function with the new subpath and the value corresponding to the root key.", "Arguments": ":param d: dict. The dictionary to retrieve the nested value from.\n:param path: str. The path to the nested value in dot notation.\n:param default: Any. The value to return if the nested value is not found. Defaults to None.\n:return: Any. The nested value if found, or the default value if not found."}, "tests": ["tests/core/test_utils.py::FindNestedValueTest::test_find_deeply_nested_value", "tests/core/test_utils.py::FindNestedValueTest::test_find_flat_value", "tests/core/test_utils.py::FindNestedValueTest::test_find_disambiguated_dotted_path_values", "tests/core/test_utils.py::FindNestedValueTest::test_find_nested_value", "tests/core/test_utils.py::FindNestedValueTest::test_fallback_default_value"], "indent": 4}
{"namespace": "alembic.operations.ops.DropConstraintOp.from_constraint", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [157, 157], "body_position": [158, 174], "dependency": {"intra_class": ["alembic.operations.ops.DropConstraintOp.__init__"], "intra_file": ["alembic.operations.ops.AddConstraintOp", "alembic.operations.ops.AddConstraintOp.from_constraint"], "cross_file": ["alembic.util.sqla_compat", "alembic.util.sqla_compat._table_for_constraint", "alembic.util.sqla_compat.constraint_name_or_none"]}, "requirement": {"Functionality": "This function creates a DropConstraintOp instance based on the given constraint. It determines the type of constraint and creates the instance with the corresponding parameters.", "Arguments": ":param cls: type. The DropConstraintOp class.\n:param constraint: Constraint. The constraint object to create the DropConstraintOp instance from.\n:return: DropConstraintOp. The created DropConstraintOp instance."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_drop_fk_constraint", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_check", "tests/test_postgresql.py::PostgresqlAutogenRenderTest::test_drop_exclude_constraint", "tests/test_op.py::ObjectFromToTest::test_drop_unique_constraint_change_name", "tests/test_autogen_render.py::AutogenRenderTest::test_drop_unique_constraint_schema"], "indent": 8}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_response", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [261, 261], "body_position": [270, 296], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.needs_more_data", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_next_chunk", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_offset", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_state", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.trim_buffer_and_resize", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.try_read_content", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.try_read_headers"], "intra_file": ["mssqlcli.jsonrpc.jsonrpcclient.ReadState", "mssqlcli.jsonrpc.jsonrpcclient.ReadState.Content", "mssqlcli.jsonrpc.jsonrpcclient.ReadState.Header", "mssqlcli.jsonrpc.jsonrpcclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function reads a JSON RPC message from a buffer. It iterates through a loop, attempting to read the header and content until it successfully retrieves both. After that, it trims the buffer, parses the content as JSON, and returns the resulting object. If any step fails, it logs the error and raises a ValueError.", "Arguments": ":param self: JsonRpcReader. An instance of the JsonRpcReader class.\n:return: JSON object. The deserialized JSON object read from the buffer."}, "tests": ["tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_nested_request", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_basic_response", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_stream_closes_during_read_and_write", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_max_buffer_resize", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_trigger_buffer_resize"], "indent": 8}
{"namespace": "pycoin.crack.bip32.crack_bip32", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/crack/bip32.py", "signature_position": [22, 22], "body_position": [23, 29], "dependency": {"intra_class": [], "intra_file": ["pycoin.crack.bip32.ascend_bip32"], "cross_file": ["pycoin.key.BIP32Node.BIP32Node.subkey_for_path"]}, "requirement": {"Functionality": "This function cracks a BIP32 public node by iterating through a given path and updating the secret exponent. It returns a new BIP32 public node with the updated secret exponent.", "Arguments": ":param bip32_pub_node: BIP32PublicNode. The BIP32 public node to crack.\n:param secret_exponent: int. The secret exponent to update.\n:param path: str. The path to iterate through.\n:return: BIP32PublicNode. The new BIP32 public node with the updated secret exponent."}, "tests": ["tests/crack_bip32_test.py::CrackBIP32Test::test_crack_bip32"], "indent": 4}
{"namespace": "rows.fields.JSONField.deserialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [470, 470], "body_position": [471, 475], "dependency": {"intra_class": ["rows.fields.JSONField.TYPE"], "intra_file": ["rows.fields.Field", "rows.fields.Field.deserialize"], "cross_file": []}, "requirement": {"Functionality": "Deserialize a JSONField value. It first calls the parent class's deserialize method to perform basic deserialization. Then, it checks if the deserialized value is None or already an instance of required type. If so, it returns the value as is. Otherwise, it convert the value into a Python object.", "Arguments": ":param cls: Class. The JSONField class itself.\n:param value: Any. The value to be deserialized.\n:param *args: Any. Additional positional arguments.\n:param **kwargs: Any. Additional keyword arguments.\n:return: Any. The deserialized value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_JSONField"], "indent": 8}
{"namespace": "boto.dynamodb2.fields.BaseIndexField.schema", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/fields.py", "signature_position": [126, 126], "body_position": [147, 158], "dependency": {"intra_class": ["boto.dynamodb2.fields.BaseIndexField.name", "boto.dynamodb2.fields.BaseIndexField.parts"], "intra_file": ["boto.dynamodb2.fields.BaseSchemaField.schema"], "cross_file": []}, "requirement": {"Functionality": "This function returns the schema structure that DynamoDB expects for the given index field. It constructs the schema by iterating over the parts of the index field and appending their schemas to the key schema.", "Arguments": ":param self: BaseIndexField. An instance of the BaseIndexField class.\n:return: Dict. The schema structure that DynamoDB expects for the index field. The structure includes the index name, key schema, and projection type."}, "tests": ["tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_all_index", "tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_keys_only_index"], "indent": 8}
{"namespace": "twtxt.config.Config.create_config", "type": "method", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/config.py", "signature_position": [63, 63], "body_position": [73, 93], "dependency": {"intra_class": ["twtxt.config.Config.__init__", "twtxt.config.Config.write_config"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a new configuration file at the specified location with the given parameters. It creates a new configuration file using the configparser module and sets the values for various sections and options based on the input parameters.", "Arguments": ":param cls: Class. The class object.\n:param cfgfile: String. The path to the configuration file.\n:param nick: String. The nickname to use for own tweets.\n:param twtfile: String. The path to the local twtxt file.\n:param twturl: String. The URL to the remote twtxt file.\n:param disclose_identity: Bool. If True, the user's id will be disclosed.\n:param add_news: Bool. If True, follow the twtxt news feed.\n:return: Config. The created Config instance."}, "tests": ["tests/test_config.py::test_create_config"], "indent": 8}
{"namespace": "boltons.ioutils.SpooledIOBase.writelines", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [114, 114], "body_position": [120, 122], "dependency": {"intra_class": ["boltons.ioutils.SpooledIOBase._checkClosed", "boltons.ioutils.SpooledIOBase.write"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Write each line in the input iterable to the buffer of a SpooledIOBase instance. It does not add line separators.\n", "Arguments": ":param self: SpooledIOBase, an instance of SpooledIOBase class.\n:param lines: iterable, lines to be written to the file.\n:return: No return values.\n"}, "tests": ["tests/test_ioutils.py::TestSpooledBytesIO::test_writelines", "tests/test_ioutils.py::TestSpooledStringIO::test_writelines"], "indent": 8}
{"namespace": "kinto.plugins.accounts.utils.get_cached_reset_password", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/accounts/utils.py", "signature_position": [55, 55], "body_position": [57, 62], "dependency": {"intra_class": [], "intra_file": ["kinto.plugins.accounts.utils.ACCOUNT_RESET_PASSWORD_CACHE_KEY"], "cross_file": ["kinto.core.utils.hmac_digest", "kinto.core.cache", "kinto.core.utils"]}, "requirement": {"Functionality": "This function retrieves the reset password for a given username from the cache. It first generates a cache key using the username and a secret key. Then, it retrieves the corresponding value from the cache using the cache key.", "Arguments": ":param username: String. The username for which to retrieve the reset password.\n:param registry: Dictionary. The registry containing the settings and cache.\n:return: The reset password value retrieved from the cache."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_reset_password_sends_email", "tests/plugins/test_accounts.py::AccountValidationCreationTest::test_use_reset_password_to_change_password"], "indent": 4}
{"namespace": "falcon.request.Request.subdomain", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [872, 873], "body_position": [874, 875], "dependency": {"intra_class": ["falcon.request.Request.host"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function extracts the subdomain from the host of a Request instance. It splits the host string into three parts: the subdomain, the separator (.), and the remainder of the string. If the separator is found, it returns the subdomain; otherwise, it returns None.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String or None. The extracted subdomain from the host, or None if no subdomain is found."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_subdomain"], "indent": 8}
{"namespace": "alembic.operations.schemaobj.SchemaObjects.index", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/schemaobj.py", "signature_position": [241, 248], "body_position": [249, 260], "dependency": {"intra_class": ["alembic.operations.schemaobj.SchemaObjects.metadata"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates an Index object based on the given parameters. It first creates a Table object using the provided tablename and schema, and then creates an Index object using the table and column names. The function returns the created Index object.", "Arguments": ":param self: SchemaObjects. An instance of the `SchemaObjects` class.\n:param name: Optional string. The name of the index.\n:param tablename: Optional string. The name of the table to create the index on.\n:param columns: Sequence of strings, TextClause, or ColumnElement. The columns to include in the index.\n:param schema: Optional string. The schema of the table.\n:param **kw: Additional keyword arguments that can be passed to the Index object.\n:return: Index. The created Index object."}, "tests": ["tests/test_op.py::ObjectFromToTest::test_drop_index", "tests/test_op.py::ObjectFromToTest::test_create_index_add_kw", "tests/test_op.py::ObjectFromToTest::test_drop_index_add_kw", "tests/test_op.py::ObjectFromToTest::test_create_index"], "indent": 8}
{"namespace": "twilio.base.serialize.prefixed_collapsible_map", "type": "function", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/base/serialize.py", "signature_position": [35, 35], "body_position": [39, 61], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["twilio.base.values", "twilio.base.values.unset"]}, "requirement": {"Functionality": "This function takes a dictionary `m` and a prefix as input and returns a new dictionary with the same keys and values as `m`, but with the added prefix to the keys.", "Arguments": ":param m: Dictionary. The input dictionary.\n:param prefix: String. The prefix to be added to the keys in the input dictionary.\n:return: Dictionary. A new dictionary with the same keys and values as the input dictionary, but with the added prefix to the keys."}, "tests": ["tests/unit/base/test_serialize.py::PrefixedCollapsibleMapTestCase::test_list", "tests/unit/base/test_serialize.py::PrefixedCollapsibleMapTestCase::test_single_key", "tests/unit/base/test_serialize.py::PrefixedCollapsibleMapTestCase::test_nested_key", "tests/unit/base/test_serialize.py::PrefixedCollapsibleMapTestCase::test_unset", "tests/unit/base/test_serialize.py::PrefixedCollapsibleMapTestCase::test_multiple_keys"], "indent": 4}
{"namespace": "kinto.plugins.accounts.views.validation.on_account_activated", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/accounts/views/validation.py", "signature_position": [121, 121], "body_position": [122, 135], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["kinto.plugins.accounts.mails.Emailer", "kinto.plugins.accounts.mails.Emailer.send_confirmation"]}, "requirement": {"Functionality": "This function is triggered when an account is activated. It checks if the account validation setting is enabled. If it is enabled, it iterates through the impacted objects in the event and checks if the old account was validated or if the new account is not validated. If either of these conditions is true, it skips to the next impacted object. If neither condition is true, it sends a confirmation email to the account.", "Arguments": ":param event: The event object containing information about the account activation.\n:return: No return values."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_user_validation_listener"], "indent": 4}
{"namespace": "falcon.asgi.reader.BufferedReader.read_until", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/asgi/reader.py", "signature_position": [289, 289], "body_position": [290, 297], "dependency": {"intra_class": ["falcon.asgi.reader.BufferedReader._consume_delimiter", "falcon.asgi.reader.BufferedReader._iter_delimited", "falcon.asgi.reader.BufferedReader._read_from"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Read data from the BufferedReader instance until a specified delimiter is encountered. It reads data from the internal iterator that yields chunks of data until the delimiter is found or the specified size is reached. If consume_delimiter is True, it also consumes the delimiter from the input data.", "Arguments": ":param self: BufferedReader. An instance of the BufferedReader class.\n:param delimiter: The delimiter to search for in the input data.\n:param size: Integer. The maximum number of bytes to read. Defaults to -1, which means read until the delimiter is found.\n:param consume_delimiter: Bool. Whether to consume the delimiter from the input data. Defaults to False.\n:return: The data read from the BufferedReader instance until the delimiter is encountered."}, "tests": ["tests/asgi/test_buffered_reader.py::test_read_until_shared_boundary"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox._to_box_autocomplete", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [431, 431], "body_position": [432, 452], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._process_typeaheads", "zulipterminal.ui_tools.boxes.WriteBox.view"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a text and a state as input and returns a string for autocomplete. It performs the following steps:\n1. Get the list of users from the view.\n2. Split the text by comma and get the most recent recipient for autocomplete.\n3. Find the users that match the latest text.\n4. Append the autocompleted recipients to the string containing the previous recipients.\n5. Get the full names of the matching users.\n6. Process the typeaheads using the updated recipients, state, and user names.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param text: String. The input text for autocomplete.\n:param state: Optional[int]. The state for autocomplete. Defaults to None.\n:return: Optional[str]. The string for autocomplete."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test__to_box_autocomplete", "tests/ui_tools/test_boxes.py::TestWriteBox::test__to_box_autocomplete_with_multiple_recipients"], "indent": 8}
{"namespace": "falcon.request.Request.relative_uri", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [803, 803], "body_position": [804, 812], "dependency": {"intra_class": ["falcon.request.Request._cached_relative_uri", "falcon.request.Request.app", "falcon.request.Request.path", "falcon.request.Request.query_string"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the relative URI of a Request instance. If the relative URI is not cached, it is generated based on the app, path, and query string of the Request instance. The output format is \"{app}{path}\" or \"{app}{path}?{query string}\".", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The relative URI of the Request instance."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_relative_uri"], "indent": 8}
{"namespace": "viztracer.tracer._VizTracer.start", "type": "method", "project_path": "System/viztracer", "completion_path": "System/viztracer/src/viztracer/tracer.py", "signature_position": [244, 244], "body_position": [245, 252], "dependency": {"intra_class": ["viztracer.tracer._VizTracer._tracer", "viztracer.tracer._VizTracer.config", "viztracer.tracer._VizTracer.enable", "viztracer.tracer._VizTracer.exclude_files", "viztracer.tracer._VizTracer.include_files", "viztracer.tracer._VizTracer.log_print", "viztracer.tracer._VizTracer.overload_print", "viztracer.tracer._VizTracer.parsed"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Start the input VizTracer instance. It sets the enable flag to True and the parsed flag to False. If the log print is True, it overloads the print function. It checks if both included files and excluded files are specified, and raises an exception if they are. It then enables the config and starts the tracer.", "Arguments": ":param self: _VizTracer. An instance of the _VizTracer class.\n:return: No return values."}, "tests": ["tests/test_tracer.py::TestCircularBuffer::test_wrap", "tests/test_tracer.py::TestTracerFeature::test_log_gc", "tests/test_tracer.py::TestTracerFilter::test_include_exclude_exception", "tests/test_basic.py::TestTracerBasic::test_builtin_func", "tests/test_tracer.py::TestTracerFeature::test_log_func_retval"], "indent": 8}
{"namespace": "boto.s3.bucket.Bucket.get_tags", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/bucket.py", "signature_position": [1829, 1829], "body_position": [1830, 1837], "dependency": {"intra_class": ["boto.s3.bucket.Bucket.get_xml_tags"], "intra_file": [], "cross_file": ["boto.handler", "boto.handler.XmlHandler", "boto.s3.tagging.Tags"]}, "requirement": {"Functionality": "This function retrieves the tags associated with a bucket. It sends a request to get the XML tags of the bucket and parses the response to extract the tags.", "Arguments": ":param self: Bucket. An instance of the Bucket class.\n:param headers: Dict. Optional headers to include in the request.\n:return: Tags. The tags associated with the bucket."}, "tests": ["tests/unit/s3/test_tagging.py::TestS3Tagging::test_parse_tagging_response"], "indent": 8}
{"namespace": "pyinfra.operations.files.get", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/files.py", "signature_position": [717, 723], "body_position": [748, 773], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra.api.util.get_file_sha1", "pyinfra.facts.files.File", "pyinfra.facts.files.Sha1File", "pyinfra.api.host.Host.get_fact", "pyinfra.api.state.State.get_temp_filename"]}, "requirement": {"Functionality": "This function is used to download a file from a remote system. It takes the source file path and the destination file path as input parameters and provides options to add the deploy directory, create the local directory if it doesn't exist, and force the download even if the local copy matches. It also includes an example and a note about the suitability of this operation for large files.", "Arguments": ":param src: String. The remote filename to download.\n:param dest: String. The local filename to download the file to.\n:param add_deploy_dir: Bool. Whether the destination is relative to the deploy directory. Defaults to True.\n:param create_local_dir: Bool. Whether to create the local directory if it doesn't exist. Defaults to False.\n:param force: Bool. Whether to always download the file, even if the local copy matches. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_file_download_op"], "indent": 4}
{"namespace": "ydata_profiling.report.presentation.flavours.html.image.HTMLImage.render", "type": "method", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/report/presentation/flavours/html/image.py", "signature_position": [6, 6], "body_position": [7, 8], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["ydata_profiling.report.presentation.flavours.html.templates", "ydata_profiling.report.presentation.flavours.html.templates.template"]}, "requirement": {"Functionality": "Render the HTML content of an image. It uses a template file called \"diagram.html\" and passes the content of the image as arguments to the template.", "Arguments": ":param self: HTMLImage. An instance of the HTMLImage class.\n:return: str. The rendered HTML content of the image."}, "tests": ["tests/unit/test_renderable.py::test_html_image"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.enable", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [537, 537], "body_position": [553, 567], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient._raw_command_untagged", "imapclient.imapclient.IMAPClient.capabilities"], "intra_file": [], "cross_file": ["imapclient.exceptions.IllegalStateError", "imapclient.exceptions"]}, "requirement": {"Functionality": "This function enables one or more server-side capability extensions in the IMAPClient instance. It sends an ENABLE command to the server with the requested extensions and returns a list of the successfully enabled extensions.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param capabilities: Variable number of strings. The capability extensions to enable on the server.\n:return: List of strings. The requested extensions that were successfully enabled on the server."}, "tests": ["tests/test_enable.py::TestEnable::test_success", "tests/test_enable.py::TestEnable::test_failed1", "tests/test_enable.py::TestEnable::test_multiple", "tests/test_enable.py::TestEnable::test_failed2", "tests/test_enable.py::TestEnable::test_wrong_state"], "indent": 8}
{"namespace": "diffprivlib.accountant.BudgetAccountant.check", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/accountant.py", "signature_position": [275, 275], "body_position": [297, 311], "dependency": {"intra_class": ["diffprivlib.accountant.BudgetAccountant.__min_epsilon", "diffprivlib.accountant.BudgetAccountant.delta", "diffprivlib.accountant.BudgetAccountant.epsilon", "diffprivlib.accountant.BudgetAccountant.remaining", "diffprivlib.accountant.BudgetAccountant.spent_budget", "diffprivlib.accountant.BudgetAccountant.total"], "intra_file": [], "cross_file": ["diffprivlib.utils.Budget", "diffprivlib.utils.BudgetError", "diffprivlib.validation.check_epsilon_delta"]}, "requirement": {"Functionality": "This function checks if the provided (epsilon, delta) values can be spent without exceeding the budget ceiling of the BudgetAccountant instance. It performs various checks and calculations to determine if the budget can be spent or if a budget error should be raised \"Privacy spend of ({epsilon},{delta}) not permissible; will exceed remaining privacy budget. Use {class name}.{method for remaining budget}() to check remaining budget.\"", "Arguments": ":param self: BudgetAccountant. An instance of the BudgetAccountant class.\n:param epsilon: float. The epsilon budget spend to check.\n:param delta: float. The delta budget spend to check.\n:return: bool. True if the budget can be spent."}, "tests": ["tests/test_BudgetAccountant.py::TestBudgetAccountant::test_spent_budget", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_inf_spend"], "indent": 8}
{"namespace": "imapclient.imapclient._normalise_search_criteria", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1826, 1826], "body_position": [1827, 1850], "dependency": {"intra_class": [], "intra_file": ["imapclient.imapclient._normalise_search_criteria", "imapclient.imapclient._quoted", "imapclient.imapclient._quoted.maybe"], "cross_file": ["imapclient.datetime_util.format_criteria_date", "imapclient.exceptions", "imapclient.exceptions.InvalidCriteriaError", "imapclient.util.to_bytes"]}, "requirement": {"Functionality": "This function normalizes the search criteria by converting them into a standardized format. It handles different types of criteria and converts them accordingly including \"int, str, datatime, list, tuple, bytes\". If no criteria are specified, it raises the corresponding error. If no character set is specified, it defaults to \"us-ascii\".", "Arguments": ":param criteria: The search criteria to be normalized. It can be a string, bytes, list, tuple, int, datetime, or date.\n:param charset: The character set to be used for encoding. Defaults to \"us-ascii\" if not specified.\n:return: A list of normalized search criteria."}, "tests": ["tests/test_util_functions.py::Test_normalise_search_criteria::test_empty", "tests/test_util_functions.py::Test_normalise_search_criteria::test_None"], "indent": 4}
{"namespace": "pyinfra.api.connect.connect_all", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/connect.py", "signature_position": [11, 11], "body_position": [19, 46], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra.api.state.State.activate_host", "pyinfra.api.state.State.fail_hosts", "pyinfra.api.state.State.inventory", "pyinfra.progress.progress_spinner"]}, "requirement": {"Functionality": "This function connects to all the configured servers in parallel. It reads and writes the inventory of the input State instance. It activates the hosts that are initially connected to and updates the state accordingly.", "Arguments": ":param state: State. The state object containing the inventory to connect to.\n:return: No return values."}, "tests": ["tests/test_connectors/test_ssh.py::TestSSHConnector::test_connect_with_rsa_ssh_key_password_from_prompt", "tests/test_connectors/test_ssh.py::TestSSHConnector::test_connect_with_missing_ssh_key", "tests/test_api/test_api_facts.py::TestFactsApi::test_get_fact_current_op_global_arguments", "tests/test_connectors/test_ssh.py::TestSSHConnector::test_connect_with_rsa_ssh_key_wrong_password", "tests/test_connectors/test_docker.py::TestDockerConnector::test_connect_all"], "indent": 4}
{"namespace": "mingus.core.keys.get_key_signature", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/keys.py", "signature_position": [79, 79], "body_position": [85, 91], "dependency": {"intra_class": [], "intra_file": ["mingus.core.keys.is_valid_key", "mingus.core.keys.keys"], "cross_file": ["mingus.core.mt_exceptions.NoteFormatError"]}, "requirement": {"Functionality": "This function returns the key signature for a given key. It assigns a value of 0 for the key of C (major) or a (minor), negative numbers for flat key signatures, and positive numbers for sharp key signatures.\n", "Arguments": ":param key: str. The key for which the key signature is to be determined. It defaults to \"C\" if not specified.\n:return: int. The key signature for the given key.\n"}, "tests": ["tests/unit/core/test_keys.py::test_keys::test_get_key_signature"], "indent": 4}
{"namespace": "mrjob.step.StepFailedException.__repr__", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/step.py", "signature_position": [154, 154], "body_position": [155, 159], "dependency": {"intra_class": ["mrjob.step.StepFailedException._FIELDS"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the StepFailedException instance: '{class name}({\", \"-separated list of fields: {field name}={field value}})'.", "Arguments": ":param self: StepFailedException. An instance of the StepFailedException class.\n:return: str. The string representation of the StepFailedException instance."}, "tests": ["tests/test_step.py::StepFailedExceptionTestCase::test_empty", "tests/test_step.py::StepFailedExceptionTestCase::test_num_steps_with_no_step_num", "tests/test_step.py::StepFailedExceptionTestCase::test_step_num_with_num_steps", "tests/test_step.py::StepFailedExceptionTestCase::test_step_num", "tests/test_step.py::StepFailedExceptionTestCase::test_reason"], "indent": 8}
{"namespace": "diffprivlib.models.standard_scaler._incremental_mean_and_var", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/standard_scaler.py", "signature_position": [58, 59], "body_position": [60, 92], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["diffprivlib.accountant.BudgetAccountant"]}, "requirement": {"Functionality": "This function calculates the incremental mean and variance of a given dataset. It takes into account the previous mean, variance, and sample count, and updates them based on the new data increment.", "Arguments": ":param X: Array-like. The input dataset.\n:param epsilon: Float. The privacy parameter for the mean and variance calculations.\n:param bounds: Tuple. The lower and upper bounds for the dataset values.\n:param last_mean: Float. The previous mean of the dataset.\n:param last_variance: Float. The previous variance of the dataset.\n:param last_sample_count: Int. The previous sample count of the dataset.\n:param random_state: RandomState. The random state for the calculations. Defaults to None.\n:return: Tuple. The updated mean, variance, and sample count of the dataset."}, "tests": ["tests/models/test_incremental_mean_and_var.py::TestIncrementalMeanAndVar::test_duplicate_dataset", "tests/models/test_incremental_mean_and_var.py::TestIncrementalMeanAndVar::test_inf_epsilon", "tests/models/test_incremental_mean_and_var.py::TestIncrementalMeanAndVar::test_no_range", "tests/models/test_incremental_mean_and_var.py::TestIncrementalMeanAndVar::test_increment_inf_epsilon", "tests/models/test_incremental_mean_and_var.py::TestIncrementalMeanAndVar::test_different_results"], "indent": 4}
{"namespace": "mrjob.conf.combine_path_lists", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [525, 525], "body_position": [532, 542], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.combine_lists"], "cross_file": ["mrjob.util.expand_path"]}, "requirement": {"Functionality": "This function combines multiple path sequences into a single list. It resolves `~` (home dir) and environment variables, and expands globs that refer to the local filesystem. It can take single strings as well as lists.", "Arguments": ":param path_seqs: Variable number of sequences. The path sequences to be combined.\n:return: List. The combined list of paths after resolving `~`, environment variables, and expanding globs."}, "tests": ["tests/test_conf.py::CombineAndExpandPathsTestCase::test_combine_path_lists", "tests/test_conf.py::CombineAndExpandPathsTestCase::test_globbing", "tests/test_conf.py::CombineAndExpandPathsTestCase::test_combine_path_lists_on_strings", "tests/test_conf.py::CombineAndExpandPathsTestCase::test_combine_path_lists_empty"], "indent": 4}
{"namespace": "pyramid.urldispatch.RoutesMapper.connect", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/urldispatch.py", "signature_position": [46, 54], "body_position": [55, 67], "dependency": {"intra_class": ["pyramid.urldispatch.RoutesMapper.routelist", "pyramid.urldispatch.RoutesMapper.routes", "pyramid.urldispatch.RoutesMapper.static_routes"], "intra_file": ["pyramid.urldispatch.Route", "pyramid.urldispatch.Route.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function is used to connect a route to a RoutesMapper instance. It creates a new Route instance with the given parameters and adds it to the routes dictionary. If a route with the same name already exists, it is replaced with the new route. The function also adds the route to the routelist or static routes list depending on the value of the static parameter.", "Arguments": ":param self: RoutesMapper. An instance of the RoutesMapper class.\n:param name: String. The name of the route.\n:param pattern: String. The URL pattern for the route.\n:param factory: [optional] Any type. The factory function or object to be associated with the route.\n:param predicates: [optional] Tuple. A tuple of predicates to be applied to the route.\n:param pregenerator: [optional] Any type. The pregenerator function or object to be associated with the route.\n:param static: [optional] Bool. Whether the route is a static route or not. Defaults to False.\n:return: Route. The created Route object."}, "tests": ["tests/test_urldispatch.py::RoutesMapperTests::test___call__root_route_matches2", "tests/test_urldispatch.py::RoutesMapperTests::test___call__route_matches", "tests/test_urldispatch.py::RoutesMapperTests::test_connect_static_overridden", "tests/test_urldispatch.py::RoutesMapperTests::test___call__root_route_when_path_info_notempty", "tests/test_urldispatch.py::RoutesMapperTests::test___call__route_matches_with_predicates"], "indent": 8}
{"namespace": "feedparser.api._open_resource", "type": "function", "project_path": "Text-Processing/feedparser", "completion_path": "Text-Processing/feedparser/feedparser/api.py", "signature_position": [76, 76], "body_position": [110, 137], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["feedparser.http", "feedparser.http.get"]}, "requirement": {"Functionality": "This function takes in a URL, pathname to local or network file, or string as input and returns a stream object. It provides a uniform way to handle different types of input sources. The returned object has standard read methods (read, readline, readlines) and should be closed using the .close() method when no longer needed.", "Arguments": ":param url_file_stream_or_string: The input source, which can be a URL, filename, or string.\n:param etag: The value of the If-None-Match request header. Defaults to None.\n:param modified: The value of the If-Modified-Since request header. Can be a tuple of 9 integers or a date string. Defaults to None.\n:param agent: The value of the User-Agent request header. Defaults to None.\n:param referrer: The value of the Referer request header. Defaults to None.\n:param handlers: A list of handlers used to build a urllib2 opener. Defaults to None.\n:param request_headers: A dictionary of HTTP request headers that override the values generated by FeedParser. Defaults to None.\n:param result: A placeholder for the result. Defaults to None.\n:return: A bytes object representing the stream."}, "tests": ["tests/runtests.py::TestOpenResource::test_fileobj", "tests/runtests.py::TestOpenResource::test_string", "tests/runtests.py::TestOpenResource::test_unicode_1", "tests/runtests.py::TestOpenResource::test_http_client_basic_auth_type_error", "tests/runtests.py::TestOpenResource::test_unicode_2"], "indent": 4}
{"namespace": "alembic.autogenerate.api.compare_metadata", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/api.py", "signature_position": [45, 45], "body_position": [166, 167], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.api.produce_migrations"], "cross_file": ["alembic.operations.ops.MigrationScript.upgrade_ops", "alembic.runtime.migration.MigrationContext", "alembic.operations.ops.OpContainer.as_diffs"]}, "requirement": {"Functionality": "This function compares a database schema to the schema given in a MetaData instance. It uses a MigrationContext object to provide database connectivity and optional comparison functions for datatypes and server defaults. The function returns a list of \"diff\" directives, each representing individual differences between the two schemas.", "Arguments": ":param context: MigrationContext. An instance of the MigrationContext class that provides database connectivity and comparison functions.\n:param metadata: MetaData. An instance of the MetaData class that represents the database schema to compare against.\n:return: Any. The return format is a list of \"diff\" directives representing the differences between the two schemas."}, "tests": ["tests/test_autogen_diffs.py::CompareServerDefaultTest::test_server_default_yes_positives"], "indent": 4}
{"namespace": "exodus_bundler.bundling.Elf.dependencies", "type": "method", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [399, 399], "body_position": [401, 411], "dependency": {"intra_class": ["exodus_bundler.bundling.Elf.direct_dependencies", "exodus_bundler.bundling.Elf.linker_file", "exodus_bundler.bundling.Elf.find_direct_dependencies"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function runs the linker for the files iteratively and returns a set of all library dependencies. It starts with a set of direct dependencies and then iteratively finds the dependencies of those dependencies until no new dependencies are found.", "Arguments": ":param self: Elf. An instance of the Elf class.\n:return: Set. A set of all library dependencies."}, "tests": ["tests/test_bundling.py::test_elf_dependencies"], "indent": 8}
{"namespace": "pyramid.renderers.RendererHelper.render_to_response", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [466, 466], "body_position": [467, 468], "dependency": {"intra_class": ["pyramid.renderers.RendererHelper._make_response", "pyramid.renderers.RendererHelper.render"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a value, system values, and an optional request parameter as inputs. It renders the value using an input RendererHelper instance. It then creates a response and returns it.", "Arguments": ":param self: RendererHelper. An instance of the RendererHelper class.\n:param value: The value to be rendered.\n:param system_values: The system values to be used during rendering.\n:param request: Optional. The request object. Defaults to None.\n:return: The response generated by rendering the value."}, "tests": ["tests/test_renderers.py::TestRendererHelper::test_render_to_response"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.delete_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [855, 855], "body_position": [907, 917], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._build_filters", "boto.dynamodb2.table.Table._encode_keys", "boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.exceptions.ConditionalCheckFailedException", "boto.dynamodb2.layer1.DynamoDBConnection.delete_item", "boto.dynamodb2.types.FILTER_OPERATORS", "boto.dynamodb2.exceptions"]}, "requirement": {"Functionality": "This function deletes a single item from a table in DynamoDB. It allows for conditional deletes, where the item is only deleted if specific conditions are met. The function takes in the expected attribute values of the item to be deleted and the key attributes of the item. It returns True if the delete operation is successful and False if the conditional delete fails.", "Arguments": ":param self: Table. An instance of the Table class.\n:param expected: Dictionary. Optional. A dictionary of expected attribute value conditions.\n:param conditional_operator: String. Optional. The conditional operator to apply to the expected attribute value conditions. Defaults to 'AND'.\n:param kwargs: Key attributes of the item to be deleted.\n:return: Bool. True if the delete operation is successful, False if the conditional delete fails."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_delete_item_conditionally", "tests/unit/dynamodb2/test_table.py::TableTestCase::test_delete_item"], "indent": 8}
{"namespace": "threatingestor.state.State.save_state", "type": "method", "project_path": "Security/threatingestor", "completion_path": "Security/threatingestor/threatingestor/state.py", "signature_position": [24, 24], "body_position": [26, 28], "dependency": {"intra_class": ["threatingestor.state.State.conn", "threatingestor.state.State.cursor"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to create or update a state record in a database. It takes a name and state as input parameters, and inserts or replaces the corresponding values in the \"states\" table of the database.", "Arguments": ":param self: State. An instance of the State class.\n:param name: String. The name of the state record.\n:param state: Any data type. The state value to be stored.\n:return: No return values."}, "tests": ["tests/test_state.py::TestState::test_state_updates_known_state", "tests/test_state.py::TestState::test_state_saves"], "indent": 8}
{"namespace": "boto.awslambda.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/awslambda/__init__.py", "signature_position": [37, 37], "body_position": [38, 41], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.awslambda.layer1.AWSLambdaConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the AWSLambdaConnection class from the boto library. It creates a connection to the AWS Lambda service in the specified region.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection class.\n:return: AWSLambdaConnection. The connection object to the AWS Lambda service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestConnectAwslambda::test_connect_to_region"], "indent": 4}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.shutdown", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [169, 169], "body_position": [173, 183], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.cancel", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.request_queue", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.request_thread", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.writer"], "intra_file": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcWriter.close", "mssqlcli.jsonrpc.jsonrpcclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function shuts down the JsonRpcClient instance. It sets the cancel flag to True, enqueues None to unblock background threads, waits for the request thread to finish, closes the underlying writer, and logs a message indicating the shutdown.", "Arguments": ":param self: JsonRpcClient. An instance of the JsonRpcClient class.\n:return: No return values."}, "tests": ["tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_receive_invalid_response_exception", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_normal_shutdown"], "indent": 8}
{"namespace": "bplustree.node.Node.dump", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/node.py", "signature_position": [50, 50], "body_position": [51, 71], "dependency": {"intra_class": ["bplustree.node.Node._node_type_int", "bplustree.node.Node._tree_conf", "bplustree.node.Node.entries", "bplustree.node.Node.next_page"], "intra_file": [], "cross_file": ["bplustree.const.ENDIAN", "bplustree.const.PAGE_REFERENCE_BYTES", "bplustree.entry.Entry.dump"]}, "requirement": {"Functionality": "This function is used to dump the data of a Node instance into a bytearray. It iterates through the entries in the node and dumps each record. It then constructs the header of the bytearray, which includes the node type, used page length, and next page reference. The header is appended to the data bytearray. Padding is added to ensure that the total length of the data is equal to the page size specified in the tree configuration. The final data bytearray is returned.", "Arguments": ":param self: Node. An instance of the Node class.\n:return: bytearray. The dumped data of the Node instance."}, "tests": ["tests/test_node.py::test_leaf_node_serialization", "tests/test_node.py::test_root_node_serialization"], "indent": 8}
{"namespace": "zxcvbn.matching.spatial_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [302, 302], "body_position": [303, 307], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.GRAPHS", "zxcvbn.matching.RANKED_DICTIONARIES", "zxcvbn.matching.spatial_match_helper"], "cross_file": []}, "requirement": {"Functionality": "This function performs a spatial matching algorithm on a given password. It iterates through a set of predefined graphs and calls a helper function to find spatial matches in each graph. The matches are then sorted based on their position in the password.", "Arguments": ":param password: String. The password to perform spatial matching on.\n:param _graphs: Dictionary. A dictionary containing predefined graphs for spatial matching. Defaults to GRAPHS.\n:param _ranked_dictionaries: Dictionary. A dictionary containing ranked dictionaries for spatial matching. Defaults to RANKED_DICTIONARIES.\n:return: List. A sorted list of matches found in the password."}, "tests": ["tests/matching_test.py::test_spatial_matching"], "indent": 4}
{"namespace": "sslyze.plugins.certificate_info._cert_chain_analyzer._certificate_matches_hostname", "type": "function", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/certificate_info/_cert_chain_analyzer.py", "signature_position": [274, 274], "body_position": [277, 298], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["sslyze.plugins.certificate_info._certificate_utils.SubjectAlternativeNameExtension.dns_names", "sslyze.plugins.certificate_info._certificate_utils.SubjectAlternativeNameExtension.ip_addresses", "sslyze.plugins.certificate_info._certificate_utils.get_common_names", "sslyze.plugins.certificate_info._certificate_utils.parse_subject_alternative_name_extension"]}, "requirement": {"Functionality": "This function verifies whether the given certificate was issued for the specified hostname. It extracts the names from the certificate and creates a dictionary with the properly formatted names. Then, it check if the server_hostname matches any of the names in the certificate. If a CertificateError is raised during the matching process, it returns False.", "Arguments": ":param certificate: Certificate. The certificate to be verified.\n:param server_hostname: String. The hostname to be checked against the certificate.\n:return: Bool. True if the certificate matches the hostname, False otherwise."}, "tests": ["tests/plugins_tests/certificate_info/test_certificate_utils.py::TestCertificateUtils::test_certificate_matches_hostname_good_hostname"], "indent": 4}
{"namespace": "boltons.cacheutils.ThresholdCounter.elements", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [726, 726], "body_position": [730, 731], "dependency": {"intra_class": ["boltons.cacheutils.ThresholdCounter.iteritems"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns an iterator that yields all the common elements tracked by the counter. Each key is yielded as many times as it has been seen.", "Arguments": ":param self: ThresholdCounter. An instance of the ThresholdCounter class.\n:return: Iterator. An iterator that yields the common elements tracked by the counter."}, "tests": ["tests/test_cacheutils.py::test_threshold_counter"], "indent": 8}
{"namespace": "pyramid.path.Resolver.get_package", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/path.py", "signature_position": [113, 113], "body_position": [114, 118], "dependency": {"intra_class": ["pyramid.path.Resolver.package"], "intra_file": ["pyramid.path.CALLER_PACKAGE", "pyramid.path.caller_package"], "cross_file": []}, "requirement": {"Functionality": "This function returns the package that is associated with the Resolver instance. If the package is set to CALLER_PACKAGE, it retrieves the package of the caller. Otherwise, it returns the package that is set in the instance.", "Arguments": ":param self: Resolver. An instance of the Resolver class.\n:return: The package associated with the Resolver instance."}, "tests": ["tests/test_path.py::TestResolver::test_get_package_caller_package", "tests/test_path.py::TestResolver::test_get_package_string"], "indent": 8}
{"namespace": "exodus_bundler.bundling.detect_elf_binary", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [156, 156], "body_position": [158, 164], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["exodus_bundler.errors.MissingFileError"]}, "requirement": {"Functionality": "This function checks if a file has an ELF header. It reads the first four bytes of the file and compares them to the ELF header signature.", "Arguments": ":param filename: String. The path to the file to be checked.\n:return: Bool. True if the file has an ELF header, False otherwise."}, "tests": ["tests/test_bundling.py::test_detect_elf_binary"], "indent": 4}
{"namespace": "twilio.twiml.voice_response.VoiceResponse.enqueue", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [114, 124], "body_position": [139, 150], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Enqueue", "twilio.twiml.voice_response.Enqueue.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates an <Enqueue> element for a VoiceResponse object. It sets various attributes of the <Enqueue> element based on the input parameters.", "Arguments": ":param self: VoiceResponse. An instance of the VoiceResponse class.\n:param name: String. The friendly name of the <Enqueue> element.\n:param action: String. The action URL of the <Enqueue> element.\n:param max_queue_size: Integer. The maximum size of the queue for the <Enqueue> element.\n:param method: String. The HTTP method to be used for the action URL.\n:param wait_url: String. The wait URL for the <Enqueue> element.\n:param wait_url_method: String. The HTTP method to be used for the wait URL.\n:param workflow_sid: String. The TaskRouter Workflow SID for the <Enqueue> element.\n:param kwargs: Additional attributes for the <Enqueue> element.\n:return: <Enqueue> element. The created <Enqueue> element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestEnqueue::test_enqueue"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.buttons.MessageLinkButton._parse_narrow_link", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [465, 465], "body_position": [479, 519], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.ui_tools.buttons.ParsedNarrowLink"], "cross_file": ["zulipterminal.helper.hash_util_decode", "zulipterminal.ui.View.__init__"]}, "requirement": {"Functionality": "This function parses a given link and returns a dictionary with narrow parameters for supported links. If the link does not match any of the supported formats, an empty dictionary is returned.\nWe expect the fragment to be one of the following types:\na. narrow/stream/[{stream_id}-]{stream-name}\nb. narrow/stream/[{stream_id}-]{stream-name}/near/{message_id}\nc. narrow/stream/[{stream_id}-]{stream-name}/topic/{encoded.20topic.20name}\nd. narrow/stream/[{stream_id}-]{stream-name}/topic/{encoded.20topic.20name}/near/{message_id}", "Arguments": ":param cls: MessageLinkButton. The MessageLinkButton class.\n:param link: String. The link to be parsed.\n:return: ParsedNarrowLink. A dictionary with narrow parameters for supported links."}, "tests": ["tests/ui_tools/test_buttons.py::TestMessageLinkButton::test__parse_narrow_link"], "indent": 8}
{"namespace": "pyramid.testing.DummyRequest.response", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [398, 398], "body_position": [399, 401], "dependency": {"intra_class": ["pyramid.testing.DummyRequest.registry"], "intra_file": [], "cross_file": ["pyramid.response._get_response_factory"]}, "requirement": {"Functionality": "This function returns the response generated by the response factory using the input DummyRequest instance as the argument.", "Arguments": ":param self: DummyRequest. An instance of the DummyRequest class.\n:return: The response generated by the response factory function."}, "tests": ["tests/test_testing.py::TestDummyRequest::test_response_without_responsefactory", "tests/test_renderers.py::Test_string_renderer_factory::test_with_request_content_type_set", "tests/test_renderers.py::TestJSONP::test_render_to_jsonp_with_dot", "tests/test_renderers.py::TestJSONP::test_render_to_json", "tests/test_testing.py::TestDummyRequest::test_response_with_responsefactory"], "indent": 8}
{"namespace": "awesome_autodl.get_bib_abbrv_obj", "type": "function", "project_path": "Database/awesome-autodl", "completion_path": "Database/awesome-autodl/awesome_autodl/__init__.py", "signature_position": [79, 79], "body_position": [80, 83], "dependency": {"intra_class": [], "intra_file": ["awesome_autodl.get_bib_abbrv_file"], "cross_file": []}, "requirement": {"Functionality": "This function returns an instance of the BibAbbreviations class, which is created based on the file path obtained.", "Arguments": ":param: No input parameters.\n:return: BibAbbreviations. An instance of the BibAbbreviations class."}, "tests": ["tests/test_format.py::TestFormat::test_simple"], "indent": 4}
{"namespace": "ehforwarderbot.utils.get_config_path", "type": "function", "project_path": "Communications/ehforwarderbot", "completion_path": "Communications/ehforwarderbot/ehforwarderbot/utils.py", "signature_position": [88, 88], "body_position": [103, 110], "dependency": {"intra_class": [], "intra_file": ["ehforwarderbot.utils.get_base_path", "ehforwarderbot.utils.get_data_path"], "cross_file": ["ehforwarderbot.coordinator", "ehforwarderbot.coordinator.profile", "ehforwarderbot.types.ModuleID"]}, "requirement": {"Functionality": "This function returns the path to the configuration file based on the given module ID and extension. If the module ID is not provided, it uses the profile name from the coordinator. It also creates the path if it does not exist like \"profiles/{profile_name}/{module_id}/config.yaml\".", "Arguments": ":param module_id: ModuleID. The ID of the module. Defaults to None.\n:param ext: String. The extension name of the config file. Defaults to \"yaml\".\n:return: Path. The path to the configuration file."}, "tests": ["tests/test_channel_loading.py::test_load_config"], "indent": 4}
{"namespace": "bentoml._internal.utils.metrics.linear_buckets", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/utils/metrics.py", "signature_position": [59, 59], "body_position": [67, 80], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.utils.metrics.INF", "bentoml._internal.utils.metrics.MAX_BUCKET_COUNT"], "cross_file": []}, "requirement": {"Functionality": "This function creates buckets for a Prometheus histogram based on the given start, step, and end values. The buckets are created by starting with the start value and incrementing it by the step value until it reaches the end value. The function also includes the end value as the second last value in the returned tuple and positive infinity as the last value.", "Arguments": ":param start: float. The lower bound of the lowest bucket.\n:param step: float. The increment value for each subsequent bucket.\n:param end: float. The upper bound of the last bucket.\n:return: tuple[float, ...]. A tuple containing the created buckets, where each value represents the upper bound of a bucket. The tuple also includes the end value as the second last value and positive infinity as the last value."}, "tests": ["tests/unit/_internal/utils/test_metrics.py::test_linear_buckets"], "indent": 4}
{"namespace": "pyramid.csrf.CookieCSRFStoragePolicy.new_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [136, 136], "body_position": [138, 145], "dependency": {"intra_class": ["pyramid.csrf.CookieCSRFStoragePolicy._token_factory", "pyramid.csrf.CookieCSRFStoragePolicy.cookie_name"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a new CSRF token and sets it into the request cookies. It also adds a response callback to set the CSRF token into the response cookies.", "Arguments": ":param self: CookieCSRFStoragePolicy. An instance of the CookieCSRFStoragePolicy class.\n:param request: The request object.\n:return: String. The generated CSRF token."}, "tests": ["tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_new_cookie_csrf_with_existing_cookie_sets_cookies", "tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_get_csrf_token_returns_the_new_token"], "indent": 8}
{"namespace": "pyramid.config.Configurator.__getattr__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/__init__.py", "signature_position": [698, 699], "body_position": [700, 711], "dependency": {"intra_class": ["pyramid.config.Configurator.registry"], "intra_file": [], "cross_file": ["pyramid.config.actions.action_method"]}, "requirement": {"Functionality": "This function is a method of the Configurator class that allows accessing attributes dynamically and allow directive extension names to work. It checks if the attribute name exists in the registry's directives. If it does, it retrieves the corresponding value and performs additional actions if necessary. Finally, it returns a bound method of the retrieved value.", "Arguments": ":param self: Configurator. An instance of the Configurator class.\n:param name: String. The name of the attribute to be accessed.\n:return: Bound method. The bound method of the retrieved attribute value."}, "tests": ["tests/test_config/test_init.py::ConfiguratorTests::test___getattr__missing_when_directives_exist", "tests/test_config/test_init.py::ConfiguratorTests::test___getattr__missing_when_directives_dont_exist"], "indent": 8}
{"namespace": "fs.path.recursepath", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [116, 117], "body_position": [133, 151], "dependency": {"intra_class": [], "intra_file": ["fs.path.abspath", "fs.path.normpath"], "cross_file": []}, "requirement": {"Functionality": "Take a path and a boolean value as input and return a list of intermediate paths from the root to the given path. \n", "Arguments": ":param path: String, the input path for which intermediate paths are to be generated.\n:param reverse: Bool, a boolean flag that specifies whether to reverse the order of the paths. Defaults to False.\n:return: List[String], a list of intermediate paths from the root to the given path.\n"}, "tests": ["tests/test_path.py::TestPathFunctions::test_recursepath"], "indent": 4}
{"namespace": "chatette.parsing.IntentDefBuilder.create_concrete", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [162, 162], "body_position": [163, 172], "dependency": {"intra_class": ["chatette.parsing.IntentDefBuilder.identifier", "chatette.parsing.IntentDefBuilder.nb_testing_ex", "chatette.parsing.IntentDefBuilder.nb_training_ex", "chatette.parsing.IntentDefBuilder.variation"], "intra_file": ["chatette.parsing.UnitDefBuilder._build_modifiers_repr", "chatette.parsing.UnitDefBuilder._check_information"], "cross_file": ["chatette.units.ast.AST", "chatette.units.modifiable.definitions.intent.IntentDefinition", "chatette.utils.Singleton.get_or_create", "chatette.utils.UnitType", "chatette.utils.UnitType.intent"]}, "requirement": {"Functionality": "This function creates a concrete instance of an IntentDefinition based on the given conditions. It first checks if all the necessary information is provided. If a variation is specified, it retrieves the definitions from the AST and checks if the identifier is already present. If it is, it returns the corresponding definition. Otherwise, it creates a new IntentDefinition instance with the provided identifier, modifiers representation, number of training examples, and number of testing examples.", "Arguments": ":param self: IntentDefBuilder. An instance of the IntentDefBuilder class.\n:return: IntentDefinition. The created concrete instance of IntentDefinition."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestIntentDefBuilder::test_create_concrete", "tests/unit-testing/parsing/test_init.py::TestIntentDefBuilder::test_new_variation"], "indent": 8}
{"namespace": "boto.s3.bucket.Bucket.new_key", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/bucket.py", "signature_position": [614, 614], "body_position": [624, 626], "dependency": {"intra_class": ["boto.s3.bucket.Bucket.key_class"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a new key in the Bucket instance. It takes a key name as input and returns an instance of the newly created key object.", "Arguments": ":param self: Bucket. An instance of the Bucket class.\n:param key_name: String. The name of the key to create.\n:return: :class:`boto.s3.key.Key` or subclass. An instance of the newly created key object."}, "tests": ["tests/unit/s3/test_key.py::TestS3KeyRetries::test_400_timeout", "tests/unit/s3/test_key.py::TestS3KeyRetries::test_500_retry", "tests/unit/s3/test_key.py::TestS3KeyRetries::test_502_bad_gateway", "tests/unit/s3/test_key.py::TestS3KeyRetries::test_504_gateway_timeout"], "indent": 8}
{"namespace": "sacred.host_info.host_info_getter", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/host_info.py", "signature_position": [84, 84], "body_position": [107, 115], "dependency": {"intra_class": [], "intra_file": ["sacred.host_info.host_info_gatherers"], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator that adds the decorated function to the process of collecting host information.", "Arguments": ":param func: callable. A function that can be called without arguments and returns some JSON-serializable information.\n:param name: str, optional. The name of the corresponding entry in host_info. Defaults to the name of the function.\n:return: The function itself."}, "tests": ["tests/test_host_info.py::test_host_info_decorator_with_name", "tests/test_host_info.py::test_host_info_decorator", "tests/test_host_info.py::test_host_info_decorator_depreciation_warning"], "indent": 4}
{"namespace": "pycorrector.en_spell.EnSpell.correct_word", "type": "method", "project_path": "Text-Processing/pycorrector", "completion_path": "Text-Processing/pycorrector/pycorrector/en_spell.py", "signature_position": [99, 99], "body_position": [106, 109], "dependency": {"intra_class": ["pycorrector.en_spell.EnSpell.candidates", "pycorrector.en_spell.EnSpell.check_init"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function corrects the spelling of a given word by finding the most probable spelling correction. It first checks if the EnSpell instance has been initialized. Then, it calculates the probability of each candidate spelling correction for the word and sorts them in ascending order. Finally, it returns the correction with the highest probability.", "Arguments": ":param self: EnSpell. An instance of the EnSpell class.\n:param word: String. The word to be corrected.\n:return: String. The most probable spelling correction for the word."}, "tests": ["tests/en_spell_bug_fix_test.py::EnBugTestCase::test_en_bug_correct2"], "indent": 8}
{"namespace": "boltons.dictutils.ManyToMany.add", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [967, 967], "body_position": [968, 973], "dependency": {"intra_class": ["boltons.dictutils.ManyToMany.data", "boltons.dictutils.ManyToMany.inv"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Add a key-value pair to a ManyToMany instance. It adds the key to the data dictionary and associates it with a set of values, then add value to the set. It also adds the value to the inv.data dictionary and associates it with a set of keys, then add key to the set.", "Arguments": ":param self: ManyToMany. An instance of the ManyToMany class.\n:param key: The key to add to the data dictionary.\n:param val: The value to add to the set associated with the key in the data dictionary.\n:return: No return values."}, "tests": ["tests/test_dictutils.py::test_many_to_many"], "indent": 8}
{"namespace": "hl7.datatypes.parse_datetime", "type": "function", "project_path": "Communications/hl7", "completion_path": "Communications/hl7/hl7/datatypes.py", "signature_position": [29, 29], "body_position": [37, 91], "dependency": {"intra_class": [], "intra_file": ["hl7.datatypes.DTM_TZ_RE", "hl7.datatypes._UTCOffset", "hl7.datatypes._UTCOffset.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function parses a string in the HL7 DTM format and returns a datetime object. The HL7 DTM format is of the form \"YYYY[MM[DD[HH[MM[SS[.S[S[S[S]]]]]]]]][+/-HHMM]\". If the input string is empty, it returns None.", "Arguments": ":param value: String. The HL7 DTM string to be parsed.\n:return: datetime.datetime. The parsed datetime object."}, "tests": ["tests/test_datetime.py::DatetimeTest::test_parse_datetime_frac", "tests/test_datetime.py::DatetimeTest::test_parse_tz", "tests/test_datetime.py::DatetimeTest::test_parse_datetime", "tests/test_datetime.py::DatetimeTest::test_parse_date"], "indent": 4}
{"namespace": "pycoin.bloomfilter.BloomFilter.add_spendable", "type": "method", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/bloomfilter.py", "signature_position": [48, 48], "body_position": [49, 50], "dependency": {"intra_class": ["pycoin.bloomfilter.BloomFilter.add_item"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Add a spendable to the BloomFilter instance. It converts the spendable into bytes and adds it to the BloomFilter.", "Arguments": ":param self: BloomFilter. An instance of the BloomFilter class.\n:param spendable: The spendable to be added to the BloomFilter.\n:return: No return values."}, "tests": ["tests/bloomfilter_test.py::BloomFilterTest::test_BloomFilter"], "indent": 8}
{"namespace": "boltons.cacheutils.LRI.setdefault", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [295, 295], "body_position": [296, 302], "dependency": {"intra_class": ["boltons.cacheutils.LRI._lock", "boltons.cacheutils.LRI.soft_miss_count"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if a key exists. If the key exists, it returns the value associated with that key. If the key doesn't exist, it increments a counter to count this kind of miss, sets the key to the default value, and returns the default value.\n", "Arguments": ":param self: LRI, an instance of the LRI class.\n:param key: The key for which the default value is to be set.\n:param default: The default value to be set for the key if it doesn't exist. Defaults to None.\n:return: The value associated with the key if it exists, otherwise the default value. No return if an exception occurs.\n"}, "tests": ["tests/test_cacheutils.py::test_lru_basic"], "indent": 8}
{"namespace": "kinto.core.errors.http_error", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/errors.py", "signature_position": [89, 91], "body_position": [104, 122], "dependency": {"intra_class": [], "intra_file": ["kinto.core.errors.ERRORS", "kinto.core.errors.ErrorSchema", "kinto.core.errors.ERRORS.UNDEFINED"], "cross_file": []}, "requirement": {"Functionality": "This function takes in various parameters related to an HTTP exception and returns a JSON-formatted response that matches the error HTTP API. It constructs a response object with the provided parameters and sets the appropriate attributes and content type.", "Arguments": ":param httpexception: Instance of :mod:`~pyramid:pyramid.httpexceptions`. The HTTP exception that occurred.\n:param errno: Integer. A stable application-level error number. Defaults to ERRORS.UNDEFINED if not specified.\n:param code: Integer. The HTTP status code that matches the error. Defaults to the code of the httpexception if not specified.\n:param error: String. A description of the error type. Defaults to the title of the httpexception if not specified.\n:param message: String. Context information about the error. Defaults to None.\n:param info: String. Additional information about the error, such as a URL for troubleshooting. Defaults to None.\n:param details: Any additional structured details about the error, such as conflicting objects. Defaults to colander.drop.\n:return: pyramid.httpexceptions.HTTPException. The formatted response object."}, "tests": ["tests/core/test_views_errors.py::ErrorViewTest::test_405_can_have_custom_message", "tests/core/test_views_errors.py::ErrorViewTest::test_503_can_have_custom_message", "tests/core/test_views_errors.py::ErrorViewTest::test_404_can_be_overridden", "tests/core/test_views_errors.py::ErrorViewTest::test_403_can_be_overridded", "tests/plugins/test_default_bucket.py::DefaultBucketViewTest::test_formatted_error_are_passed_through"], "indent": 4}
{"namespace": "mingus.core.keys.relative_major", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/keys.py", "signature_position": [145, 145], "body_position": [152, 155], "dependency": {"intra_class": [], "intra_file": ["mingus.core.keys.keys"], "cross_file": ["mingus.core.mt_exceptions.NoteFormatError"]}, "requirement": {"Functionality": "This function takes a minor key as input and returns the relative major key.\n", "Arguments": ":param key: str. The minor key for which the relative major key is to be found.\n:return: str. The relative major key corresponding to the given minor key.\n"}, "tests": ["tests/unit/core/test_keys.py::test_keys::test_relative_major"], "indent": 4}
{"namespace": "sacred.utils.convert_to_nested_dict", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [537, 537], "body_position": [539, 542], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.iterate_flattened", "sacred.utils.set_by_dotted_path"], "cross_file": []}, "requirement": {"Functionality": "This function converts a dictionary with dotted path keys into a corresponding nested dictionary. It iterates through the flattened dictionary and sets the values in the nested dictionary using the dotted path keys.", "Arguments": ":param dotted_dict: Dict. The dictionary with dotted path keys to be converted.\n:return: Dict. The corresponding nested dictionary."}, "tests": ["tests/test_utils.py::test_convert_to_nested_dict", "tests/test_utils.py::test_convert_to_nested_dict_nested"], "indent": 4}
{"namespace": "pyramid.config.Configurator.with_package", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/__init__.py", "signature_position": [713, 713], "body_position": [717, 728], "dependency": {"intra_class": ["pyramid.config.Configurator.autocommit", "pyramid.config.Configurator.basepath", "pyramid.config.Configurator.includepath", "pyramid.config.Configurator.info", "pyramid.config.Configurator.introspection", "pyramid.config.Configurator.registry", "pyramid.config.Configurator.root_package", "pyramid.config.Configurator.route_prefix"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a new instance of the Configurator class with the same registry as the current instance. The new instance will have the specified package and other attributes copied from the current instance. ``package`` may be an actual Python package object or a :term:`dotted Python name` representing a package.", "Arguments": ":param self: Configurator. The current instance of the Configurator class.\n:param package: The package to be set for the new instance. It can be an actual Python package object or a dotted Python name representing a package.\n:return: Configurator. The new instance of the Configurator class."}, "tests": ["tests/test_config/test_init.py::ConfiguratorTests::test_with_package", "tests/test_config/test_init.py::TestConfigurator_add_directive::test_directive_persists_across_configurator_creations", "tests/test_config/test_init.py::ConfiguratorTests::test_with_package_module", "tests/test_config/test_init.py::ConfiguratorTests::test_with_package_package"], "indent": 8}
{"namespace": "mrjob.fs.ssh.SSHFilesystem.ls", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/ssh.py", "signature_position": [173, 173], "body_position": [174, 185], "dependency": {"intra_class": ["mrjob.fs.ssh.SSHFilesystem._ssh_finish_run", "mrjob.fs.ssh.SSHFilesystem._ssh_launch"], "intra_file": ["mrjob.fs.ssh._SSH_URI_RE"], "cross_file": ["mrjob.py2.to_unicode"]}, "requirement": {"Functionality": "List all the files in the specified path of the SSH filesystem. It uses the SSH connection to execute the \"find\" command and retrieves the file paths.", "Arguments": ":param self: SSHFilesystem. An instance of the SSHFilesystem class.\n:param path_glob: str. The path pattern to match the files.\n:return: Generator. A generator that yields the file paths in the specified path."}, "tests": ["tests/fs/test_ssh.py::SSHFSTestCase::test_ls_without_required_sudo", "tests/fs/test_ssh.py::SSHFSTestCase::test_ls_recurse", "tests/fs/test_ssh.py::SSHFSTestCase::test_worker_ls_without_required_sudo", "tests/fs/test_ssh.py::SSHFSTestCase::test_ls_empty", "tests/fs/test_ssh.py::SSHFSTestCase::test_worker_ls"], "indent": 8}
{"namespace": "mrjob.conf.dump_mrjob_conf", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [346, 346], "body_position": [361, 365], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf._dump_yaml_with_clear_tags"], "cross_file": []}, "requirement": {"Functionality": "This function writes out configuration options to a file. It takes a configuration dictionary as input and writes it to the specified file object. The function supports both YAML and JSON formats for writing the configuration. If YAML is available, it uses it, otherwise it uses JSON.", "Arguments": ":param conf: dict. The configuration options to be written to the file.\n:param f: File object. The file object to write the configuration to.\n:return: No return values."}, "tests": ["tests/test_conf.py::MRJobConfNoYAMLTestCase::test_no_support_for_clear_tags", "tests/test_conf.py::MRJobBasicConfTestCase::test_nested_include", "tests/test_conf.py::MRJobBasicConfTestCase::test_include_order_beats_include", "tests/test_conf.py::MRJobConfNoYAMLTestCase::test_using_json_and_not_yaml", "tests/test_conf.py::MRJobBasicConfTestCase::test_include_relative_to_real_path"], "indent": 4}
{"namespace": "jinja2.bccache.MemcachedBytecodeCache.load_bytecode", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/bccache.py", "signature_position": [386, 386], "body_position": [387, 393], "dependency": {"intra_class": ["jinja2.bccache.MemcachedBytecodeCache.client", "jinja2.bccache.MemcachedBytecodeCache.ignore_memcache_errors", "jinja2.bccache.MemcachedBytecodeCache.prefix"], "intra_file": ["jinja2.bccache.Bucket.bytecode_from_string", "jinja2.bccache.Bucket.key", "jinja2.bccache._MemcachedClient.get"], "cross_file": []}, "requirement": {"Functionality": "Load the bytecode from the Memcached server and assign it to the given bucket. The key is generated by concatenating the prefix and the bucket key. If an exception occurs during the retrieval of the bytecode and the flag to ignore errors is not set, the exception is re-raised.", "Arguments": ":param self: MemcachedBytecodeCache. An instance of the MemcachedBytecodeCache class.\n:param bucket: Bucket. The bucket object to assign the retrieved bytecode to.\n:return: No return values."}, "tests": ["tests/test_bytecode_cache.py::TestMemcachedBytecodeCache::test_exception", "tests/test_bytecode_cache.py::TestMemcachedBytecodeCache::test_dump_load"], "indent": 8}
{"namespace": "rest_framework.serializers.Serializer.fields", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/serializers.py", "signature_position": [345, 345], "body_position": [352, 356], "dependency": {"intra_class": ["rest_framework.serializers.Serializer.get_fields"], "intra_file": [], "cross_file": ["rest_framework.utils.serializer_helpers.BindingDict"]}, "requirement": {"Functionality": "This function returns a dictionary of field names and their corresponding field instances. It lazily evaluates the fields to avoid import issues with modules that use ModelSerializers as fields before Django's app-loading stage has run.", "Arguments": ":param: self: Serializer. An instance of the Serializer class.\n:return: Dictionary. A dictionary of {field_name: field_instance}."}, "tests": ["tests/importable/test_installed.py::test_serializer_fields_initialization"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.get_flags", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1232, 1232], "body_position": [1239, 1240], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._filter_fetch_dict", "imapclient.imapclient.IMAPClient.fetch"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Return a dictionary that contains the flags set for each message in the input parameter `messages`.\n", "Arguments": ":param self: IMAPClient, an instance of IMAPClient class.\n:param messages: List, a list of message IDs for which to retrieve the flags.\n:return: Dict, a dictionary that contains the flags set for each message, structured as follows: \"{msgid1: (flag1, flag2, ...),}\".\n"}, "tests": ["tests/test_store.py::TestFlags::test_get"], "indent": 8}
{"namespace": "praw.util.token_manager.FileTokenManager.post_refresh_callback", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/util/token_manager.py", "signature_position": [88, 88], "body_position": [90, 91], "dependency": {"intra_class": ["praw.util.token_manager.FileTokenManager._filename"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function updates the saved copy of the refresh token by writing it to the file of the instance.", "Arguments": ":param self: FileTokenManager. An instance of the FileTokenManager class.\n:param authorizer: The authorizer object containing the refresh token.\n:return: No return values."}, "tests": ["tests/unit/util/test_token_manager.py::TestFileTokenManager::test_post_refresh_token_callback__writes_to_file"], "indent": 8}
{"namespace": "dash._grouping.make_grouping_by_index", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_grouping.py", "signature_position": [68, 68], "body_position": [80, 110], "dependency": {"intra_class": [], "intra_file": ["dash._grouping.flatten_grouping"], "cross_file": []}, "requirement": {"Functionality": "This function creates a grouping based on the provided grouping schema. It takes a schema and a list of flat values, and uses the values from the list to populate the grouping structure defined by the schema.", "Arguments": ":param schema: The grouping schema that defines the structure of the grouping to be created.\n:param flat_values: A list of values with a length that matches the grouping length of the schema. These values will be used to populate the resulting grouping.\n:return: The created grouping structure based on the schema and flat values."}, "tests": ["tests/unit/library/test_grouping.py::test_map_grouping_mixed", "tests/unit/library/test_grouping.py::test_make_grouping_by_position_mixed", "tests/unit/library/test_grouping.py::test_make_grouping_by_position_dict", "tests/unit/library/test_grouping.py::test_make_grouping_by_position_list", "tests/unit/library/test_grouping.py::test_make_grouping_by_position_scalar"], "indent": 4}
{"namespace": "trailscraper.boto_service_definitions.operation_definition", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/boto_service_definitions.py", "signature_position": [32, 32], "body_position": [34, 36], "dependency": {"intra_class": [], "intra_file": ["trailscraper.boto_service_definitions.service_definition_file"], "cross_file": []}, "requirement": {"Functionality": "This function returns the operation definition for a specific service and operation. It reads the service definition file for the given service name, loads the JSON content, and returns the operation definition based on the given operation name.", "Arguments": ":param servicename: String. The name of the service.\n:param operationname: String. The name of the operation.\n:return: The operation definition for the specified service and operation."}, "tests": ["tests/boto_service_definitions_test.py::test_should_find_operation_definitions"], "indent": 4}
{"namespace": "datasette.utils.asgi.Response.text", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/asgi.py", "signature_position": [393, 393], "body_position": [394, 399], "dependency": {"intra_class": ["datasette.utils.asgi.Response.__init__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a Response instance with the given parameters. It sets the body, status, headers, and content type of the response.", "Arguments": ":param cls: Class. The class of the Response instance.\n:param body: Any. The body of the response.\n:param status: Integer. The status code of the response. It defaults to 200 if not specified.\n:param headers: Dictionary. The headers of the response. It defaults to None if not specified.\n:return: Response. The created Response instance."}, "tests": ["tests/test_internals_response.py::test_response_text"], "indent": 8}
{"namespace": "alembic.testing.env._write_config_file", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/env.py", "signature_position": [241, 241], "body_position": [242, 245], "dependency": {"intra_class": [], "intra_file": ["alembic.testing.env._testing_config"], "cross_file": ["alembic.config.Config.config_file_name"]}, "requirement": {"Functionality": "This function writes the given text to a configuration file. It first creates a testing configuration instance, then opens the configuration file in write mode and writes the text to it. Finally, it returns the testing configuration instance.", "Arguments": ":param text: String. The text to be written to the configuration file.\n:return: TestingConfig. The testing configuration instance."}, "tests": ["tests/test_config.py::FileConfigTest::test_config_args"], "indent": 4}
{"namespace": "zxcvbn.matching.regex_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [444, 444], "body_position": [445, 457], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.RANKED_DICTIONARIES", "zxcvbn.matching.REGEXEN"], "cross_file": []}, "requirement": {"Functionality": "This function takes a password as input and matches it against a set of regular expressions. It creates a list of matches, where each match contains information about the matched pattern, the matched token, the start and end indices of the match, the name of the regex pattern, and the regex match object. The list of matches is then sorted based on the start and end indices.", "Arguments": ":param password: String. The password to be matched against the regular expressions.\n:param _regexen: Dictionary. A dictionary containing the regular expressions to be used for matching. It is optional and defaults to REGEXEN.\n:param _ranked_dictionaries: Dictionary. A dictionary containing ranked dictionaries. It is optional and defaults to RANKED_DICTIONARIES.\n:return: List. A sorted list of matches, where each match is a dictionary containing information about the matched pattern, token, indices, regex name, and regex match object."}, "tests": ["tests/matching_test.py::test_regex_matching"], "indent": 4}
{"namespace": "mingus.containers.note_container.NoteContainer.from_chord_shorthand", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note_container.py", "signature_position": [112, 112], "body_position": [122, 124], "dependency": {"intra_class": ["mingus.containers.note_container.NoteContainer.add_notes", "mingus.containers.note_container.NoteContainer.empty"], "intra_file": [], "cross_file": ["mingus.core.chords", "mingus.core.chords.from_shorthand"]}, "requirement": {"Functionality": "This function clears the NoteContainer and adds the notes corresponding to the shorthand notation.\n", "Arguments": ":param self: NoteContainer. An instance of the NoteContainer class.\n:param shorthand: str. The shorthand notation representing the chords.\n:return: NoteContainer. The updated NoteContainer instance.\n"}, "tests": ["tests/unit/containers/test_note_containers.py::test_NoteContainers::test_from_chord_shorthand"], "indent": 8}
{"namespace": "boto.ec2.cloudwatch.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/cloudwatch/__init__.py", "signature_position": [48, 48], "body_position": [59, 61], "dependency": {"intra_class": [], "intra_file": ["boto.ec2.cloudwatch.CloudWatchConnection"], "cross_file": ["boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns a CloudWatchConnection object.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param kw_params: keyword arguments. Additional parameters that can be passed to the connect function.\n:return: CloudWatchConnection or None. A connection to the specified region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestCloudwatchConnection::test_connect_to_region"], "indent": 4}
{"namespace": "pythonforandroid.bootstrap.Bootstrap.get_bootstrap_from_recipes", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/bootstrap.py", "signature_position": [251, 251], "body_position": [256, 295], "dependency": {"intra_class": ["pythonforandroid.bootstrap.Bootstrap.get_bootstrap", "pythonforandroid.bootstrap.Bootstrap.get_usable_bootstraps_for_recipes"], "intra_file": ["pythonforandroid.bootstrap._cmp_bootstraps_by_priority", "pythonforandroid.bootstrap.expand_dependencies"], "cross_file": ["pythonforandroid.logger.info"]}, "requirement": {"Functionality": "This function selects a recommended default bootstrap from a list of recipes and returns it. It follows a set of rules to determine the appropriate bootstrap based on the given recipes. The rules are following SDL2 bootstrap if there's an sdl2 dep or \"webview\" if we depend on common web recipe.", "Arguments": ":param cls: Class. The Bootstrap class.\n:param recipes: List of strings. The list of recipes to consider when selecting the bootstrap.\n:param ctx: Context. The context in which the function is being called.\n:return: Bootstrap. The selected default bootstrap."}, "tests": ["tests/test_bootstrap.py::TestBootstrapBasic::test_get_bootstraps_from_recipes"], "indent": 8}
{"namespace": "mrjob.compat.translate_jobconf_dict", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/compat.py", "signature_position": [677, 677], "body_position": [686, 715], "dependency": {"intra_class": [], "intra_file": ["mrjob.compat.log", "mrjob.compat.translate_jobconf", "mrjob.compat.translate_jobconf_for_all_versions"], "cross_file": []}, "requirement": {"Functionality": "This function translates the configuration property names in the jobconf dictionary to match those accepted in the specified hadoop version. It also prints a warning message if any configuration property name does not match the name in the hadoop version. Finally, it combines the original jobconf with the translated jobconf and returns a map consisting of the original and translated configuration property names and values. The warning message is \"Detected hadoop configuration property names that do not match version {hadoop version}:\\nThe have been translated to the following names:\\n{translated names}\". The translated names are sorted and one variable and variant per line, separated by a colon.", "Arguments": ":param jobconf: dict. The original jobconf dictionary containing configuration property names and values.\n:param hadoop_version: str. The version of Hadoop to which the configuration property names should be translated. Defaults to None.\n:return: dict. A map consisting of the original and translated configuration property names and values."}, "tests": ["tests/test_compat.py::TranslateJobConfDictTestCase::test_hadoop_2", "tests/test_compat.py::TranslateJobConfDictTestCase::test_no_version", "tests/test_compat.py::TranslateJobConfDictTestCase::test_hadoop_1", "tests/test_compat.py::TranslateJobConfDictTestCase::test_dont_overwrite", "tests/test_compat.py::TranslateJobConfDictTestCase::test_empty"], "indent": 4}
{"namespace": "boto.configservice.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/configservice/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.configservice.layer1.ConfigServiceConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the AWS Config service. It creates a connection to the Config service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: ConfigServiceConnection. The connection object to the Config service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestConfigserviceConnection::test_connect_to_region"], "indent": 4}
{"namespace": "pyramid.util.TopologicalSorter.add", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [462, 462], "body_position": [481, 499], "dependency": {"intra_class": ["pyramid.util.TopologicalSorter.default_after", "pyramid.util.TopologicalSorter.default_before", "pyramid.util.TopologicalSorter.name2after", "pyramid.util.TopologicalSorter.name2before", "pyramid.util.TopologicalSorter.name2val", "pyramid.util.TopologicalSorter.names", "pyramid.util.TopologicalSorter.order", "pyramid.util.TopologicalSorter.remove", "pyramid.util.TopologicalSorter.req_after", "pyramid.util.TopologicalSorter.req_before"], "intra_file": ["pyramid.util.is_nonstr_iter"], "cross_file": []}, "requirement": {"Functionality": "This function adds a node to the sort input of the TopologicalSorter instance. It assigns a name and a value to the node, and specifies its position relative to other nodes in the sorting order.", "Arguments": ":param self: TopologicalSorter. An instance of the TopologicalSorter class.\n:param name: str or any hashable object. The name of the node to be added.\n:param val: Any sortable object. The value associated with the node.\n:param after: str or sequence of str. The name(s) of the node(s) that should come before the added node in the sorting order. It can also be the special sentinel value FIRST, representing the first position. Defaults to None.\n:param before: String or sequence of strings. The name(s) of the node(s) that should come after the added node in the sorting order. It can also be the special sentinel value LAST, representing the last position. Defaults to None.\n:return: No return values."}, "tests": ["tests/test_util.py::TestTopologicalSorter::test_sorted_ordering_missing_before_and_after_partials", "tests/test_util.py::TestTopologicalSorter::test_sorted_ordering_missing_after_partial", "tests/test_util.py::TestTopologicalSorter::test_sorted_ordering_conflict_indirect", "tests/test_util.py::TestTopologicalSorter::test_add", "tests/test_util.py::TestTopologicalSorter::test_sorted_ordering_with_partial_fallbacks"], "indent": 8}
{"namespace": "alembic.operations.ops.CreateIndexOp.from_index", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [897, 897], "body_position": [898, 906], "dependency": {"intra_class": ["alembic.operations.ops.CreateIndexOp.__init__"], "intra_file": [], "cross_file": ["alembic.util.sqla_compat", "alembic.util.sqla_compat._get_index_expressions"]}, "requirement": {"Functionality": "This function creates a CreateIndexOp instance based on the given Index object. It extracts the necessary information from the Index object and uses it to initialize the CreateIndexOp instance.", "Arguments": ":param cls: Class. The class of the CreateIndexOp instance.\n:param index: Index. The Index object from which to create the CreateIndexOp instance.\n:return: CreateIndexOp. The created CreateIndexOp instance."}, "tests": ["tests/test_postgresql.py::PostgresqlAutogenRenderTest::test_render_index_nulls_not_distinct_constraint", "tests/test_autogen_render.py::AutogenRenderTest::test_render_add_index_text", "tests/test_autogen_render.py::AutogenRenderTest::test_render_add_index_func", "tests/test_autogen_render.py::RenderNamingConventionTest::test_render_add_index", "tests/test_postgresql.py::PostgresqlAutogenRenderTest::test_jsonb_expression_in_index"], "indent": 8}
{"namespace": "boto.ses.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ses/__init__.py", "signature_position": [38, 38], "body_position": [50, 52], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.regioninfo.connect", "boto.ses.connection.SESConnection"]}, "requirement": {"Functionality": "Connect to a specific region and return a SESConnection object for the Amazon Simple Email Service (SES).", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the `connect` function.\n:return: boto.ses.connection.SESConnection or None. A connection object for the specified region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestSesConnection::test_connect_to_region"], "indent": 4}
{"namespace": "stellar.models.Table.get_table_name", "type": "method", "project_path": "Utilities/stellar", "completion_path": "Utilities/stellar/stellar/models.py", "signature_position": [47, 47], "body_position": [48, 66], "dependency": {"intra_class": ["stellar.models.Table.snapshot", "stellar.models.Table.table_name"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a table name based on the given postfix and whether it is an old table. It first checks if there is a snapshot available and if the snapshot hash is not empty. If the snapshot is not available, it raises an Exception 'Table name requires snapshot'. If the snapshot hash is empty, it raises an Exception 'Snapshot hash is empty.' Then, it constructs the table name by concatenating the table name, snapshot hash, and postfix. If it is an old table, it returns a table name string formatted as 'stellar_{table name}{snapshot hash}{postfix}'. Otherwise, it returns a table name string generated using the hashlib module. It creates a hash by concatenating the table name, snapshot hash, and postfix with the pipe character ('|') in between. The resulting string is encoded in UTF-8 format and then hashed using MD5. The resulting hash is then converted to a hexadecimal string. The first 16 characters of the hexadecimal string are extracted and returned as the table name as 'stellar_{table name}'.", "Arguments": ":param self: Table. An instance of the Table class.\n:param postfix: String. The postfix to be added to the table name.\n:param old: Bool. Whether it is an old table. Defaults to False.\n:return: String. The generated table name."}, "tests": ["tests/test_models.py::test_table"], "indent": 8}
{"namespace": "ehforwarderbot.chat.Chat.add_member", "type": "method", "project_path": "Communications/ehforwarderbot", "completion_path": "Communications/ehforwarderbot/ehforwarderbot/chat.py", "signature_position": [502, 505], "body_position": [533, 540], "dependency": {"intra_class": ["ehforwarderbot.chat.Chat.members"], "intra_file": ["ehforwarderbot.chat.ChatMember", "ehforwarderbot.chat.ChatMember.__init__"], "cross_file": ["ehforwarderbot.middleware.Middleware", "ehforwarderbot.types.ChatID"]}, "requirement": {"Functionality": "This function adds a member to the chat. It creates a ChatMember instance with the given parameters and adds it to the list of members in the chat.", "Arguments": ":param self: Chat. An instance of the Chat class.\n:param name: String. The name of the member.\n:param uid: ChatID. The ID of the member.\n:param alias: Optional string. The alias of the member.\n:param id: ChatID. The ID of the member. Deprecated, use uid instead.\n:param vendor_specific: Dictionary. Any vendor specific attributes.\n:param description: String. A text description of the chat.\n:param middleware: Optional Middleware. Initialize this chat as a part of a middleware.\n:return: ChatMember. The created ChatMember instance."}, "tests": ["tests/test_chat.py::test_add_member"], "indent": 8}
{"namespace": "alembic.script.revision.RevisionMap._topological_sort", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [912, 916], "body_position": [924, 1014], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._revision_map"], "intra_file": ["alembic.script.revision.Revision", "alembic.script.revision.Revision._normalized_down_revisions", "alembic.script.revision.Revision._versioned_down_revisions"], "cross_file": []}, "requirement": {"Functionality": "This function performs a topological sort on a collection of Revision objects based on their dependencies. It returns a list of revision ids in the sorted order.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param revisions: Collection of Revision. A collection of Revision objects to be sorted.\n:param heads: Any. The heads of the revisions to be sorted.\n:return: List of str. The revision ids in the topological sorted order."}, "tests": ["tests/test_revision.py::GraphWithLoopTest::test_revision_dupe_head"], "indent": 8}
{"namespace": "praw.exceptions.RedditErrorItem.error_message", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/exceptions.py", "signature_position": [24, 24], "body_position": [26, 31], "dependency": {"intra_class": ["praw.exceptions.RedditErrorItem.error_type", "praw.exceptions.RedditErrorItem.field", "praw.exceptions.RedditErrorItem.message"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the completed error message string for a RedditErrorItem instance. It concatenates the error type, message (if available), and field (if available) to form the error message like \"{type}: {message} on field {field}\".", "Arguments": ":param self: RedditErrorItem. An instance of the RedditErrorItem class.\n:return: str. The completed error message string."}, "tests": ["tests/unit/test_exceptions.py::TestRedditErrorItem::test_property"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.anomalous.score_sessions", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/anomalous.py", "signature_position": [19, 21], "body_position": [57, 78], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["msticpy.analysis.anomalous_sequence.model.Model", "msticpy.analysis.anomalous_sequence.model.Model.compute_rarest_windows", "msticpy.analysis.anomalous_sequence.model.Model.rare_window_likelihoods", "msticpy.analysis.anomalous_sequence.model.Model.rare_windows", "msticpy.analysis.anomalous_sequence.model.Model.train", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function models sessions using a sliding window approach within a Markov model. It takes a DataFrame as input, which should contain a column for sessions. It then trains the model using the sessions data and computes the likelihood metrics for each session based on the specified window length. The function appends two additional columns to the input DataFrame, one for the computed likelihood and another for the rarest window.", "Arguments": ":param data: pd.DataFrame. The DataFrame containing the sessions data.\n:param session_column: str. The name of the column in the DataFrame that contains the sessions.\n:param window_length: int. The length of the sliding window to use when computing the likelihood metrics for each session.\n:return: pd.DataFrame. The input DataFrame with two additional columns appended, one for the computed likelihood and another for the rarest window."}, "tests": ["tests/analysis/test_anom_seq.py::TestAnomalous::test_score_sessions"], "indent": 4}
{"namespace": "whereami.predict.crossval", "type": "function", "project_path": "Utilities/whereami", "completion_path": "Utilities/whereami/whereami/predict.py", "signature_position": [25, 25], "body_position": [26, 39], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["whereami.get_data.get_train_data", "whereami.pipeline.get_model"]}, "requirement": {"Functionality": "Perform cross-validation on a given classifier using the specified data. First, if the input data X or labels y are not provided, the function will retrieve them from a given path. Then, if the number of samples in X is less than the number of folds, it will raise a ValueError 'There are not enough samples ({length of X}). Need at least {folds number}.'.\nNext, if no classifier model is provided, it will obtain one from the given path.\nIt then prints \"KFold folds={folds number}, running {n} times\". The function then performs cross-validation by iterating n times. In each iteration, it  evaluate the performance of the classifier on each fold, and calculates the average accuracy. After each iteration, it prints \"{iteration number (starting from 1)}/{n}: {average accuracy of the iteration}\". Finally, after all iterations are complete, it prints \"-------- total --------\" and then prints the total average accuracy obtained from all iterations and returns this value.", "Arguments": ":param clf: Classifier. The classifier to be used for cross-validation. If not provided, it retrieves the classifier from the specified path.\n:param X: Array-like. The input data features. If not provided, it retrieves the training data features from the specified path.\n:param y: Array-like. The target variable. If not provided, it retrieves the training data target variable from the specified path.\n:param folds: Integer. The number of folds to be used in cross-validation. Defaults to 10.\n:param n: Integer. The number of times to run cross-validation. Defaults to 5.\n:param path: String. The path to the training data. If not provided, the data is assumed to be already provided in X and y.\n:return: Float. The average score obtained from cross-validation."}, "tests": ["tests/all_test.py::test_crossval"], "indent": 4}
{"namespace": "faker.utils.loading.find_available_locales", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/loading.py", "signature_position": [41, 41], "body_position": [42, 49], "dependency": {"intra_class": [], "intra_file": ["faker.utils.loading.list_module"], "cross_file": []}, "requirement": {"Functionality": "This function finds and returns a list of available locales based on the given list of providers. It iterates through each provider, imports the provider module, checks if it is localized, and retrieves the list of languages from the module. The available locales are then updated with the languages found and returned in sorted order.", "Arguments": ":param providers: List of strings. A list of provider paths.\n:return: List of strings. A sorted list of available locales."}, "tests": ["tests/utils/test_utils.py::UtilsTestCase::test_find_available_locales"], "indent": 4}
{"namespace": "pycoin.bloomfilter.filter_size_required", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/bloomfilter.py", "signature_position": [10, 15], "body_position": [16, 17], "dependency": {"intra_class": [], "intra_file": ["pycoin.bloomfilter.LOG_2"], "cross_file": []}, "requirement": {"Functionality": "Calculate the required size of a filter based on the number of elements and the desired false positive probability. The function uses a formula: '(-1 / pow(log(2), 2) * element_count * log(false_positive_probability)) / 8' to calculate the size in bytes and ensures that it does not exceed a maximum size.", "Arguments": ":param element_count: Integer. The number of elements in the filter.\n:param false_positive_probability: Float. The desired false positive probability.\n:return: Integer. The required size of the filter in bytes."}, "tests": ["tests/bloomfilter_test.py::BloomFilterTest::test_filter_size_required"], "indent": 4}
{"namespace": "sacred.utils.iterate_flattened_separately", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [410, 410], "body_position": [418, 435], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.PATHCHANGE", "sacred.utils.is_non_empty_dict", "sacred.utils.iterate_flattened_separately", "sacred.utils.join_paths"], "cross_file": []}, "requirement": {"Functionality": "This function recursively iterates over the items of a dictionary in a specific order. It first iterates over manually sorted keys, then over all items that are non-dictionary values (sorted by keys), and finally over the rest of the items (sorted by keys). It provides full dotted paths for every leaf. Before iterating into non-empty dictionary values, it also yields the key with the path change token as the value.", "Arguments": ":param dictionary: Dictionary. The dictionary to iterate over.\n:param manually_sorted_keys: List of keys. The keys that should be iterated over first, in the specified order. Defaults to an empty list.\n:return: Generator. Yields key-value pairs in the specified order, with full dotted paths for every leaf."}, "tests": ["tests/test_utils.py::test_iterate_flattened_separately"], "indent": 4}
{"namespace": "mrjob.hadoop.HadoopJobRunner._args_for_streaming_step", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [479, 479], "body_position": [480, 485], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner.get_hadoop_bin", "mrjob.hadoop.HadoopJobRunner.get_hadoop_streaming_jar"], "intra_file": [], "cross_file": ["mrjob.bin.MRJobBinRunner._hadoop_streaming_jar_args"]}, "requirement": {"Functionality": "This function returns the arguments needed to run a Hadoop streaming step. It first checks if the Hadoop streaming jar is available. If not, it raises an exception with the error message 'no Hadoop streaming jar'. Then it constructs the command line arguments for the Hadoop streaming step: the Hadoop binary, 'jar', the Hadoop streaming jar, and the arguments for the Hadoop streaming step.", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:param step_num: int. The step number for which the arguments are being generated.\n:return: list. The arguments needed to run the Hadoop streaming step."}, "tests": ["tests/test_hadoop.py::StreamingArgsTestCase::test_basic_mapper_pre_yarn", "tests/test_hadoop.py::StreamingArgsTestCase::test_basic_mapper", "tests/test_hadoop.py::StreamingArgsTestCase::test_basic_reducer", "tests/test_hadoop.py::StreamingArgsTestCase::test_pre_filters", "tests/test_hadoop.py::StreamingArgsTestCase::test_pre_filter_escaping"], "indent": 8}
{"namespace": "mingus.core.intervals.is_perfect_consonant", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [507, 507], "body_position": [516, 517], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.measure"], "cross_file": []}, "requirement": {"Functionality": "This function checks if the interval between two notes is a perfect consonant. Perfect consonances are either unisons, perfect fourths or fifths, or octaves (which is the same as a unison in this model). Perfect fourths are usually included as well, but can be excluded if desired.\n", "Arguments": ":param note1: str. The first note.\n:param note2: str. The second note.\n:param include_fourths: bool. Whether to include perfect fourths as perfect consonances. Defaults to True. \n:return: bool. True if the interval is a perfect consonant one, False otherwise.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_is_perfect_consonant"], "indent": 4}
{"namespace": "pyramid.threadlocal.ThreadLocalManager.get", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/threadlocal.py", "signature_position": [25, 25], "body_position": [26, 29], "dependency": {"intra_class": ["pyramid.threadlocal.ThreadLocalManager.default", "pyramid.threadlocal.ThreadLocalManager.stack"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the topmost item from the stack of thread-local objects. If the stack is empty, it calls the default value.", "Arguments": ":param self: ThreadLocalManager. An instance of the ThreadLocalManager class.\n:return: The topmost object from the stack or a new object created by the default method."}, "tests": ["tests/test_threadlocal.py::TestThreadLocalManager::test_set_get_and_clear", "tests/test_threadlocal.py::TestThreadLocalManager::test_push_and_pop", "tests/test_threadlocal.py::TestThreadLocalManager::test_init", "tests/test_threadlocal.py::TestThreadLocalManager::test_default"], "indent": 8}
{"namespace": "oletools.ooxml.ZipSubFile.read", "type": "method", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/ooxml.py", "signature_position": [312, 312], "body_position": [318, 326], "dependency": {"intra_class": ["oletools.ooxml.ZipSubFile.handle", "oletools.ooxml.ZipSubFile.pos", "oletools.ooxml.ZipSubFile.size", "oletools.ooxml.ZipSubFile.read"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function reads a given number of bytes (or all data) from a stream. It checks if the handle is closed and if the current position is at the end of the file. If so, it returns an empty byte string. Otherwise, it reads the specified number of bytes from the handle, updates the current position, and returns the data.", "Arguments": ":param self: ZipSubFile. An instance of the ZipSubFile class.\n:param size: Integer. The number of bytes to read from the stream. If set to -1, it reads all data from the stream. Defaults to -1.\n:return: Bytes. The data read from the stream."}, "tests": ["tests/ooxml/test_zip_sub_file.py::TestZipSubFile::test_check_size", "tests/ooxml/test_zip_sub_file.py::TestZipSubFile::test_seek_forward", "tests/ooxml/test_zip_sub_file.py::TestZipSubFile::test_read", "tests/ooxml/test_zip_sub_file.py::TestZipSubFile::test_error_read"], "indent": 8}
{"namespace": "kinto.core.utils.instance_uri_registry", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [495, 495], "body_position": [501, 503], "dependency": {"intra_class": [], "intra_file": ["kinto.core.utils.instance_uri"], "cross_file": []}, "requirement": {"Functionality": "This function returns the URI for a given resource, even if there is no request object available. It creates a dummy request object and sets the registry of the request object to the given registry. Then it find the URI.", "Arguments": ":param registry: The registry object to be set as the registry attribute of the dummy request object.\n:param resource_name: The name of the resource for which the URI is to be generated.\n:param **params: Additional parameters.\n:return: The URI for the given resource."}, "tests": ["tests/core/test_utils.py::InstanceURIRegistryTest::test_instance_uri_registry_calls_instance_uri"], "indent": 4}
{"namespace": "mrjob.logs.task._match_task_log_path", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/task.py", "signature_position": [219, 219], "body_position": [230, 250], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.task._PRE_YARN_TASK_LOG_PATH_RE", "mrjob.logs.task._YARN_TASK_LOG_PATH_RE"], "cross_file": ["mrjob.logs.ids._to_job_id"]}, "requirement": {"Functionality": "This function checks if the given path is a task log path, including Spark logs. If it is, it returns a dictionary containing application_id and container_id (on YARN) or attempt_id (on pre-YARN Hadoop), plus log_type (either stdout, stderr, or syslog). Otherwise, it returns None. If the attempt ID is available but does not match the passed job ID, it returns None. Similarly, if the application ID is available but does not match the passed application ID, it returns None.", "Arguments": ":param path: str. The path or URI to check if it is a task log path.\n:param application_id: str. The application ID to filter the logs by (for YARN). Defaults to None.\n:param job_id: str. The job ID to filter the logs by (for pre-YARN Hadoop). Defaults to None.\n:return: dict or None. A dictionary containing the application ID, container ID or attempt ID, and the log type if the path is a task log path. Otherwise, it returns None."}, "tests": ["tests/logs/test_task.py::MatchTaskLogPathTestCase::test_yarn_syslog_gz", "tests/logs/test_task.py::MatchTaskLogPathTestCase::test_pre_yarn_stderr", "tests/logs/test_task.py::MatchTaskLogPathTestCase::test_match_yarn_stderr", "tests/logs/test_task.py::MatchTaskLogPathTestCase::test_yarn_syslog", "tests/logs/test_task.py::MatchTaskLogPathTestCase::test_pre_yarn_syslog"], "indent": 4}
{"namespace": "praw.models.listing.generator.ListingGenerator._extract_sublist", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/models/listing/generator.py", "signature_position": [69, 69], "body_position": [70, 84], "dependency": {"intra_class": [], "intra_file": ["praw.models.listing.listing.FlairListing.CHILD_ATTRIBUTE"], "cross_file": ["praw.models.listing.listing.FlairListing", "praw.models.listing.listing.ModNoteListing"]}, "requirement": {"Functionality": "This function extracts a sublist from the given listing. It checks the type of the listing and returns the appropriate sublist based on the type. If the type is a list [FlairListing, ModNoteListing], it returns the second element of the list. If the type is a dictionary, it checks for specific listing types and returns the corresponding sublist. If none of the recognized listing types are found, it raises a ValueError \"The generator returned a dictionary PRAW didn't recognize. File a bug report at PRAW.\"", "Arguments": ":param self: ListingGenerator. An instance of the ListingGenerator class.\n:param listing: The listing to extract the sublist from. It can be a list or a dictionary.\n:return: The extracted sublist."}, "tests": ["tests/unit/models/listing/test_generator.py::TestListingGenerator::test_bad_dict"], "indent": 8}
{"namespace": "boltons.setutils.complement", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/setutils.py", "signature_position": [475, 475], "body_position": [555, 559], "dependency": {"intra_class": [], "intra_file": ["boltons.setutils._ComplementSet", "boltons.setutils._ComplementSet.__init__", "boltons.setutils._ComplementSet.complemented"], "cross_file": []}, "requirement": {"Functionality": "This function takes a set or any other iterable and converts it into a complement set. A complement set keeps track of what it does not contain, unlike a regular set which keeps track of what it contains. The function provides examples and explanations of how complement sets work and their advantages over regular sets.", "Arguments": ":param wrapped: set. A set or any other iterable which should be turned into a complement set.\n:return: _ComplementSet. The created complement set instance."}, "tests": ["tests/test_setutils.py::test_complement_set"], "indent": 4}
{"namespace": "falcon.request.Request.remote_addr", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [950, 950], "body_position": [951, 956], "dependency": {"intra_class": ["falcon.request.Request.env"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the remote address of the request. It first tries to get the remote address from the 'REMOTE_ADDR' key in the 'env' dictionary. If the key is not found, it returns the default value of '127.0.0.1'.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The remote address of the request."}, "tests": ["tests/test_request_access_route.py::test_remote_addr_non_default", "tests/test_request_access_route.py::test_remote_addr_default", "tests/test_request_access_route.py::test_remote_addr_only"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.idle_done", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [984, 984], "body_position": [998, 1000], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._consume_until_tagged_response", "imapclient.imapclient.IMAPClient._idle_tag", "imapclient.imapclient.IMAPClient._imap"], "intra_file": ["imapclient.imapclient.logger"], "cross_file": []}, "requirement": {"Functionality": "Take the IMAP server out of IDLE mode. It sends the \"DONE\" command to the server and returns the response from the server, which includes the command text and a list of parsed idle responses received since the last call to \"idle_check()\".", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:return: Tuple. The return value is a tuple of the form (command_text, idle_responses), where command_text is the text sent by the server when the IDLE command finished and idle_responses is a list of parsed idle responses received since the last call to idle_check()."}, "tests": ["tests/test_imapclient.py::TestIdleAndNoop::test_idle_done"], "indent": 8}
{"namespace": "rest_framework.fields.Field.root", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [613, 613], "body_position": [617, 620], "dependency": {"intra_class": ["rest_framework.fields.Field.parent"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the top-level serializer for a given field. It iteratively checks if the field has a parent and assigns the parent to the root variable until there is no parent. Finally, it returns the root serializer.", "Arguments": ":param self: Field. An instance of the Field class.\n:return: Field. The top-level serializer for the given field."}, "tests": ["tests/test_relations.py::TestManyRelatedField::test_get_value_multi_dictionary_partial", "tests/test_relations.py::TestManyRelatedField::test_get_value_regular_dictionary_partial", "tests/test_fields.py::Test5087Regression::test_parent_binding"], "indent": 8}
{"namespace": "mackup.utils.get_dropbox_folder_location", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [196, 196], "body_position": [203, 211], "dependency": {"intra_class": [], "intra_file": ["mackup.utils.error"], "cross_file": ["mackup.constants.ERROR_UNABLE_TO_FIND_STORAGE", "mackup.constants"]}, "requirement": {"Functionality": "This function tries to locate the Dropbox folder by reading the host.db file whose path is like \"{home}.dropbox/host\". It then decodes the Dropbox home path and returns it.", "Arguments": ":param: No input parameters.\n:return: str. The full path to the current Dropbox folder."}, "tests": ["tests/utils_test.py::TestMackup::test_failed_backup_location"], "indent": 4}
{"namespace": "tools.cgrep.group_diff", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [301, 301], "body_position": [312, 321], "dependency": {"intra_class": [], "intra_file": ["tools.cgrep.get_ip_parents"], "cross_file": []}, "requirement": {"Functionality": "This function compares two different group objects and returns the common lines, the differences from the first object to the second object, and the differences from the second object to the first object.", "Arguments": ":param options: The options sent to the script.\n:param db: The network and service definitions.\n:return: tuple. The common lines, the differences from the first object to the second object, and the differences from the second object to the first object."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_group_diff", "tests/lib/cgrep_test.py::CgrepTest::test_group_diff_identical"], "indent": 2}
{"namespace": "pylatex.utils._latex_item_to_string", "type": "function", "project_path": "Text-Processing/PyLaTeX", "completion_path": "Text-Processing/PyLaTeX/pylatex/utils.py", "signature_position": [204, 204], "body_position": [223, 234], "dependency": {"intra_class": [], "intra_file": ["pylatex.utils.escape_latex"], "cross_file": ["pylatex.base_classes.latex_object.LatexObject", "pylatex.base_classes", "pylatex.base_classes.latex_object.LatexObject.dumps", "pylatex.base_classes.latex_object.LatexObject.dumps_as_content"]}, "requirement": {"Functionality": "This function converts an object to a string representation in LaTeX format. It first checks if the input object is a Latex object and further convert the latex into a string. If the input object is not a Latex object, the function converts it to a string. Then, the function escapes the LaTeX special characters in the string based on the input parameter `escape` and returns the string.", "Arguments": ":param item: object. The object that needs to be converted to a string.\n:param escape: bool. Flag that indicates if escaping is needed for LaTeX special characters.\n:param as_content: bool. Indicates whether the item should be dumped as content.\n:return: NoEscape. The converted string in LaTeX format."}, "tests": ["tests/test_utils_latex_item_to_string.py::test_string", "tests/test_utils_latex_item_to_string.py::test_user_latex_object", "tests/test_utils_latex_item_to_string.py::test_foreign_object"], "indent": 4}
{"namespace": "chatette.parsing.UnitDefBuilder._build_modifiers_repr", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [125, 125], "body_position": [126, 128], "dependency": {"intra_class": ["chatette.parsing.UnitDefBuilder.arg_name"], "intra_file": ["chatette.parsing.ItemBuilder", "chatette.parsing.ItemBuilder._build_modifiers_repr"], "cross_file": ["chatette.modifiers.representation.ModifiersRepresentation.argument_name"]}, "requirement": {"Functionality": "This function builds the representation of modifiers for a UnitDefBuilder instance. It first gets the modifiers, then sets the argument name of the modifiers to the arg name of the UnitDefBuilder instance. Finally, it returns the modifiers.", "Arguments": ":param self: UnitDefBuilder. An instance of the UnitDefBuilder class.\n:return: The representation of modifiers for the UnitDefBuilder instance."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestAliasDefBuilder::test_create_concrete", "tests/unit-testing/parsing/test_init.py::TestSlotDefBuilder::test_create_concrete", "tests/unit-testing/parsing/test_init.py::TestIntentDefBuilder::test_create_concrete"], "indent": 8}
{"namespace": "parsel.utils.extract_regex", "type": "function", "project_path": "Text-Processing/parsel", "completion_path": "Text-Processing/parsel/parsel/utils.py", "signature_position": [58, 60], "body_position": [66, 84], "dependency": {"intra_class": [], "intra_file": ["parsel.utils.flatten"], "cross_file": []}, "requirement": {"Functionality": "This function extracts a list of strings from the given text using a regular expression. It follows certain policies to determine which strings to extract:\n- If the regular expression contains a named group called \"extract\", the value of that group will be returned.\n- If the regular expression contains multiple numbered groups, all those groups will be returned as a flattened list.\n- If the regular expression doesn't contain any groups, the entire matching string will be returned.", "Arguments": ":param regex: Union[str, Pattern[str]]. The regular expression pattern to match against the text. It can be either a string or a compiled regular expression pattern.\n:param text: str. The text to search for matches.\n:param replace_entities: bool. Optional. Whether to replace HTML entities in the extracted strings. Defaults to True.\n:return: List[str]. A list of extracted strings from the text."}, "tests": ["tests/test_utils.py::test_extract_regex"], "indent": 4}
{"namespace": "mingus.containers.note.Note.from_int", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note.py", "signature_position": [202, 202], "body_position": [211, 213], "dependency": {"intra_class": ["mingus.containers.note.Note.name", "mingus.containers.note.Note.octave"], "intra_file": [], "cross_file": ["mingus.core.notes", "mingus.core.notes.int_to_note"]}, "requirement": {"Functionality": "This function sets the Note instance based on the given integer value. It calculates the name and octave of the Note based on the integer value.\n", "Arguments": ":param self: Note. An instance of the Note class.\n:param integer: int. The integer value representing the Note.\n:return: Note. The Note instance with the name and octave set based on the given integer value.\n"}, "tests": ["tests/unit/containers/test_note.py::test_Note::test_from_int"], "indent": 8}
{"namespace": "falcon.routing.converters.IntConverter.convert", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/routing/converters.py", "signature_position": [69, 69], "body_position": [70, 92], "dependency": {"intra_class": ["falcon.routing.converters.IntConverter._max", "falcon.routing.converters.IntConverter._min", "falcon.routing.converters.IntConverter._num_digits"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts a given value to an integer based on certain conditions. It checks if the number of digits in the value matches the specified number of digits. It also checks if the value contains any whitespace characters before or after the number. If any of these conditions are not met, it returns None. It then tries to convert the value to an integer. If the conversion fails, it returns None. Finally, it checks if the converted value is within the specified minimum and maximum range. If it is not, it returns None. If all conditions are met, it returns the converted integer value.", "Arguments": ":param self: IntConverter. An instance of the IntConverter class.\n:param value: The value to be converted to an integer.\n:return: int. The converted integer value."}, "tests": ["tests/test_uri_converters.py::test_int_converter"], "indent": 8}
{"namespace": "datasette.utils.call_with_supported_arguments", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1003, 1003], "body_position": [1004, 1005], "dependency": {"intra_class": [], "intra_file": ["datasette.utils._gather_arguments"], "cross_file": []}, "requirement": {"Functionality": "This function calls the given function with the supported arguments. It gathers the arguments that are supported by the function and then calls the function with those arguments.", "Arguments": ":param fn: Function. The function to be called.\n:param kwargs: Keyword arguments. The arguments to be passed to the function.\n:return: The return value of the function call."}, "tests": ["tests/test_utils.py::test_call_with_supported_arguments"], "indent": 4}
{"namespace": "wal_e.log_help.WalELogger.fmt_logline", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/log_help.py", "signature_position": [161, 161], "body_position": [162, 179], "dependency": {"intra_class": ["wal_e.log_help.WalELogger._fmt_structured"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Format a log line with the given message, detail, hint, and structured data. It creates a list to format these information, and the forst is \"['MSG: {message}', 'DETAIL: {detail}', 'HINT: {hint}', 'STRUCTURED: {structured data}']\". Then, it joins them with a newline character to obtain the log line.", "Arguments": ":param msg: String. The main message to be included in the log line.\n:param detail: String [optional]. Additional details to be included in the log line.\n:param hint: String [optional]. A hint or suggestion related to the log message.\n:param structured: Dictionary [optional]. Additional structured data to be included in the log line.\n:return: String. The formatted log line."}, "tests": ["tests/test_log_help.py::test_fmt_logline_simple"], "indent": 8}
{"namespace": "jwt.algorithms.HMACAlgorithm.from_jwk", "type": "method", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/algorithms.py", "signature_position": [290, 290], "body_position": [291, 304], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["jwt.exceptions.InvalidKeyError", "jwt.types.JWKDict", "jwt.utils.base64url_decode"]}, "requirement": {"Functionality": "This function takes a JWK (JSON Web Key) as input and returns the corresponding HMAC (Hash-based Message Authentication Code) key. It first checks if the input is a valid JSON string or dictionary. Then, it verifies if the key type is \"oct\" (indicating HMAC). Finally, it decodes and returns the HMAC key.", "Arguments": ":param jwk: str or JWKDict. The JWK (JSON Web Key) to extract the HMAC key from. It can be either a JSON string or a dictionary.\n:return: bytes. The extracted HMAC key."}, "tests": ["tests/test_algorithms.py::TestAlgorithms::test_hmac_from_jwk_should_raise_exception_if_not_hmac_key", "tests/test_algorithms.py::TestAlgorithms::test_hmac_jwk_should_parse_and_verify"], "indent": 8}
{"namespace": "pyramid.util.InstancePropertyHelper.apply", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [184, 184], "body_position": [186, 187], "dependency": {"intra_class": ["pyramid.util.InstancePropertyHelper.apply_properties", "pyramid.util.InstancePropertyHelper.properties"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function applies all the configured properties to the target instance.", "Arguments": ":param self: InstancePropertyHelper. An instance of the InstancePropertyHelper class.\n:param target: The target instance to which the properties will be applied.\n:return: No return values."}, "tests": ["tests/test_util.py::Test_InstancePropertyHelper::test_add_property", "tests/test_util.py::Test_InstancePropertyHelper::test_apply_multiple_times"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage.categorymembers", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [1047, 1047], "body_position": [1058, 1060], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._categorymembers", "wikipediaapi.WikipediaPage._fetch"], "intra_file": ["wikipediaapi.PagesDict"], "cross_file": []}, "requirement": {"Functionality": "This function returns all pages belonging to the current category. It is a wrapper for the MediaWiki API's query+categorymembers module.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: PagesDict. A dictionary containing all pages belonging to the current category."}, "tests": ["tests/categorymembers_test.py::TestCategoryMembers::test_links_multi_page_count", "tests/categorymembers_test.py::TestCategoryMembers::test_links_single_page_titles", "tests/categorymembers_test.py::TestCategoryMembers::test_links_single_page_count", "tests/categorymembers_test.py::TestCategoryMembers::test_links_multi_page_titles"], "indent": 8}
{"namespace": "rest_framework.templatetags.rest_framework.add_query_param", "type": "function", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/templatetags/rest_framework.py", "signature_position": [148, 148], "body_position": [152, 155], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["rest_framework.utils.urls.replace_query_param"]}, "requirement": {"Functionality": "This function adds a query parameter to the current request URL and returns the new URL. It first gets the full path of the request URL, converts it to a URI, replaces the query parameter with the given key and value, and then escapes the URI before returning it.", "Arguments": ":param request: The current request object.\n:param key: The key of the query parameter to be added.\n:param val: The value of the query parameter to be added.\n:return: The new URL with the added query parameter."}, "tests": ["tests/test_templatetags.py::TemplateTagTests::test_add_query_param_with_non_latin_character"], "indent": 4}
{"namespace": "zxcvbn.scoring.dictionary_guesses", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [263, 264], "body_position": [265, 271], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.scoring.l33t_variations", "zxcvbn.scoring.uppercase_variations"], "cross_file": []}, "requirement": {"Functionality": "Calculate the number of guesses needed to crack a password based on the given match. It calculates the base guesses, uppercase variations, l33t variations, and reversed variations, and returns the product of these values.", "Arguments": ":param match: Dictionary. A dictionary containing information about the password match, including the rank, whether it is reversed, and other properties.\n:return: Integer. The number of guesses needed to crack the password."}, "tests": ["tests/scoring_test.py::test_dictionary_guesses"], "indent": 4}
{"namespace": "mrjob.job.MRJob.execute", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [676, 678], "body_position": [679, 692], "dependency": {"intra_class": ["mrjob.job.MRJob.options", "mrjob.job.MRJob.run_combiner", "mrjob.job.MRJob.run_job", "mrjob.job.MRJob.run_mapper", "mrjob.job.MRJob.run_reducer", "mrjob.job.MRJob.run_spark"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function executes a MapReduce job based on the options specified. It checks the value of the options and calls the corresponding method to run the mapper, combiner, reducer, or spark job. If none of the options are specified, it just runs job.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:return: No return values."}, "tests": ["tests/test_job.py::RunSparkTestCase::test_spark", "tests/test_job.py::RunSparkTestCase::test_too_many_args", "tests/test_job.py::RunSparkTestCase::test_wrong_step_num", "tests/test_job.py::RunSparkTestCase::test_too_few_args", "tests/test_job.py::RunSparkTestCase::test_wrong_step_type"], "indent": 8}
{"namespace": "falcon.inspect.inspect_app", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [29, 29], "body_position": [41, 46], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect.AppInfo", "falcon.inspect.AppInfo.__init__", "falcon.inspect.inspect_error_handlers", "falcon.inspect.inspect_middleware", "falcon.inspect.inspect_routes", "falcon.inspect.inspect_sinks", "falcon.inspect.inspect_static_routes"], "cross_file": ["falcon.app.App", "falcon.app.App._ASGI"]}, "requirement": {"Functionality": "This function inspects an application by calling several helper functions to gather information about the routes, static routes, sinks, error handlers, and middleware of the application. It then creates an AppInfo object with the gathered information and returns it.", "Arguments": ":param app: App. The application to inspect. It can be an instance of either `falcon.App` or `falcon.asgi.App`.\n:return: AppInfo. An object containing information about the application."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_app_no_sink", "tests/test_inspect.py::TestStringVisitor::test_app_no_errors", "tests/test_inspect.py::TestStringVisitor::test_app_static_routes", "tests/test_inspect.py::TestInspectApp::test_dependent_middleware", "tests/test_inspect.py::test_info_class_repr_to_string"], "indent": 4}
{"namespace": "sumy.evaluation.rouge._recon_lcs", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/evaluation/rouge.py", "signature_position": [81, 81], "body_position": [90, 104], "dependency": {"intra_class": [], "intra_file": ["sumy.evaluation.rouge._get_index_of_lcs", "sumy.evaluation.rouge._lcs"], "cross_file": []}, "requirement": {"Functionality": "This function returns the Longest Common Subsequence (LCS) between two sequences of words. It designs a helper function to recursively reconstruct the LCS based on a table that saves the length of LCS at any position.", "Arguments": ":param x: List of words. The first sequence of words.\n:param y: List of words. The second sequence of words.\n:return: List of words. The LCS of x and y."}, "tests": ["tests/test_evaluation/test_evaluation_rouge.py::test_recon_lcs"], "indent": 4}
{"namespace": "datasette.utils.escape_css_string", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [338, 338], "body_position": [339, 342], "dependency": {"intra_class": [], "intra_file": ["datasette.utils._css_re"], "cross_file": []}, "requirement": {"Functionality": "This function escapes special characters in a CSS string by replacing them with their Unicode escape sequences. It also replaces Windows-style line breaks with Unix-style line breaks.", "Arguments": ":param s: String. The CSS string to be escaped.\n:return: String. The escaped CSS string."}, "tests": ["tests/test_utils.py::test_escape_css_string"], "indent": 4}
{"namespace": "boto.dynamodb2.fields.BaseSchemaField.definition", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/fields.py", "signature_position": [27, 27], "body_position": [40, 43], "dependency": {"intra_class": ["boto.dynamodb2.fields.BaseSchemaField.data_type", "boto.dynamodb2.fields.BaseSchemaField.name"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the attribute definition structure that DynamoDB expects for a schema field. It includes the attribute name and attribute type.", "Arguments": ":param self: BaseSchemaField. An instance of the BaseSchemaField class.\n:return: Dictionary. The attribute definition structure that DynamoDB expects."}, "tests": ["tests/unit/dynamodb2/test_table.py::SchemaFieldsTestCase::test_alternate_type", "tests/unit/dynamodb2/test_table.py::SchemaFieldsTestCase::test_hash_key", "tests/unit/dynamodb2/test_table.py::SchemaFieldsTestCase::test_range_key"], "indent": 8}
{"namespace": "alembic.operations.ops.DropIndexOp.to_index", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [1060, 1062], "body_position": [1063, 1073], "dependency": {"intra_class": ["alembic.operations.ops.DropIndexOp._reverse", "alembic.operations.ops.DropIndexOp.index_name", "alembic.operations.ops.DropIndexOp.kw", "alembic.operations.ops.DropIndexOp.schema", "alembic.operations.ops.DropIndexOp.table_name"], "intra_file": ["alembic.operations.ops.CreateIndexOp.columns"], "cross_file": ["alembic.operations.schemaobj", "alembic.operations.schemaobj.SchemaObjects", "alembic.operations.schemaobj.SchemaObjects.index", "alembic.runtime.migration.MigrationContext"]}, "requirement": {"Functionality": "This function converts a DropIndexOp instance into an Index instance. It creates a schema object based on the given migration context and then creates an index using the index name, table name, columns, schema, and other keyword arguments provided in the DropIndexOp instance.", "Arguments": ":param self: DropIndexOp. An instance of the DropIndexOp class.\n:param migration_context: Optional. An optional MigrationContext object. Defaults to None.\n:return: Index. The created Index instance."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_create_index", "tests/test_op.py::ObjectFromToTest::test_create_index_add_kw", "tests/test_op.py::ObjectFromToTest::test_drop_index_add_kw", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_index"], "indent": 8}
{"namespace": "asyncssh.packet.SSHPacket.check_end", "type": "method", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/packet.py", "signature_position": [103, 103], "body_position": [106, 107], "dependency": {"intra_class": [], "intra_file": ["asyncssh.packet.PacketDecodeError"], "cross_file": []}, "requirement": {"Functionality": "This function checks if all the data in the SSHPacket instance has been consumed. If there is any remaining data, it raises an error.", "Arguments": ":param self: SSHPacket. An instance of the SSHPacket class.\n:return: No return values."}, "tests": ["tests/test_packet.py::_TestPacket::test_packet"], "indent": 8}
{"namespace": "pyramid.util.InstancePropertyHelper.set_property", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [170, 170], "body_position": [172, 173], "dependency": {"intra_class": ["pyramid.util.InstancePropertyHelper.apply_properties", "pyramid.util.InstancePropertyHelper.make_property"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function applies a single property to an instance. It creates a property using the given callable and optional name and reify parameters, and then applies the property to the target instance.", "Arguments": ":param cls: type. InstancePropertyHelper.\n:param target: The instance to apply the property to.\n:param callable: The callable object that defines the behavior of the property.\n:param name: str. The name of the property. If not specified, the name of the callable is used. Defaults to None.\n:param reify: bool. A boolean indicating whether the property should be reified. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_util.py::Test_InstancePropertyHelper::test_callable_with_name_reify", "tests/test_util.py::Test_InstancePropertyHelper::test_callable_with_name", "tests/test_util.py::Test_InstancePropertyHelper::test_callable", "tests/test_util.py::Test_InstancePropertyHelper::test_property_with_reify", "tests/test_util.py::Test_InstancePropertyHelper::test_property_with_name"], "indent": 8}
{"namespace": "mopidy.config.types.LogColor.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [339, 339], "body_position": [340, 342], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_choice", "mopidy.internal.log.COLORS", "mopidy.config.validators", "mopidy.internal.log"]}, "requirement": {"Functionality": "Deserialize a value by decoding it and validating if it is a valid choice from a list of colors. It returns the lowercase value.", "Arguments": ":param self: LogColor. An instance of the LogColor class.\n:param value: The value to be deserialized.\n:return: The deserialized value."}, "tests": ["tests/config/test_types.py::TestLogColor::test_deserialize", "tests/config/test_types.py::TestLogColor::test_deserialize_enforces_choices"], "indent": 8}
{"namespace": "bentoml._internal.models.model.Model.from_fs", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/models/model.py", "signature_position": [219, 219], "body_position": [220, 234], "dependency": {"intra_class": ["bentoml._internal.models.model.Model.__init__", "bentoml._internal.models.model.Model.validate"], "intra_file": ["bentoml._internal.models.model.MODEL_YAML_FILENAME", "bentoml._internal.models.model.ModelInfo", "bentoml._internal.models.model.ModelInfo.from_yaml_file", "bentoml._internal.models.model.ModelInfo.tag"], "cross_file": ["bentoml.exceptions.BentoMLException"]}, "requirement": {"Functionality": "This function creates a Model instance based on the given item_fs. It reads the model information from the yaml file in the item_fs and creates a ModelInfo object. Then it creates a Model instance with the tag, model_fs, info, and _internal attributes set. Finally, it validates the created Model instance and returns it.", "Arguments": ":param cls: Type[Model]. The class object of the Model class.\n:param item_fs: FS. The file system object from which to read the model information.\n:return: Model. The created Model instance."}, "tests": ["tests/unit/_internal/models/test_model.py::test_load_bad_model", "tests/unit/_internal/models/test_model.py::test_model_export_import"], "indent": 8}
{"namespace": "mingus.core.intervals.minor_third", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [178, 178], "body_position": [179, 180], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.third"], "cross_file": []}, "requirement": {"Functionality": "This function returns the minor third note above the given note.\n", "Arguments": ":param note: str. The starting note for calculating the minor third interval.\n:return: str. The adjusted note that represents a minor third interval above the given note.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_minor_thirds"], "indent": 4}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.get_response", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [68, 68], "body_position": [72, 86], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.exception_queue", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.response_map"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the latest response from a JsonRpcClient instance. It checks the response map for the given request_id and owner_uri in priority order: Response, Event, Exception. If a response is found, it is returned. If no response is found, an exception is raised if available. If no exception is available, None is returned.", "Arguments": ":param self: JsonRpcClient. An instance of the JsonRpcClient class.\n:param request_id: int. The ID of the request to retrieve the response for. Defaults to 0.\n:param owner_uri: int. The URI of the owner to retrieve the response for. Defaults to 0.\n:return: The latest response from the JsonRpcClient instance, or None if no response is available."}, "tests": ["tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_response_stream_closed_exception", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_response_dequeued", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_receive_invalid_response_exception", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_get_response_with_id"], "indent": 8}
{"namespace": "alembic.operations.schemaobj.SchemaObjects.unique_constraint", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/schemaobj.py", "signature_position": [121, 128], "body_position": [129, 140], "dependency": {"intra_class": ["alembic.operations.schemaobj.SchemaObjects.metadata"], "intra_file": [], "cross_file": ["alembic.util.sqla_compat", "alembic.util.sqla_compat._ConstraintNameDefined"]}, "requirement": {"Functionality": "Create a unique constraint on a table in the schema. It creates a table object based on the input parameters and adds a unique constraint to it. The table object is then updated with the new constraint.", "Arguments": ":param self: SchemaObjects. An instance of the `SchemaObjects` class.\n:param name: Optional. The name of the unique constraint. If not provided, a default name will be generated.\n:param source: String. The name of the table on which the unique constraint is to be created.\n:param local_cols: Sequence of strings. The names of the columns on which the unique constraint is to be applied.\n:param schema: Optional. The name of the schema in which the table resides. If not provided, the default schema will be used.\n:param kw: Additional keyword arguments that can be passed to the UniqueConstraint constructor.\n:return: UniqueConstraint. The created unique constraint object."}, "tests": ["tests/test_op.py::ObjectFromToTest::test_create_unique_constraint", "tests/test_op.py::ObjectFromToTest::test_drop_unique_constraint_change_name", "tests/test_op.py::ObjectFromToTest::test_drop_unique_constraint", "tests/test_op.py::ObjectFromToTest::test_create_unique_constraint_add_kw"], "indent": 8}
{"namespace": "dash._grouping.validate_grouping", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_grouping.py", "signature_position": [201, 201], "body_position": [206, 224], "dependency": {"intra_class": [], "intra_file": ["dash._grouping.SchemaKeysValidationError", "dash._grouping.SchemaKeysValidationError.check", "dash._grouping.SchemaLengthValidationError", "dash._grouping.SchemaLengthValidationError.check", "dash._grouping.SchemaTypeValidationError", "dash._grouping.SchemaTypeValidationError.check", "dash._grouping.validate_grouping"], "cross_file": []}, "requirement": {"Functionality": "This function validates whether the provided grouping conforms to the provided schema. If full shema is none, it use the schema to replace. It recursively checks the grouping against the schema and raises an error by different type of shcema to check the grouping, full schema, path and different expected_type like type, length, set.", "Arguments": ":param grouping: The grouping to be validated.\n:param schema: The schema to validate against.\n:param full_schema: Optional. The full schema to use for validation. Defaults to the provided schema.\n:param path: Optional. The current path in the schema. Defaults to an empty tuple.\n:return: No return values. Raises a SchemaValidationError if the validation fails."}, "tests": ["tests/unit/library/test_grouping.py::test_validate_schema_mixed", "tests/unit/library/test_grouping.py::test_validate_schema_grouping_list", "tests/unit/library/test_grouping.py::test_validate_schema_dict"], "indent": 4}
{"namespace": "dash._grouping.map_grouping", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_grouping.py", "signature_position": [113, 113], "body_position": [123, 129], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["dash._utils.AttributeDict"]}, "requirement": {"Functionality": "This function maps a given function over all the scalar values of a grouping while maintaining the grouping structure. It recursively applies the function to each scalar value in the grouping and returns a new grouping with the same structure but with updated scalar values.", "Arguments": ":param fn: Function. A single-argument function that accepts and returns scalar grouping values.\n:param grouping: Any. The grouping to map the function over.\n:return: Any. A new grouping with the same structure as the input grouping, but with scalar values updated by the input function."}, "tests": ["tests/unit/library/test_grouping.py::test_map_grouping_mixed", "tests/unit/library/test_grouping.py::test_map_grouping_dict", "tests/unit/library/test_grouping.py::test_map_grouping_scalar", "tests/unit/library/test_grouping.py::test_map_grouping_list"], "indent": 4}
{"namespace": "ydata_profiling.model.summarizer.BaseSummarizer.summarize", "type": "method", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/model/summarizer.py", "signature_position": [34, 36], "body_position": [42, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["ydata_profiling.config.Settings", "ydata_profiling.model.handler.Handler.handle"]}, "requirement": {"Functionality": "This function summarizes a given series of data based on the specified configuration and data type.", "Arguments": ":param self: BaseSummarizer. An instance of the BaseSummarizer class.\n:param config: Settings. The configuration settings for the summarization process.\n:param series: pd.Series. The series of data to be summarized.\n:param dtype: Type[VisionsBaseType]. The data type of the series.\n:return: dict. The summary of the data."}, "tests": ["tests/unit/test_summarizer.py::test_summarizer"], "indent": 8}
{"namespace": "alembic.command.merge", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [302, 308], "body_position": [326, 355], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.config.Config.get_main_option", "alembic.runtime.environment.EnvironmentContext", "alembic.script.base.Script", "alembic.script.revision._RevIdType", "alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.generate_revision", "alembic.script.ScriptDirectory.run_env", "alembic.util", "alembic.util.rev_id"]}, "requirement": {"Functionality": "This function merges two revisions together and creates a new migration file. It uses the provided input parameters to configure the merge process and generate the revision.", "Arguments": ":param config: Config. An instance of the Config class.\n:param revisions: _RevIdType. The revisions to be merged.\n:param message: Optional string. The message to apply to the new revision.\n:param branch_label: Optional _RevIdType. The label name to apply to the new revision.\n:param rev_id: Optional string. The hardcoded revision identifier instead of generating a new one.\n:return: Optional Script. The generated migration script."}, "tests": ["tests/test_command.py::RevisionEnvironmentTest::test_merge_cmd_revision_environment", "tests/test_command.py::RevisionTest::test_create_rev_autogenerate_post_merge", "tests/test_command.py::RevisionTest::test_create_rev_autogenerate_db_not_up_to_date_post_merge", "tests/test_command.py::RevisionTest::test_create_rev_plain_post_merge"], "indent": 4}
{"namespace": "boto.logs.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/logs/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.logs.layer1.CloudWatchLogsConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CloudWatchLogsConnection class. It creates a connection with the specified parameters and returns the CloudWatchLogsConnection object.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: CloudWatchLogsConnection. The connection object to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestLogsConnection::test_connect_to_region"], "indent": 4}
{"namespace": "pyinfra.connectors.ansible.AnsibleInventoryConnector.make_names_data", "type": "method", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/connectors/ansible.py", "signature_position": [44, 44], "body_position": [45, 55], "dependency": {"intra_class": [], "intra_file": ["pyinfra.connectors.ansible.parse_inventory", "pyinfra.connectors.ansible.show_warning"], "cross_file": ["pyinfra.api.exceptions.InventoryError"]}, "requirement": {"Functionality": "This function reads an Ansible inventory file and returns the parsed data. It first checks if the inventory filename is provided, and if not, raises an inventory error \"No Ansible inventory filename provided!\" Then it checks if the inventory file exists, and if not, raises an InventoryError \"Could not find Ansible inventory file: {0}\". Finally, it parses the inventory file and returns the parsed data.", "Arguments": ":param inventory_filename: Optional[str]. The filename of the Ansible inventory file. Defaults to None.\n:return: The parsed data from the Ansible inventory file."}, "tests": ["tests/test_connectors/test_ansible.py::TestAnsibleConnector::test_make_names_data_ini", "tests/test_connectors/test_ansible.py::TestAnsibleConnector::test_make_names_data_no_file", "tests/test_connectors/test_ansible.py::TestAnsibleConnector::test_make_names_data_json"], "indent": 8}
{"namespace": "pyinfra.operations.files.put", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/files.py", "signature_position": [782, 792], "body_position": [842, 928], "dependency": {"intra_class": [], "intra_file": ["pyinfra.operations.files._create_remote_dir"], "cross_file": ["pyinfra.api.util.get_call_location", "pyinfra.api.util.get_file_sha1", "pyinfra.api.util.get_path_permissions_mode", "pyinfra.facts.files.Directory", "pyinfra.facts.files.File", "pyinfra.facts.files.Sha1File", "pyinfra.logger", "pyinfra.operations.util.files.chmod", "pyinfra.operations.util.files.chown", "pyinfra.operations.util.files.ensure_mode_int", "pyinfra.operations.util.files.unix_path_join", "pyinfra.api.host.Host.get_fact", "pyinfra.api.host.Host.noop", "pyinfra.operations.util.files", "pyinfra.api.state.State.get_temp_filename"]}, "requirement": {"Functionality": "This function uploads a local file or file-like object to a remote system. It allows for specifying various parameters such as the user, group, mode, and destination directory. It also provides options for creating the remote directory if it doesn't exist and forcing the upload even if the remote copy matches.", "Arguments": ":param src: The filename or IO-like object to upload.\n:param dest: The remote filename to upload to.\n:param user: The user to own the files.\n:param group: The group to own the files.\n:param mode: The permissions of the files. Use \"True\" to copy the local file.\n:param add_deploy_dir: Whether the src is relative to the deploy directory.\n:param create_remote_dir: Whether to create the remote directory if it doesn't exist.\n:param force: Whether to always upload the file, even if the remote copy matches.\n:param assume_exists: Whether to assume the local file exists.\n:return: No return values."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_file_upload_op"], "indent": 4}
{"namespace": "mrjob.job.MRJob.run_job", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [620, 620], "body_position": [630, 649], "dependency": {"intra_class": ["mrjob.job.MRJob._should_cat_output", "mrjob.job.MRJob.make_runner", "mrjob.job.MRJob.options", "mrjob.job.MRJob.set_up_logging", "mrjob.job.MRJob.stderr", "mrjob.job.MRJob.stdout"], "intra_file": ["mrjob.job.log"], "cross_file": ["mrjob.step.StepFailedException"]}, "requirement": {"Functionality": "This function runs all the steps of a job. It sets up logging, creates a runner, and runs the job. If any step fails, it logs the error and exits the program. If the output needs to be concatenated, it writes the output to the standard output stream.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:return: No return values."}, "tests": ["tests/test_local.py::ExitWithoutExceptionTestCase::test_exit_42_job", "tests/test_job.py::LaunchJobTestCase::test_output", "tests/test_job.py::LaunchJobTestCase::test_output_dir_with_explicit_cat_output", "tests/test_job.py::LaunchJobTestCase::test_exit_on_step_failure", "tests/test_job.py::LaunchJobTestCase::test_pass_through_other_exceptions"], "indent": 8}
{"namespace": "kinto.core.openapi.OpenAPI.expose_authentication_method", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/openapi.py", "signature_position": [27, 27], "body_position": [50, 51], "dependency": {"intra_class": ["kinto.core.openapi.OpenAPI.security_definitions", "kinto.core.openapi.OpenAPI.security_roles"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function allows security extensions to expose authentication methods on the OpenAPI documentation. It adds the provided method name and definition to the security definitions dictionary of the OpenAPI class. It also adds the scopes from the definition to the security roles dictionary.", "Arguments": ":param cls: OpenAPI. The OpenAPI class.\n:param method_name: String. The name of the authentication method.\n:param definition: Dictionary. The definition of the authentication method, following the OpenAPI 2.0 specification.\n:return: No return values."}, "tests": ["tests/core/test_openapi.py::OpenAPITest::test_security_extensions"], "indent": 8}
{"namespace": "kinto.core.storage.postgresql.migrator.MigratorMixin.create_or_migrate_schema", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/storage/postgresql/migrator.py", "signature_position": [42, 42], "body_position": [44, 54], "dependency": {"intra_class": ["kinto.core.storage.postgresql.migrator.MigratorMixin.create_schema", "kinto.core.storage.postgresql.migrator.MigratorMixin.get_installed_version", "kinto.core.storage.postgresql.migrator.MigratorMixin.migrate_schema", "kinto.core.storage.postgresql.migrator.MigratorMixin.name", "kinto.core.storage.postgresql.migrator.MigratorMixin.schema_version"], "intra_file": ["kinto.core.storage.postgresql.migrator.logger"], "cross_file": []}, "requirement": {"Functionality": "This function either creates a new schema or migrates an existing schema based on the current version. If there is no existing version, it creates a new schema. If the current version matches the desired schema version, it logs that the schema is up-to-date. Otherwise, it migrates the schema to the desired version.", "Arguments": ":param self: MigratorMixin. An instance of the MigratorMixin class.\n:param dry_run: Bool. Whether to perform a dry run of the schema creation or migration. Defaults to False.\n:return: None."}, "tests": ["tests/core/test_storage_migrations.py::MigratorTest::test_schema_is_created_if_no_version", "tests/core/test_storage_migrations.py::MigratorTest::test_migration_files_are_listed_if_ran_with_dry_run", "tests/core/test_storage_migrations.py::MigratorTest::test_migration_fails_if_intermediary_version_is_missing", "tests/core/test_storage_migrations.py::MigratorTest::test_migration_file_is_executed_for_every_intermediary_version"], "indent": 8}
{"namespace": "chatette.utils.cast_to_unicode", "type": "function", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/utils.py", "signature_position": [60, 60], "body_position": [67, 84], "dependency": {"intra_class": [], "intra_file": ["chatette.utils.cast_to_unicode"], "cross_file": []}, "requirement": {"Functionality": "This function is used to cast any string in `anything` to unicode if executed with Python 2.7. If executed with Python 3, it returns `anything` as it is. The function can handle various data types such as strings, arrays, and dictionaries.", "Arguments": ":param anything: Any data type. The input data that needs to be cast to unicode if executed with Python 2.7.\n:return: The input data casted to unicode if executed with Python 2.7, or the input data as it is if executed with Python 3."}, "tests": ["tests/unit-testing/test_utils.py::TestCastToUnicode::test_nb", "tests/unit-testing/test_utils.py::TestCastToUnicode::test_dict"], "indent": 4}
{"namespace": "prometheus_client.mmap_dict.MmapedDict.write_value", "type": "method", "project_path": "System/prometheus-client", "completion_path": "System/prometheus-client/prometheus_client/mmap_dict.py", "signature_position": [127, 127], "body_position": [128, 131], "dependency": {"intra_class": ["prometheus_client.mmap_dict.MmapedDict._init_value", "prometheus_client.mmap_dict.MmapedDict._m", "prometheus_client.mmap_dict.MmapedDict._positions"], "intra_file": ["prometheus_client.mmap_dict._pack_two_doubles"], "cross_file": []}, "requirement": {"Functionality": "This function writes a value to a key in the MmapedDict instance. If the key does not exist in the instance, it initializes the key and then writes the value and timestamp to the corresponding position in the memory-mapped file.", "Arguments": ":param self: MmapedDict. An instance of the MmapedDict class.\n:param key: The key to write the value to.\n:param value: The value to be written.\n:param timestamp: The timestamp associated with the value.\n:return: No return values."}, "tests": ["tests/test_multiprocess.py::TestMmapedDict::test_corruption_detected", "tests/test_multiprocess.py::TestMmapedDict::test_multi_expansion", "tests/test_multiprocess.py::TestMmapedDict::test_expansion", "tests/test_multiprocess.py::TestMmapedDict::test_process_restart"], "indent": 8}
{"namespace": "fs.path.normpath", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [50, 51], "body_position": [72, 92], "dependency": {"intra_class": [], "intra_file": ["fs.path._requires_normalization"], "cross_file": ["fs.errors.IllegalBackReference"]}, "requirement": {"Functionality": "This function normalizes a given path by collapsing back-references (such as \"..\") and removing duplicated separators (\"/\"). If the input describes a path that can not be reached, such as \"foo/../../bar\", an IndexError will be excepted and the function will raise an illegal back reference instead.", "Arguments": ":param path: Text. The path to be normalized. For example, \"/foo//bar/frob/../baz\".\n:return: Text. A valid file system path. For example, '/foo/bar/baz',"}, "tests": ["tests/test_path.py::TestPathFunctions::test_normpath"], "indent": 4}
{"namespace": "pyramid.authentication.RepozeWho1AuthenticationPolicy.forget", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [363, 363], "body_position": [370, 374], "dependency": {"intra_class": ["pyramid.authentication.RepozeWho1AuthenticationPolicy._get_identifier", "pyramid.authentication.RepozeWho1AuthenticationPolicy._get_identity"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to forget the current authenticated user. It returns headers that, if included in a response, will delete the cookie responsible for tracking the current user.", "Arguments": ":param self: RepozeWho1AuthenticationPolicy. An instance of the RepozeWho1AuthenticationPolicy class.\n:param request: The current request object.\n:return: List of headers. The headers that, if included in a response, will delete the user tracking cookie."}, "tests": ["tests/test_authentication.py::TestRepozeWho1AuthenticationPolicy::test_forget", "tests/test_authentication.py::TestRepozeWho1AuthenticationPolicy::test_forget_no_plugins"], "indent": 8}
{"namespace": "sumy._compat.to_bytes", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/_compat.py", "signature_position": [50, 50], "body_position": [51, 57], "dependency": {"intra_class": [], "intra_file": ["sumy._compat.bytes", "sumy._compat.instance_to_bytes", "sumy._compat.unicode"], "cross_file": []}, "requirement": {"Functionality": "Convert the input object to bytes. If the object is already of type bytes, it is returned as is. If the object is of type unicode, it is encoded to UTF-8 and returned. Otherwise, the function tries to encode the object to bytes using a custom function.", "Arguments": ":param object: Object. The object to be converted to bytes.\n:return: bytes. The object converted to bytes."}, "tests": ["tests/test_utils/test_compat.py::test_unicode_object_to_bytes", "tests/test_utils/test_unicode_compatible_class.py::test_to_bytes", "tests/test_utils/test_compat.py::test_repr_object_to_bytes", "tests/test_utils/test_compat.py::test_unicode_to_bytes", "tests/test_utils/test_compat.py::test_str_object_to_bytes"], "indent": 4}
{"namespace": "twilio.jwt.taskrouter.capabilities.WorkerCapabilityToken.allow_update_activities", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/taskrouter/capabilities.py", "signature_position": [59, 59], "body_position": [60, 61], "dependency": {"intra_class": ["twilio.jwt.taskrouter.capabilities.WorkerCapabilityToken.resource_url"], "intra_file": [], "cross_file": ["twilio.jwt.taskrouter.TaskRouterCapabilityToken._make_policy"]}, "requirement": {"Functionality": "This function creates a policy with the resource URL, HTTP method \"POST\", and post_filter {\"ActivitySid\": {\"required\": True}}.", "Arguments": ":param self: WorkerCapabilityToken. An instance of the WorkerCapabilityToken class.\n:return: No return values."}, "tests": ["tests/unit/jwt/test_task_router.py::WorkerCapabilityTokenTest::test_allow_activity_updates"], "indent": 8}
{"namespace": "mrjob.parse.parse_s3_uri", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [52, 52], "body_position": [60, 66], "dependency": {"intra_class": [], "intra_file": ["mrjob.parse.urlparse", "mrjob.parse.urlparse.netloc", "mrjob.parse.urlparse.path", "mrjob.parse.urlparse.scheme"], "cross_file": []}, "requirement": {"Functionality": "Parses an S3 URI and extracts the bucket and key components. If uri is not an S3 URI, raise a ValueError.\n", "Arguments": ":param uri: String. The S3 URI to be parsed.\n:return: Tuple of strings. The bucket name and the key.\n"}, "tests": ["tests/test_parse.py::URITestCase::test_parse_s3_uri"], "indent": 4}
{"namespace": "wikipediaapi.WikipediaPage.text", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [969, 969], "body_position": [975, 980], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage.sections", "wikipediaapi.WikipediaPage.summary"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the text of the current Wikipedia page. It first initializes the text with the summary of the page. Then, it appends the full text of each section to the text. Finally, it returns the trimmed text.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: str. The text of the current Wikipedia page."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_text", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_text_and_summary_without_sections", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_text", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_with_erroneous_edit"], "indent": 8}
{"namespace": "pyramid.path.PkgResourcesAssetDescriptor.abspath", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/path.py", "signature_position": [375, 375], "body_position": [376, 378], "dependency": {"intra_class": ["pyramid.path.PkgResourcesAssetDescriptor.path", "pyramid.path.PkgResourcesAssetDescriptor.pkg_name", "pyramid.path.PkgResourcesAssetDescriptor.pkg_resources"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the absolute path of a PkgResourcesAssetDescriptor instance.", "Arguments": ":param self: PkgResourcesAssetDescriptor. An instance of the PkgResourcesAssetDescriptor class.\n:return: String. The absolute path of the asset descriptor."}, "tests": ["tests/test_path.py::TestPkgResourcesAssetDescriptor::test_abspath"], "indent": 8}
{"namespace": "boltons.cacheutils.ThresholdCounter.most_common", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [733, 733], "body_position": [737, 742], "dependency": {"intra_class": ["boltons.cacheutils.ThresholdCounter.iteritems"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the top \"n\" keys and counts as a list of tuples. If \"n\" is not specified, it returns all the key-count pairs.\n", "Arguments": ":param self: ThresholdCounter object\n:param n: int. The number of top keys and counts to retrieve. Defaults to None.\n:return: list of tuples. The top \"n\" keys and counts from the ThresholdCounter object.\n"}, "tests": ["tests/test_cacheutils.py::test_threshold_counter"], "indent": 8}
{"namespace": "boto.route53.domains.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/route53/domains/__init__.py", "signature_position": [37, 37], "body_position": [38, 41], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.regioninfo.connect", "boto.route53.domains.layer1.Route53DomainsConnection"]}, "requirement": {"Functionality": "Connect to a specific region in the AWS Route53 service. It creates a connection to the Route53Domains service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: Route53DomainsConnection. The connection object to the Route53Domains service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestRoute53DomainsConnection::test_connect_to_region"], "indent": 4}
{"namespace": "mopidy.config.types.Pair.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [241, 241], "body_position": [242, 259], "dependency": {"intra_class": ["mopidy.config.types.Pair._optional_pair", "mopidy.config.types.Pair._required", "mopidy.config.types.Pair._separator", "mopidy.config.types.Pair._subtypes"], "intra_file": ["mopidy.config.types.decode", "mopidy.config.types.encode", "mopidy.config.types.String.deserialize"], "cross_file": ["mopidy.config.validators.validate_required", "mopidy.config.validators"]}, "requirement": {"Functionality": "Deserialize a value and return a pair of deserialized values. It first decodes the input value and removes any leading or trailing whitespace. Then, it validates the raw value based on whether it is required or not. If the raw value is empty, it returns None. If the separator is present in the raw value, it splits the value into two parts. If the optional pair flag is set, it assigns the same value to both parts. Otherwise, it raises a ValueError indicating that the config value must include the separator. Finally, it encodes and deserializes each part of the pair using the corresponding subtypes.", "Arguments": ":param self: Pair. An instance of the Pair class.\n:param value: The value to be deserialized.\n:return: Tuple. A pair of deserialized values."}, "tests": ["tests/config/test_types.py::TestPair::test_deserialize_respects_optional_separator", "tests/config/test_types.py::TestPair::test_deserialize_with_optional_custom_subtypes", "tests/config/test_types.py::TestPair::test_deserialize_enforces_required_pair_values_with_custom_separator", "tests/config/test_types.py::TestPair::test_deserialize_respects_optional_custom_separator", "tests/config/test_types.py::TestPair::test_deserialize_conversion_success"], "indent": 8}
{"namespace": "pyramid.security.PermitsResult.__repr__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/security.py", "signature_position": [180, 180], "body_position": [181, 185], "dependency": {"intra_class": ["pyramid.security.PermitsResult.msg"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function overrides the default \"__repr__\" method for the PermitsResult class. It returns a string representation of the instance, including the class name, instance id, and the message. The output format is \"<{class name} instance at {instance id} with msg {message}>\"", "Arguments": ":param self: PermitsResult. An instance of the PermitsResult class.\n:return: String. A string representation of the instance."}, "tests": ["tests/test_security.py::TestACLAllowed::test_it", "tests/test_security.py::TestACLDenied::test_it", "tests/test_security.py::TestAllowed::test_it", "tests/test_security.py::TestDenied::test_it"], "indent": 8}
{"namespace": "datasette.utils.derive_named_parameters", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [1125, 1125], "body_position": [1126, 1132], "dependency": {"intra_class": [], "intra_file": ["datasette.utils._re_named_parameter"], "cross_file": []}, "requirement": {"Functionality": "This function derives the named parameters from a SQL query by executing an \"explain\" statement on the query. It first constructs the \"explain\" statement by stripping any trailing semicolon from the input SQL query. Then, it finds all possible named parameters in the query using a regular expression. Next, it executes the \"explain\" statement on the database with a dictionary of named parameters, where the values are set to None. Finally, it returns a list of named parameters that are identified as variables in the \"explain\" results, after removing the leading \":\" character.", "Arguments": ":param db: The database connection object.\n:param sql: The SQL query from which to derive the named parameters.\n:return: A list of named parameters identified as variables in the \"explain\" results, after removing the leading \":\" character. If there is an error executing the \"explain\" statement, it returns the list of possible named parameters found in the input SQL query."}, "tests": ["tests/test_utils.py::test_derive_named_parameters"], "indent": 4}
{"namespace": "trailscraper.boto_service_definitions.service_definition_file", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/boto_service_definitions.py", "signature_position": [20, 20], "body_position": [23, 29], "dependency": {"intra_class": [], "intra_file": ["trailscraper.boto_service_definitions.boto_service_definition_files"], "cross_file": []}, "requirement": {"Functionality": "This function returns the path to the most recent service definition file for a given service. It first retrieves all the service definition files. Then, it filters the files based on the provided service name and a specific pattern (\"**/\" + servicename + \"/*/service-*.json\"). The filtered files are sorted in ascending order based on their names, and the path of the last file is returned.", "Arguments": ":param servicename: String. The name of the service.\n:return: String. The path to the most recent service definition file for the given service."}, "tests": ["tests/boto_service_definitions_test.py::test_should_find_most_recent_service_definition_file_for_ec2"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.PandasDataFrameContainer.to_payload", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [381, 385], "body_position": [386, 415], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.external_typing.PdSeries", "bentoml._internal.utils.pickle.pep574_dumps", "bentoml._internal.external_typing", "bentoml._internal.runner.container.DataContainer.create_payload"]}, "requirement": {"Functionality": "This function converts a Pandas DataFrame or Series into a Payload object. It first checks if the batch dimension is 0, as PandasDataFrameContainer only supports batch_dim of 0. If the batch is a Series, it converts it into a DataFrame. Then, it creates a meta dictionary with the format set to \"pickle5\". It then performs some operations to obtain the bytes, concat_buffer_bs, and indices. If indices exist, it sets the \"with_buffer\" key in the meta dictionary to True and assigns the concat_buffer_bs, base64 encoded pickle bytes, and indices to the corresponding keys in the meta dictionary. If indices do not exist, it sets the \"with_buffer\" key to False and assigns the bs to the data variable. Finally, it creates a Payload object with the data, batch shape, and meta dictionary.", "Arguments": ":param cls: PandasDataFrameContainer. The class itself.\n:param batch: Pandas DataFrame or Series. The batch to be converted into a Payload object.\n:param batch_dim: int. The batch dimension. It must be 0 for PandasDataFrameContainer.\n:return: Payload. The created Payload object."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_pandas_container"], "indent": 8}
{"namespace": "pyramid.config.views.MultiView.__call_permissive__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/views.py", "signature_position": [138, 138], "body_position": [139, 141], "dependency": {"intra_class": ["pyramid.config.views.MultiView.match"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a method of the MultiView class. It is used to call the matched view with the given context and request. If the matched view is call permissive, this custom method is called instead.", "Arguments": ":param self: MultiView. An instance of the MultiView class.\n:param context: The context object to be passed to the view.\n:param request: The request object to be passed to the view.\n:return: The result of calling the matched view with the given context and request."}, "tests": ["tests/test_config/test_views.py::TestMultiView::test___call_permissive_has_no_call_permissive", "tests/test_config/test_views.py::TestMultiView::test___call_permissive_has_call_permissive"], "indent": 8}
{"namespace": "kinto.core.permission.memory.Permission.get_object_permission_principals", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/permission/memory.py", "signature_position": [90, 90], "body_position": [91, 93], "dependency": {"intra_class": ["kinto.core.permission.memory.Permission._store"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the set of principals that have the specified permission for the given object ID. It retrieves the set of principals from the store based on the permission key and returns it.", "Arguments": ":param self: Permission. An instance of the Permission class.\n:param object_id: The ID of the object for which the permission is being checked.\n:param permission: The specific permission being checked.\n:return: Set. The set of principals that have the specified permission for the given object ID."}, "tests": ["tests/core/resource/test_object_permissions.py::DeletedObjectPermissionTest::test_permissions_are_deleted_when_object_is_deleted", "tests/core/resource/test_object_permissions.py::DeletedObjectPermissionTest::test_permissions_are_deleted_when_plural_is_deleted"], "indent": 8}
{"namespace": "mrjob.examples.mr_text_classifier.parse_doc_filename", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/examples/mr_text_classifier.py", "signature_position": [65, 65], "body_position": [70, 85], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.util.file_ext"]}, "requirement": {"Functionality": "This function parses a filename in a specific format and returns a dictionary containing the parsed information. The filename is expected to be in the format \"some_id-cat1-cat2-not_cat3.txt\", and should be parsed into ``dict(id='some_id', cats=dict(cat1=True, cat2=True, cat3=False))``. The function extracts the id and categories from the filename and stores them in a dictionary.", "Arguments": ":param input_uri: String. The input filename to be parsed.\n:return: Dictionary. A dictionary containing the parsed information, with keys \"id\" and \"cats\". The value of \"id\" is the extracted id from the filename, and the value of \"cats\" is another dictionary containing the categories as keys and their corresponding boolean values."}, "tests": ["tests/examples/test_mr_text_classifier.py::ParseDocFileNameTestCase::test_no_cats", "tests/examples/test_mr_text_classifier.py::ParseDocFileNameTestCase::test_with_cats", "tests/examples/test_mr_text_classifier.py::ParseDocFileNameTestCase::test_not_cat", "tests/examples/test_mr_text_classifier.py::ParseDocFileNameTestCase::test_empty"], "indent": 4}
{"namespace": "music_dl.utils.colorize", "type": "function", "project_path": "Utilities/pymusic-dl", "completion_path": "Utilities/pymusic-dl/music_dl/utils.py", "signature_position": [31, 31], "body_position": [32, 37], "dependency": {"intra_class": [], "intra_file": ["music_dl.utils.colors"], "cross_file": []}, "requirement": {"Functionality": "This function takes a string and a color as input and returns the string wrapped in the specified color. If the color is not supported or the platform is Windows, the function returns the original string without any color formatting.", "Arguments": ":param string: The input string to be colorized.\n:param color: The color to be applied to the string. It should be one of the supported colors.\n:return: The colorized string."}, "tests": ["tests/test_utils.py::test_color"], "indent": 4}
{"namespace": "mrjob.logs.step._parse_step_syslog", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/step.py", "signature_position": [252, 252], "body_position": [271, 272], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.step._parse_step_syslog_from_log4j_records"], "cross_file": ["mrjob.logs.log4j._parse_hadoop_log4j_records"]}, "requirement": {"Functionality": "A helper function that parses syslog from the \"hadoop jar\" command. It returns a dictionary with various keys(application_id, counters, errors, job_id, output_dir) depending on the information found in the syslog.\n", "Arguments": ":param lines: List of strings. The syslog lines to be parsed.\n:return: Dictionary. A dictionary with various keys that may include application_id, counters, errors, job_id, and output_dir.\n"}, "tests": ["tests/logs/test_step.py::ParseStepSyslogTestCase::test_pre_yarn", "tests/logs/test_step.py::ParseStepSyslogTestCase::test_empty", "tests/logs/test_step.py::ParseStepSyslogTestCase::test_not_a_valid_jar", "tests/logs/test_step.py::ParseStepSyslogTestCase::test_yarn"], "indent": 4}
{"namespace": "mrjob.util.safeeval", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/util.py", "signature_position": [134, 134], "body_position": [142, 167], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.py2.PY2"]}, "requirement": {"Functionality": "This function evaluates an expression in a safe environment. It creates a dictionary of safe global variables, including True, False, None, set and range or xrange. `open` is specially handled to raise a NameError with the message \"name 'open' is not defined\".", "Arguments": ":param expr: The expression to be evaluated.\n:param globals: dict. Optional dictionary mapping names to values for global variables. Defaults to None.\n:param locals: dict. Optional dictionary mapping names to values for local variables. Defaults to None.\n:return: The result of evaluating the expression."}, "tests": ["tests/test_util.py::SafeEvalTestCase::test_range_type", "tests/test_util.py::SafeEvalTestCase::test_no_mischief", "tests/test_util.py::SafeEvalTestCase::test_globals_and_locals", "tests/test_util.py::SafeEvalTestCase::test_simple_data_structures"], "indent": 4}
{"namespace": "boto.dynamodb.batch.BatchList.to_dict", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb/batch.py", "signature_position": [206, 206], "body_position": [210, 215], "dependency": {"intra_class": ["boto.dynamodb.batch.BatchList.to_dict"], "intra_file": [], "cross_file": ["boto.dynamodb.table", "boto.dynamodb.table.Table.name"]}, "requirement": {"Functionality": "This function converts a BatchList object into a dictionary format that is required for Layer1.", "Arguments": ":param self: BatchList. An instance of the BatchList class.\n:return: dict. The dictionary representation of the BatchList object."}, "tests": ["tests/unit/dynamodb/test_batch.py::TestBatchObjects::test_batch_list_consistent_read"], "indent": 8}
{"namespace": "boto.machinelearning.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/machinelearning/__init__.py", "signature_position": [39, 39], "body_position": [40, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.machinelearning.layer1.MachineLearningConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the MachineLearningConnection class from the boto library. It creates a connection to the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: MachineLearningConnection. The connection object to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestMachinelearningConnection::test_connect_to_region"], "indent": 4}
{"namespace": "mingus.containers.note_container.NoteContainer.from_interval_shorthand", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note_container.py", "signature_position": [130, 130], "body_position": [143, 149], "dependency": {"intra_class": ["mingus.containers.note_container.NoteContainer.add_notes", "mingus.containers.note_container.NoteContainer.empty"], "intra_file": [], "cross_file": ["mingus.containers.note.Note", "mingus.containers.note.Note.dynamics", "mingus.containers.note.Note.name", "mingus.containers.note.Note.octave", "mingus.containers.note.Note.transpose"]}, "requirement": {"Functionality": "This function empties the NoteContainer instance and adds a note to it based on the given startnote and shorthand. It first empties the NoteContainer instance and converts startnote to a Note object if its type is a string. The shorthand is used to determine the interval to transpose the startnote by. The resulting notes are then added to the NoteContainer instance.", "Arguments": ":param self: NoteContainer. An instance of the NoteContainer class.\n:param startnote: String or Note. The starting note for the interval transposition. If it is a string, it will be converted to a Note object.\n:param shorthand: String. The shorthand representation of the interval to transpose the startnote by. See core.intervals for the recognized format.\n:param up: Bool. Whether to transpose the interval up or down. Defaults to True.\n:return: NoteContainer. The modified NoteContainer instance."}, "tests": ["tests/unit/containers/test_note_containers.py::test_NoteContainers::test_from_interval_shorthand"], "indent": 8}
{"namespace": "pyramid.static.ManifestCacheBuster.manifest", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/static.py", "signature_position": [410, 410], "body_position": [412, 419], "dependency": {"intra_class": ["pyramid.static.ManifestCacheBuster._manifest", "pyramid.static.ManifestCacheBuster._mtime", "pyramid.static.ManifestCacheBuster.exists", "pyramid.static.ManifestCacheBuster.get_manifest", "pyramid.static.ManifestCacheBuster.getmtime", "pyramid.static.ManifestCacheBuster.manifest_path", "pyramid.static.ManifestCacheBuster.reload"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the current manifest dictionary. If the reload flag is set to True, it will reload the manifest if the manifest file exists and has been modified since the last time it was loaded.", "Arguments": ":param self: ManifestCacheBuster. An instance of the ManifestCacheBuster class.\n:return: Dictionary. The current manifest dictionary."}, "tests": ["tests/test_static.py::TestManifestCacheBuster::test_invalid_manifest_with_reload"], "indent": 8}
{"namespace": "jinja2.idtracking.Symbols.find_ref", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/idtracking.py", "signature_position": [68, 68], "body_position": [69, 75], "dependency": {"intra_class": ["jinja2.idtracking.Symbols.parent", "jinja2.idtracking.Symbols.refs", "jinja2.idtracking.Symbols.find_ref"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function searches for a reference with the given name in the Symbols instance and recursively in its parent nodes.", "Arguments": ":param self: Symbols. An instance of the Symbols class.\n:param name: str. The name of the reference to search for.\n:return: Optional[str]. The value of the reference if found, otherwise None."}, "tests": ["tests/test_idtracking.py::test_complex"], "indent": 8}
{"namespace": "datasette.app.Datasette.invoke_startup", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [386, 387], "body_position": [388, 396], "dependency": {"intra_class": ["datasette.app.Datasette._startup_invoked", "datasette.app.Datasette.jinja_env"], "intra_file": [], "cross_file": ["datasette.plugins.pm", "datasette.utils.await_me_maybe"]}, "requirement": {"Functionality": "This function is used to invoke the startup process for a Datasette instance. It ensures that the necessary steps are taken to put the Datasette instance in a usable state.", "Arguments": ":param self: Datasette. An instance of the Datasette class.\n:return: No return value."}, "tests": ["tests/test_internals_datasette.py::test_datasette_render_template_no_request"], "indent": 8}
{"namespace": "boltons.cacheutils.LRI.update", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [304, 305], "body_position": [306, 318], "dependency": {"intra_class": ["boltons.cacheutils.LRI.__setitem__", "boltons.cacheutils.LRI._lock"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Update the LRI instance with the key-value pairs from the input dictionaries. It iterates over the keys and values of the dictionaries and adds them to the LRI instance. If the input dictionary has a callable 'keys' attribute, it uses it to iterate over the keys. Otherwise, it assumes that the input dictionary is an iterable of key-value pairs. The function also accepts keyword arguments and adds them to the LRI instance.", "Arguments": ":param self: LRI. An instance of the LRI class.\n:param E: Dictionary or iterable. The dictionary or iterable containing key-value pairs to be added to the LRI instance.\n:param F: Varable-length keyword arguments. Additional key-value pairs to be added to the LRI instance.\n:return: None."}, "tests": ["tests/test_cacheutils.py::test_lru_basic"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.Dial.sip", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [2194, 2212], "body_position": [2235, 2254], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Sip", "twilio.twiml.voice_response.Sip.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Sip>` element based on the given parameters. It initializes an instance of the `Sip` class with the provided arguments and returns it.", "Arguments": ":param self: Dial. An instance of the `Dial` class.\n:param sip_url: String. The SIP URL.\n:param username: String. The SIP username.\n:param password: String. The SIP password.\n:param url: String. The action URL.\n:param method: String. The action URL method.\n:param status_callback_event: String. The status callback events.\n:param status_callback: String. The status callback URL.\n:param status_callback_method: String. The status callback URL method.\n:param machine_detection: Boolean. Enable machine detection or end of greeting detection.\n:param amd_status_callback_method: String. The HTTP method to use with `amd_status_callback`.\n:param amd_status_callback: String. The URL to call to send AMD status information to your application.\n:param machine_detection_timeout: Integer. The number of seconds to wait for machine detection.\n:param machine_detection_speech_threshold: Integer. The number of milliseconds for measuring stick for the length of the speech activity.\n:param machine_detection_speech_end_threshold: Integer. The number of milliseconds of silence after speech activity.\n:param machine_detection_silence_timeout: Integer. The number of milliseconds of initial silence.\n:param kwargs: Additional attributes.\n:return: Sip. The created `<Sip>` element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestDial::test_sip", "tests/unit/twiml/test_voice_response.py::TestDial::test_sip_username_password"], "indent": 8}
{"namespace": "fs.path.relativefrom", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [543, 544], "body_position": [560, 569], "dependency": {"intra_class": [], "intra_file": ["fs.path.iteratepath"], "cross_file": []}, "requirement": {"Functionality": "This function returns a path relative to a given base path. It inserts backrefs as necessary to reach the path from the base.", "Arguments": ":param base: Text. The base path directory.\n:param path: Text. The path to make relative.\n:return: Text. The path to the base from the given path."}, "tests": ["tests/test_path.py::TestPathFunctions::test_realtivefrom"], "indent": 4}
{"namespace": "pythonforandroid.prerequisites.AutomakePrerequisite.darwin_checker", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [309, 309], "body_position": [310, 313], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "Check if the \"automake\" formula is installed on a Darwin system using Homebrew.", "Arguments": ":param self: AutomakePrerequisite. An instance of the AutomakePrerequisite class.\n:return: bool. True if the \"automake\" formula is installed, False otherwise."}, "tests": ["tests/test_prerequisites.py::TestAutomakePrerequisite::test_darwin_checker"], "indent": 8}
{"namespace": "exodus_bundler.bundling.resolve_file_path", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [200, 200], "body_position": [210, 216], "dependency": {"intra_class": [], "intra_file": ["exodus_bundler.bundling.resolve_binary"], "cross_file": ["exodus_bundler.errors.MissingFileError", "exodus_bundler.errors.UnexpectedDirectoryError"]}, "requirement": {"Functionality": "This function attempts to find a normalized path to a file. It checks if the file exists and if it is a directory. If the file is not found or if it is a directory, appropriate exceptions will be thrown.", "Arguments": ":param path: str. Either a relative or absolute path to a file, or the name of an executable if `search_environment_path` is `True`.\n:param search_environment_path: bool. Whether PATH should be used to resolve the file.\n:return: str. The normalized path to the file."}, "tests": ["tests/test_bundling.py::test_resolve_file_path"], "indent": 4}
{"namespace": "fs.path.iteratepath", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [95, 96], "body_position": [110, 113], "dependency": {"intra_class": [], "intra_file": ["fs.path.normpath", "fs.path.relpath"], "cross_file": []}, "requirement": {"Functionality": "This function takes a path as input and iterates over its individual components. It returns a list of path components.", "Arguments": ":param path: Text. The path to iterate over. For example, '/foo/bar/baz'.\n:return: List of Text. A list of path components."}, "tests": ["tests/test_path.py::TestPathFunctions::test_iteratepath"], "indent": 4}
{"namespace": "oletools.ppt_record_parser.is_ppt", "type": "function", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/ppt_record_parser.py", "signature_position": [143, 143], "body_position": [158, 194], "dependency": {"intra_class": [], "intra_file": ["oletools.ppt_record_parser.PptFile", "oletools.ppt_record_parser.PptRecordCurrentUser"], "cross_file": ["oletools.record_base.OleRecordStream.iter_records", "oletools.record_base.OleRecordFile.iter_streams", "oletools.record_base.OleRecordStream.close"]}, "requirement": {"Functionality": "This function determines whether a given file is a PowerPoint 2003 (ppt) OLE file. It tries to parse the file using the ppt-parse method and returns False if parsing fails. It looks for specific required streams and records in the file.", "Arguments": ":param filename: String. The name of the file or file data or data stream to be checked.\n:return: Bool. True if the file is a PowerPoint 2003 (ppt) OLE file, False otherwise."}, "tests": ["tests/ppt_parser/test_basic.py::TestBasic::test_is_ppt"], "indent": 4}
{"namespace": "boto.vpc.VPCConnection.get_all_vpc_peering_connections", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/vpc/__init__.py", "signature_position": [1552, 1553], "body_position": [1591, 1598], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.build_filter_params", "boto.vpc.vpc_peering_connection.VpcPeeringConnection", "boto.connection.AWSQueryConnection.get_list", "boto.connection.AWSQueryConnection.build_list_params"]}, "requirement": {"Functionality": "This function retrieves information about VPC peering connections. It allows you to filter the results based on specific search parameters. If no filters are specified, it returns information about all VPC peering connections associated with your account.", "Arguments": ":param self: VPCConnection. An instance of the VPCConnection class.\n:param vpc_peering_connection_ids: List of strings. A list of VPC peering connection IDs to retrieve information for.\n:param filters: List of tuples. A list of filters to apply to the results. Each filter consists of a key and a value.\n:param dry_run: Bool. Set to True if the operation should not actually run.\n:return: List of VPC. A list of VPC peering connections that match the search parameters."}, "tests": ["tests/unit/vpc/test_vpc_peering_connection.py::TestDeleteVpcPeeringConnectionShortForm::test_delete_vpc_peering_connection"], "indent": 8}
{"namespace": "pythonforandroid.androidndk.AndroidNDK.llvm_prebuilt_dir", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/androidndk.py", "signature_position": [24, 24], "body_position": [25, 27], "dependency": {"intra_class": ["pythonforandroid.androidndk.AndroidNDK.host_tag", "pythonforandroid.androidndk.AndroidNDK.ndk_dir"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the directory path of the LLVM prebuilt files in the Android NDK. It constructs the directory path by joining the NDK directory path, \"toolchains\", \"llvm\", \"prebuilt\", and the host tag.", "Arguments": ":param self: AndroidNDK. An instance of the AndroidNDK class.\n:return: String. The directory path of the LLVM prebuilt files."}, "tests": ["tests/test_androidndk.py::TestAndroidNDK::test_llvm_prebuilt_dir"], "indent": 8}
{"namespace": "rest_framework.utils.mediatypes._MediaType.precedence", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/utils/mediatypes.py", "signature_position": [65, 65], "body_position": [69, 75], "dependency": {"intra_class": ["rest_framework.utils.mediatypes._MediaType.main_type", "rest_framework.utils.mediatypes._MediaType.params", "rest_framework.utils.mediatypes._MediaType.sub_type"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the precedence level of a media type based on its specificity. It checks the main type, sub type, and parameters of the media type to determine the precedence level.", "Arguments": ":param self: _MediaType. An instance of the _MediaType class.\n:return: int. The precedence level of the media type, ranging from 0 to 3."}, "tests": ["tests/test_negotiation.py::TestAcceptedMediaType::test_mediatype_precedence_with_wildcard_subtype"], "indent": 8}
{"namespace": "hypertools.datageometry.DataGeometry.plot", "type": "method", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/datageometry.py", "signature_position": [149, 149], "body_position": [171, 193], "dependency": {"intra_class": ["hypertools.datageometry.DataGeometry.align", "hypertools.datageometry.DataGeometry.corpus", "hypertools.datageometry.DataGeometry.data", "hypertools.datageometry.DataGeometry.kwargs", "hypertools.datageometry.DataGeometry.normalize", "hypertools.datageometry.DataGeometry.reduce", "hypertools.datageometry.DataGeometry.semantic", "hypertools.datageometry.DataGeometry.vectorizer", "hypertools.datageometry.DataGeometry.xform_data"], "intra_file": [], "cross_file": ["hypertools.plot.plot.plot"]}, "requirement": {"Functionality": "This function plots the data. It takes in the data to be plotted and any additional keyword arguments.", "Arguments": ":param self: DataGeometry. An instance of the DataGeometry class.\n:param data: numpy array, pandas dataframe or list of arrays/dfs. The data to be plotted. If no data is passed, the `xform_data` from the `DataGeometry` object will be used.\n:param kwargs: keyword arguments. Any keyword arguments supported by `hypertools.plot` can be passed to this method.\n:return: DataGeometry. A new `DataGeometry` object."}, "tests": ["tests/test_geo.py::test_geo_plot"], "indent": 8}
{"namespace": "alembic.operations.ops.AlterColumnOp.to_diff_tuple", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [1682, 1682], "body_position": [1683, 1760], "dependency": {"intra_class": ["alembic.operations.ops.AlterColumnOp.column_name", "alembic.operations.ops.AlterColumnOp.existing_comment", "alembic.operations.ops.AlterColumnOp.existing_nullable", "alembic.operations.ops.AlterColumnOp.existing_server_default", "alembic.operations.ops.AlterColumnOp.existing_type", "alembic.operations.ops.AlterColumnOp.modify_comment", "alembic.operations.ops.AlterColumnOp.modify_nullable", "alembic.operations.ops.AlterColumnOp.modify_server_default", "alembic.operations.ops.AlterColumnOp.modify_type"], "intra_file": ["alembic.operations.ops.AlterTableOp.schema", "alembic.operations.ops.AlterTableOp.table_name"], "cross_file": []}, "requirement": {"Functionality": "This function converts the AlterColumnOp instance into a tuple that represents the differences between the existing column and the modified column. It checks for modifications in the column type, nullable property, server default value, and comment.", "Arguments": ":param self: AlterColumnOp. An instance of the AlterColumnOp class.\n:return: Any. A tuple representing the differences between the existing column and the modified column."}, "tests": ["tests/test_autogen_diffs.py::AutogenerateDiffTest::test_custom_type_compare"], "indent": 8}
{"namespace": "mopidy.ext.Extension.get_data_dir", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/ext.py", "signature_position": [109, 109], "body_position": [117, 123], "dependency": {"intra_class": ["mopidy.ext.Extension.ext_name"], "intra_file": ["mopidy.ext.Config"], "cross_file": ["mopidy.internal.path.expand_path", "mopidy.internal.path.get_or_create_dir", "mopidy.internal.path"]}, "requirement": {"Functionality": "This function is a class method that gets or creates a data directory for the extension. It uses the Mopidy config object to determine the data directory path and creates the directory if it doesn't exist.", "Arguments": ":param cls: Class. The Extension class.\n:param config: Config. The Mopidy config object.\n:return: Path. The path to the data directory for the extension."}, "tests": ["tests/test_ext.py::TestExtension::test_get_data_dir_raises_error"], "indent": 8}
{"namespace": "faker.decode.unidecode", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/decode/__init__.py", "signature_position": [4, 4], "body_position": [5, 13], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["faker.decode.codes"]}, "requirement": {"Functionality": "This function takes a string as input and returns a new string with all non-ASCII characters replaced by their closest ASCII equivalents. It iterates over each character in the input string, checks its codepoint, and replaces it with the corresponding ASCII character if available.", "Arguments": ":param txt: String. The input text to be processed.\n:return: String. The processed text with non-ASCII characters replaced by their closest ASCII equivalents."}, "tests": ["tests/test_decode.py::test_out_of_bounds", "tests/test_decode.py::test_7bit_text_purity", "tests/test_decode.py::test_transliterate", "tests/test_decode.py::test_7bit_purity"], "indent": 4}
{"namespace": "tools.cgrep.is_valid_ip", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/tools/cgrep.py", "signature_position": [51, 51], "body_position": [63, 67], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["capirca.lib.nacaddr", "capirca.lib.nacaddr.IP"]}, "requirement": {"Functionality": "This function validates whether a given value is a valid IP address or not. It takes a potential IP address as a string and checks if it is a valid IP. If it is a valid IP, it returns the IP object. If it is not a valid IP, it raises an error.", "Arguments": ":param arg: String. The potential IP address to be validated.\n:return: String. The input IP address if it is valid.\n:raises: ArgumentTypeError. If the input IP address is not valid."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_valid_ips_v6", "tests/lib/cgrep_test.py::CgrepTest::test_invalid_ip", "tests/lib/cgrep_test.py::CgrepTest::test_invalid_ipv6", "tests/lib/cgrep_test.py::CgrepTest::test_valid_ips"], "indent": 2}
{"namespace": "rest_framework.utils.mediatypes._MediaType.__str__", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/utils/mediatypes.py", "signature_position": [77, 77], "body_position": [78, 81], "dependency": {"intra_class": ["rest_framework.utils.mediatypes._MediaType.main_type", "rest_framework.utils.mediatypes._MediaType.params", "rest_framework.utils.mediatypes._MediaType.sub_type"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the _MediaType instance to a string representation. It concatenates the main type and sub type with a \"/\" separator. Then, it iterates over the parameters dictionary and appends each key-value pair to the string representation.", "Arguments": ":param self: _MediaType. An instance of the _MediaType class.\n:return: String. The string representation of the _MediaType instance."}, "tests": ["tests/test_negotiation.py::TestAcceptedMediaType::test_mediatype_string_representation"], "indent": 8}
{"namespace": "bentoml._internal.resource.get_resource", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/resource.py", "signature_position": [23, 25], "body_position": [26, 40], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.resource.Resource", "bentoml._internal.resource._RESOURCE_REGISTRY"], "cross_file": ["bentoml.exceptions.BentoMLConfigException"]}, "requirement": {"Functionality": "This function retrieves a resource from a dictionary of resources based on the specified resource kind. It first checks if the resource kind is registered in the resource registry. If it is, it retrieves the corresponding resource class. Then, it checks if the resource kind exists in the resources dictionary. If it does, it checks the value associated with the resource kind. If the value is \"system\", it creates a resource instance from the system. Otherwise, it creates a resource instance from the specified resource specification. If the validate parameter is True, it validates the created resource instance. If the resource kind does not exist in the resources dictionary, it returns None.", "Arguments": ":param resources: Dict[str, Any]. A dictionary of resources where the keys are resource kinds and the values are resource specifications.\n:param resource_kind: str. The kind of resource to retrieve.\n:param validate: bool. Whether to validate the created resource instance. Defaults to True.\n:return: Any. The retrieved resource instance or None if the resource kind does not exist in the resources dictionary."}, "tests": ["tests/unit/_internal/test_resource.py::test_get_resource"], "indent": 4}
{"namespace": "authlib.oauth2.rfc6749.util.extract_basic_authorization", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/oauth2/rfc6749/util.py", "signature_position": [24, 24], "body_position": [25, 40], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["authlib.common.encoding.to_unicode"]}, "requirement": {"Functionality": "This function extracts the username and password from the Authorization header in the given headers dictionary. It first checks if the Authorization header exists and contains a space. If not, it returns None for both username and password. If the Authorization header exists and is of type 'basic', it decodes the auth_token and splits it into username and password. If the auth_token does not contain a colon, it returns the auth_token as the username and None for the password.", "Arguments": ":param headers: Dictionary. The headers dictionary containing the Authorization header.\n:return: Tuple. The extracted username and password from the Authorization header."}, "tests": ["tests/core/test_oauth2/test_rfc6749_misc.py::OAuth2UtilTest::test_extract_basic_authorization"], "indent": 4}
{"namespace": "twtxt.config.Config.options", "type": "method", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/config.py", "signature_position": [114, 114], "body_position": [116, 120], "dependency": {"intra_class": ["twtxt.config.Config.cfg"], "intra_file": ["twtxt.config.logger"], "cross_file": []}, "requirement": {"Functionality": "This function returns a dictionary of all configuration options. It tries to retrieve the options from the \"twtxt\" section of the config file. If the section does not exist, it returns an empty dictionary.", "Arguments": ":param self: Config. An instance of the Config class.\n:return: dict. A dictionary containing all config options."}, "tests": ["tests/test_config.py::test_create_config"], "indent": 8}
{"namespace": "mingus.core.progressions.substitute_major_for_minor", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/progressions.py", "signature_position": [329, 329], "body_position": [341, 360], "dependency": {"intra_class": [], "intra_file": ["mingus.core.progressions.interval_diff", "mingus.core.progressions.parse_string", "mingus.core.progressions.skip", "mingus.core.progressions.tuple_to_string"], "cross_file": []}, "requirement": {"Functionality": "This function substitutes major chords for their minor equivalent based on the given progression and index.\nThe function first parses the chord progression to extract the roman numeral, accidental, and suffix of the chord at the specified index. Then, it performs the major to minor substitution by adjusting the interval and appending the appropriate suffix based on the original suffix or the 'ignore_suffix' flag.\n", "Arguments": ""}, "tests": ["tests/unit/core/test_progressions.py::test_progressions::test_substitute_major_for_minor"], "indent": 4}
{"namespace": "faker.utils.loading.find_available_providers", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/loading.py", "signature_position": [52, 52], "body_position": [53, 60], "dependency": {"intra_class": [], "intra_file": ["faker.utils.loading.list_module"], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of modules as input and finds the available providers. It iterates over each module in the input list, checks if the module has a package, and then creates a list of providers by joining the package name with each module name (excluding \"__pycache__\"). The function then updates a set of available providers with the newly created list and returns the sorted list of available providers.", "Arguments": ":param modules: List of ModuleType. A list of modules to search for available providers.\n:return: List of str. The sorted list of available providers."}, "tests": ["tests/utils/test_utils.py::UtilsTestCase::test_find_available_providers"], "indent": 4}
{"namespace": "boltons.tableutils.Table.extend", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tableutils.py", "signature_position": [292, 292], "body_position": [296, 300], "dependency": {"intra_class": ["boltons.tableutils.Table._data", "boltons.tableutils.Table._fill", "boltons.tableutils.Table._set_width"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function appends the given data to the end of the Table instance. It first checks if the data is empty, and if so, it returns without making any changes. Otherwise, it extends the internal data list with the given data, updates the width of the table, and fills any empty cells with empty strings.", "Arguments": ":param self: Table. An instance of the Table class.\n:param data: Iterable. The data to be appended to the table.\n:return: No return values."}, "tests": ["tests/test_tableutils.py::test_table_dicts"], "indent": 8}
{"namespace": "wikipediaapi.Wikipedia.page", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [199, 204], "body_position": [232, 235], "dependency": {"intra_class": ["wikipediaapi.Wikipedia.language"], "intra_file": ["wikipediaapi.Namespace", "wikipediaapi.Namespace.MAIN", "wikipediaapi.WikiNamespace", "wikipediaapi.WikipediaPage", "wikipediaapi.WikipediaPage.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function constructs a Wikipedia page object with the given title. It is the first step in extracting information from a Wikipedia page.", "Arguments": ":param self: Wikipedia. An instance of the Wikipedia class.\n:param title: String. The title of the Wikipedia page as used in the URL.\n:param ns: WikiNamespace. The namespace of the Wikipedia page. It defaults to Namespace.MAIN if not specified.\n:param unquote: Bool. If True, the title will be unquoted. It defaults to False.\n:return: WikipediaPage. An object representing the Wikipedia page."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_subsection_by_title", "tests/categories_test.py::TestCategories::test_categories_count", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_top_level_section_titles", "tests/wikipedia_page_test.py::TestWikipediaPage::test_article_method", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_summary"], "indent": 8}
{"namespace": "boto.glacier.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/glacier/__init__.py", "signature_position": [39, 39], "body_position": [40, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.glacier.layer2.Layer2", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the AWS Glacier service. It creates a connection to the Glacier service using the provided region name and additional keyword parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword parameters that can be passed to the connection.\n:return: Connection. The connection object to the Glacier service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestGlacierConnection::test_connect_to_region"], "indent": 4}
{"namespace": "alembic.config.Config.print_stdout", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/config.py", "signature_position": [162, 162], "body_position": [178, 183], "dependency": {"intra_class": ["alembic.config.Config.messaging_opts", "alembic.config.Config.stdout"], "intra_file": [], "cross_file": ["alembic.util", "alembic.util.messaging.write_outstream"]}, "requirement": {"Functionality": "This function is used to render a message to standard output. It takes a text string as input and formats it with additional arguments if provided. The formatted message is then output to the standard output. If no additional arguments are provided, the text is output verbatim. This function does nothing if the \"quiet\" messaging option is enabled.", "Arguments": ":param self: Config. An instance of the Config class.\n:param text: String. The text to be rendered to standard output.\n:param *arg: Additional arguments to be formatted against the provided text.\n:return: None."}, "tests": ["tests/test_config.py::StdoutOutputEncodingTest::test_plain", "tests/test_config.py::StdoutOutputEncodingTest::test_ascii_unicode", "tests/test_config.py::StdoutOutputEncodingTest::test_utf8_unicode", "tests/test_config.py::StdoutOutputEncodingTest::test_only_formats_output_with_args"], "indent": 8}
{"namespace": "falcon.request.Request.get_header", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [1124, 1124], "body_position": [1148, 1171], "dependency": {"intra_class": ["falcon.request.Request.env"], "intra_file": ["falcon.request.WSGI_CONTENT_HEADERS"], "cross_file": ["falcon.errors.HTTPMissingHeader", "falcon.errors"]}, "requirement": {"Functionality": "This function retrieves the raw string value for a given header in a request. It first converts the header name to uppercase and replaces any hyphens with underscores. Then, it tries to retrieve the header value from the request environment using the modified header name. If the header is not found and is not required, it returns the default value. If the header is not found and is required, it raises an HTTPBadRequest exception.", "Arguments": ":param self: Request. An instance of the Request class.\n:param name: str. The name of the header to retrieve.\n:param required: bool. Set to True to raise an HTTPBadRequest exception if the header is not found (default False).\n:param default: any. The value to return if the header is not found (default None).\n:return: str. The value of the specified header if it exists, or the default value if the header is not found and is not required.\n:raises: HTTPBadRequest. The header was not found in the request, but it was required."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_content_length_method", "tests/test_request_attrs.py::TestRequestAttributes::test_content_type_method", "tests/test_request_attrs.py::TestRequestAttributes::test_reconstruct_url"], "indent": 8}
{"namespace": "boltons.ioutils.SpooledStringIO.read", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [405, 405], "body_position": [406, 409], "dependency": {"intra_class": ["boltons.ioutils.SpooledStringIO._tell", "boltons.ioutils.SpooledStringIO.buffer", "boltons.ioutils.SpooledStringIO.len", "boltons.ioutils.SpooledStringIO.tell"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed"], "cross_file": []}, "requirement": {"Functionality": "Read and return the specified number of characters from the SpooledStringIO instance. It checks if the instance is closed, reads the characters from the buffer, updates the current position, and returns the characters.", "Arguments": ":param self: SpooledStringIO. An instance of the SpooledStringIO class.\n:param n: int. The number of characters to read. Defaults to -1, which means read all characters.\n:return: str. The characters read from the instance."}, "tests": ["tests/test_ioutils.py::TestSpooledStringIO::test_seek_encoded", "tests/test_ioutils.py::TestSpooledStringIO::test_tell_codepoints", "tests/test_ioutils.py::TestSpooledStringIO::test_x80_codepoint", "tests/test_ioutils.py::TestSpooledStringIO::test_codepoints_all_enc"], "indent": 8}
{"namespace": "boto.ec2.ec2object.TaggedEC2Object.remove_tags", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/ec2object.py", "signature_position": [122, 122], "body_position": [136, 144], "dependency": {"intra_class": ["boto.ec2.ec2object.TaggedEC2Object.id", "boto.ec2.ec2object.TaggedEC2Object.tags"], "intra_file": ["boto.ec2.ec2object.EC2Object.connection"], "cross_file": ["boto.ec2.connection.EC2Connection.delete_tags"]}, "requirement": {"Functionality": "This function removes tags from a TaggedEC2Object instance.. It sends a request to the EC2 service to remove the specified tags.", "Arguments": ":param self: TaggedEC2Object. An instance of the TaggedEC2Object class.\n:param tags: dict. A dictionary of key-value pairs for the tags being removed.\n:param dry_run: bool. Whether to perform a dry run, which means the tags will not actually be removed. Defaults to False.\n:return: None."}, "tests": ["tests/unit/ec2/test_ec2object.py::TestRemoveTags::test_remove_tags_wrong_values", "tests/unit/ec2/test_ec2object.py::TestRemoveTags::test_remove_tags", "tests/unit/ec2/test_ec2object.py::TestRemoveTags::test_remove_tags_none_values"], "indent": 8}
{"namespace": "kinto.core.utils.native_value", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [118, 118], "body_position": [124, 129], "dependency": {"intra_class": [], "intra_file": ["kinto.core.utils.json", "kinto.core.utils.json.loads"], "cross_file": []}, "requirement": {"Functionality": "This function converts a string value to its corresponding native Python value. If the input value is a string, it tries to parse it as JSON and return the parsed value. If the parsing fails, it returns the original string value.", "Arguments": ":param value: str. The value to be interpreted.\n:return: The value coerced to its corresponding Python type."}, "tests": ["tests/core/test_utils.py::NativeValueTest::test_non_string_values", "tests/core/test_utils.py::NativeValueTest::test_zero_and_one_coerce_to_integers", "tests/core/test_utils.py::NativeValueTest::test_defined_string", "tests/core/test_utils.py::NativeValueTest::test_bad_string_values", "tests/core/test_utils.py::NativeValueTest::test_integer"], "indent": 4}
{"namespace": "alembic.testing.env._no_sql_testing_config", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/env.py", "signature_position": [201, 201], "body_position": [204, 238], "dependency": {"intra_class": [], "intra_file": ["alembic.testing.env._get_staging_directory", "alembic.testing.env._write_config_file"], "cross_file": []}, "requirement": {"Functionality": "This function generates a configuration file for no-SQL testing. It creates a configuration file with specific settings for the Alembic migration tool and logging. The file is written to a specific directory.", "Arguments": ":param dialect: String. The type of database dialect to use. It defaults to \"postgresql\" if not specified.\n:param directives: String. Additional directives to include in the configuration file.\n:return: None."}, "tests": ["tests/test_post_write.py::RunHookTest::test_empty_hooks", "tests/test_post_write.py::RunHookTest::test_generic", "tests/test_post_write.py::RunHookTest::test_exec_executable_missing", "tests/test_post_write.py::RunHookTest::test_console_scripts_entrypoint_missing", "tests/test_post_write.py::RunHookTest::test_no_type"], "indent": 4}
{"namespace": "mrjob.fs.base.Filesystem.cat", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/base.py", "signature_position": [54, 54], "body_position": [61, 66], "dependency": {"intra_class": ["mrjob.fs.base.Filesystem._cat_file", "mrjob.fs.base.Filesystem.ls"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function reads and concatenates the contents of all files that match the given path pattern. It decompresses the files if necessary. The function yields the contents of the files as bytes, yields `b''` between each file.", "Arguments": ":param self: Filesystem. An instance of the Filesystem class.\n:param path_glob: String. The path pattern to match the files.\n:return: No return values. The function yields the contents of the files as bytes."}, "tests": ["tests/fs/test_base.py::CatTestCase::test_multiple_files", "tests/fs/test_local.py::LocalFSTestCase::test_put", "tests/fs/test_hadoop.py::HadoopFSTestCase::test_put"], "indent": 8}
{"namespace": "boto.dynamodb2.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/__init__.py", "signature_position": [39, 39], "body_position": [40, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in DynamoDB using the provided region name and additional keyword parameters. It creates a connection to DynamoDB using the specified region and returns the connection object.", "Arguments": ":param region_name: String. The name of the region to connect to in DynamoDB.\n:param **kw_params: Additional keyword parameters that can be passed to the connection.\n:return: DynamoDBConnection. The connection object to the specified region in DynamoDB."}, "tests": ["tests/unit/test_connect_to_region.py::TestDynamodb2Connection::test_connect_to_unkown_region", "tests/unit/test_connect_to_region.py::TestDynamodb2Connection::test_connect_to_region"], "indent": 4}
{"namespace": "pyramid.registry.Introspector.get", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [131, 131], "body_position": [132, 134], "dependency": {"intra_class": ["pyramid.registry.Introspector._categories"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves an item from the Introspector instance based on the given category name and discriminator. If the item is not found, it returns the default value.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param category_name: str. The name of the category to retrieve the item from.\n:param discriminator: The discriminator of the item to retrieve.\n:param default: Any data type. The value to return if the item is not found. Defaults to None.\n:return: Any data type. The retrieved item or the default value if the item is not found."}, "tests": ["tests/test_registry.py::TestIntrospector::test_get_success", "tests/test_registry.py::TestIntrospector::test_get_fail", "tests/test_registry.py::TestIntrospector::test_get_success_byhash"], "indent": 8}
{"namespace": "ydata_profiling.model.summary_algorithms.histogram_compute", "type": "function", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/model/summary_algorithms.py", "signature_position": [29, 35], "body_position": [36, 48], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["ydata_profiling.config.Histogram.bins", "ydata_profiling.config.Histogram.density", "ydata_profiling.config.Histogram.max_bins", "ydata_profiling.config.Plot.histogram", "ydata_profiling.config.Settings", "ydata_profiling.config.Settings.plot"]}, "requirement": {"Functionality": "This function computes the histogram of a given array of finite values. It first determines the number of bins based on the configuration settings. If the number of bins exceeds the maximum allowed bins, it reduces the number of bins to the maximum value. It then computes the histogram using the numpy library and returns the histogram statistics.", "Arguments": ":param config: Settings. The configuration settings for the histogram computation.\n:param finite_values: np.ndarray. An array of finite values for which the histogram is computed.\n:param n_unique: int. The number of unique values in the finite_values array.\n:param name: str. The name of the histogram. Defaults to \"histogram\".\n:param weights: Optional[np.ndarray]. An optional array of weights for the histogram computation. Defaults to None.\n:return: dict. A dictionary containing the computed histogram statistics."}, "tests": ["tests/unit/test_summary_algos.py::test_compute_histogram"], "indent": 4}
{"namespace": "diffprivlib.tools.utils.std", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [462, 463], "body_position": [516, 519], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._std"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the standard deviation of the input array along the specified axis, with differential privacy. It adds noise to the computation to satisfy differential privacy requirements. The standard deviation is calculated for the flattened array by default, but can also be calculated over a specified axis. The behavior of this function closely follows the Numpy variant of `std`.", "Arguments": ":param array: array_like. The array for which the standard deviation is calculated.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: int or tuple of ints, optional. The axis or axes along which the standard deviation is computed. The default is to compute the standard deviation of the flattened array. If a tuple of ints is provided, the standard deviation is performed over multiple axes.\n:param dtype: dtype, optional. The type to use in computing the standard deviation. For arrays of integer type, the default is float64. For arrays of float types, it is the same as the array type.\n:param keepdims: bool, default: False. If set to True, the axes which are reduced are left in the result as dimensions with size one. This allows the result to broadcast correctly against the input array.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm. To obtain deterministic behavior during randomization, the random_state has to be fixed to an integer.\n:param accountant: BudgetAccountant, optional. An accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. A new array containing the standard deviation."}, "tests": ["tests/tools/test_std.py::TestStd::test_nan", "tests/tools/test_std.py::TestStd::test_large_epsilon", "tests/tools/test_std.py::TestStd::test_missing_bounds", "tests/tools/test_std.py::TestStd::test_accountant", "tests/tools/test_std.py::TestStd::test_clipped_output"], "indent": 4}
{"namespace": "diffprivlib.accountant.BudgetAccountant.__repr__", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/accountant.py", "signature_position": [153, 153], "body_position": [154, 170], "dependency": {"intra_class": ["diffprivlib.accountant.BudgetAccountant.delta", "diffprivlib.accountant.BudgetAccountant.epsilon", "diffprivlib.accountant.BudgetAccountant.slack", "diffprivlib.accountant.BudgetAccountant.spent_budget"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the BudgetAccountant instance. It includes the values of the instance's attributes in the string representation. For epsilon, it is included if it is not equal to infinity.\nFor delta, it is included if it differs from the default value of 1. For slack, it is included if it is greater than 0. The function also checks the spent budget. If length of spent budget exceeds a certain maximum of budget, only a subset of its elements is included, followed an additional ellipsis (\"...\") to indicate truncation and a replacement of \"\u201c\" with \"\". All these attributes will then be appended in the format:{\"{attribute name}={attribute value}\" like \"delta=0.3\"}. Finally, the output format is \"BudgetAccountant({processed attributes separating each element by a comma and a space} )\"", "Arguments": ":param self: BudgetAccountant. An instance of the BudgetAccountant class.\n:param n_budget_max: Integer. The maximum number of elements to include in the spent budget. Defaults to 5.\n:return: String. The string representation of the BudgetAccountant instance."}, "tests": ["tests/test_BudgetAccountant.py::TestBudgetAccountant::test_repr"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage.backlinks", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [1015, 1015], "body_position": [1026, 1028], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._backlinks", "wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch"], "intra_file": ["wikipediaapi.PagesDict"], "cross_file": []}, "requirement": {"Functionality": "This function returns all the pages that link to the current Wikipedia page. It is a wrapper for the MediaWiki API's backlinks module.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: PagesDict. A dictionary containing the pages that link to the current page."}, "tests": ["tests/backlinks_test.py::TestBackLinks::test_backlinks_multi_page_titles", "tests/backlinks_test.py::TestBackLinks::test_backlinks_multi_page_count", "tests/backlinks_test.py::TestBackLinks::test_backlinks_nonexistent_count", "tests/backlinks_test.py::TestBackLinks::test_backlinks_single_page_titles", "tests/backlinks_test.py::TestBackLinks::test_backlinks_single_page_count"], "indent": 8}
{"namespace": "pycoin.blockchain.ChainFinder.ChainFinder.find_ancestral_path", "type": "method", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/blockchain/ChainFinder.py", "signature_position": [85, 85], "body_position": [86, 98], "dependency": {"intra_class": ["pycoin.blockchain.ChainFinder.ChainFinder.maximum_path"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Find the ancestral path between two nodes in a chain.\n", "Arguments": ":param h1: The first node in the chain.\n:param h2: The second node in the chain.\n:param path_cache: Dict, a dictionary that caches computed paths. It is optional and defaults to an empty dictionary.\n:return: Tuple, a tuple containing two lists. The first list is the ancestral path from h1 to the common ancestor. The second list is the ancestral path from h2 to the common ancestor.\n"}, "tests": ["tests/chainfinder_test.py::ChainFinderTestCase::test_find_ancestral_path", "tests/chainfinder_test.py::ChainFinderTestCase::test_large"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.noop", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [869, 869], "body_position": [885, 886], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._consume_until_tagged_response", "imapclient.imapclient.IMAPClient._imap"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function executes the NOOP command in the IMAPClient instance. The NOOP command returns immediately and can be used to receive any server-side status updates or reset any auto-logout timers.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:return: The server command response message followed by a list of status responses."}, "tests": ["tests/test_imapclient.py::TestIdleAndNoop::test_noop"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.starttls", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [361, 361], "body_position": [378, 388], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._checkok", "imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient._starttls_done", "imapclient.imapclient.IMAPClient.host", "imapclient.imapclient.IMAPClient.ssl"], "intra_file": [], "cross_file": ["imapclient.exceptions.IMAPClientAbortError", "imapclient.imap4.IMAP4WithTimeout.file", "imapclient.imap4.IMAP4WithTimeout.sock", "imapclient.tls.wrap_socket", "imapclient.exceptions", "imapclient.tls"]}, "requirement": {"Functionality": "This function switches the connection to an SSL encrypted connection by sending a STARTTLS command. It establishes an SSL connection using the provided SSL context or a default SSL context. It also checks the hostname in the server's certificate against the hostname used for connecting. If the SSL connection cannot be established or the server does not support STARTTLS, appropriate exceptions are raised.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param ssl_context: SSLContext. Optional. The SSL context to use for establishing the SSL connection. If not provided, a default SSL context with reasonable default settings will be used.\n:return: The response from the server after executing the STARTTLS command."}, "tests": ["tests/test_starttls.py::TestStarttls::test_fails_if_called_twice", "tests/test_starttls.py::TestStarttls::test_command_fails", "tests/test_starttls.py::TestStarttls::test_works"], "indent": 8}
{"namespace": "boltons.dictutils.ManyToMany.replace", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [983, 983], "body_position": [987, 993], "dependency": {"intra_class": ["boltons.dictutils.ManyToMany.data", "boltons.dictutils.ManyToMany.inv"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function replaces instances of a key with a new key in a ManyToMany instance. It updates the data dictionary by replacing the key with the new key and updates the corresponding sets in both the forward and inverse dictionaries.", "Arguments": ":param self: ManyToMany. An instance of the ManyToMany class.\n:param key: The key to be replaced.\n:param newkey: The new key to replace the old key with.\n:return: No return values."}, "tests": ["tests/test_dictutils.py::test_many_to_many"], "indent": 8}
{"namespace": "mopidy.internal.validation.check_instances", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/validation.py", "signature_position": [69, 69], "body_position": [70, 72], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.validation._check_iterable"], "cross_file": ["mopidy.exceptions.ValidationError", "mopidy.exceptions"]}, "requirement": {"Functionality": "This function checks if all elements in the input argument are instances of a specified class. If any element is not an instance of the class, it raises a validation error with a specified error message.", "Arguments": ":param arg: Any. The input argument to be checked.\n:param cls: Class. The class that all elements in the input argument should be instances of.\n:param msg: String. The error message to be raised if any element is not an instance of the class. It defaults to \"Expected a list of {name}, not {arg!r}\".\n:return: No return values. It raises a validation error if any element is not an instance of the class."}, "tests": ["tests/internal/test_validation.py::test_check_instances_error_message", "tests/internal/test_validation.py::test_check_instances_with_invalid_values"], "indent": 4}
{"namespace": "boltons.socketutils.BufferedSocket.getsendbuffer", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [194, 194], "body_position": [196, 197], "dependency": {"intra_class": ["boltons.socketutils.BufferedSocket._send_lock", "boltons.socketutils.BufferedSocket.sbuf"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a copy of the send buffer list in the BufferedSocket instance.", "Arguments": ":param self: BufferedSocket. An instance of the BufferedSocket class.\n:return: bytes. A copy of the send buffer list."}, "tests": ["tests/test_socketutils.py::test_client_disconnecting", "tests/test_socketutils.py::test_buffers"], "indent": 8}
{"namespace": "jc.parsers.xrandr._parse_screen", "type": "function", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/parsers/xrandr.py", "signature_position": [292, 292], "body_position": [293, 312], "dependency": {"intra_class": [], "intra_file": ["jc.parsers.xrandr.Device", "jc.parsers.xrandr.Screen", "jc.parsers.xrandr._parse_device", "jc.parsers.xrandr._screen_pattern"], "cross_file": []}, "requirement": {"Functionality": "This function parses a screen definition from a list of lines. It first pops the next line from the list and checks if it matches the screen pattern. If it doesn't match, the line is appended back to the list and None is returned. If it matches, the raw matches are extracted and stored in a dictionary. Then, it iterates through the remaining lines and parses each device definition. The parsed devices are appended to the \"devices\" list in the screen dictionary. Finally, the screen dictionary is returned.", "Arguments": ":param next_lines: List of strings. The list of lines to parse the screen definition from.\n:return: Optional[Screen]. The parsed screen definition, or None if the next line doesn't match the screen pattern."}, "tests": ["tests/test_xrandr.py::XrandrTests::test_screens"], "indent": 4}
{"namespace": "pyramid.renderers.RendererHelper.render_view", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [433, 433], "body_position": [434, 443], "dependency": {"intra_class": ["pyramid.renderers.RendererHelper.name", "pyramid.renderers.RendererHelper.render_to_response"], "intra_file": [], "cross_file": ["pyramid.csrf.get_csrf_token"]}, "requirement": {"Functionality": "This function renders a view using a specified renderer. It creates a dictionary called \"system\" that contains various information related to the rendering process, such as the view, renderer name, renderer info, context, request, and CSRF token. It uses the provided response, system, and request parameters to generate the final response.", "Arguments": ":param self: RendererHelper. An instance of the RendererHelper class.\n:param request: The request object.\n:param response: The response object.\n:param view: The view to be rendered.\n:param context: The context data to be passed to the system.\n:return: No return value."}, "tests": ["tests/test_renderers.py::TestRendererHelper::test_render_view"], "indent": 8}
{"namespace": "twtxt.config.Config.from_file", "type": "method", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/config.py", "signature_position": [36, 36], "body_position": [41, 54], "dependency": {"intra_class": ["twtxt.config.Config.__init__", "twtxt.config.Config.check_config_sanity"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function tries to load a given config file. It first checks if the file exists, and then reads the file. It creates a Config instance with the file path and the parsed configuration. It checks the sanity of the configuration and returns the instance if it is valid.", "Arguments": ":param cls: Class. The class of the `Config` instance.\n:param file: String. The full path to the config file to load.\n:return: Config. The created `Config` instance."}, "tests": ["tests/test_config.py::test_check_config_file_sanity", "tests/test_config.py::test_from_file"], "indent": 8}
{"namespace": "discord.utils.snowflake_time", "type": "function", "project_path": "Software-Development/discord-py", "completion_path": "Software-Development/discord-py/discord/utils.py", "signature_position": [375, 375], "body_position": [391, 392], "dependency": {"intra_class": [], "intra_file": ["discord.utils.DISCORD_EPOCH"], "cross_file": []}, "requirement": {"Functionality": "This function calculates and returns the creation time of a given snowflake ID. It converts the snowflake ID into a timestamp and then converts the timestamp into a datetime object in UTC.", "Arguments": ":param id: int. The snowflake ID.\n:return: datetime.datetime. An aware datetime object in UTC representing the creation time of the snowflake."}, "tests": ["tests/test_utils.py::test_snowflake_time"], "indent": 4}
{"namespace": "zxcvbn.matching.dictionary_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [96, 96], "body_position": [97, 118], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.RANKED_DICTIONARIES"], "cross_file": []}, "requirement": {"Functionality": "This function performs a dictionary match on a given password. It checks if any substrings of the password are present in a ranked dictionary. If a match is found, it creates a dictionary with information about the match and appends it to a list. The list is then sorted based on the starting and ending indices of the matches.", "Arguments": ":param password: String. The password to be checked for dictionary matches.\n:param _ranked_dictionaries: Dictionary. A dictionary containing ranked dictionaries of words.\n:return: List. A list of dictionaries containing information about the matches found in the password."}, "tests": ["tests/matching_test.py::test_dictionary_matching"], "indent": 4}
{"namespace": "mrjob.step.StepFailedException.__str__", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/step.py", "signature_position": [128, 128], "body_position": [131, 152], "dependency": {"intra_class": ["mrjob.step.StepFailedException.last_step_num", "mrjob.step.StepFailedException.num_steps", "mrjob.step.StepFailedException.reason", "mrjob.step.StepFailedException.step_desc", "mrjob.step.StepFailedException.step_num"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a human-readable version of the StepFailedException exception. If the reason is available, it returns '{step description} failed: {reason}'. Otherwise, it returns '{step description} failed'. If the step description is not available, it will generate a step description based on the step number. If the step number is not available, it will use 'Step' as the step description. If the total number of steps is available, it will use '{step name} of {total number of steps}' as the step description; otherwise it will use the step name as the step description. If the last step number is available, it will use 'Steps {step number + 1}-{last step number + 1}' as the step description; otherwise it will use 'Step {step number + 1}' as the step description.", "Arguments": ":param self: StepFailedException. An instance of the StepFailedException class.\n:return: str. A human-readable version of the exception."}, "tests": ["tests/test_step.py::StepFailedExceptionTestCase::test_empty", "tests/test_step.py::StepFailedExceptionTestCase::test_num_steps_with_no_step_num", "tests/test_step.py::StepFailedExceptionTestCase::test_step_num_with_num_steps", "tests/test_step.py::StepFailedExceptionTestCase::test_step_num", "tests/test_step.py::StepFailedExceptionTestCase::test_reason"], "indent": 8}
{"namespace": "sacred.utils.recursive_update", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [392, 392], "body_position": [401, 407], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.recursive_update"], "cross_file": []}, "requirement": {"Functionality": "This function takes two dictionaries, `d` and `u`, and recursively updates the dictionary `d` with the key-value pairs from `u`. If a key in `u` already exists in `d` and the value is also a dictionary, the function recursively updates the nested dictionary. If the value is not a dictionary, the function simply updates the value in `d` with the value from `u`.", "Arguments": ":param d: Dictionary. The dictionary to be updated.\n:param u: Dictionary. The dictionary containing the key-value pairs to update `d` with.\n:return: Dictionary. The updated dictionary `d`."}, "tests": ["tests/test_utils.py::test_recursive_update"], "indent": 4}
{"namespace": "pyramid.authentication.SessionAuthenticationHelper.forget", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [1270, 1270], "body_position": [1272, 1274], "dependency": {"intra_class": ["pyramid.authentication.SessionAuthenticationHelper.userid_key"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes the stored user ID from the session.", "Arguments": ":param self: SessionAuthenticationHelper. An instance of the SessionAuthenticationHelper class.\n:param request: The request object.\n:param **kw: Additional keyword arguments.\n:return: An empty list."}, "tests": ["tests/test_authentication.py::TestSessionAuthenticationHelper::test_forget", "tests/test_authentication.py::TestSessionAuthenticationHelper::test_forget_no_identity"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.set_quota", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1605, 1605], "body_position": [1610, 1630], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._raw_command_untagged"], "intra_file": ["imapclient.imapclient._parse_quota", "imapclient.imapclient._quote"], "cross_file": ["imapclient.util.to_bytes"]}, "requirement": {"Functionality": "This function sets one or more quotas on resources in an IMAPClient instance. It takes a list of Quota objects as input and constructs the necessary arguments to set the quotas. It then sends the SETQUOTA command to the IMAP server and returns the parsed response.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param quotas: List of Quota objects. The quotas to be set on resources.\n:return: No return values."}, "tests": ["tests/test_imapclient.py::TestQuota::test_set_quota"], "indent": 8}
{"namespace": "pyramid.csrf.SessionCSRFStoragePolicy.check_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [86, 86], "body_position": [88, 91], "dependency": {"intra_class": ["pyramid.csrf.SessionCSRFStoragePolicy.get_csrf_token"], "intra_file": [], "cross_file": ["pyramid.util.bytes_", "pyramid.util.strings_differ"]}, "requirement": {"Functionality": "Check if the supplied CSRF token is valid by comparing it with the expected token. It converts both tokens to bytes and checks if they are equal.", "Arguments": ":param self: SessionCSRFStoragePolicy. An instance of the SessionCSRFStoragePolicy class.\n:param request: The request object.\n:param supplied_token: The CSRF token supplied by the client.\n:return: Bool. True if the supplied token is valid, False otherwise."}, "tests": ["tests/test_csrf.py::TestSessionCSRFStoragePolicy::test_check_csrf_token"], "indent": 8}
{"namespace": "asyncssh.misc.write_file", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/misc.py", "signature_position": [225, 225], "body_position": [228, 229], "dependency": {"intra_class": [], "intra_file": ["asyncssh.misc.FilePath", "asyncssh.misc.open_file"], "cross_file": []}, "requirement": {"Functionality": "This function writes or appends data to a file with home directory expansion. It opens the file using the specified mode, writes the data to the file, and returns the number of bytes written.", "Arguments": ":param filename: FilePath. The path of the file to write or append to.\n:param data: bytes. The data to write to the file.\n:param mode: str. The mode in which to open the file. It defaults to 'wb'.\n:return: int. The number of bytes written to the file."}, "tests": ["tests/test_public_key.py::_TestPublicKeyTopLevel::test_public_key_algorithm_mismatch"], "indent": 4}
{"namespace": "fs.wildcard.get_matcher", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/wildcard.py", "signature_position": [101, 102], "body_position": [124, 129], "dependency": {"intra_class": [], "intra_file": ["fs.wildcard.imatch_any", "fs.wildcard.match_any"], "cross_file": []}, "requirement": {"Functionality": "Return a callable that can match names against given wildcard patterns. If the list of patterns is empty, return True when called.\n", "Arguments": ":param patterns: List[String], a list of wildcard patterns, e.g., ``[\"*.py\", \"*.pyc\"]``.\n:param case_sensitive: Bool, if True, the matching will be case sensitive. If False, the matching will be case insensitive.\n:return: Callable, a matcher that returns True if the name given as an argument matches any of the given patterns.\n"}, "tests": ["tests/test_wildcard.py::TestFNMatch::test_get_matcher"], "indent": 4}
{"namespace": "mopidy.ext.Extension.get_cache_dir", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/ext.py", "signature_position": [77, 77], "body_position": [85, 91], "dependency": {"intra_class": ["mopidy.ext.Extension.ext_name"], "intra_file": ["mopidy.ext.Config"], "cross_file": ["mopidy.internal.path.expand_path", "mopidy.internal.path.get_or_create_dir", "mopidy.internal.path"]}, "requirement": {"Functionality": "This function is a class method that gets or creates a cache directory for the extension. It uses the Mopidy config object to determine the cache directory path and creates the directory if it doesn't exist.", "Arguments": ":param cls: Class. The Extension class.\n:param config: Config. The Mopidy config object.\n:return: Path. The pathlib.Path object representing the cache directory path."}, "tests": ["tests/test_ext.py::TestExtension::test_get_cache_dir_raises_error"], "indent": 8}
{"namespace": "asyncssh.saslprep.saslprep", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/saslprep.py", "signature_position": [107, 107], "body_position": [110, 116], "dependency": {"intra_class": [], "intra_file": ["asyncssh.saslprep._map_saslprep", "asyncssh.saslprep._stringprep"], "cross_file": []}, "requirement": {"Functionality": "This function implements the SASLprep profile defined in RFC 4013. It takes a string as input and applies a series of string preparation steps to it.", "Arguments": ":param s: String. The input string to be processed.\n:return: String. The processed string after applying the SASLprep profile."}, "tests": ["tests/test_saslprep.py::_TestSASLPrep::test_nonstring", "tests/test_saslprep.py::_TestSASLPrep::test_prohibited", "tests/test_saslprep.py::_TestSASLPrep::test_bidi", "tests/test_saslprep.py::_TestSASLPrep::test_map_to_whitespace", "tests/test_saslprep.py::_TestSASLPrep::test_map_to_nothing"], "indent": 4}
{"namespace": "boltons.listutils.BarrelList.sort", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/listutils.py", "signature_position": [310, 312], "body_position": [313, 321], "dependency": {"intra_class": ["boltons.listutils.BarrelList._balance_list", "boltons.listutils.BarrelList.lists"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Sort the elements in the BarrelList instance. It sorts the elements in each list individually and merges them into a single sorted list. It then balance the list.", "Arguments": ":param self: BarrelList. An instance of the BarrelList class.\n:return: No return values."}, "tests": ["tests/test_listutils.py::test_barrel_list"], "indent": 8}
{"namespace": "boto.opsworks.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/opsworks/__init__.py", "signature_position": [39, 39], "body_position": [40, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.opsworks.layer1.OpsWorksConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the OpsWorks service using the provided region name and additional keyword parameters. It creates an instance of the OpsWorksConnection class and returns it.", "Arguments": ":param region_name: String. The name of the region to connect to in the OpsWorks service.\n:param **kw_params: Additional keyword parameters that can be passed to the connect function.\n:return: OpsWorksConnection. An instance of the OpsWorksConnection class."}, "tests": ["tests/unit/test_connect_to_region.py::TestOpsworksConnection::test_connect_to_region"], "indent": 4}
{"namespace": "pyramid.config.assets.PackageOverrides.insert", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/assets.py", "signature_position": [111, 111], "body_position": [112, 117], "dependency": {"intra_class": ["pyramid.config.assets.PackageOverrides.overrides"], "intra_file": ["pyramid.config.assets.DirectoryOverride", "pyramid.config.assets.DirectoryOverride.__init__", "pyramid.config.assets.FileOverride", "pyramid.config.assets.FileOverride.__init__"], "cross_file": []}, "requirement": {"Functionality": "Insert a new override into the PackageOverrides instance. It creates a new override object based on the given path and source, and inserts it at the beginning of the overrides list in the PackageOverrides instance.", "Arguments": ":param self: PackageOverrides. An instance of the PackageOverrides class.\n:param path: str. The path of the override. If it is empty or it ends with a slash, it is treated as a directory override. Otherwise, it is treated as a file override.\n:param source: Object. The source of the override.\n:return: The created override object."}, "tests": ["tests/test_config/test_assets.py::TestPackageOverrides::test_insert_directory", "tests/test_config/test_assets.py::TestPackageOverrides::test_insert_emptystring", "tests/test_config/test_assets.py::TestPackageOverrides::test_insert_file"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.sort", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1173, 1173], "body_position": [1195, 1201], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._raw_command_untagged"], "intra_file": ["imapclient.imapclient._normalise_search_criteria", "imapclient.imapclient._normalise_sort_criteria"], "cross_file": ["imapclient.util.to_bytes"]}, "requirement": {"Functionality": "This function sorts the message ids from the currently selected folder based on the given sort criteria and optionally filters them based on the criteria. It uses the SORT command of the IMAP protocol to perform the sorting.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param sort_criteria: List of strings or a single string. The criteria to sort the message ids by. Valid values include 'ARRIVAL', 'SUBJECT', 'REVERSE SIZE', etc.\n:param criteria: String. The criteria to filter the message ids. Defaults to \"ALL\".\n:param charset: String. The character set to use for the criteria. Defaults to \"UTF-8\".\n:return: List of integers. The sorted message ids from the currently selected folder."}, "tests": ["tests/test_sort.py::TestSort::test_single_criteria", "tests/test_sort.py::TestSort::test_all_args", "tests/test_sort.py::TestSort::test_multiple_criteria"], "indent": 8}
{"namespace": "mrjob.logs.history._parse_pre_yarn_history_log", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/history.py", "signature_position": [287, 287], "body_position": [294, 333], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.history._parse_pre_yarn_counters", "mrjob.logs.history._parse_pre_yarn_history_records"], "cross_file": ["mrjob.logs.counters._sum_counters"]}, "requirement": {"Functionality": "Parses a pre-YARN history file and collects useful information.\nThe function `_parse_pre_yarn_history_log` is used to extract useful information from a pre-YARN history file. It takes in a list of strings `lines` representing the lines of the history file. It initializes an empty dictionary `result` and an empty dictionary `task_to_counters`. The function iterates over each record in the parsed pre-YARN history records. It checks the type of the record and performs different operations based on the type.\nIf job is successful, it get counters for the entire job at the end, therwise, compile counters for each successful task. That is, if the record type is 'Task' and it contains 'COUNTERS' and 'TASKID' in the fields, it extracts the counters and assigns them to `task_to_counters` dictionary with the task ID as the key. If the record is FAILED, it only want FAILED (not KILLED) tasks with non-blank errors. It appends a new dictionary to a list as the value of errors key of dictionary. The dictionary contains the error message, start line, and number of lines, as well as the task attempt ID.After processing all the records, if job failed, patch together counters from successful task_to_counters.\n", "Arguments": ":param lines: List of strings. The lines of the history file.\n:return: Dict. The parsed information from the history file.\n"}, "tests": ["tests/logs/test_history.py::ParsePreYARNHistoryLogTestCase::test_ignore_killed_task_with_empty_error", "tests/logs/test_history.py::ParsePreYARNHistoryLogTestCase::test_task_counters", "tests/logs/test_history.py::ParsePreYARNHistoryLogTestCase::test_errors", "tests/logs/test_history.py::ParsePreYARNHistoryLogTestCase::test_empty", "tests/logs/test_history.py::ParsePreYARNHistoryLogTestCase::test_job_counters_beat_task_counters"], "indent": 4}
{"namespace": "dash.development._collect_nodes.collect_nodes", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/development/_collect_nodes.py", "signature_position": [49, 49], "body_position": [50, 74], "dependency": {"intra_class": [], "intra_file": ["dash.development._collect_nodes.collect_array", "dash.development._collect_nodes.collect_nodes", "dash.development._collect_nodes.collect_object", "dash.development._collect_nodes.collect_union", "dash.development._collect_nodes.is_node", "dash.development._collect_nodes.is_shape"], "cross_file": []}, "requirement": {"Functionality": "This function collects all the nodes in the metadata dictionary and returns them as a list. It recursively traverses the metadata dictionary and checks the type of each value to determine if it is a node, an array, a shape, a union, or an object. It appends the corresponding keys to the nodes list.", "Arguments": ":param metadata: Dictionary. The metadata dictionary containing the nodes.\n:param base: String. The base key to be used for nested nodes. Defaults to an empty string.\n:param nodes: List. The list to store the collected nodes. Defaults to an empty list.\n:return: List. The list of collected nodes."}, "tests": ["tests/unit/development/test_collect_nodes.py::test_dcn002_base_nodes", "tests/unit/development/test_collect_nodes.py::test_dcn001_collect_nodes"], "indent": 4}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.try_read_headers", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [334, 334], "body_position": [345, 394], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.CR", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.LF", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.buffer", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.buffer_end_offset", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.expected_content_length", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.headers", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_offset", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_state", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.trim_buffer_and_resize"], "intra_file": ["mssqlcli.jsonrpc.jsonrpcclient.ReadState", "mssqlcli.jsonrpc.jsonrpcclient.ReadState.Content", "mssqlcli.jsonrpc.jsonrpcclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function tries to read the Header information from the internal buffer of a JsonRpcReader instance. It scans the buffer until it finds the last header containing '\\r\\n\\r\\n'. It then splits the headers by new line, extracts the key-value pairs, and stores them in the headers dictionary of the instance. It also checks if the 'content-length' header is present and stores its value in the expected content length of the instance.", "Arguments": ":param self: JsonRpcReader. An instance of the JsonRpcReader class.\n:return: bool. True if the header information was successfully read, False otherwise."}, "tests": ["tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_read_state"], "indent": 8}
{"namespace": "mopidy.config.types.Secret.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [138, 138], "body_position": [139, 141], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.types.String", "mopidy.config.types.String.serialize"], "cross_file": []}, "requirement": {"Functionality": "Serialize a value based on the given condition. If the value is not None and the display flag is set to True, it returns \"********\". Otherwise, it makes the superclass to serialize that and returns the result.", "Arguments": ":param self: Secret. An instance of the Secret class.\n:param value: The value to be serialized.\n:param display: Bool. Whether to display the serialized value. Defaults to False.\n:return: The serialized value."}, "tests": ["tests/config/test_types.py::TestSecret::test_serialize_none", "tests/config/test_types.py::TestSecret::test_serialize_for_display_masks_value", "tests/config/test_types.py::TestSecret::test_serialize_transformed_value_for_display_masks_value", "tests/config/test_types.py::TestSecret::test_serialize_none_for_display", "tests/config/test_types.py::TestSecret::test_serialize_transformed_value"], "indent": 8}
{"namespace": "boto.dynamodb2.table.BatchTable.resend_unprocessed", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1703, 1706], "body_position": [1707, 1724], "dependency": {"intra_class": ["boto.dynamodb2.table.BatchTable._unprocessed", "boto.dynamodb2.table.BatchTable.handle_unprocessed", "boto.dynamodb2.table.BatchTable.table"], "intra_file": ["boto.dynamodb2.table.Table.connection"], "cross_file": ["boto.log", "boto", "boto.dynamodb2.layer1.DynamoDBConnection.batch_write_item"]}, "requirement": {"Functionality": "Resend unprocessed items in the BatchTable instance. It iterates over the unprocessed items and sends them in batches until all items are processed.", "Arguments": ":param self: BatchTable. An instance of the BatchTable class.\n:return: No return values."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write_unprocessed_items"], "indent": 8}
{"namespace": "folium.utilities.get_bounds", "type": "function", "project_path": "Scientific-Engineering/folium", "completion_path": "Scientific-Engineering/folium/folium/utilities.py", "signature_position": [382, 382], "body_position": [388, 402], "dependency": {"intra_class": [], "intra_file": ["folium.utilities._locations_mirror", "folium.utilities.iter_coords", "folium.utilities.none_max", "folium.utilities.none_min"], "cross_file": []}, "requirement": {"Functionality": "This function computes the bounds of the object based on the given locations. It iterates through the coordinates of the locations and updates the bounds accordingly. The bounds are returned in the form of [[lat_min, lon_min], [lat_max, lon_max]].", "Arguments": ":param locations: The locations of the object.\n:param lonlat: Bool. Whether the coordinates are in the form of [lon, lat]. Defaults to False.\n:return: The bounds of the object in the form of [[lat_min, lon_min], [lat_max, lon_max]]."}, "tests": ["tests/test_vector_layers.py::test_polygon_marker", "tests/test_vector_layers.py::test_polyline", "tests/test_vector_layers.py::test_mulyipolyline"], "indent": 4}
{"namespace": "ydata_profiling.model.pandas.correlations_pandas.pandas_cramers_compute", "type": "function", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/model/pandas/correlations_pandas.py", "signature_position": [85, 87], "body_position": [88, 121], "dependency": {"intra_class": [], "intra_file": ["ydata_profiling.model.pandas.correlations_pandas._cramers_corrected_stat"], "cross_file": ["ydata_profiling.config.Settings", "ydata_profiling.config.Settings.categorical_maximum_correlation_distinct"]}, "requirement": {"Functionality": "This function computes the Cramer's V correlation matrix for categorical variables in a pandas DataFrame. It first identifies the categorical variables based on the given summary dictionary and a threshold value. Then, it creates an empty correlation matrix with the identified categorical variables as both the index and columns. Next, it calculates the Cramer's V correlation coefficient for each pair of categorical variables and stores the result in the correlation matrix.", "Arguments": ":param config: Settings. An instance of the Settings class that contains the configuration parameters.\n:param df: pd.DataFrame. The pandas DataFrame containing the data.\n:param summary: dict. A dictionary that summarizes the variables in the DataFrame. It should have the variable names as keys and a dictionary with information about each variable as values.\n:return: Optional[pd.DataFrame]. The computed Cramer's V correlation matrix as a pandas DataFrame. If there are less than or equal to 1 categorical variable, None is returned."}, "tests": ["tests/unit/test_pandas/test_correlations.py::test_categorical_auto_equals_equals_cramers"], "indent": 4}
{"namespace": "dash.development.base_component.Component.to_plotly_json", "type": "method", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/development/base_component.py", "signature_position": [203, 204], "body_position": [205, 228], "dependency": {"intra_class": ["dash.development.base_component.Component._namespace", "dash.development.base_component.Component._prop_names", "dash.development.base_component.Component._type"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts a Component instance into a JSON object that can be used by Plotly. It extracts the normal properties of the Component instance and adds them to the JSON object. It also adds any wildcard properties (properties starting with \"data-\" or \"aria-\") to the JSON object. Finally, it includes the properties, type and namespace of the Component instance in the JSON object.", "Arguments": ":param self: Component. An instance of the Component class.\n:return: JSON. The JSON representation of the Component instance."}, "tests": ["tests/unit/development/test_base_component.py::test_debc022_to_plotly_json_with_children", "tests/unit/development/test_base_component.py::test_debc012_to_plotly_json_full_tree", "tests/unit/development/test_base_component.py::test_debc020_to_plotly_json_without_children", "tests/unit/development/test_base_component.py::test_debc023_to_plotly_json_with_wildcards", "tests/unit/development/test_base_component.py::test_debc021_to_plotly_json_with_null_arguments"], "indent": 8}
{"namespace": "imapclient.util.assert_imap_protocol", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/util.py", "signature_position": [33, 33], "body_position": [34, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["imapclient.exceptions.ProtocolError", "imapclient.exceptions"]}, "requirement": {"Functionality": "This function is used to assert whether a condition is true. If the condition is false, it raises the corresponding exception with a specific error message \"Server replied with a response that violates the IMAP protocol\".", "Arguments": ":param condition: Bool. The condition to be checked.\n:param message: Optional bytes. An optional message to be included in the error message. Defaults to None.\n:return: No return values. Or raises a protocol error."}, "tests": ["tests/test_util_functions.py::TestAssertIMAPProtocol::test_assert_imap_protocol_with_message", "tests/test_util_functions.py::TestAssertIMAPProtocol::test_assert_imap_protocol"], "indent": 4}
{"namespace": "trailscraper.record_sources.local_directory_record_source.LocalDirectoryRecordSource.load_from_dir", "type": "method", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/record_sources/local_directory_record_source.py", "signature_position": [37, 37], "body_position": [39, 44], "dependency": {"intra_class": ["trailscraper.record_sources.local_directory_record_source.LocalDirectoryRecordSource._valid_log_files"], "intra_file": [], "cross_file": ["trailscraper.cloudtrail.LogFile.contains_events_for_timeframe", "trailscraper.cloudtrail.LogFile.records"]}, "requirement": {"Functionality": "Load all CloudTrail records from a directory within a specified date range. It iterates through all valid log files in the directory and checks if each file contains events within the specified date range. If a file meets the criteria, it retrieves the records from that file and adds them to the list of records.", "Arguments": ":param self: LocalDirectoryRecordSource. An instance of the LocalDirectoryRecordSource class.\n:param from_date: The starting date of the desired records.\n:param to_date: The ending date of the desired records.\n:return: List of CloudTrail records. The records that fall within the specified date range."}, "tests": ["tests/record_sources/local_directory_record_source_test.py::test_load_gzipped_files_including_those_that_were_delivered_only_an_hour_after_the_event_time_we_are_looking_for", "tests/record_sources/local_directory_record_source_test.py::test_load_gzipped_files_in_timeframe_from_dir", "tests/record_sources/local_directory_record_source_test.py::test_load_no_gzipped_files_outsite_timeframe_from_dir"], "indent": 8}
{"namespace": "alembic.command.history", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [472, 477], "body_position": [489, 538], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.config.Config.get_main_option", "alembic.script.ScriptDirectory.from_config", "alembic.util", "alembic.util.CommandError"]}, "requirement": {"Functionality": "This function lists the changeset scripts in chronological order. It takes a configuration instance, a revision range, a verbose flag, and an indicate_current flag as input. It uses the input parameters to display the history of changeset scripts.", "Arguments": ":param config: Config. An instance of the Config class.\n:param rev_range: Optional string. The revision range to display the history for.\n:param verbose: Bool. Whether to output in verbose mode.\n:param indicate_current: Bool. Whether to indicate the current revision.\n:return: None."}, "tests": ["tests/test_command.py::HistoryTest::test_history_indicate_current", "tests/test_command.py::HistoryTest::test_history_num_range_environment", "tests/test_command.py::HistoryTest::test_history_num_plus_relative", "tests/test_command.py::HistoryTest::test_history_num_to_head", "tests/test_command.py::HistoryTest::test_history_num_to_head_environment"], "indent": 4}
{"namespace": "mrjob.fs.local.LocalFilesystem.put", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [68, 68], "body_position": [70, 71], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "Copy a file from the source path to the destination path. Note to converts the input path from a file URI to a local path.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param src: String. The path of the source file to be copied.\n:param path: String. The destination path where the file will be copied to.\n:return: No return values."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_put"], "indent": 8}
{"namespace": "boltons.socketutils.BufferedSocket.recv", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [199, 199], "body_position": [219, 237], "dependency": {"intra_class": ["boltons.socketutils.BufferedSocket._recv_lock", "boltons.socketutils.BufferedSocket._recvsize", "boltons.socketutils.BufferedSocket.rbuf", "boltons.socketutils.BufferedSocket.sock", "boltons.socketutils.BufferedSocket.timeout"], "intra_file": ["boltons.socketutils.Timeout", "boltons.socketutils.Timeout.__init__", "boltons.socketutils._UNSET"], "cross_file": []}, "requirement": {"Functionality": "This function receives up to a specified number of bytes from the socket. It first checks if there are enough bytes in the internal buffer to fulfill the request. If so, it returns the requested bytes from the buffer. If not, it checks if there are any remaining bytes in the buffer and returns them. If the buffer is empty, it sets a timeout for the socket and performs a single receive operation on the socket to receive the requested bytes. If the operation times out, a timeout exception is raised. If the received data is larger than the requested size, the excess bytes are stored in the buffer for future use.", "Arguments": ":param self: BufferedSocket. An instance of the BufferedSocket class.\n:param size: int. The maximum number of bytes to receive.\n:param flags: int. Kept for API compatibility with sockets. Only the default, `0`, is valid. If any other value is provided, a ValueError is raised: 'non-zero flags not supported: {flags!r}'.\n:param timeout: float. The timeout for this operation. Can be `0` for nonblocking and `None` for no timeout. Defaults to the value set in the constructor of BufferedSocket.\n:return: bytes. The received data."}, "tests": ["tests/test_socketutils.py::test_client_disconnecting"], "indent": 8}
{"namespace": "bentoml._internal.resource.CpuResource.from_system", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/resource.py", "signature_position": [105, 105], "body_position": [106, 109], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.resource.query_cgroup_cpu_count", "bentoml._internal.resource.query_os_cpu_count"], "cross_file": []}, "requirement": {"Functionality": "This function returns the number of CPU resources available in the system. It checks the operating system type and calls the appropriate function to retrieve the CPU count.", "Arguments": ":param cls: Class. The class itself.\n:return: Float. The number of CPU resources available in the system."}, "tests": ["tests/unit/_internal/test_resource.py::test_CpuResource"], "indent": 8}
{"namespace": "rows.fields.BinaryField.serialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [113, 113], "body_position": [114, 123], "dependency": {"intra_class": [], "intra_file": ["rows.fields.value_error"], "cross_file": []}, "requirement": {"Functionality": "Serialize a binary value into a string representation. If the value is not None, it checks if the value is of type binary. If it is, it encodes the binary value using base64 encoding and decodes it by ascii. If there is an error during encoding, it returns the original binary value. If the value is not of type binary, execute error processing. If the value is None, it returns an empty string.", "Arguments": ":param cls: BinaryField. The class itself.\n:param value: Any. The binary value to be serialized.\n:param *args: Any. Additional positional arguments.\n:param **kwargs: Any. Additional keyword arguments.\n:return: str. The serialized string representation of the binary value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_BinaryField"], "indent": 8}
{"namespace": "praw.models.util.ExponentialCounter.counter", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/models/util.py", "signature_position": [209, 209], "body_position": [211, 214], "dependency": {"intra_class": ["praw.models.util.ExponentialCounter._base", "praw.models.util.ExponentialCounter._max"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function increments the counter and returns the current value with jitter. It calculates the value by adding a random float jitter to the base value and updates the base value for the next increment. The maximum amount of jitter is set to 1/16 of the base value. The function generates a random number within the range of negative half of the maximum jitter to positive half of the maximum jitter and adds it to the base value to create the final value. Then, it updates the base value to double of its previous value if it hasn't exceeded half of the maximum allowed value else to the maximum allowed value. Finally, it returns the generated final value.", "Arguments": ":param self: ExponentialCounter. An instance of the ExponentialCounter class.\n:return: Union[int, float]. The current value of the counter with jitter."}, "tests": ["tests/unit/models/test_util.py::TestExponentialCounter::test_exponential_counter__max_value", "tests/unit/models/test_util.py::TestExponentialCounter::test_exponential_counter__counter", "tests/unit/models/test_util.py::TestExponentialCounter::test_exponential_counter__reset"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox.stream_box_edit_view", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [401, 403], "body_position": [404, 414], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._set_stream_write_box_style", "zulipterminal.ui_tools.boxes.WriteBox._setup_common_stream_compose", "zulipterminal.ui_tools.boxes.WriteBox.edit_mode_button", "zulipterminal.ui_tools.boxes.WriteBox.header_write_box", "zulipterminal.ui_tools.boxes.WriteBox.model", "zulipterminal.ui_tools.boxes.WriteBox.stream_write_box"], "intra_file": [], "cross_file": ["zulipterminal.ui_tools.buttons.EditModeButton", "zulipterminal.core.Controller"]}, "requirement": {"Functionality": "This function sets up the view for editing a stream box. It creates a text widget for the stream write box and sets up the common stream compose elements. It also adds an edit mode button to the header write box. Finally, it sets the style of the stream write box using a callback.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param stream_id: int. The ID of the stream.\n:param caption: str. The caption for the stream write box. Defaults to an empty string.\n:param title: str. The title for the stream write box. Defaults to an empty string.\n:return: No return values."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test_write_box_header_contents", "tests/ui_tools/test_boxes.py::TestWriteBox::test_keypress_CYCLE_COMPOSE_FOCUS"], "indent": 8}
{"namespace": "diffprivlib.validation.clip_to_bounds", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/validation.py", "signature_position": [167, 167], "body_position": [185, 200], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.validation.check_bounds"], "cross_file": []}, "requirement": {"Functionality": "This function clips the examples of a 2-dimensional array to given bounds. It checks if the input array is a numpy array, then it checks the bounds and clips the array accordingly. It first checks that the bounds are indeed tuple and that shape is an integer. If these conditions are not met, the function raises a error of type. It then extracts the lower and upper bounds, ensuring they are in the correct format and adjusting them to be arrays of the specified data type (dtype). The function enforces that the lower and upper bounds must be of the same shape and dimensionality, specifically either scalar or 1-dimensional arrays.", "Arguments": ":param array: np.ndarray. The array to be clipped. After clipping, all examples have a 2-norm of at most `clip`.\n:param bounds: tuple. The bounds of the form (min, max) which the array is to be clipped to. `min` and `max` must be scalar, unless the array is 2-dimensional.\n:return: np.ndarray. The clipped array."}, "tests": ["tests/test_clip_to_bounds.py::TestClipToBounds::test_incorrect_parameterisation", "tests/test_clip_to_bounds.py::TestClipToBounds::test_bad_bounds", "tests/test_clip_to_bounds.py::TestClipToBounds::test_1d_array", "tests/test_clip_to_bounds.py::TestClipToBounds::test_iris", "tests/test_clip_to_bounds.py::TestClipToBounds::test_different_bounds"], "indent": 4}
{"namespace": "bentoml._internal.utils.validate_metadata", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/utils/__init__.py", "signature_position": [321, 321], "body_position": [322, 329], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.utils._validate_metadata_entry"], "cross_file": []}, "requirement": {"Functionality": "This function validates the metadata dictionary by validate each entry in the dictionary.", "Arguments": ":param metadata: MetadataDict. The metadata dictionary to be validated.\n:return: No return values."}, "tests": ["tests/unit/_internal/test_utils.py::test_validate_metadata"], "indent": 4}
{"namespace": "datasette.utils.asgi.Response.html", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/asgi.py", "signature_position": [384, 384], "body_position": [385, 390], "dependency": {"intra_class": ["datasette.utils.asgi.Response.__init__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a Response instance with HTML content. It sets the body, status, headers, and content type of the response.", "Arguments": ":param cls: Class. The class of the Response instance.\n:param body: Any. The body of the response.\n:param status: int. The status code of the response. It defaults to 200 if not specified.\n:param headers: dict. The headers of the response. It defaults to None if not specified.\n:return: Response. The created Response instance."}, "tests": ["tests/test_internals_response.py::test_response_html"], "indent": 8}
{"namespace": "twitter.api.Api._TweetTextWrap", "type": "method", "project_path": "Internet/python-twitter", "completion_path": "Internet/python-twitter/twitter/api.py", "signature_position": [1431, 1434], "body_position": [1435, 1470], "dependency": {"intra_class": ["twitter.api.Api.GetHelpConfiguration", "twitter.api.Api._config"], "intra_file": ["twitter.api.CHARACTER_LIMIT"], "cross_file": ["twitter.error.TwitterError", "twitter.twitter_utils.is_url"]}, "requirement": {"Functionality": "This function takes a status message and wraps it into multiple tweets based on the character limit. It splits the status into words and checks if each word exceeds the character limit. If a word exceeds the limit, it raises an exception. It then calculates the length of the line by adding the length of each word and checks if it exceeds the character limit. If it does, it appends the line to the list of tweets and starts a new line with the current word. If it doesn't exceed the limit, it adds the word to the line. Finally, it appends the last line to the list of tweets and returns it.", "Arguments": ":param self: Api. An instance of the Api class.\n:param status: String. The status message to be wrapped into tweets.\n:param char_lim: Integer. The character limit for each tweet. Defaults to CHARACTER_LIMIT.\n:return: List of strings. The wrapped status message split into multiple tweets."}, "tests": ["tests/test_tweet_length.py::TestTweetLength::test_split_tweets"], "indent": 8}
{"namespace": "pyinfra.operations.python.call", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/operations/python.py", "signature_position": [13, 13], "body_position": [46, 57], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra.api.util.get_call_location", "pyinfra.logger"]}, "requirement": {"Functionality": "This function executes a Python function within a deploy. It takes a function, along with its arguments and keyword arguments, and yields a FunctionCommand object.", "Arguments": ":param function: The Python function to execute.\n:param args: The arguments to pass to the function.\n:param kwargs: The keyword arguments to pass to the function.\n:return: A FunctionCommand object."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_function_call_op", "tests/test_api/test_api_operations.py::TestNestedOperationsApi::test_nested_op_api"], "indent": 4}
{"namespace": "boltons.formatutils.tokenize_format_str", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/formatutils.py", "signature_position": [203, 203], "body_position": [210, 220], "dependency": {"intra_class": [], "intra_file": ["boltons.formatutils.BaseFormatField", "boltons.formatutils.BaseFormatField.__init__", "boltons.formatutils.infer_positional_format_args"], "cross_file": []}, "requirement": {"Functionality": "This function takes a format string and converts it into a list of alternating string literals and BaseFormatField tokens. It also has an option to infer anonymous positional references into explicit, numbered positional references.", "Arguments": ":param fstr: String. The format string to be tokenized.\n:param resolve_pos: Bool. Whether to infer anonymous positional references into explicit, numbered positional references. Defaults to True.\n:return: List. A list of alternating string literals and BaseFormatField tokens."}, "tests": ["tests/test_formatutils.py::test_tokenize_format_str"], "indent": 4}
{"namespace": "pyinfra.api.operations.run_ops", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/operations.py", "signature_position": [358, 358], "body_position": [369, 382], "dependency": {"intra_class": [], "intra_file": ["pyinfra.api.operations._run_no_wait_ops", "pyinfra.api.operations._run_serial_ops", "pyinfra.api.operations._run_single_op"], "cross_file": ["pyinfra.api.state.State.get_op_order", "pyinfra.api.state.State.is_executing", "pyinfra.context.ctx_state", "pyinfra.context.ContextManager.use"]}, "requirement": {"Functionality": "This function runs all operations across all servers in a configurable manner. It allows the user to choose whether to run operations host by host, run all operations on each server in parallel without waiting, or run all operations in order, waiting at each operation for all servers to complete.", "Arguments": ":param state: State. An instance of the State class. The deploy state to execute.\n:param serial: Bool. Whether to run operations host by host. Defaults to False.\n:param no_wait: Bool. Whether to run all the ops on each server in parallel without waiting at each operation. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_api/test_api_operations.py::TestNestedOperationsApi::test_nested_op_api", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op", "tests/test_api/test_api_operations.py::TestOperationsApi::test_run_once_serial_op", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_with_strict_host_key_checking_disabled", "tests/test_api/test_api_operations.py::TestOperationsApi::test_file_upload_op"], "indent": 4}
{"namespace": "bplustree.tree.BPlusTree._left_record_node", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/tree.py", "signature_position": [278, 278], "body_position": [279, 282], "dependency": {"intra_class": ["bplustree.tree.BPlusTree.LeafNode", "bplustree.tree.BPlusTree.LonelyRootNode", "bplustree.tree.BPlusTree._mem", "bplustree.tree.BPlusTree._root_node"], "intra_file": [], "cross_file": ["bplustree.memory.FileMemory.get_node", "bplustree.node.Node.smallest_entry"]}, "requirement": {"Functionality": "This function returns the leftmost record node in the B+ tree. It starts from the root node and traverses down the tree until it reaches a node that is either a lonely root node or a leaf node.", "Arguments": ":param self: BPlusTree. An instance of the BPlusTree class.\n:return: Union['LonelyRootNode', 'LeafNode']. The leftmost record node in the B+ tree."}, "tests": ["tests/test_tree.py::test_left_record_node_in_tree"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox._topic_box_autocomplete", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [454, 454], "body_position": [455, 460], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._process_typeaheads", "zulipterminal.ui_tools.boxes.WriteBox.model", "zulipterminal.ui_tools.boxes.WriteBox.stream_id"], "intra_file": [], "cross_file": ["zulipterminal.helper.match_topics", "zulipterminal.model.Model.topics_in_stream"]}, "requirement": {"Functionality": "This function provides autocomplete suggestions for a given text input based on the available topics in a stream. It retrieves the list of topic names from the model and matches them with the input text to generate typeaheads. It then processes the typeaheads and returns them as suggestions.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param text: str. The input text for which autocomplete suggestions are required.\n:param state: Optional[int]. The state of the autocomplete process. Defaults to None.\n:return: Optional[str]. The generated autocomplete suggestions for the input text."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test__topic_box_autocomplete"], "indent": 8}
{"namespace": "exodus_bundler.input_parsing.extract_open_path", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/input_parsing.py", "signature_position": [41, 41], "body_position": [43, 56], "dependency": {"intra_class": [], "intra_file": ["exodus_bundler.input_parsing.strip_pid_prefix"], "cross_file": []}, "requirement": {"Functionality": "This function parses a line of strace output and extracts the file path that is being opened. It checks for different prefixes in the line and extracts the file path if the line matches the expected format.", "Arguments": ":param line: str. The line of strace output to be parsed.\n:return: str or None. The file path being opened, or None if no file path is found in the line."}, "tests": ["tests/test_input_parsing.py::test_extract_open_path"], "indent": 4}
{"namespace": "sslyze.plugins.http_headers_plugin._detect_http_redirection", "type": "function", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/http_headers_plugin.py", "signature_position": [270, 270], "body_position": [272, 291], "dependency": {"intra_class": [], "intra_file": ["sslyze.plugins.http_headers_plugin._extract_first_header_value"], "cross_file": []}, "requirement": {"Functionality": "This function detects if an HTTP response contains a redirection to the same server. If it does, it returns the path to the new location.", "Arguments": ":param http_response: HTTPResponse. The HTTP response object.\n:param server_host_name: str. The hostname of the server.\n:param server_port: int. The port number of the server.\n:return: Optional[str]. The path to the new location if a redirection to the same server is found, otherwise None."}, "tests": ["tests/plugins_tests/test_http_headers_plugin.py::TestHttpRedirection::test_redirection_relative_url", "tests/plugins_tests/test_http_headers_plugin.py::TestHttpRedirection::test_redirection_absolute_url_same_server"], "indent": 4}
{"namespace": "gunicorn.http.body.LengthReader.read", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/http/body.py", "signature_position": [114, 114], "body_position": [115, 136], "dependency": {"intra_class": ["gunicorn.http.body.LengthReader.length", "gunicorn.http.body.LengthReader.unreader"], "intra_file": [], "cross_file": ["gunicorn.http.unreader.Unreader.read", "gunicorn.http.unreader.Unreader.unread"]}, "requirement": {"Functionality": "This function reads a specified number of bytes from the LengthReader instance. It checks if the input size is valid (checks if size is an integer, and if not, it raises a TypeError \"size must be an integral type\". It then checks if size to be read is negative and raises a ValueError \"Size must be positive.\" if it is. If size is 0, the method returns an empty byte string (b\"\").) The method then creates a Bytes buffer, which is used to store the data read from the stream. It reads data from the unreader until the buffer's size (in bytes) reaches or exceeds the requested size. The buffer is checked in a while loop, and if the size has been reached, the loop is terminated.\nThe data stored in the buffer is then retrieved. The method splits the retrieved data into two parts: ret (the first size bytes) and rest (the remaining bytes).\nThe method then push the rest bytes back into the stream. This allows for future reads to start where the previous read left off.\nFinally, the method updates the length by subtracting the number of bytes read (size) to keep track of how many more bytes can still be read from the stream. The method then returns the ret bytes and.", "Arguments": ":param self: LengthReader. An instance of the LengthReader class.\n:param size: int. The number of bytes to read from the instance.\n:return: bytes. The read data from the instance."}, "tests": ["tests/test_http.py::test_length_reader_read", "tests/test_http.py::test_length_reader_read_invalid_size"], "indent": 8}
{"namespace": "boltons.cacheutils.LRI.__repr__", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [333, 333], "body_position": [334, 337], "dependency": {"intra_class": ["boltons.cacheutils.LRI.max_size", "boltons.cacheutils.LRI.on_miss"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Provide a string representation of the instance. It includes the class name, max size, on miss, and values of the instance: '{class name}(max_size={max size}, on_miss={on miss}, values={values})'.", "Arguments": ":param self: LRI. An instance of the LRI class.\n:return: str. The string representation of the instance."}, "tests": ["tests/test_cacheutils.py::test_lru_basic"], "indent": 8}
{"namespace": "boltons.cacheutils.LRI._get_flattened_ll", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [166, 166], "body_position": [167, 174], "dependency": {"intra_class": ["boltons.cacheutils.LRI._anchor"], "intra_file": ["boltons.cacheutils.KEY", "boltons.cacheutils.NEXT", "boltons.cacheutils.VALUE"], "cross_file": []}, "requirement": {"Functionality": "This function returns the flattened version of the linked list.\n", "Arguments": ":param self: LRI, an instance of the LRI class.\n:return: list. The flattened version of the linked list.\n"}, "tests": ["tests/test_cacheutils.py::test_cache_sizes_on_repeat_insertions"], "indent": 8}
{"namespace": "mrjob.protocol._KeyCachingProtocol.read", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/protocol.py", "signature_position": [83, 83], "body_position": [91, 96], "dependency": {"intra_class": ["mrjob.protocol._KeyCachingProtocol._last_key_decoded", "mrjob.protocol._KeyCachingProtocol._last_key_encoded", "mrjob.protocol._KeyCachingProtocol._loads"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Decodes a line of raw input into a tuple of key and value.\nSplits the input line at the first occurrence of the tab character. Then it updates the last key encoded by loading the key we obtained. It also decodes the value and returns a tuple of the last key decoded and the decoded value.\n", "Arguments": ":param line: String. A line of raw input to the job, without trailing newline.\n:return: tuple. A tuple of ``(key, value)``.\n"}, "tests": ["tests/test_protocol.py::StandardJSONProtocolTestCase::test_numerical_keys_become_strs", "tests/test_protocol.py::StandardJSONProtocolTestCase::test_tuples_become_lists", "tests/test_protocol.py::ReprProtocolTestCase::test_uses_repr_format", "tests/test_protocol.py::StandardJSONProtocolTestCase::test_uses_json_format"], "indent": 8}
{"namespace": "mrjob.bin.MRJobBinRunner._task_python_bin", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/bin.py", "signature_position": [185, 185], "body_position": [188, 189], "dependency": {"intra_class": ["mrjob.bin.MRJobBinRunner._python_bin"], "intra_file": [], "cross_file": ["mrjob.runner.MRJobRunner._opts"]}, "requirement": {"Functionality": "This function returns the Python binary used to invoke a job with specific options. If the task python binary option is set, it returns the value of task python binary. Otherwise, it returns the default Python binary.", "Arguments": ":param self: MRJobBinRunner. An instance of the MRJobBinRunner class.\n:return: str. The Python binary used to invoke the job."}, "tests": ["tests/test_bin.py::TaskPythonBinTestCase::test_default", "tests/test_bin.py::TaskPythonBinTestCase::test_python_bin", "tests/test_bin.py::TaskPythonBinTestCase::test_empty_python_bin_means_default", "tests/test_bin.py::TaskPythonBinTestCase::test_task_python_bin"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.probabilities.compute_cmds_probs", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/probabilities.py", "signature_position": [14, 18], "body_position": [41, 62], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix"]}, "requirement": {"Functionality": "This function computes the probabilities for individual commands and the probabilities for the transitions of commands. It takes the counts of individual commands and sequence commands as input and returns the computed probabilities.", "Arguments": ":param seq1_counts: Union[StateMatrix, dict]. The counts of individual commands.\n:param seq2_counts: Union[StateMatrix, dict]. The counts of sequence commands (length 2).\n:param unk_token: str. A dummy command to represent unseen commands.\n:return: Tuple[StateMatrix, StateMatrix]. The computed probabilities for individual commands and sequence commands (length 2)."}, "tests": ["tests/analysis/test_anom_seq_probabilities.py::TestProbabilities::test_compute_cmds_probs"], "indent": 4}
{"namespace": "OpenSSL.rand.add", "type": "function", "project_path": "Security/pyOpenSSL", "completion_path": "Security/pyOpenSSL/src/OpenSSL/rand.py", "signature_position": [8, 8], "body_position": [25, 31], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["OpenSSL._util.lib"]}, "requirement": {"Functionality": "This function adds bytes from a buffer into the PRNG (Pseudo-Random Number Generator) state. It is used to mix additional randomness into the PRNG state.", "Arguments": ":param buffer: bytes. The buffer containing random data to be mixed into the PRNG state.\n:param entropy: int. The lower bound estimate of how much randomness is contained in the buffer, measured in bytes.\n:return: None."}, "tests": ["tests/test_rand.py::TestRand::test_add_wrong_args"], "indent": 4}
{"namespace": "mrjob.job.MRJob.is_task", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [1221, 1221], "body_position": [1227, 1230], "dependency": {"intra_class": ["mrjob.job.MRJob.options"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the current instance of MRJob is a mapper, combiner, reducer, or Spark script.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:return: bool. True if the current instance is a mapper, combiner, reducer, or Spark script. False otherwise."}, "tests": ["tests/test_job.py::IsTaskTestCase::test_is_task"], "indent": 8}
{"namespace": "boto.cloudsearch2.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudsearch2/__init__.py", "signature_position": [36, 36], "body_position": [37, 40], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudsearch2.layer1.CloudSearchConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the cloudsearch service. It creates a connection to the cloudsearch service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: CloudSearchConnection. The connection object to the cloudsearch service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCloudsearch2Connection::test_connect_to_region"], "indent": 4}
{"namespace": "twilio.twiml.messaging_response.MessagingResponse.message", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/messaging_response.py", "signature_position": [21, 30], "body_position": [44, 54], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.messaging_response.Message", "twilio.twiml.messaging_response.Message.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Message>` element for a MessagingResponse instance. It takes in various parameters such as the message body, phone numbers, action URL, and additional attributes, and returns the created `<Message>` element.", "Arguments": ":param self: MessagingResponse. An instance of the MessagingResponse class.\n:param body: String. The body of the message.\n:param to: String. The phone number to send the message to.\n:param from_: String. The phone number to send the message from.\n:param action: String. The action URL.\n:param method: String. The method to use for the action URL.\n:param status_callback: String. The status callback URL. Deprecated in favor of action.\n:param kwargs: Additional attributes for the `<Message>` element.\n:return: `<Message>` element. The created `<Message>` element."}, "tests": ["tests/unit/twiml/test_messaging_response.py::TestResponse::test_nested_verbs", "tests/unit/twiml/test_messaging_response.py::TestResponse::test_response", "tests/unit/twiml/test_messaging_response.py::TestResponse::test_response_chain", "tests/unit/twiml/test_messaging_response.py::TestMessage::test_body"], "indent": 8}
{"namespace": "pycoin.satoshi.stackops.do_OP_RIPEMD160", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [113, 113], "body_position": [114, 115], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pycoin.encoding.hash.ripemd160"]}, "requirement": {"Functionality": "This function performs the RIPEMD-160 hash operation on the top element of the stack and appends the resulting digest to the stack.", "Arguments": ":param stack: List. The stack containing elements.\n:return: No return values."}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_RIPEMD160"], "indent": 4}
{"namespace": "falcon.request.Request.host", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [831, 831], "body_position": [832, 843], "dependency": {"intra_class": ["falcon.request.Request.env"], "intra_file": [], "cross_file": ["falcon.util.uri.parse_host"]}, "requirement": {"Functionality": "This function retrieves the host information from the request. It first tries to get the host information from the 'HTTP_HOST' header in the request environment. If the header is not found, it retrieves the host information from the 'SERVER_NAME' field in the request environment.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The host information extracted from the request."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_host"], "indent": 8}
{"namespace": "pyramid.traversal.find_resource", "type": "function", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/traversal.py", "signature_position": [35, 35], "body_position": [79, 86], "dependency": {"intra_class": [], "intra_file": ["pyramid.traversal.traverse"], "cross_file": ["pyramid.util.ascii_"]}, "requirement": {"Functionality": "Given a resource object and a string or tuple representing a path, this function returns a resource in the application's resource tree at the specified path. If the path cannot be resolved (if the respective node in the resource tree does not exist), a `KeyError` will be raised.", "Arguments": ":param resource: The resource object.\n:param path: str or Tuple[str]. The path to the resource. It can be absolute (starting at the root resource) or relative (starting at the given resource). If it is a str, starting with a slash indicates an absolute path, and not starting with a slash indicates a relative path. Each path segment must be UTF-8 encoded and escaped using Python's `urllib.quote`. If it is a tuple, starting with an '' indicates an absolute path, and not starting with an '' indicates a relative path. No URL-quoting of individual path segments is required.\n:return: The resource in the application's resource tree at the specified path."}, "tests": ["tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_resources"], "indent": 4}
{"namespace": "mrjob.hadoop.HadoopJobRunner.fs", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [192, 192], "body_position": [196, 209], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner._fs"], "intra_file": [], "cross_file": ["mrjob.fs.composite.CompositeFilesystem", "mrjob.fs.composite.CompositeFilesystem.add_fs", "mrjob.fs.hadoop.HadoopFilesystem", "mrjob.fs.local.LocalFilesystem"]}, "requirement": {"Functionality": "This function returns a file system object for HDFS and the local filesystem. If the file system object has already been created, it returns it. Otherwise, it creates a CompositeFilesystem object and adds HadoopFilesystem and LocalFilesystem to it.", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:return: Filesystem. The Filesystem object for HDFS and the local filesystem."}, "tests": ["tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_io_error_from_fs_exists", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_fs_exists", "tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_fs_exists", "tests/test_hadoop.py::StreamHistoryLogDirsTestCase::test_io_error_from_fs_exists"], "indent": 8}
{"namespace": "pythonforandroid.graph.get_dependency_tuple_list_for_recipe", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/graph.py", "signature_position": [42, 42], "body_position": [46, 61], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.graph.fix_deplist"], "cross_file": []}, "requirement": {"Functionality": "This function takes a recipe and a blacklist as input and returns a list of dependencies for the recipe. The dependencies are filtered based on the blacklist and converted into tuples and filter out blacklisted items and turn lowercase.", "Arguments": ":param recipe: The recipe for which the dependencies need to be retrieved.\n:param blacklist: Set. A set of items to be filtered out from the dependencies. Defaults to None.\n:return: List of tuples. The dependencies of the recipe after filtering and conversion into tuples."}, "tests": ["tests/test_graph.py::test_get_dependency_tuple_list_for_recipe"], "indent": 4}
{"namespace": "boto.dynamodb2.table.Table.update_global_secondary_index", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [557, 557], "body_position": [584, 608], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.update_table", "boto.log", "boto"]}, "requirement": {"Functionality": "This function updates the global index(es) in DynamoDB after the table has been created. It takes a dictionary of global indexes as input and updates the read and write capacity units for each index. It then updates the table with the new global index information.", "Arguments": ":param self: Table. An instance of the Table class.\n:param global_indexes: Dictionary. A dictionary specifying the global indexes to be updated. Each key in the dictionary represents the index name, and the corresponding value is another dictionary containing the read and write capacity units for the index.\n:return: Bool. Returns True if the global indexes are successfully updated, False otherwise."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_update_global_secondary_index"], "indent": 8}
{"namespace": "mingus.core.notes.is_valid_note", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/notes.py", "signature_position": [71, 71], "body_position": [73, 78], "dependency": {"intra_class": [], "intra_file": ["mingus.core.notes._note_dict"], "cross_file": []}, "requirement": {"Functionality": "This function checks if a given note is in a recognized format. It returns True if the note is in the recognized format, and False otherwise.\n", "Arguments": ":param note: str. The note to be checked for recognition.\n:return: bool. Returns True if the note is in a recognized format, and False otherwise.\n"}, "tests": ["tests/unit/core/test_notes.py::test_notes::test_exotic_note_validity", "tests/unit/core/test_notes.py::test_notes::test_faulty_note_invalidity", "tests/unit/core/test_notes.py::test_notes::test_base_note_validity", "tests/unit/core/test_notes.py::test_notes::test_flat_note_validity", "tests/unit/core/test_notes.py::test_notes::test_sharp_note_validity"], "indent": 4}
{"namespace": "boltons.dictutils.OneToOne.popitem", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [864, 864], "body_position": [865, 867], "dependency": {"intra_class": ["boltons.dictutils.OneToOne.inv"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes and returns an arbitrary item from a OneToOne dictionary. It removes the item from the dictionary and its inverse mapping.\n", "Arguments": ":param self: OneToOne. An instance of the OneToOne class.\n:return: Tuple. The key-value pair that was removed from the OneToOne dictionary.\n"}, "tests": ["tests/test_dictutils.py::test_one_to_one"], "indent": 8}
{"namespace": "boto.utils.get_instance_userdata", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/utils.py", "signature_position": [430, 431], "body_position": [432, 441], "dependency": {"intra_class": [], "intra_file": ["boto.utils._build_instance_metadata_url", "boto.utils.retry_url"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the user data of an instance. It builds the URL for the user data based on the input parameters and then uses the URL to retrieve the user data. If the user data is not empty, it can be further processed based on the separator provided.", "Arguments": ":param version: String. The version of the instance metadata to use. It defaults to 'latest' if not specified.\n:param sep: String. The separator used to split the user data into key-value pairs. If not specified, the user data is returned as is.\n:param url: String. The base URL for the instance metadata service. It defaults to 'http://169.254.169.254' if not specified.\n:param timeout: Float. The timeout value for the HTTP request. If not specified, the default timeout is used.\n:param num_retries: Integer. The number of retries to attempt if the HTTP request fails. It defaults to 5 if not specified.\n:return: String or Dictionary. The user data of the instance. If the separator is provided, it is returned as a dictionary of key-value pairs. Otherwise, it is returned as a string."}, "tests": ["tests/unit/utils/test_utils.py::TestLazyLoadMetadata::test_user_data_timeout", "tests/unit/utils/test_utils.py::TestLazyLoadMetadata::test_user_data"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.get_quota_root", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1584, 1584], "body_position": [1594, 1602], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient._raw_command_untagged"], "intra_file": ["imapclient.imapclient.MailboxQuotaRoots", "imapclient.imapclient._parse_quota"], "cross_file": ["imapclient.response_parser.parse_response", "imapclient.util.to_bytes", "imapclient.util.to_unicode"]}, "requirement": {"Functionality": "This function retrieves the quota roots and associated quotas for a given mailbox from the IMAP server. It sends the appropriate IMAP command to the server and parses the response to extract the quota roots and quotas.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param mailbox: String. The name of the mailbox to retrieve the quota roots for.\n:return: Tuple. A tuple containing the MailboxQuotaRoots object, which represents the quota roots, and a list of Quota objects, which represent the associated quotas."}, "tests": ["tests/test_imapclient.py::TestQuota::test_get_quota_root"], "indent": 8}
{"namespace": "pyt.vulnerabilities.trigger_definitions_parser.parse", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/vulnerabilities/trigger_definitions_parser.py", "signature_position": [69, 69], "body_position": [75, 82], "dependency": {"intra_class": [], "intra_file": ["pyt.vulnerabilities.trigger_definitions_parser.Definitions", "pyt.vulnerabilities.trigger_definitions_parser.Source", "pyt.vulnerabilities.trigger_definitions_parser.Sink", "pyt.vulnerabilities.trigger_definitions_parser.Sink.from_json"], "cross_file": []}, "requirement": {"Functionality": "This function parses a file to extract source and sink definitions. It reads the contents of the file, converts it into a dictionary using JSON, and then creates the sources and sinks based on the extracted data. Finally, it returns a tuple containing the created sources and sinks.", "Arguments": ":param trigger_word_file: The file to be parsed for source and sink definitions.\n:return: Definitions. A tuple containing the created sources and sinks."}, "tests": ["tests/vulnerabilities/vulnerabilities_test.py::EngineTest::test_parse"], "indent": 4}
{"namespace": "rest_framework.reverse.reverse", "type": "function", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/reverse.py", "signature_position": [32, 32], "body_position": [38, 49], "dependency": {"intra_class": [], "intra_file": ["rest_framework.reverse._reverse", "rest_framework.reverse.preserve_builtin_query_params"], "cross_file": ["rest_framework.versioning.BaseVersioning.reverse"]}, "requirement": {"Functionality": "This function is used to reverse a viewname into a URL. If versioning is being used, the function passes the reverse call to the versioning scheme instance to modify the resulting URL if needed.", "Arguments": ":param viewname: The name of the view to reverse. Default to None.\n:param args: List. Positional arguments to be passed to the view. Default to None.\n:param kwargs: Dict. Keyword arguments to be passed to the view. Default to None.\n:param request: HttpRequest. The current request being processed. Default to None.\n:param format: String. The format of the URL. Default to None.\n:param extra: Dict. Extra keyword arguments to be passed to the view.\n:return: String. The reversed URL."}, "tests": ["tests/test_reverse.py::ReverseTests::test_reverse_with_versioning_scheme"], "indent": 4}
{"namespace": "pythonforandroid.build.Context.setup_dirs", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/build.py", "signature_position": [141, 141], "body_position": [144, 149], "dependency": {"intra_class": ["pythonforandroid.build.Context.build_dir", "pythonforandroid.build.Context.dist_dir", "pythonforandroid.build.Context.storage_dir"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets up the storage, build, and distribution directories for the Context instance. It calculates the paths for these directories based on the given storage directory and ensures that the directories exist.", "Arguments": ":param self: Context. An instance of the Context class.\n:param storage_dir: String. The path to the storage directory.\n:return: No return values."}, "tests": ["tests/test_build.py::TestContext::test_sdk_ndk_paths"], "indent": 8}
{"namespace": "pyramid.csrf.CookieCSRFStoragePolicy.get_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [147, 147], "body_position": [150, 154], "dependency": {"intra_class": ["pyramid.csrf.CookieCSRFStoragePolicy.cookie_profile", "pyramid.csrf.CookieCSRFStoragePolicy.new_csrf_token"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the currently active CSRF token from the cookies sent with the current request. If the token is not found in the cookies, a new CSRF token is generated and returned.", "Arguments": ":param self: CookieCSRFStoragePolicy. An instance of the CookieCSRFStoragePolicy class.\n:param request: The current request object.\n:return: The CSRF token."}, "tests": ["tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_existing_cookie_csrf_does_not_set_cookie", "tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_get_cookie_csrf_with_no_existing_cookie_sets_cookies", "tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_get_cookie_csrf_nondefault_samesite", "tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_get_csrf_token_returns_the_new_token"], "indent": 8}
{"namespace": "boltons.socketutils.BufferedSocket.recv_close", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [262, 262], "body_position": [270, 284], "dependency": {"intra_class": ["boltons.socketutils.BufferedSocket._recv_lock", "boltons.socketutils.BufferedSocket.maxsize", "boltons.socketutils.BufferedSocket.rbuf", "boltons.socketutils.BufferedSocket.recv_size"], "intra_file": ["boltons.socketutils.ConnectionClosed", "boltons.socketutils.MessageTooLong", "boltons.socketutils.MessageTooLong.__init__", "boltons.socketutils._RECV_LARGE_MAXSIZE", "boltons.socketutils._UNSET"], "cross_file": []}, "requirement": {"Functionality": "This function receives data from the socket until the connection is closed, up to a specified maximum size. If more than the maximum size is received, it raises a `MessageTooLong` exception.\n", "Arguments": ":param self: BufferedSocket, an instance of the BufferedSocket class.\n:param timeout: int. The timeout value for receiving data. Defaults to `_UNSET` if not specified.\n:param maxsize: int. The maximum size of received data. Defaults to `_UNSET` if not specified.\n:return: bytes. The received data up to the maximum size specified.\n"}, "tests": ["tests/test_socketutils.py::test_short_lines"], "indent": 8}
{"namespace": "zulipterminal.helper.get_unused_fence", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/helper.py", "signature_position": [711, 711], "body_position": [717, 724], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["zulipterminal.config.regexes.REGEX_QUOTED_FENCE_LENGTH"]}, "requirement": {"Functionality": "This function generates a fence for a quoted message based on a regex pattern of continuous back-ticks. It calculates the maximum length of the fence by finding the longest match of the regex pattern in the content and adds 1 to it. Then it returns a string of back-ticks with a length equal to the maximum length of the fence.", "Arguments": ":param content: String. The content of the quoted message.\n:return: String. The generated fence for the quoted message."}, "tests": ["tests/helper/test_helper.py::test_get_unused_fence"], "indent": 4}
{"namespace": "mopidy.config.types.LogLevel.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [372, 372], "body_position": [373, 376], "dependency": {"intra_class": ["mopidy.config.types.LogLevel.levels"], "intra_file": ["mopidy.config.types.encode"], "cross_file": []}, "requirement": {"Functionality": "Serialize a value based on the LogLevel instance. It looks up the value in the levels dictionary and returns the corresponding key. If the value is not found, it returns an empty string.", "Arguments": ":param self: LogLevel. An instance of the LogLevel class.\n:param value: The value to be serialized.\n:param display: Bool. Whether to display the serialized value. Defaults to False.\n:return: String. The serialized value or an empty string if the value is not found."}, "tests": ["tests/config/test_types.py::TestLogLevel::test_serialize", "tests/config/test_types.py::TestLogLevel::test_serialize_ignores_unknown_level"], "indent": 8}
{"namespace": "gunicorn.http.unreader.IterUnreader.chunk", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/http/unreader.py", "signature_position": [72, 72], "body_position": [73, 79], "dependency": {"intra_class": ["gunicorn.http.unreader.IterUnreader.iter"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the next chunk of data from the iterator. If the iterator is empty, it returns an empty byte string. If the iterator is exhausted, it sets the iterator to None and returns an empty byte string.", "Arguments": ":param self: IterUnreader. An instance of the IterUnreader class.\n:return: bytes. The next chunk of data from the iterator."}, "tests": ["tests/test_http.py::test_iter_unreader_chunk"], "indent": 8}
{"namespace": "mistune.markdown.Markdown.read", "type": "method", "project_path": "Text-Processing/mistune", "completion_path": "Text-Processing/mistune/src/mistune/markdown.py", "signature_position": [96, 96], "body_position": [97, 105], "dependency": {"intra_class": ["mistune.markdown.Markdown.block", "mistune.markdown.Markdown.parse"], "intra_file": [], "cross_file": ["mistune.core.BlockState.env", "mistune.core.Parser.state_cls"]}, "requirement": {"Functionality": "Read the content of a file and parse it using the Markdown instance. It first sets the state of the Markdown instance, then reads the content of the file using the specified encoding. Finally, it decodes the content and parses it using the Markdown instance.", "Arguments": ":param self: Markdown. An instance of the Markdown class.\n:param filepath: String. The path of the file to be read.\n:param encoding: String. The encoding of the file. It defaults to 'utf-8' if not specified.\n:param state: Object. The state object to be used for parsing. It defaults to None if not specified.\n:return: The parsed content of the file using the Markdown instance."}, "tests": ["tests/test_directives.py::TestDirectiveInclude::test_html_include"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.PkgConfigPrerequisite.darwin_checker", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [341, 341], "body_position": [342, 345], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "Check if the \"pkg-config\" formula is installed on a macOS system using Homebrew.", "Arguments": ":param self: PkgConfigPrerequisite. An instance of the PkgConfigPrerequisite class.\n:return: bool. True if the \"pkg-config\" formula is installed, False otherwise."}, "tests": ["tests/test_prerequisites.py::TestPkgConfigPrerequisite::test_darwin_checker"], "indent": 8}
{"namespace": "sacred.config.signature.Signature.get_free_parameters", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/signature.py", "signature_position": [66, 66], "body_position": [67, 68], "dependency": {"intra_class": ["sacred.config.signature.Signature._get_expected_args"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of free parameters based on the given arguments and keyword arguments. Free parameters are those that need to be filled in by the user.", "Arguments": ":param self: Signature. An instance of the Signature class.\n:param args: list. The positional arguments passed to the function.\n:param kwargs: dict. The keyword arguments passed to the function.\n:param bound: bool. Whether the signature is bound to an instance or not. Defaults to False.\n:return: List[str]. The list of free parameters."}, "tests": ["tests/test_config/test_signature.py::test_get_free_parameters"], "indent": 8}
{"namespace": "zulipterminal.helper.canonicalize_color", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/helper.py", "signature_position": [640, 640], "body_position": [645, 655], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["zulipterminal.config.regexes.REGEX_COLOR_3_DIGIT", "zulipterminal.config.regexes.REGEX_COLOR_6_DIGIT"]}, "requirement": {"Functionality": "This function takes a color string in the format '#xxxxxx' or '#xxx', use regex matching to determine which format it is, and converts it to the format '#xxx' with lowercase hex digits.", "Arguments": ":param color: str. The color string to be converted.\n:return: str."}, "tests": ["tests/helper/test_helper.py::test_color_formats", "tests/helper/test_helper.py::test_invalid_color_format"], "indent": 4}
{"namespace": "falcon.inspect.inspect_static_routes", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [105, 105], "body_position": [116, 120], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect.StaticRouteInfo", "falcon.inspect.StaticRouteInfo.__init__"], "cross_file": ["falcon.app.App", "falcon.app.App._static_routes"]}, "requirement": {"Functionality": "This function inspects the static routes of an application. It retrieves the information about the static routes that have been added to the application.", "Arguments": ":param app: falcon.App. The application to inspect. It can be an instance of either falcon.App or falcon.asgi.App.\n:return: List[StaticRouteInfo]. A list of StaticRouteInfo objects that represent the static routes added to the application."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_static_route", "tests/test_inspect.py::TestInspectApp::test_static_routes"], "indent": 4}
{"namespace": "mopidy.config.types.LogColor.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [344, 344], "body_position": [345, 347], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.types.encode"], "cross_file": ["mopidy.internal.log.COLORS", "mopidy.internal.log"]}, "requirement": {"Functionality": "Serialize a value to its corresponding color code if it is a valid color. If the value is not a valid color, an empty string is returned.", "Arguments": ":param self: LogColor. An instance of the LogColor class.\n:param value: String. The value to be serialized.\n:param display: Bool. Whether to display the color code. Defaults to False.\n:return: String. The color code corresponding to the value, or an empty string if the value is not a valid color."}, "tests": ["tests/config/test_types.py::TestLogColor::test_serialize", "tests/config/test_types.py::TestLogColor::test_serialize_ignores_unknown_color"], "indent": 8}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.read_next_chunk", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [298, 298], "body_position": [308, 332], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.BUFFER_RESIZE_TRIGGER", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.buffer", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.buffer_end_offset", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcReader.stream"], "intra_file": ["mssqlcli.jsonrpc.jsonrpcclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function reads a chunk of data from the output stream and stores it in a buffer. It checks if the buffer needs to be resized and resizes it if necessary. It then reads data from the stream into the buffer and updates the buffer offset. If the stream is empty or closed externally, an exception is raised.", "Arguments": ":param self: JsonRpcReader. An instance of the JsonRpcReader class.\n:return: bool. True if a chunk was successfully read from the stream, False otherwise."}, "tests": ["tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_read_state"], "indent": 8}
{"namespace": "pyinfra_cli.commands.get_func_and_args", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra_cli/commands.py", "signature_position": [11, 11], "body_position": [12, 36], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra_cli.util.try_import_module_attribute"]}, "requirement": {"Functionality": "This function takes a list of commands as input and returns the corresponding operation function and its arguments. It first extracts the operation name from the commands list and imports the corresponding module attribute. Then, it parses the arguments and returns them along with the operation function.", "Arguments": ":param commands: List of strings. The list of commands to be processed.\n:return: Tuple. The operation function and its arguments."}, "tests": ["tests/test_cli/test_cli_util.py::TestCliUtil::test_setup_op_and_args", "tests/test_cli/test_cli_util.py::TestCliUtil::test_setup_no_op", "tests/test_cli/test_cli_util.py::test_user_op", "tests/test_cli/test_cli_util.py::TestCliUtil::test_setup_op_and_json_args", "tests/test_cli/test_cli_util.py::TestCliUtil::test_setup_no_module"], "indent": 4}
{"namespace": "mrjob.conf.combine_opts", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [545, 545], "body_position": [558, 574], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.ClearedValue", "mrjob.conf._resolve_clear_tags_in_list", "mrjob.conf.combine_values"], "cross_file": []}, "requirement": {"Functionality": "This function is the master combiner used to combine dictionaries of options with sub-combiners. It takes in multiple dictionaries and combines their values based on the provided sub-combiners. Ignoring values of type ClearedValue\nFirst collects all the keys from the dictionaries that are not wrapped in `ClearedValue`. It iterates through each key and uses the sub-combiner specified in the `combiners` map for that key, or defaults to a function. The value processed by sub-combiner is stored with the key in a new dictionary. Finally, the function returns the dictionary.\n", "Arguments": ":param combiners: Dict. A map from option name to a combine_*() function to combine options by that name. By default, options are combined using the combine_values function\n:param opts_list: List of dict. One or more dictionaries to combine.\n:return: Dict. The combined options as a dictionary.\n"}, "tests": ["tests/test_conf.py::CombineOptsTestCase::test_cant_clear_entire_opt_dicts", "tests/test_conf.py::CombineOptsTestCase::test_combine_opts", "tests/test_conf.py::CombineOptsTestCase::test_cleared_opt_values", "tests/test_conf.py::CombineOptsTestCase::test_empty"], "indent": 4}
{"namespace": "mrjob.fs.local.LocalFilesystem.md5sum", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [101, 101], "body_position": [102, 104], "dependency": {"intra_class": ["mrjob.fs.local.LocalFilesystem._md5sum_file"], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "Calculates the MD5 checksum of a file.\n", "Arguments": ":param self: LocalFilesystem, an instance of the LocalFilesystem class.\n:param path: String. The path of the file for which to calculate the MD5 checksum. It can be a file URI or a local file path.\n:return: String. The MD5 checksum of the file.\n"}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_md5sum"], "indent": 8}
{"namespace": "bplustree.node.Node.from_page_data", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/node.py", "signature_position": [145, 146], "body_position": [147, 158], "dependency": {"intra_class": [], "intra_file": ["bplustree.node.InternalNode", "bplustree.node.InternalNode.__init__", "bplustree.node.LeafNode", "bplustree.node.LeafNode.__init__", "bplustree.node.LonelyRootNode", "bplustree.node.LonelyRootNode.__init__", "bplustree.node.RootNode", "bplustree.node.RootNode.__init__"], "cross_file": ["bplustree.const.ENDIAN", "bplustree.const.NODE_TYPE_BYTES", "bplustree.const.TreeConf"]}, "requirement": {"Functionality": "This function creates a Node instance based on the given tree configuration and data. It first extracts the node type from the data and then creates the corresponding Node instance based on the node type.", "Arguments": ":param cls: Node. The class of the Node instance to be created.\n:param tree_conf: TreeConf. The tree configuration used to create the Node instance.\n:param data: Bytes. The data used to create the Node instance.\n:param page: Int. The page number associated with the Node instance. Defaults to None.\n:return: Node. The created Node instance based on the node type."}, "tests": ["tests/test_node.py::test_empty_node_serialization", "tests/test_node.py::test_get_node_from_page_data"], "indent": 8}
{"namespace": "googleapiclient.model.BaseModel.response", "type": "method", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/model.py", "signature_position": [197, 197], "body_position": [210, 222], "dependency": {"intra_class": ["googleapiclient.model.BaseModel._log_response", "googleapiclient.model.BaseModel.deserialize", "googleapiclient.model.BaseModel.no_content_response"], "intra_file": ["googleapiclient.model.LOGGER"], "cross_file": ["googleapiclient.errors.HttpError"]}, "requirement": {"Functionality": "This function is a method of the BaseModel class. It is used to convert the response from a HTTP request into a Python object. It also handles error cases and raises an http error if a non 2xx response is received.", "Arguments": ":param self: BaseModel. An instance of the BaseModel class.\n:param resp: httplib2.Response. The HTTP response headers and status.\n:param content: string. The body of the HTTP response.\n:return: The body de-serialized as a Python object."}, "tests": ["tests/test_protobuf_model.py::Model::test_good_response", "tests/test_protobuf_model.py::Model::test_no_content_response", "tests/test_json_model.py::Model::test_no_data_wrapper_deserialize_text_format", "tests/test_json_model.py::Model::test_good_response_wo_data_str", "tests/test_json_model.py::Model::test_no_data_wrapper_deserialize"], "indent": 8}
{"namespace": "fs.path.parts", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [269, 270], "body_position": [284, 290], "dependency": {"intra_class": [], "intra_file": ["fs.path.normpath"], "cross_file": []}, "requirement": {"Functionality": "This function takes a path as input and splits it into its component parts. It removes any leading or trailing slashes and returns a list of the components.", "Arguments": ":param path: Text. The path to be split into parts.\n:return: List of Text. The components of the path. For example: the result of parts('/foo/bar/baz') is ['/', 'foo', 'bar', 'baz']"}, "tests": ["tests/test_path.py::TestPathFunctions::test_parts"], "indent": 4}
{"namespace": "bentoml._internal.utils.analytics.usage_stats._track_serve_init", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/utils/analytics/usage_stats.py", "signature_position": [129, 135], "body_position": [136, 176], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.utils.analytics.usage_stats.ServeInfo", "bentoml._internal.utils.analytics.usage_stats.ServeInfo.serve_id", "bentoml._internal.utils.analytics.usage_stats.track"], "cross_file": ["bentoml._internal.bento.bento", "bentoml._internal.bento.bento.Bento.info", "bentoml._internal.bento.bento.Bento.creation_time", "bentoml._internal.configuration.containers.BentoMLContainer", "bentoml._internal.models", "bentoml._internal.utils.analytics.schemas.ServeInitEvent", "bentoml._internal.configuration.containers._BentoMLContainerClass.serve_info"]}, "requirement": {"Functionality": "This function tracks the initialization of a service and sends an event with relevant information. It creates an instance of a serve init event with information about the service, such as the serve ID, whether it is served from a BentoML container or a server API, production status, serve kind, creation timestamp of the BentoML container (if applicable), number of models, runners, and APIs in the service, and the types of models, runners, API inputs, and API outputs.", "Arguments": ":param svc: Service. The service instance being initialized.\n:param production: Bool. Whether the service is in production mode.\n:param serve_kind: String. The kind of serve being initialized.\n:param from_server_api: Bool. Whether the serve is from a server API.\n:param serve_info: ServeInfo. The serve information obtained from the BentoML container. Defaults to the serve_info provided by the BentoML container.\n:return: No return values."}, "tests": ["tests/unit/_internal/utils/test_analytics.py::test_track_serve_init"], "indent": 4}
{"namespace": "mingus.containers.bar.Bar.transpose", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/bar.py", "signature_position": [180, 180], "body_position": [185, 186], "dependency": {"intra_class": ["mingus.containers.bar.Bar.bar"], "intra_file": [], "cross_file": ["mingus.containers.note_container.NoteContainer.transpose"]}, "requirement": {"Functionality": "Transpose the notes in the bar up or down the given interval.\n", "Arguments": ":param self: Bar, an instance of the Bar class.\n:param interval: str, the interval by which to transpose the notes.\n:param up: bool, optional. Determines whether to transpose the notes up or down. If True (default), transpose up. If False, transpose down.\n:return: no return values.\n"}, "tests": ["tests/unit/containers/test_bar.py::test_Bar::test_transpose"], "indent": 8}
{"namespace": "pyramid.registry.Introspector.add", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [124, 124], "body_position": [125, 129], "dependency": {"intra_class": ["pyramid.registry.Introspector._categories", "pyramid.registry.Introspector._counter"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds an introspectable object to the Introspector instance. The introspectable object is categorized and stored based on its category name and discriminator. It also assigns an order to the introspectable object based on the current counter value.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param intr: The introspectable object to be added to the instance.\n:return: No return values."}, "tests": ["tests/test_registry.py::TestIntrospector::test_remove", "tests/test_registry.py::TestIntrospector::test_get_success", "tests/test_registry.py::TestIntrospector::test_unrelate", "tests/test_registry.py::TestIntrospector::test_get_category", "tests/test_registry.py::TestIntrospector::test_get_success_byhash"], "indent": 8}
{"namespace": "boltons.setutils.IndexedSet.add", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/setutils.py", "signature_position": [238, 238], "body_position": [240, 242], "dependency": {"intra_class": ["boltons.setutils.IndexedSet.item_index_map", "boltons.setutils.IndexedSet.item_list"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Add an item to the IndexedSet instance if the item is not already in the set.", "Arguments": ":param self: IndexedSet. An instance of the IndexedSet class.\n:param item: The item to be added to the set.\n:return: No return values."}, "tests": ["tests/test_setutils.py::test_iset_index_method"], "indent": 8}
{"namespace": "ydata_profiling.profile_report.ProfileReport.typeset", "type": "method", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/profile_report.py", "signature_position": [239, 239], "body_position": [240, 243], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["ydata_profiling.model.typeset.ProfilingTypeSet", "ydata_profiling.config"]}, "requirement": {"Functionality": "This function returns the typeset object associated with the ProfileReport instance. If the typeset object is not already created, it creates a new one using the configuration and type schema of the ProfileReport instance.", "Arguments": ":param self: ProfileReport. An instance of the ProfileReport class.\n:return: Optional[VisionsTypeset]. The typeset object associated with the ProfileReport instance, or None if it is not created yet."}, "tests": ["tests/unit/test_typeset_default.py::test_type_schema"], "indent": 8}
{"namespace": "bplustree.entry.Reference.__repr__", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/entry.py", "signature_position": [187, 187], "body_position": [188, 190], "dependency": {"intra_class": ["bplustree.entry.Reference.after", "bplustree.entry.Reference.before", "bplustree.entry.Reference.key"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function overrides the default __repr__ method for the Reference class '<Reference: key={} before={} after={}>'.", "Arguments": ":param self: Reference. An instance of the Reference class.\n:return: String. A string representation of the Reference object."}, "tests": ["tests/test_entry.py::test_reference_repr"], "indent": 8}
{"namespace": "falcon.request.Request.forwarded_prefix", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [822, 822], "body_position": [823, 828], "dependency": {"intra_class": ["falcon.request.Request._cached_forwarded_prefix", "falcon.request.Request.app", "falcon.request.Request.forwarded_host", "falcon.request.Request.forwarded_scheme"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the forwarded prefix of the request. It concatenates the forwarded scheme, forwarded host, and app to form the forwarded prefix. The output format is \"{forwarded scheme}://{forwarded host}{app}\".", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The forwarded prefix of the request."}, "tests": ["tests/test_request_forwarded.py::test_x_forwarded_proto", "tests/test_request_forwarded.py::test_no_forwarded_headers_with_port", "tests/test_request_forwarded.py::test_x_forwarded_host_with_port", "tests/test_request_forwarded.py::test_no_forwarded_headers", "tests/test_request_forwarded.py::test_x_forwarded_host"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.VoiceResponse.dial", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [33, 54], "body_position": [80, 102], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Dial", "twilio.twiml.voice_response.Dial.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a <Dial> element for a VoiceResponse object. It sets various attributes for the <Dial> element based on the input parameters and returns the <Dial> element.", "Arguments": ":param self: VoiceResponse. An instance of the VoiceResponse class.\n:param number: String. The phone number to dial.\n:param action: String. The action URL.\n:param method: String. The action URL method.\n:param timeout: Integer. The time to wait for an answer.\n:param hangup_on_star: Bool. Whether to hang up the call on star press.\n:param time_limit: Integer. The maximum time length.\n:param caller_id: String. The caller ID to display.\n:param record: Bool. Whether to record the call.\n:param trim: Bool. Whether to trim the recording.\n:param recording_status_callback: String. The recording status callback URL.\n:param recording_status_callback_method: String. The recording status callback URL method.\n:param recording_status_callback_event: String. The recording status callback events.\n:param answer_on_bridge: Bool. Whether to preserve the ringing behavior of the inbound call until the dialed call picks up.\n:param ring_tone: String. The ringtone to override the ringback tone.\n:param recording_track: String. The audio track to be recorded.\n:param sequential: Bool. Whether to dial child TwiML nouns in order (sequential) or all at once (parallel). Defaults to false, parallel.\n:param refer_url: String. The webhook that will receive future SIP REFER requests.\n:param refer_method: String. The HTTP method to use for the refer webhook.\n:param kwargs: additional attributes.\n:return: <Dial> element. The created <Dial> element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestDial::test_dial"], "indent": 8}
{"namespace": "fs.info.Info.type", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/info.py", "signature_position": [280, 281], "body_position": [291, 293], "dependency": {"intra_class": ["fs.info.Info._require_namespace", "fs.info.Info.get"], "intra_file": [], "cross_file": ["fs.enums.ResourceType"]}, "requirement": {"Functionality": "This function returns the type of the resource stored in the Info instance. It requires the \"details\" namespace to be present in the Info instance. If the \"details\" namespace is not found, it raises a MissingInfoNamespace exception.", "Arguments": ":param self: Info. An instance of the Info class.\n:return: ResourceType. The type of the resource stored in the Info instance."}, "tests": ["tests/test_info.py::TestInfo::test_empty", "tests/test_info.py::TestInfo::test_details"], "indent": 8}
{"namespace": "mackup.utils.can_file_be_synced_on_current_platform", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [365, 365], "body_position": [383, 397], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mackup.constants.PLATFORM_LINUX", "mackup.constants"]}, "requirement": {"Functionality": "This function checks if a given file or folder can be synced locally on the current platform. It specifically checks if it makes sense to sync the file at the given path on the current platform, taking into account certain exceptions.", "Arguments": ":param path: str. The path to the file or folder to check. If the path is relative, it should be prepended with the home folder. For example, 'abc' becomes '~/abc' and '/def' remains '/def'.\n:return: bool. True if the given file can be synced, False otherwise."}, "tests": ["tests/utils_test.py::TestMackup::test_can_file_be_synced_on_current_platform"], "indent": 4}
{"namespace": "mopidy.internal.validation.check_uri", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/validation.py", "signature_position": [122, 122], "body_position": [123, 126], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mopidy.exceptions.ValidationError", "mopidy.exceptions"]}, "requirement": {"Functionality": "Check if the given argument is a valid URI. If not, raise a validation error with a custom error message. The function first checks if the argument is a string, and then checks if the scheme of the URI is empty.", "Arguments": ":param arg: Any. The argument to be checked if it is a valid URI.\n:param msg: String. The custom error message to be raised if the argument is not a valid URI. It defaults to \"Expected a valid URI, not {arg!r}\".\n:return: No return values."}, "tests": ["tests/internal/test_validation.py::test_check_uri_with_invalid_values", "tests/internal/test_validation.py::test_check_uri_error_message"], "indent": 4}
{"namespace": "boltons.ioutils.MultiFileReader.seek", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [593, 593], "body_position": [597, 604], "dependency": {"intra_class": ["boltons.ioutils.MultiFileReader._fileobjs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets the position of the file cursor to a given offset. Currently, it only supports setting the offset to 0. It iterates through all the file objects in the MultiFileReader instance and sets their positions to the start. If whence is not os.SEEK_SET, it raises a NotImplementedError: 'MultiFileReader.seek() only supports os.SEEK_SET'. If the offset is not 0, it raises a NotImplementedError: 'MultiFileReader only supports seeking to start at this time'.", "Arguments": ":param self: MultiFileReader. An instance of the MultiFileReader class.\n:param offset: int. The offset to set the file cursor position to. Currently, only 0 is supported.\n:param whence: int. The reference point for the offset. It defaults to os.SEEK_SET.\n:return: No return values."}, "tests": ["tests/test_ioutils.py::TestMultiFileReader::test_read_seek_text", "tests/test_ioutils.py::TestMultiFileReader::test_read_seek_bytes"], "indent": 8}
{"namespace": "playhouse.kv.KeyValue.pop", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/kv.py", "signature_position": [163, 163], "body_position": [164, 173], "dependency": {"intra_class": ["playhouse.kv.KeyValue._database"], "intra_file": ["playhouse.kv.Sentinel"], "cross_file": []}, "requirement": {"Functionality": "This function removes the specified key from the KeyValue instance and returns the corresponding value. If the key is not found and no default value is provided, an exception is raised. The function also ensures that the operation is atomic by using a database transaction.", "Arguments": ":param self: KeyValue. An instance of the KeyValue class.\n:param key: The key to be removed from the instance.\n:param default: Optional. The value to be returned if the key is not found. Defaults to Sentinel.\n:return: The value corresponding to the key, or the default value if provided."}, "tests": ["tests/kv.py::TestKeyValue::test_basic_apis"], "indent": 8}
{"namespace": "pyramid.renderers.RendererHelper.clone", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [493, 493], "body_position": [494, 500], "dependency": {"intra_class": ["pyramid.renderers.RendererHelper.name", "pyramid.renderers.RendererHelper.package", "pyramid.renderers.RendererHelper.registry"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a clone of the RendererHelper instance with optional new values for name, package, and registry. If any of the new values are not provided, the corresponding values from the original instance are used.", "Arguments": ":param self: RendererHelper. An instance of the RendererHelper class.\n:param name: String [optional]. The new name for the cloned instance. If not provided, the name from the original instance is used.\n:param package: String [optional]. The new package for the cloned instance. If not provided, the package from the original instance is used.\n:param registry: Registry [optional]. The new registry for the cloned instance. If not provided, the registry from the original instance is used.\n:return: RendererHelper. The cloned instance with the new values."}, "tests": ["tests/test_renderers.py::TestRendererHelper::test_clone_noargs", "tests/test_renderers.py::TestRendererHelper::test_clone_allargs"], "indent": 8}
{"namespace": "gunicorn.config.Config.worker_class", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [113, 113], "body_position": [114, 124], "dependency": {"intra_class": ["gunicorn.config.Config.settings"], "intra_file": [], "cross_file": ["gunicorn.util", "gunicorn.util.load_class"]}, "requirement": {"Functionality": "This function returns the worker class based on the configuration settings. It first retrieves the worker class URI from settings of this instance. Then, it checks if the worker is a threaded worker and if the number of threads is greater than 1. If so, it updates the URI to use the threaded worker class. Next, it loads the worker class using the URI and setup it if can. Finally, it returns the worker class.", "Arguments": ":param self: Config. An instance of the Config class.\n:return: The worker class based on the configuration settings."}, "tests": ["tests/test_config.py::test_property_access"], "indent": 8}
{"namespace": "boltons.iterutils.chunked", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [303, 303], "body_position": [319, 323], "dependency": {"intra_class": [], "intra_file": ["boltons.iterutils.chunked_iter"], "cross_file": []}, "requirement": {"Functionality": "This function takes an iterable and divides it into chunks of a specified size. It returns a list of chunks, where each chunk contains the specified number of elements. If the iterable is not evenly divisible by the chunk size, the final chunk will have fewer elements. Padding can be enabled by providing a fill value.", "Arguments": ":param src: Iterable. The input iterable to be divided into chunks.\n:param size: int. The size of each chunk.\n:param count: int. The number of chunks to be generated. If None, all chunks will be generated. Throw away the remaining chunks.\n:param **kw: Keyword arguments. Can only be 'fill' for padding.\n:return: list. A list of chunks, where each chunk is a list of elements from the input iterable."}, "tests": ["tests/test_iterutils.py::test_chunked_bytes"], "indent": 4}
{"namespace": "boto.dynamodb2.items.Item.partial_save", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [369, 369], "body_position": [388, 413], "dependency": {"intra_class": ["boto.dynamodb2.items.Item.build_expects", "boto.dynamodb2.items.Item.get_keys", "boto.dynamodb2.items.Item.mark_clean", "boto.dynamodb2.items.Item.prepare_partial", "boto.dynamodb2.items.Item.table"], "intra_file": [], "cross_file": ["boto.dynamodb2.table.Table._update_item"]}, "requirement": {"Functionality": "This function saves only the changed data of an Item instance to DynamoDB. It updates only the fields that have been modified, rather than pushing the entire item. This helps prevent accidental overwrites and reduces the amount of data transferred over the network.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: bool. Returns True if the save operation is successful, False if no save was performed or if the write failed."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_partial_with_changes"], "indent": 8}
{"namespace": "boto.s3.cors.CORSConfiguration.add_rule", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/cors.py", "signature_position": [146, 148], "body_position": [194, 210], "dependency": {"intra_class": [], "intra_file": ["boto.s3.cors.CORSRule", "boto.s3.cors.CORSRule.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function adds a rule to the CORS configuration. It takes in various parameters such as allowed methods, allowed origins, ID, allowed headers, max age seconds, and expose headers. It creates a CORSRule object with these parameters and appends it to the CORS configuration.", "Arguments": ":param self: CORSRule. An instance of the CORSRule class.\n:param allowed_method: List of strings. The HTTP methods that are allowed for the specified origin.\n:param allowed_origin: List of strings. The origins that are allowed for cross-domain requests.\n:param id: String. A unique identifier for the rule.\n:param allowed_header: List of strings. The headers that are allowed in a pre-flight OPTIONS request.\n:param max_age_seconds: Integer. The time in seconds that the browser should cache the preflight response.\n:param expose_header: List of strings. The headers that customers are allowed to access from their applications.\n:return: No return value."}, "tests": ["tests/unit/s3/test_cors_configuration.py::TestCORSConfiguration::test_two_rules", "tests/unit/s3/test_cors_configuration.py::TestCORSConfiguration::test_one_rule_with_id", "tests/unit/s3/test_cors_configuration.py::TestCORSConfiguration::test_minimal"], "indent": 8}
{"namespace": "pyramid.csrf.SessionCSRFStoragePolicy.new_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [72, 72], "body_position": [74, 76], "dependency": {"intra_class": ["pyramid.csrf.SessionCSRFStoragePolicy._token_factory", "pyramid.csrf.SessionCSRFStoragePolicy.key"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates a new CSRF token and stores it in the session. It then returns the generated token.", "Arguments": ":param self: SessionCSRFStoragePolicy. An instance of the SessionCSRFStoragePolicy class.\n:param request: The request object.\n:return: String. The newly generated CSRF token."}, "tests": ["tests/test_csrf.py::TestSessionCSRFStoragePolicy::test_get_csrf_token_returns_the_new_token"], "indent": 8}
{"namespace": "jc.parsers.xrandr._parse_model", "type": "function", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/parsers/xrandr.py", "signature_position": [400, 400], "body_position": [401, 431], "dependency": {"intra_class": [], "intra_file": ["jc.parsers.pyedid.edid.Edid.name", "jc.parsers.pyedid.edid.Edid.product", "jc.parsers.pyedid.edid.Edid.serial", "jc.parsers.xrandr.Model", "jc.parsers.xrandr._edid_head_pattern", "jc.parsers.xrandr._edid_line_pattern"], "cross_file": ["jc.parsers.pyedid.edid.Edid", "jc.parsers.pyedid.helpers.edid_helper.EdidHelper", "jc.parsers.pyedid.helpers.edid_helper.EdidHelper.hex2bytes"]}, "requirement": {"Functionality": "This function parses a model from a list of strings. It checks if the list is empty and returns None if it is. It then pops the last string from the list and checks if it matches a specific pattern. If it doesn't match, the string is appended back to the list and None is returned. If it matches, the function continues to pop strings from the list and checks if they match another pattern. The matching strings are concatenated to form a hexadecimal value. The hexadecimal value is then converted to bytes using a helper function. Finally, a model dictionary is created with the extracted information from the converted bytes and returned.", "Arguments": ":param next_lines: List of strings. The list of strings to parse the model from.\n:param quiet: Bool. Whether to suppress any output during parsing. Defaults to False.\n:return: Optional[Model]. The parsed model dictionary, or None if the list is empty or no model is found."}, "tests": ["tests/test_xrandr.py::XrandrTests::test_model"], "indent": 4}
{"namespace": "zxcvbn.scoring.spatial_guesses", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [335, 335], "body_position": [336, 365], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.scoring.KEYBOARD_AVERAGE_DEGREE", "zxcvbn.scoring.KEYBOARD_STARTING_POSITIONS", "zxcvbn.scoring.KEYPAD_AVERAGE_DEGREE", "zxcvbn.scoring.KEYPAD_STARTING_POSITIONS", "zxcvbn.scoring.nCk"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the number of possible guesses for a given match. It takes into account the starting positions and average degree of the keyboard or keypad, the length of the token, and the number of turns. It also considers the additional guesses for shifted keys.", "Arguments": ":param match: Dictionary. Contains information about the match, including the graph type ('qwerty' or 'dvorak'), the token, the number of turns, and the number of shifted keys.\n:return: Integer. The number of possible guesses for the match."}, "tests": ["tests/scoring_test.py::test_spatial_guesses"], "indent": 4}
{"namespace": "mingus.extra.tunings.get_tunings", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/extra/tunings.py", "signature_position": [448, 448], "body_position": [459, 494], "dependency": {"intra_class": [], "intra_file": ["mingus.extra.tunings._known"], "cross_file": []}, "requirement": {"Functionality": "This function searches for tunings based on the given parameters such as instrument, number of strings, and number of courses. It returns a list of tunings that match the search criteria.", "Arguments": ":param instrument: String [optional]. The instrument to search for tunings. It is treated as a case-insensitive prefix. Defaults to None.\n:param nr_of_strings: Integer [optional]. The number of strings to search for tunings. Defaults to None.\n:param nr_of_courses: Integer [optional]. The number of courses to search for tunings. Defaults to None.\n:return: List. A list of tunings that match the search criteria."}, "tests": ["tests/unit/extra/test_tunings.py::test_Tunings::test_get_tunings"], "indent": 4}
{"namespace": "boltons.dictutils.ManyToMany.iteritems", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [995, 995], "body_position": [996, 998], "dependency": {"intra_class": ["boltons.dictutils.ManyToMany.data"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Iterate over the items in the ManyToMany instance. It yields each key-value pair in the instance.", "Arguments": ":param self: ManyToMany. An instance of the ManyToMany class.\n:return: Yields a tuple of key-value pairs in the instance."}, "tests": ["tests/test_dictutils.py::test_many_to_many"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.ls", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [40, 40], "body_position": [41, 50], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "List all the files and directories in the given path. It first converts the input path from a file URI to a regular path. Then, it checks if the path is a directory. If it is, it recursively walks through all the subdirectories and yields the file paths. If it is not a directory, it simply yields the path. The returned paths are in file URI format.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param path_glob: String. The path or file URI to list files and directories from.\n:return: String. Yields the paths of all files and directories in the given path."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_ls_basic", "tests/fs/test_local.py::LocalFSTestCase::test_ls_basic_2", "tests/fs/test_local.py::LocalFSTestCase::test_ls_dir_with_file_uri", "tests/fs/test_local.py::LocalFSTestCase::test_ls_recurse", "tests/fs/test_local.py::LocalFSTestCase::test_ls_with_file_uri"], "indent": 8}
{"namespace": "boto.dynamodb2.table.BatchTable.delete_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1651, 1651], "body_position": [1652, 1655], "dependency": {"intra_class": ["boto.dynamodb2.table.BatchTable._to_delete", "boto.dynamodb2.table.BatchTable.flush", "boto.dynamodb2.table.BatchTable.should_flush"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds the given item to the list of items to be deleted in the BatchTable instance. If the number of items to be deleted reaches a certain threshold, it delete the items from the table by flushing.", "Arguments": ":param self: BatchTable. An instance of the BatchTable class.\n:param kwargs: Keyword arguments representing the item to be deleted.\n:return: No return values."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write", "tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write_flushing"], "indent": 8}
{"namespace": "fs.path.iswildcard", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [575, 576], "body_position": [592, 593], "dependency": {"intra_class": [], "intra_file": ["fs.path._WILD_CHARS"], "cross_file": []}, "requirement": {"Functionality": "Check if a given path ends with a wildcard based on a set of wildcard characters.\n", "Arguments": ":param path: String, a string representing the path to be checked, e.g., ``'a/b/c'``.\n:return: Bool, True if the path ends with a wildcard, False otherwise.\n"}, "tests": ["tests/test_path.py::TestPathFunctions::test_iswildcard"], "indent": 4}
{"namespace": "chatette.parsing.AliasDefBuilder.create_concrete", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [139, 139], "body_position": [140, 146], "dependency": {"intra_class": [], "intra_file": ["chatette.parsing.UnitDefBuilder._build_modifiers_repr", "chatette.parsing.UnitDefBuilder._check_information", "chatette.parsing.UnitDefBuilder.identifier", "chatette.parsing.UnitDefBuilder.variation"], "cross_file": ["chatette.units.ast.AST", "chatette.units.modifiable.definitions.alias.AliasDefinition", "chatette.utils.Singleton.get_or_create", "chatette.utils.UnitType", "chatette.utils.UnitType.alias"]}, "requirement": {"Functionality": "This function creates a concrete alias definition based on the given conditions. It first checks if the variation is not None and if the identifier exists in the definitions. If so, it returns the corresponding definition. Otherwise, it creates a new AliasDefinition instance with the identifier and the modifiers representation.", "Arguments": ":param self: AliasDefBuilder. An instance of the AliasDefBuilder class.\n:return: AliasDefinition. The created AliasDefinition instance."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestAliasDefBuilder::test_create_concrete", "tests/unit-testing/parsing/test_init.py::TestAliasDefBuilder::test_new_variation"], "indent": 8}
{"namespace": "boto.dynamodb.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb/__init__.py", "signature_position": [39, 39], "body_position": [40, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.dynamodb.layer2.Layer2", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in DynamoDB using the provided region name and additional keyword parameters. It creates a Layer2 instance and uses it to establish the connection.", "Arguments": ":param region_name: String. The name of the region to connect to in DynamoDB.\n:param **kw_params: Additional keyword parameters that can be passed to the connection.\n:return: Connection. The connection object to the specified region in DynamoDB."}, "tests": ["tests/unit/test_connect_to_region.py::TestDynamodbConnection::test_connect_to_region"], "indent": 4}
{"namespace": "authlib.oauth2.rfc6749.parameters.parse_implicit_response", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/oauth2/rfc6749/parameters.py", "signature_position": [153, 153], "body_position": [194, 208], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["authlib.oauth2.rfc6749.errors.MismatchingStateException", "authlib.oauth2.rfc6749.errors.MissingTokenException", "authlib.oauth2.rfc6749.errors.MissingTokenTypeException"]}, "requirement": {"Functionality": "This function parses the implicit token response URI into a dictionary. It extracts the parameters to the fragment component of the redirection URI using the ``application/x-www-form-urlencoded`` format: REQUIRED **access_token** issued by the authorization server. REQUIRED token_type, RECOMMENDED **expires_in** which means the lifetime in seconds of the access token, OPTIONAL **scope** if identical to the scope requested by the client, otherwise REQUIRED and REQUIRED **state** if the \"state\" parameter was present in the client authorization request. The exact value received from the client. The function will returns them as key-value pairs in a dictionary and raise MissingException if REQUIRED params are not satisfied.", "Arguments": ":param uri: String. The URI containing the token response.\n:param state: String. The state parameter received from the client authorization request. Defaults to None.\n:return: Dictionary. A dictionary containing the parsed parameters from the URI, including the access token, token type, expiration time, scope, and state."}, "tests": ["tests/core/test_oauth2/test_rfc6749_misc.py::OAuth2ParametersTest::test_parse_implicit_response"], "indent": 4}
{"namespace": "dominate.util.include", "type": "function", "project_path": "Text-Processing/dominate", "completion_path": "Text-Processing/dominate/dominate/util.py", "signature_position": [34, 34], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": ["dominate.util.raw"], "cross_file": []}, "requirement": {"Functionality": "This function includes the contents of a file on disk. It opens the file, reads its contents, and returns the raw data.", "Arguments": ":param f: String. The filename of the file to be included.\n:return: The raw data read from the file."}, "tests": ["tests/test_utils.py::test_include"], "indent": 2}
{"namespace": "mrjob.job.MRJob._runner_kwargs", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [725, 725], "body_position": [728, 742], "dependency": {"intra_class": ["mrjob.job.MRJob._job_kwargs", "mrjob.job.MRJob._kwargs_from_switches", "mrjob.job.MRJob._non_option_kwargs", "mrjob.job.MRJob._runner_class", "mrjob.job.MRJob._steps_desc"], "intra_file": [], "cross_file": ["mrjob.conf.combine_dicts", "mrjob.options._RUNNER_OPTS"]}, "requirement": {"Functionality": "This function returns a dictionary of keyword arguments that will be used when running the MRJob. It combines various sets of keyword arguments, including non-option keyword arguments, keyword arguments from switches, and keyword arguments from the job. If the runner class is \"inline\" or \"spark\", it also includes the MRJob class in the keyword arguments. Additionally, it includes the steps description in the keyword arguments.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:return: Dictionary. The keyword arguments to be used when running the MRJob."}, "tests": ["tests/test_job.py::JobConfTestCase::test_cmd_line_options", "tests/test_job.py::LibjarsTestCase::test_libjars_attr_plus_option", "tests/test_job.py::HadoopFormatTestCase::test_empty", "tests/test_job.py::LibjarsTestCase::test_libjars_attr", "tests/test_job.py::LibjarsTestCase::test_libjars_switch"], "indent": 8}
{"namespace": "boltons.socketutils.BufferedSocket.flush", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [473, 473], "body_position": [475, 477], "dependency": {"intra_class": ["boltons.socketutils.BufferedSocket._send_lock", "boltons.socketutils.BufferedSocket.send"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sends the contents of the internal send buffer of a BufferedSocket instance. It first acquires a lock to ensure thread safety, then send an empty byte string to the contents of the buffer.", "Arguments": ":param self: BufferedSocket. An instance of the BufferedSocket class.\n:return: None."}, "tests": ["tests/test_socketutils.py::test_client_disconnecting"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox.generic_autocomplete", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [477, 477], "body_position": [478, 525], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._process_typeaheads", "zulipterminal.ui_tools.boxes.WriteBox.autocomplete_emojis", "zulipterminal.ui_tools.boxes.WriteBox.autocomplete_groups", "zulipterminal.ui_tools.boxes.WriteBox.autocomplete_mentions", "zulipterminal.ui_tools.boxes.WriteBox.autocomplete_streams", "zulipterminal.ui_tools.boxes.WriteBox.autocomplete_users", "zulipterminal.ui_tools.boxes.WriteBox.validate_and_patch_autocomplete_stream_and_topic"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function provides generic autocomplete functionality for a given text. It checks for specific prefixes in the text and calls the corresponding autocomplete function based on the prefix. It then processes the autocomplete suggestions and returns the updated text with the autocomplete suggestion.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param text: String. The input text to be autocompleted.\n:param state: Optional[int]. The state of the autocomplete. Defaults to None.\n:return: Optional[str]. The updated text with the autocomplete suggestion."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test_generic_autocomplete_no_prefix", "tests/ui_tools/test_boxes.py::TestWriteBox::test_generic_autocomplete_mentions_subscribers", "tests/ui_tools/test_boxes.py::TestWriteBox::test_generic_autocomplete_streams", "tests/ui_tools/test_boxes.py::TestWriteBox::test_generic_autocomplete_mentions", "tests/ui_tools/test_boxes.py::TestWriteBox::test_generic_autocomplete_user_mentions"], "indent": 8}
{"namespace": "boltons.mathutils.Bits.as_hex", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/mathutils.py", "signature_position": [223, 224], "body_position": [225, 227], "dependency": {"intra_class": ["boltons.mathutils.Bits.len", "boltons.mathutils.Bits.val"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert a Bits instance to a hexadecimal string representation. It first creates a template string to pad out to the number of bytes necessary to represent the bits. Then it formats the template with the value of the Bits instance and returns the resulting hexadecimal string.", "Arguments": ":param self: Bits. An instance of the Bits class.\n:return: String. The hexadecimal string representation of the Bits instance."}, "tests": ["tests/test_mathutils.py::test_bits"], "indent": 8}
{"namespace": "pyramid.renderers.JSON.add_adapter", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [237, 237], "body_position": [259, 261], "dependency": {"intra_class": ["pyramid.renderers.JSON.components"], "intra_file": [], "cross_file": ["pyramid.interfaces.IJSONAdapter"]}, "requirement": {"Functionality": "This function adds an adapter to the JSON renderer. The adapter is used to convert objects of a specific type or interface into JSON-serializable objects when they fail to automatically encode using the serializer.", "Arguments": ":param self: JSON. An instance of the JSON class.\n:param type_or_iface: Type or interface. The type or interface of the object that the adapter will be used for.\n:param adapter: Function. The adapter function that converts the object into a JSON-serializable object. It accepts two arguments: the object and the currently active request.\n:return: No return values."}, "tests": ["tests/test_renderers.py::TestJSON::test_with_custom_adapter"], "indent": 8}
{"namespace": "boto.s3.website.WebsiteConfiguration.to_xml", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/website.py", "signature_position": [77, 77], "body_position": [78, 89], "dependency": {"intra_class": ["boto.s3.website.WebsiteConfiguration.error_key", "boto.s3.website.WebsiteConfiguration.redirect_all_requests_to", "boto.s3.website.WebsiteConfiguration.routing_rules", "boto.s3.website.WebsiteConfiguration.suffix"], "intra_file": ["boto.s3.website.RoutingRules.to_xml", "boto.s3.website.tag"], "cross_file": []}, "requirement": {"Functionality": "Convert the WebsiteConfiguration instance to an XML string representation. It creates an XML string by appending different parts based on the attributes of the instance.", "Arguments": ":param self: WebsiteConfiguration. An instance of the WebsiteConfiguration class.\n:return: String. The XML representation of the WebsiteConfiguration instance."}, "tests": ["tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_suffix_and_error", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_redirect_all_requests_with_protocol", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_routing_rules_to_host_on_404", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_key_prefix", "tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_parse_xml"], "indent": 8}
{"namespace": "asyncpg._testbase.TestCase.assertLoopErrorHandlerCalled", "type": "method", "project_path": "Database/asyncpg", "completion_path": "Database/asyncpg/asyncpg/_testbase/__init__.py", "signature_position": [144, 144], "body_position": [145, 165], "dependency": {"intra_class": ["asyncpg._testbase.TestCase.loop"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to assert that a loop error handler is called with a specific message. It sets a new exception handler for the loop, executes the code block, and checks if any of the logged messages match the given regular expression. If no matching message is found, it raises an AssertionError.", "Arguments": ":param self: TestCase. An instance of the TestCase class.\n:param msg_re: String. The regular expression pattern to match the logged messages against.\n:return: No return values."}, "tests": ["tests/test_test.py::TestHelpers::test_tests_assertLoopErrorHandlerCalled_01"], "indent": 8}
{"namespace": "alembic.testing.env.env_file_fixture", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/env.py", "signature_position": [72, 72], "body_position": [73, 89], "dependency": {"intra_class": [], "intra_file": ["alembic.testing.env._get_staging_directory"], "cross_file": ["alembic.util", "alembic.util.pyc_file_from_path"]}, "requirement": {"Functionality": "This function creates an environment file fixture by writing the given text to a file named \"env.py\" in a specific directory.", "Arguments": ":param txt: String. The text to be written to the file.\n:return: None."}, "tests": ["tests/test_offline_environment.py::OfflineEnvironmentTest::test_head_rev_post_context", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_head_rev_post_context_multihead", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_starting_rev_pre_context_cmd_w_no_startrev", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_head_rev_pre_context_multihead", "tests/test_offline_environment.py::OfflineEnvironmentTest::test_starting_rev_pre_context"], "indent": 4}
{"namespace": "sacred.dependencies.PackageDependency.create", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/dependencies.py", "signature_position": [523, 523], "body_position": [524, 537], "dependency": {"intra_class": ["sacred.dependencies.PackageDependency.__init__", "sacred.dependencies.PackageDependency.modname_to_dist"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a PackageDependency instance based on the given module. It caches the correspondence between module names and package names from the metadata \"top_level.txt\" file in the working set. It then create the PackageDependency instance by retrieving the package name and version from the cached dictionary.", "Arguments": ":param cls: type. The PackageDependency class.\n:param mod: Module. The module for which the PackageDependency instance is created.\n:return: PackageDependency. The created PackageDependency instance."}, "tests": ["tests/test_dependencies.py::test_package_dependency_create_no_version", "tests/test_dependencies.py::test_gather_sources_and_dependencies"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table._introspect_indexes", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [315, 315], "body_position": [320, 321], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._PROJECTION_TYPE_TO_INDEX", "boto.dynamodb2.table.Table._introspect_all_indexes"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a raw index structure from a DynamoDB response and parses it to build high-level Python objects that represent the indexes.", "Arguments": ":param self: Table. An instance of the Table class.\n:param raw_indexes: The raw index structure from a DynamoDB response.\n:return: The high-level Python objects that represent the indexes."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test__introspect_indexes"], "indent": 8}
{"namespace": "praw.util.token_manager.FileTokenManager.pre_refresh_callback", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/util/token_manager.py", "signature_position": [93, 93], "body_position": [95, 97], "dependency": {"intra_class": ["praw.util.token_manager.FileTokenManager._filename"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function loads the refresh token from the file and assigns it to the authorizer if it is not already set.", "Arguments": ":param self: FileTokenManager. An instance of the FileTokenManager class.\n:param authorizer: The authorizer object that needs to be refreshed.\n:return: No return values."}, "tests": ["tests/unit/util/test_token_manager.py::TestFileTokenManager::test_pre_refresh_token_callback__reads_from_file"], "indent": 8}
{"namespace": "boltons.ioutils.SpooledStringIO.tell", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [508, 508], "body_position": [510, 511], "dependency": {"intra_class": ["boltons.ioutils.SpooledStringIO._tell"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed"], "cross_file": []}, "requirement": {"Functionality": "Return the codepoint position in the SpooledStringIO instance.\n", "Arguments": ":param self: SpooledStringIO, an instance of SpooledStringIO class.\n:return: Int, the codepoint position.\n"}, "tests": ["tests/test_ioutils.py::TestSpooledStringIO::test_tell_codepoints", "tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_SEEK_CUR"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.VoiceResponse.say", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [375, 375], "body_position": [387, 389], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Say", "twilio.twiml.voice_response.Say.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Say>` element for a VoiceResponse object. It takes in parameters such as the message to say, the voice to use, the number of times to loop the message, the language of the message, and additional attributes. It then returns the created `<Say>` element.", "Arguments": ":param self: VoiceResponse. An instance of the VoiceResponse class.\n:param message: String. The message to say.\n:param voice: String. The voice to use.\n:param loop: Integer. The number of times to loop the message.\n:param language: String. The language of the message.\n:param kwargs: Additional attributes.\n:return: `<Say>` element. The created `<Say>` element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestSay::test_say_loop_woman", "tests/unit/twiml/test_voice_response.py::TestSay::test_say_loop_gb", "tests/unit/twiml/test_voice_response.py::TestSay::test_say_french", "tests/unit/twiml/test_voice_response.py::TestSay::test_say_all", "tests/unit/twiml/test_voice_response.py::TestSay::test_say_hello_world"], "indent": 8}
{"namespace": "pysnooper.utils.ensure_tuple", "type": "function", "project_path": "Software-Development/PySnooper", "completion_path": "Software-Development/PySnooper/pysnooper/utils.py", "signature_position": [90, 90], "body_position": [91, 96], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pysnooper.pycompat.string_types"]}, "requirement": {"Functionality": "This function ensures that the input is converted to a tuple. If the input is already an iterable object (excluding strings), it is converted to a tuple. Otherwise, the input is wrapped in a tuple.", "Arguments": ":param x: Any data type. The input to be converted to a tuple.\n:return: Tuple. The input converted to a tuple."}, "tests": ["tests/test_utils/test_ensure_tuple.py::test_ensure_tuple"], "indent": 4}
{"namespace": "twilio.jwt.Jwt.to_jwt", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/__init__.py", "signature_position": [103, 103], "body_position": [110, 121], "dependency": {"intra_class": ["twilio.jwt.Jwt.algorithm", "twilio.jwt.Jwt.headers", "twilio.jwt.Jwt.payload", "twilio.jwt.Jwt.secret_key"], "intra_file": [], "cross_file": ["twilio.jwt"]}, "requirement": {"Functionality": "This function encodes a JWT object into a JWT string. It first checks if a signing key is configured for the JWT. Then it creates a copy of the headers and payload. If a time-to-live (ttl) value is provided, it adds an expiration time to the payload. Finally, it uses the jwt_lib library to encode the payload, secret key, algorithm, and headers into a JWT string.", "Arguments": ":param self: Jwt. An instance of the Jwt class.\n:param ttl: Integer. Overrides the time-to-live value configured in the constructor. (optional)\n:return: String. The encoded JWT string."}, "tests": ["tests/unit/jwt/test_access_token.py::AccessTokenTest::test_playback_grant", "tests/unit/jwt/test_access_token.py::AccessTokenTest::test_video_grant", "tests/unit/jwt/test_access_token.py::AccessTokenTest::test_conversations_grant", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_pass_scopes_in_constructor", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_decode"], "indent": 8}
{"namespace": "diffprivlib.tools.utils.nanmean", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [211, 212], "body_position": [265, 268], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._mean"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the differentially private arithmetic mean of an array along the specified axis, while ignoring NaN values. It adds Laplace noise to satisfy differential privacy, where the sensitivity is calculated using the specified bounds. The function closely follows the behavior of the `numpy.mean` function.", "Arguments": ":param array: array_like. An array containing numbers whose mean is desired.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: int or tuple of ints, optional. The axis or axes along which the means are computed. The default is to compute the mean of the flattened array.\n:param dtype: data-type, optional. The type to use in computing the mean. The default is `float64` for integer inputs and the same as the input dtype for floating point inputs.\n:param keepdims: bool, default: False. If set to True, the axes which are reduced are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. An accountant to keep track of the privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. Returns a new array containing the mean values."}, "tests": ["tests/tools/test_nanmean.py::TestNanMean::test_large_epsilon_axis", "tests/tools/test_nanmean.py::TestNanMean::test_no_epsilon", "tests/tools/test_nanmean.py::TestNanMean::test_no_params", "tests/tools/test_nanmean.py::TestNanMean::test_bad_bounds", "tests/tools/test_nanmean.py::TestNanMean::test_array_like"], "indent": 4}
{"namespace": "telethon.extensions.html.parse", "type": "function", "project_path": "Communications/Telethon", "completion_path": "Communications/Telethon/telethon/extensions/html.py", "signature_position": [113, 113], "body_position": [121, 128], "dependency": {"intra_class": [], "intra_file": ["telethon.extensions.html.HTMLToTelegramParser", "telethon.extensions.html.HTMLToTelegramParser.__init__", "telethon.extensions.html.HTMLToTelegramParser.entities", "telethon.extensions.html.HTMLToTelegramParser.text"], "cross_file": ["telethon.helpers.add_surrogate", "telethon.helpers.del_surrogate", "telethon.helpers.strip_text"]}, "requirement": {"Functionality": "This function parses the given HTML message and returns its stripped representation along with a list of the MessageEntity objects that were found.", "Arguments": ":param html: str. The HTML message to be parsed.\n:return: Tuple[str, List[TypeMessageEntity]]. A tuple consisting of the stripped message and a list of MessageEntity objects."}, "tests": ["tests/telethon/extensions/test_html.py::test_offset_at_emoji"], "indent": 4}
{"namespace": "mingus.core.intervals.minor_seventh", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [226, 226], "body_position": [227, 228], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.seventh"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the minor seventh note above the given note.\n", "Arguments": ":param note: str. The note for which the minor seventh interval is to be calculated.\n:return: str. The final note.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_minor_sevenths"], "indent": 4}
{"namespace": "alembic.script.revision.RevisionMap.get_revisions", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [509, 511], "body_position": [529, 556], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._resolve_revision_number", "alembic.script.revision.RevisionMap.get_revisions"], "intra_file": ["alembic.script.revision._GetRevArg", "alembic.script.revision._RevisionOrBase"], "cross_file": []}, "requirement": {"Functionality": "This function returns a tuple of Revision instances with the given rev id or identifiers. It supports various input formats such as a single identifier, a sequence of identifiers, or special symbols like \"head\" or \"base\". It also supports partial identifiers where the given identifier is matched against all identifiers that start with the given characters.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param id_: Optional[_GetRevArg]. The rev id or identifiers to retrieve the Revision instances for.\n:return: Tuple[Optional[_RevisionOrBase], ...]. A tuple of Revision instances or an empty tuple."}, "tests": ["tests/test_revision.py::APITest::test_invalid_datatype", "tests/test_revision.py::APITest::test_get_revisions_head_multiple", "tests/test_revision.py::APITest::test_get_revisions_heads_multiple"], "indent": 8}
{"namespace": "boltons.socketutils.BufferedSocket.close", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [561, 561], "body_position": [569, 575], "dependency": {"intra_class": ["boltons.socketutils.BufferedSocket._recv_lock", "boltons.socketutils.BufferedSocket._send_lock", "boltons.socketutils.BufferedSocket.rbuf", "boltons.socketutils.BufferedSocket.rbuf_unconsumed", "boltons.socketutils.BufferedSocket.sbuf", "boltons.socketutils.BufferedSocket.sock"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function closes the wrapped socket and clears the internal buffers. It is important to note that the send buffer is not automatically flushed, so if the `buffer` method has been called, a flush method should be called before calling this function. After calling this function, any future socket operations will raise a `socket.error` exception.", "Arguments": ":param self: BufferedSocket. An instance of the BufferedSocket class.\n:return: No return values."}, "tests": ["tests/test_socketutils.py::test_client_disconnecting"], "indent": 8}
{"namespace": "alembic.autogenerate.render._render_unique_constraint", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/render.py", "signature_position": [1019, 1023], "body_position": [1024, 1028], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.render._uq_constraint", "alembic.autogenerate.render._user_defined_render"], "cross_file": ["alembic.autogenerate.api.AutogenContext"]}, "requirement": {"Functionality": "This function renders a unique constraint based on the given parameters. It first tries to render the constraint using a user-defined rendering function. If the rendering is successful, it returns the rendered result. Otherwise, it falls back to the default rendering function.", "Arguments": ":param constraint: UniqueConstraint. The unique constraint to be rendered.\n:param autogen_context: AutogenContext. The autogen context object.\n:param namespace_metadata: Optional[MetaData]. The metadata object for the namespace.\n:return: str. The rendered unique constraint."}, "tests": ["tests/test_postgresql.py::PostgresqlAutogenRenderTest::test_render_unique_nulls_not_distinct_constraint", "tests/test_autogen_render.py::RenderNamingConventionTest::test_explicit_unique_constraint", "tests/test_autogen_render.py::RenderNamingConventionTest::test_explicit_named_unique_constraint", "tests/test_autogen_render.py::RenderNamingConventionTest::test_implicit_unique_constraint", "tests/test_autogen_render.py::AutogenRenderTest::test_render_unique_constraint_opts"], "indent": 4}
{"namespace": "pyramid.testing.DummyTemplateRenderer.assert_", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [116, 116], "body_position": [124, 139], "dependency": {"intra_class": ["pyramid.testing.DummyTemplateRenderer._implementation", "pyramid.testing.DummyTemplateRenderer._received"], "intra_file": ["pyramid.testing.MockTemplate._received", "pyramid.testing._marker"], "cross_file": []}, "requirement": {"Functionality": "This function is used to assert that the renderer received the expected key-value pairs. It checks if the renderer received the key with a value that matches the asserted value. If the key is not received or the value doesn't match, it raises an AssertionError.", "Arguments": ":param self: DummyTemplateRenderer. An instance of the DummyTemplateRenderer class.\n:param **kw: Arbitrary key-value pairs representing the assertions to be made.\n:return: bool. Returns True if all assertions pass."}, "tests": ["tests/test_testing.py::TestDummyTemplateRenderer::test_assert_"], "indent": 8}
{"namespace": "pycoin.satoshi.IntStreamer.IntStreamer.int_from_script_bytes", "type": "method", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/IntStreamer.py", "signature_position": [9, 9], "body_position": [10, 28], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pycoin.satoshi.errno", "pycoin.coins.SolutionChecker.ScriptError", "pycoin.satoshi.errno.UNKNOWN_ERROR"]}, "requirement": {"Functionality": "This function converts a byte array into an integer value. It first checks if the byte array is empty, and if so, returns 0. Then it reverses the byte array and extracts the first byte. It extracts the value from the first byte by performing a bitwise AND operation with 0x7f. If the \"require_minimal\" parameter is set to True, it checks if the value is 0 and if the byte array is non-minimally encoded. If so, it raises a ScriptError. It then checks if the first byte has the sign bit set, indicating a negative value. It iterates over the remaining bytes in the byte array, left-shifting the value by 8 bits and adding the current byte. If the value is negative, it negates it. Finally, it returns the resulting integer value.", "Arguments": ":param class_: The class object. It is not used in the function.\n:param s: The byte array to convert into an integer.\n:param require_minimal: Bool. Whether to check for minimal encoding. Defaults to False.\n:return: The converted integer value."}, "tests": ["tests/tools_test.py::ToolsTest::test_int_to_from_script_bytes"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.getacl", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1542, 1542], "body_position": [1546, 1550], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._normalise_folder"], "intra_file": [], "cross_file": ["imapclient.response_lexer", "imapclient.response_lexer.TokenSource"]}, "requirement": {"Functionality": "Return a list of \"(who, acl)\" tuples describing the access controls for the specified folder in the IMAPClient instance. \"who\" denotes the users, and \"acl\" means access control list.\n", "Arguments": ":param self: IMAPClient, an instance of IMAPClient class.\n:param folder: String, the name of the folder for which access controls need to be retrieved.\n:return: List[Tuple], a list of tuples containing two elements each: the \"who\" and the \"acl\" for the specified folder. \"who\" denotes the users, and \"acl\" means access control list.\n"}, "tests": ["tests/test_imapclient.py::TestAclMethods::test_getacl"], "indent": 8}
{"namespace": "feedparser.http._build_urllib2_request", "type": "function", "project_path": "Text-Processing/feedparser", "completion_path": "Text-Processing/feedparser/feedparser/http.py", "signature_position": [92, 92], "body_position": [93, 121], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["feedparser.datetimes._parse_date"]}, "requirement": {"Functionality": "Build a urllib2 request with the given parameters. It creates a request object and adds headers based on the input parameters. The request object is then returned.", "Arguments": ":param url: String. The URL to send the request to.\n:param agent: String. The user agent to be used in the request header.\n:param accept_header: String. The accept header value to be used in the request header.\n:param etag: String. The etag value to be used in the request header.\n:param modified: String or datetime.datetime. The modified date to be used in the request header.\n:param referrer: String. The referrer value to be used in the request header.\n:param auth: String. The authorization value to be used in the request header.\n:param request_headers: Dictionary. Additional headers to be added to the request.\n:return: urllib.request.Request. The created request object."}, "tests": ["tests/runtests.py::TestBuildRequest::test_extra_headers"], "indent": 4}
{"namespace": "zxcvbn.matching.repeat_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [250, 250], "body_position": [251, 299], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.RANKED_DICTIONARIES", "zxcvbn.matching.omnimatch"], "cross_file": ["zxcvbn.scoring.most_guessable_match_sequence"]}, "requirement": {"Functionality": "This function searches for repeated patterns in a given password and returns information about the matches found. It uses regular expressions to find both greedy and lazy matches of repeated substrings in the password. It then compares the lengths of the greedy and lazy matches to determine the base token and calculates the repeat count. Finally, it recursively matches and scores the base string to get additional information about the matches.", "Arguments": ":param password: String. The password to search for repeated patterns.\n:param _ranked_dictionaries: List of dictionaries. A list of ranked dictionaries used for matching. Defaults to RANKED_DICTIONARIES.\n:return: List of dictionaries. A list of dictionaries containing information about the repeated matches found in the password. Each dictionary includes the pattern type, start and end indices of the match, the matched token, the base token, the number of guesses required to guess the base token, the sequence of matches for the base token, and the repeat count."}, "tests": ["tests/matching_test.py::test_repeat_matching"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.idle_check", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [930, 930], "body_position": [948, 981], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient.AbortError", "imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient._poll_socket", "imapclient.imapclient.IMAPClient._select_poll_socket", "imapclient.imapclient.IMAPClient._set_read_timeout", "imapclient.imapclient.IMAPClient.socket"], "intra_file": ["imapclient.imapclient.POLL_SUPPORT", "imapclient.imapclient._parse_untagged_response"], "cross_file": []}, "requirement": {"Functionality": "Check for any IDLE responses sent by the server. This method should only be called if the server is in IDLE mode. It blocks until an IDLE response is received, or until a timeout is reached.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param timeout: int or None. The maximum number of seconds to wait for an IDLE response. If None, the call will block indefinitely.\n:return: list. A list of received IDLE responses, parsed with values converted to appropriate types."}, "tests": ["tests/test_imapclient.py::TestIdleAndNoop::test_idle_check_timeout_poll", "tests/test_imapclient.py::TestIdleAndNoop::test_idle_check_timeout", "tests/test_imapclient.py::TestIdleAndNoop::test_idle_check_blocking_poll", "tests/test_imapclient.py::TestIdleAndNoop::test_idle_check_blocking", "tests/test_imapclient.py::TestIdleAndNoop::test_idle_check_with_data"], "indent": 8}
{"namespace": "capirca.lib.nacaddr.IP", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/capirca/lib/nacaddr.py", "signature_position": [26, 26], "body_position": [41, 50], "dependency": {"intra_class": [], "intra_file": ["capirca.lib.nacaddr.IPv4", "capirca.lib.nacaddr.IPv6"], "cross_file": []}, "requirement": {"Functionality": "This function takes an IP address string and returns an object of the correct type (IPv4 or IPv6). It first checks if the input is already an instance of the ipaddress._BaseNetwork class. If not, it creates an ipaddress object using the ipaddress.ip_network() function. Then, based on the version of the ipaddress object, it creates and returns an instance of the corresponding IP class (IPv4 or IPv6).", "Arguments": ":param ip: String. The IP address.\n:param comment: String. Optional comment field.\n:param token: String. Optional token name where this address was extracted from.\n:param strict: Bool. Whether strict should be used in the ipaddress object. Defaults to True.\n:return: IPv4 or IPv6. The created IPv4 or IPv6 instance."}, "tests": ["tests/lib/cgrep_test.py::CgrepTest::test_one_ip_fail"], "indent": 2}
{"namespace": "zulipterminal.server_url.encode_stream", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/server_url.py", "signature_position": [16, 16], "body_position": [22, 23], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.server_url.hash_util_encode"], "cross_file": []}, "requirement": {"Functionality": "This function replaces any occurrence of whitespace with a hyphen and encode the stream name. It returns the encoded string prefixed with the stream name", "Arguments": ":param stream_id: int.\n:param stream_name: str.\n:return: str. The encoded string representing the message."}, "tests": ["tests/server_url/test_server_url.py::test_encode_stream"], "indent": 4}
{"namespace": "discord.ext.tasks.loop", "type": "function", "project_path": "Software-Development/discord-py", "completion_path": "Software-Development/discord-py/discord/ext/tasks/__init__.py", "signature_position": [765, 773], "body_position": [815, 826], "dependency": {"intra_class": [], "intra_file": ["discord.ext.tasks.LF", "discord.ext.tasks.Loop"], "cross_file": ["discord.utils.MISSING"]}, "requirement": {"Functionality": "This function is a decorator that schedules a task in the background with optional reconnect logic. It returns a Loop object that can be used to control the execution of the task.", "Arguments": ":param seconds: float. The number of seconds between every iteration.\n:param minutes: float. The number of minutes between every iteration.\n:param hours: float. The number of hours between every iteration.\n:param time: Union[datetime.time, Sequence[datetime.time]]. The exact times to run this loop at. It can be a single value or a list of datetime.time objects. Timezones are supported. This parameter cannot be used with the relative time parameters.\n:param count: Optional[int]. The number of loops to do. If set to None, it will be an infinite loop.\n:param reconnect: bool. Whether to handle errors and restart the task using an exponential back-off algorithm.\n:return: Callable[[LF], Loop[LF]]. A decorator that schedules a task in the background and returns a Loop object."}, "tests": ["tests/test_ext_tasks.py::test_task_regression_issue7659", "tests/test_ext_tasks.py::test_task_regression_issue7676"], "indent": 4}
{"namespace": "boto.glacier.job.Job.download_to_fileobj", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/glacier/job.py", "signature_position": [125, 127], "body_position": [143, 145], "dependency": {"intra_class": ["boto.glacier.job.Job.DefaultPartSize", "boto.glacier.job.Job._calc_num_chunks", "boto.glacier.job.Job._download_to_fileob"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function downloads an archive and saves its contents to a file object. It divides the download into chunks and verifies the tree hashes for each downloaded chunk.", "Arguments": ":param self: Job. An instance of the Job class.\n:param output_file: file. The file object where the archive contents will be saved.\n:param chunk_size: int. The chunk size to use when downloading the archive.\n:param verify_hashes: bool. Indicates whether or not to verify the tree hashes for each downloaded chunk. It defaults to True.\n:param retry_exceptions: tuple. A tuple of exceptions that should be retried if they occur during the download. It defaults to (socket.error,).\n:return: No return values."}, "tests": ["tests/unit/glacier/test_job.py::TestJob::test_download_to_fileobj"], "indent": 8}
{"namespace": "boto.cloudsearch.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudsearch/__init__.py", "signature_position": [39, 39], "body_position": [40, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudsearch.layer1.Layer1", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the cloudsearch service. It creates a connection to the cloudsearch service in the specified region.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: Connection. The connection object to the cloudsearch service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCloudsearchConnection::test_connect_to_region"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledBytesIO.len", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [366, 366], "body_position": [368, 376], "dependency": {"intra_class": ["boltons.ioutils.SpooledBytesIO._rolled", "boltons.ioutils.SpooledBytesIO.seek", "boltons.ioutils.SpooledBytesIO.tell"], "intra_file": ["boltons.ioutils.SpooledIOBase.fileno"], "cross_file": []}, "requirement": {"Functionality": "This function determines the length of the file. It first checks the current position of the file, then based on whether the file has been rolled or not, it calculates the length of the file using different methods. Finally, it returns the length of the file.", "Arguments": ":param self: SpooledBytesIO. An instance of the SpooledBytesIO class.\n:return: int. The length of the file."}, "tests": ["tests/test_ioutils.py::TestSpooledBytesIO::test_len_no_rollover", "tests/test_ioutils.py::TestSpooledBytesIO::test_len_rollover"], "indent": 8}
{"namespace": "exodus_bundler.input_parsing.extract_paths", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/input_parsing.py", "signature_position": [70, 70], "body_position": [80, 102], "dependency": {"intra_class": [], "intra_file": ["exodus_bundler.input_parsing.blacklisted_directories", "exodus_bundler.input_parsing.extract_exec_path", "exodus_bundler.input_parsing.extract_open_path", "exodus_bundler.input_parsing.extract_stat_path"], "cross_file": []}, "requirement": {"Functionality": "This function parses paths from a piped input. It takes the raw input, which can be either a list of files or the output of the strace command, and extracts the paths from it. It also has an option to only include paths that actually exist and are not directories.", "Arguments": ":param content: str. The raw input, can be either a list of files or the output of the strace command.\n:param existing_only: bool, optional. Requires that files actually exist and aren't directories. Defaults to True.\n:return: list. A list of paths extracted from the input."}, "tests": ["tests/test_input_parsing.py::test_extract_no_paths", "tests/test_input_parsing.py::test_extract_raw_paths", "tests/test_input_parsing.py::test_extract_strace_paths"], "indent": 4}
{"namespace": "boto.s3.bucket.Bucket.get_key", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/bucket.py", "signature_position": [145, 146], "body_position": [175, 195], "dependency": {"intra_class": ["boto.s3.bucket.Bucket._get_key_internal", "boto.s3.bucket.Bucket.new_key"], "intra_file": [], "cross_file": ["boto.exception.BotoClientError", "boto.vendored.six.iteritems", "boto.jsonresponse.XmlHandler.parse"]}, "requirement": {"Functionality": "This function checks if a specific key exists within a bucket. It sends a HEAD request to check for the existence of the key. If the key exists, it returns an instance of the Key object. Otherwise, it returns None.", "Arguments": ":param self: Bucket. An instance of the Bucket class.\n:param key_name: String. The name of the key to retrieve.\n:param headers: Dictionary. The headers to send when retrieving the key.\n:param version_id: String. The version ID of the key.\n:param response_headers: Dictionary. A dictionary containing HTTP headers/values that will override any headers associated with the stored object in the response.\n:param validate: Bool. Verifies whether the key exists. If False, this will not hit the service, constructing an in-memory object. Default is True.\n:return: Key. An instance of a Key object or None"}, "tests": ["tests/unit/s3/test_key.py::TestS3Key::test_restore_completed", "tests/unit/s3/test_key.py::TestS3Key::test_when_no_restore_header_present", "tests/unit/s3/test_key.py::TestS3Key::test_change_storage_class_new_bucket", "tests/unit/s3/test_key.py::TestS3Key::test_restore_header_with_ongoing_restore", "tests/unit/s3/test_key.py::TestS3Key::test_storage_class"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.buttons.MessageLinkButton._validate_narrow_link", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [551, 551], "body_position": [556, 580], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.ui_tools.buttons.ParsedNarrowLink", "zulipterminal.model.Model.topics_in_stream"], "cross_file": []}, "requirement": {"Functionality": "This function validates a narrow link and returns either an empty string if the validation is successful or an appropriate validation error message if the validation fails. It checks various conditions related to the parsed link and returns the corresponding error message if any condition is not met.", "Arguments": ":param self: MessageLinkButton. An instance of the MessageLinkButton class.\n:param parsed_link: ParsedNarrowLink. The parsed narrow link to be validated.\n:return: str. Either an empty string for successful validation or an appropriate validation error message."}, "tests": ["tests/ui_tools/test_buttons.py::TestMessageLinkButton::test__validate_narrow_link"], "indent": 8}
{"namespace": "mrjob.job.MRJob.set_up_logging", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [652, 652], "body_position": [661, 668], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.util.log_to_null", "mrjob.util.log_to_stream"]}, "requirement": {"Functionality": "This function sets up logging when running from the command line. It should log to the 'mrjob' logger and '__main__' logger.", "Arguments": ":param cls: type. The MRJob class.\n:param quiet: bool. If True, logging is disabled. Overrides the value of `verbose`.\n:param verbose: bool. If True, the log level is set to \"DEBUG\". The default log level is \"INFO\".\n:param stream: Stream. The stream to log to. The default stream is `sys.stderr`.\n:return: No return values."}, "tests": ["tests/test_job.py::TestToolLogging::test_default_options", "tests/test_job.py::TestToolLogging::test_verbose"], "indent": 8}
{"namespace": "mingus.core.chords.augmented_triad", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/chords.py", "signature_position": [222, 222], "body_position": [229, 233], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mingus.core.intervals", "mingus.core.intervals.major_fifth", "mingus.core.intervals.major_third", "mingus.core.notes", "mingus.core.notes.augment"]}, "requirement": {"Functionality": "Build an augmented triad based on the given note.\nBuild a major third interval on the given note. Then build a major fifth interval on the given note and augment it.\n", "Arguments": ":param note: string. The root note of the triad.\n:return: list of strings. The notes that make up the augmented triad.\n"}, "tests": ["tests/unit/core/test_chords.py::test_chords::test_augmented_triad"], "indent": 4}
{"namespace": "twtxt.config.Config.discover", "type": "method", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/config.py", "signature_position": [57, 57], "body_position": [59, 60], "dependency": {"intra_class": ["twtxt.config.Config.config_dir", "twtxt.config.Config.config_name", "twtxt.config.Config.from_file"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a class method that discovers the location of the config file and tries to load it. It constructs the file path by joining the config directory and the config name of and then load the config from the constructed file path.", "Arguments": ":param cls: The class object itself.\n:return: The loaded config object."}, "tests": ["tests/test_config.py::test_create_config"], "indent": 8}
{"namespace": "alembic.operations.ops.DropTableOp.to_table", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [1350, 1352], "body_position": [1353, 1371], "dependency": {"intra_class": ["alembic.operations.ops.DropTableOp._reverse", "alembic.operations.ops.DropTableOp.comment", "alembic.operations.ops.DropTableOp.info", "alembic.operations.ops.DropTableOp.prefixes", "alembic.operations.ops.DropTableOp.schema", "alembic.operations.ops.DropTableOp.table_kw", "alembic.operations.ops.DropTableOp.table_name"], "intra_file": ["alembic.operations.ops.CreateTableOp._constraints_included", "alembic.operations.ops.CreateTableOp.columns"], "cross_file": ["alembic.operations.schemaobj", "alembic.operations.schemaobj.SchemaObjects", "alembic.operations.schemaobj.SchemaObjects.table", "alembic.runtime.migration.MigrationContext"]}, "requirement": {"Functionality": "This function converts a DropTableOp instance into a Table instance. It creates a Table object with the specified table name, columns, constraints, comment, info, prefixes, schema, and other parameters.", "Arguments": ":param self: DropTableOp. An instance of the DropTableOp class.\n:param migration_context: Optional. An instance of the MigrationContext class. Defaults to None.\n:return: Table. The created Table instance."}, "tests": ["tests/test_op.py::ObjectFromToTest::test_create_table_add_kw", "tests/test_op.py::ObjectFromToTest::test_drop_table_add_kw", "tests/test_autogen_diffs.py::OrigObjectTest::test_add_table", "tests/test_op.py::ObjectFromToTest::test_drop_table", "tests/test_autogen_diffs.py::OrigObjectTest::test_drop_table"], "indent": 8}
{"namespace": "boto.ec2.connection.EC2Connection.get_all_instance_status", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/connection.py", "signature_position": [683, 686], "body_position": [722, 737], "dependency": {"intra_class": ["boto.ec2.connection.EC2Connection.build_filter_params"], "intra_file": [], "cross_file": ["boto.connection.AWSQueryConnection.build_list_params", "boto.connection.AWSQueryConnection.get_object", "boto.ec2.instancestatus.InstanceStatusSet"]}, "requirement": {"Functionality": "This function retrieves all the instances in the user's account that are scheduled for maintenance. It allows for filtering and pagination of the results.", "Arguments": ":param self: EC2Connection. An instance of the EC2Connection class.\n:param instance_ids: List of strings. A list of instance IDs to filter the results by.\n:param max_results: Integer. The maximum number of instances to include in each response.\n:param next_token: String. A token to specify the next set of results to return.\n:param filters: Dictionary. Optional filters to limit the results. The filter names and values depend on the request being performed.\n:param dry_run: Bool. Set to True if the operation should not actually run.\n:param include_all_instances: Bool. Set to True if all instances should be returned, including non-running instances.\n:return: List. A list of instances that have maintenance scheduled."}, "tests": ["tests/unit/ec2/test_instancestatus.py::TestInstanceStatusResponseParsing::test_include_all_instances", "tests/unit/ec2/test_instancestatus.py::TestInstanceStatusResponseParsing::test_next_token"], "indent": 8}
{"namespace": "boto.ec2.address.Address.associate", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/address.py", "signature_position": [92, 92], "body_position": [97, 114], "dependency": {"intra_class": ["boto.ec2.address.Address.allocation_id", "boto.ec2.address.Address.connection", "boto.ec2.address.Address.public_ip"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.associate_address"]}, "requirement": {"Functionality": "Associate this Elastic IP address with a currently running instance. If the address has an allocation ID, it uses the allocation ID. Otherwise, it does not use the allocation ID.", "Arguments": ":param self: Address. An instance of the Address class.\n:param instance_id: String. The ID of the instance to associate the Elastic IP address with.\n:param network_interface_id: String. The ID of the network interface to associate the Elastic IP address with.\n:param private_ip_address: String. The private IP address to associate with the Elastic IP address.\n:param allow_reassociation: Bool. Whether to allow reassociation of the Elastic IP address.\n:param dry_run: Bool. Whether to perform a dry run of the association.\n:return: The result of the association operation."}, "tests": ["tests/unit/ec2/test_address.py::AddressTest::test_associate_calls_connection_associate_address_with_correct_args", "tests/unit/ec2/test_address.py::AddressWithNetworkInterfaceTest::test_associate_calls_connection_associate_address_with_correct_args", "tests/unit/ec2/test_address.py::AddressWithAllocationTest::test_associate_calls_connection_associate_address_with_correct_args"], "indent": 8}
{"namespace": "pyramid.csrf.CookieCSRFStoragePolicy.check_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [156, 156], "body_position": [158, 161], "dependency": {"intra_class": ["pyramid.csrf.CookieCSRFStoragePolicy.get_csrf_token"], "intra_file": [], "cross_file": ["pyramid.util.bytes_", "pyramid.util.strings_differ"]}, "requirement": {"Functionality": "Check if the supplied CSRF token is valid by comparing it with the expected token. It converts both tokens to bytes and checks if they are equal.", "Arguments": ":param self: CookieCSRFStoragePolicy. An instance of the CookieCSRFStoragePolicy class.\n:param request: The HTTP request object.\n:param supplied_token: The CSRF token supplied by the client.\n:return: Bool. True if the supplied token is valid, False otherwise."}, "tests": ["tests/test_csrf.py::TestCookieCSRFStoragePolicy::test_check_csrf_token"], "indent": 8}
{"namespace": "mopidy.config.types.List.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [321, 321], "body_position": [322, 335], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.types.String", "mopidy.config.types.String.__init__", "mopidy.config.types.String.serialize"], "cross_file": []}, "requirement": {"Functionality": "Serialize a list of values into a string representation. It iterates through each item in the list and serializes each item. The serialized values are then joined together with newlines and returned as a string.", "Arguments": ":param self: List. An instance of the List class.\n:param value: The list of values to be serialized.\n:param display: Bool. Whether to include additional display information in the serialization. Defaults to False.\n:return: String. The serialized representation of the list."}, "tests": ["tests/config/test_types.py::TestList::test_serialize_ignores_blanks", "tests/config/test_types.py::TestList::test_serialize_none", "tests/config/test_types.py::TestList::test_serialize_ignores_blanks_sets", "tests/config/test_types.py::TestList::test_serialize_tuples", "tests/config/test_types.py::TestList::test_serialize_sets"], "indent": 8}
{"namespace": "gunicorn.instrument.statsd.Statsd.critical", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/instrument/statsd.py", "signature_position": [44, 44], "body_position": [45, 46], "dependency": {"intra_class": ["gunicorn.instrument.statsd.Statsd.increment"], "intra_file": [], "cross_file": ["gunicorn.glogging.Logger", "gunicorn.glogging.Logger.critical"]}, "requirement": {"Functionality": "This function logs a critical message using the Logger class and then increments a counter for \"gunicorn.log.critical\" in the Statsd instance.", "Arguments": ":param self: Statsd. An instance of the Statsd class.\n:param msg: String. The message to be logged.\n:param *args: Variable length argument list. Additional arguments to be passed to the Logger.critical() method.\n:param **kwargs: Arbitrary keyword arguments. Additional keyword arguments to be passed to the Logger.critical() method.\n:return: No return values."}, "tests": ["tests/test_statsd.py::test_instrument"], "indent": 8}
{"namespace": "mrjob.local.LocalMRJobRunner._spark_master", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/local.py", "signature_position": [233, 233], "body_position": [236, 248], "dependency": {"intra_class": [], "intra_file": ["mrjob.local._DEFAULT_EXECUTOR_MEMORY", "mrjob.local._to_num_bytes"], "cross_file": ["mrjob.sim.SimMRJobRunner._num_cores"]}, "requirement": {"Functionality": "This function returns the Spark master information for running a job locally using the local-cluster mode. It calculates the number of executors, cores per executor, and executor memory based on the provided options and returns 'local-cluster[{number of executors},{cores per executor},{executor memory in MB (rounded up)}]'.", "Arguments": ":param self: LocalMRJobRunner. An instance of the LocalMRJobRunner class.\n:return: str. The Spark master URL for running a job locally using the local-cluster mode."}, "tests": ["tests/test_local.py::SparkMasterTestCase::test_default_spark_master", "tests/test_local.py::SparkMasterTestCase::test_num_cores"], "indent": 8}
{"namespace": "sqlitedict.SqliteDict.iteritems", "type": "method", "project_path": "Database/sqlitedict", "completion_path": "Database/sqlitedict/sqlitedict.py", "signature_position": [283, 283], "body_position": [284, 286], "dependency": {"intra_class": ["sqlitedict.SqliteDict.conn", "sqlitedict.SqliteDict.decode", "sqlitedict.SqliteDict.decode_key", "sqlitedict.SqliteDict.tablename"], "intra_file": ["sqlitedict.SqliteMultithread.select"], "cross_file": []}, "requirement": {"Functionality": "Iterate over all key-value pairs in the SqliteDict instance. It executes a SQL query to retrieve all key-value pairs from the table and yields each pair after decoding the key and value.", "Arguments": ":param self: SqliteDict. An instance of the SqliteDict class.\n:return: Iterator. An iterator that yields key-value pairs from the SqliteDict instance."}, "tests": ["tests/test_temp_db.py::TempSqliteDictTest::test_manage_few_records"], "indent": 8}
{"namespace": "mopidy.ext.Extension.get_config_dir", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/ext.py", "signature_position": [94, 94], "body_position": [100, 106], "dependency": {"intra_class": ["mopidy.ext.Extension.ext_name"], "intra_file": ["mopidy.ext.Config"], "cross_file": ["mopidy.internal.path.expand_path", "mopidy.internal.path.get_or_create_dir", "mopidy.internal.path"]}, "requirement": {"Functionality": "This function is a class method that gets or creates a configuration directory for the extension. It first checks if the extension name is None, and if so, raises an AssertionError. Then, it constructs the path to the configuration directory based on the Mopidy config object and the extension name. Finally, it calls a helper function to get or create the directory and returns the path.", "Arguments": ":param cls: Class. The Extension class.\n:param config: Config. The Mopidy config object.\n:return: Path. The path to the configuration directory for the extension."}, "tests": ["tests/test_ext.py::TestExtension::test_get_config_dir_raises_error"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.create_global_secondary_index", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [460, 460], "body_position": [490, 513], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.update_table", "boto.log", "boto.dynamodb2.fields.GlobalBaseIndexField.definition", "boto.dynamodb2.fields.GlobalBaseIndexField.schema", "boto"]}, "requirement": {"Functionality": "This function creates a global secondary index in DynamoDB after the table has been created. It takes a `global_index` parameter, which should be a subclass of `GlobalBaseIndexField` representing the desired index. It updates the `global_indexes` information on the `Table` by calling `Table.describe`. It returns `True` on success.", "Arguments": ":param self: Table. An instance of the Table class.\n:param global_index: GlobalBaseIndexField subclass. The desired global index to be created.\n:return: Bool. Returns `True` if the global index is created successfully, otherwise `False`."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_create_global_secondary_index"], "indent": 8}
{"namespace": "datasette.utils.asgi.Request.full_path", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/asgi.py", "signature_position": [94, 94], "body_position": [95, 96], "dependency": {"intra_class": ["datasette.utils.asgi.Request.path", "datasette.utils.asgi.Request.query_string"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the full path of a Request instance by concatenating its path and query strings. If the query exists, the output format is \"{path}?{query}\". Otherwise, the output format is \"{path}\".", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The full path of the request."}, "tests": ["tests/test_internals_request.py::test_request_properties"], "indent": 8}
{"namespace": "boto.utils.retry_url", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/utils.py", "signature_position": [205, 205], "body_position": [212, 237], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.config", "boto.log"]}, "requirement": {"Functionality": "This function retries a URL request for accessing the metadata service on an instance. It tries to open the URL using a proxy handler and returns the result after reading it.", "Arguments": ":param url: String. The URL to be accessed.\n:param retry_on_404: Bool. Whether to retry the request if a 404 error is encountered. Defaults to True.\n:param num_retries: Integer. The number of times to retry the request. Defaults to 10.\n:param timeout: Float. The timeout value for the request. Defaults to None.\n:return: String. The result of the URL request."}, "tests": ["tests/unit/utils/test_utils.py::TestRetryURL::test_retry_url_using_bytes_and_string_response", "tests/unit/utils/test_utils.py::TestRetryURL::test_retry_url_uses_proxy"], "indent": 4}
{"namespace": "boltons.formatutils.split_format_str", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/formatutils.py", "signature_position": [107, 107], "body_position": [112, 120], "dependency": {"intra_class": [], "intra_file": ["boltons.formatutils.construct_format_field_str"], "cross_file": []}, "requirement": {"Functionality": "This function performs basic splitting of a format string and returns a list of strings. It parse the format string and constructs a format field string for each parsed field. The resulting list contains tuples of literal strings and format field strings.", "Arguments": ":param fstr: String. The format string to be split.\n:return: List of tuples. Each tuple contains a literal string and a format field string."}, "tests": ["tests/test_formatutils.py::test_split_fstr"], "indent": 4}
{"namespace": "asyncssh.public_key.SSHKey.convert_to_public", "type": "method", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/public_key.py", "signature_position": [624, 624], "body_position": [634, 637], "dependency": {"intra_class": ["asyncssh.public_key.SSHKey._comment", "asyncssh.public_key.SSHKey._filename", "asyncssh.public_key.SSHKey.public_data", "asyncssh.public_key.SSHKey.set_comment", "asyncssh.public_key.SSHKey.set_filename"], "intra_file": ["asyncssh.public_key.decode_ssh_public_key"], "cross_file": []}, "requirement": {"Functionality": "This method converts an SSHKey object that contains a private key into one that contains only the corresponding public key. It first decodes asymmetric encryption. Once decrypted, it proceeds to assign a relevant comment and filename to the associated key. Upon completion of these steps, the method returns the processed data as its final output.", "Arguments": ":param self: SSHKey. An instance of the SSHKey class.\n:return: SSHKey. The SSHKey object that contains only the corresponding public key."}, "tests": ["tests/test_agent.py::_TestAgent::test_lock", "tests/test_public_key.py::_TestPublicKeyTopLevel::test_rsa_encrypt_error", "tests/test_public_key.py::_TestPublicKeyTopLevel::test_generate_errors", "tests/test_agent.py::_TestAgent::test_reconnect", "tests/test_agent.py::_TestAgent::test_sign"], "indent": 8}
{"namespace": "faker.utils.text.slugify", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/text.py", "signature_position": [11, 11], "body_position": [19, 28], "dependency": {"intra_class": [], "intra_file": ["faker.utils.text._re_pattern", "faker.utils.text._re_pattern_allow_dots", "faker.utils.text._re_spaces"], "cross_file": []}, "requirement": {"Functionality": "This function takes a string value and converts it into a slug format. It removes non-word characters, converts spaces to hyphens, and converts the string to lowercase. It can also optionally allow dots in the slug.", "Arguments": ":param value: str. The string value to be converted into a slug format.\n:param allow_dots: bool. Whether to allow dots in the slug. Defaults to False.\n:param allow_unicode: bool. Whether to allow unicode characters in the slug. Defaults to False.\n:return: str. The converted slug string."}, "tests": ["tests/test_factory.py::FactoryTestCase::test_slugify"], "indent": 4}
{"namespace": "boto.dynamodb2.items.Item.prepare_partial", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [333, 333], "body_position": [343, 367], "dependency": {"intra_class": ["boto.dynamodb2.items.Item._data", "boto.dynamodb2.items.Item._determine_alterations", "boto.dynamodb2.items.Item._dynamizer"], "intra_file": [], "cross_file": ["boto.dynamodb.types.Dynamizer.encode"]}, "requirement": {"Functionality": "This function prepares the changed or deleted fields of an Item instance to be encoded and handed off to DynamoDB for an update operation. It determines the alterations made to the fields, encodes the values, and creates a data structure with the necessary actions and values for each field.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: Tuple. A tuple containing the final data structure with actions and values for each field, and a set of fields that were altered."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_prepare_partial", "tests/unit/dynamodb2/test_table.py::ItemTestCase::test_prepare_partial_empty_set"], "indent": 8}
{"namespace": "falcon.util.misc.secure_filename", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/util/misc.py", "signature_position": [355, 355], "body_position": [386, 392], "dependency": {"intra_class": [], "intra_file": ["falcon.util.misc._UNSAFE_CHARS"], "cross_file": []}, "requirement": {"Functionality": "This function sanitizes the provided `filename` by removing any non-ASCII characters and replacing them with an underscore. Before this replacement, it normalizes the filename to the Unicode `NKFD` form to extract more alphanumerals. If the filename starts with a period, it replaces the first period with an underscore.", "Arguments": ":param filename: String. The filename to be sanitized.\n:return: String. The sanitized filename."}, "tests": ["tests/test_utils.py::TestFalconUtils::test_secure_filename", "tests/test_utils.py::TestFalconUtils::test_secure_filename_empty_value"], "indent": 4}
{"namespace": "zxcvbn.matching.sequence_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [383, 395], "body_position": [396, 441], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.RANKED_DICTIONARIES"], "cross_file": []}, "requirement": {"Functionality": "This function identifies sequences in a given password by looking for repeated differences in unicode codepoints. It checks for sequences of lowercase letters, uppercase letters, digits, and other unicode characters. It returns a list of dictionaries, each containing information about a detected sequence.", "Arguments": ":param password: String. The password to analyze for sequences.\n:param _ranked_dictionaries: List of dictionaries. A list of ranked dictionaries to use for sequence matching. Defaults to RANKED_DICTIONARIES.\n:return: List of dictionaries. A list of dictionaries containing information about detected sequences. Each dictionary includes the following keys: 'pattern', 'i', 'j', 'token', 'sequence_name', 'sequence_space', 'ascending'."}, "tests": ["tests/matching_test.py::test_sequence_matching"], "indent": 4}
{"namespace": "ydata_profiling.model.pandas.correlations_pandas.pandas_auto_compute", "type": "function", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/model/pandas/correlations_pandas.py", "signature_position": [161, 163], "body_position": [164, 214], "dependency": {"intra_class": [], "intra_file": ["ydata_profiling.model.pandas.correlations_pandas._pairwise_cramers", "ydata_profiling.model.pandas.correlations_pandas._pairwise_spearman", "ydata_profiling.model.pandas.discretize_pandas.DiscretizationType.UNIFORM"], "cross_file": ["ydata_profiling.config.Settings", "ydata_profiling.config.Settings.categorical_maximum_correlation_distinct", "ydata_profiling.config.Settings.correlations", "ydata_profiling.model.pandas.discretize_pandas.DiscretizationType", "ydata_profiling.model.pandas.discretize_pandas.Discretizer", "ydata_profiling.model.pandas.discretize_pandas.Discretizer.discretize_dataframe"]}, "requirement": {"Functionality": "This function performs automatic computation of correlations between columns in a pandas DataFrame. It first identifies the numerical and categorical columns based on the summary dictionary. Then, it discretizes the DataFrame using a uniform discretization method. Next, it calculates the correlation scores between each pair of columns using either the pairwise Spearman correlation or the pairwise Cramers' V, depending on the column types. Finally, it returns a correlation matrix.", "Arguments": ":param config: Settings. An instance of the Settings class that contains configuration parameters.\n:param df: pd.DataFrame. The input DataFrame.\n:param summary: dict. A dictionary that summarizes the properties of each column in the DataFrame.\n:return: Optional[pd.DataFrame]. The correlation matrix if there are more than one numerical or categorical columns, otherwise None."}, "tests": ["tests/unit/test_pandas/test_correlations.py::test_numeric_auto_equals_spearman", "tests/unit/test_pandas/test_correlations.py::test_categorical_auto_equals_equals_cramers"], "indent": 4}
{"namespace": "alembic.testing.fixtures.capture_db", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/fixtures.py", "signature_position": [73, 73], "body_position": [74, 81], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.util.sqla_compat.create_mock_engine"]}, "requirement": {"Functionality": "This function creates a mock database engine and a buffer to capture the SQL statements executed on the engine. It returns the engine and the buffer.", "Arguments": ":param dialect: String. The dialect of the database engine to be created. It defaults to \"postgresql://\" if not specified.\n:return: Tuple. The created mock database engine and the buffer to capture SQL statements."}, "tests": ["tests/test_config.py::ConfigTest::test_standalone_op"], "indent": 4}
{"namespace": "boltons.tableutils.Table.__repr__", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tableutils.py", "signature_position": [437, 437], "body_position": [438, 442], "dependency": {"intra_class": ["boltons.tableutils.Table._data", "boltons.tableutils.Table.headers"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the Table object. If the Table object has headers, it includes the headers and data in the string: '{type name}(headers={headers!r}, data={data!r})'. If the Table object does not have headers, it only includes the data in the string: '{type name}({data!r})'.", "Arguments": ":param self: Table. An instance of the Table class.\n:return: String. The string representation of the Table object."}, "tests": ["tests/test_tableutils.py::test_table_lists"], "indent": 8}
{"namespace": "playhouse.signals.Signal.connect", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/signals.py", "signature_position": [15, 15], "body_position": [16, 23], "dependency": {"intra_class": ["playhouse.signals.Signal._receiver_list", "playhouse.signals.Signal._receivers"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Connect a receiver function to a signal. It adds the receiver function to the list of receivers for the signal, along with the name and sender (if specified). If a receiver with the same name and sender already exists, it raises a ValueError.", "Arguments": ":param self: Signal. An instance of the Signal class.\n:param receiver: The function to be connected as a receiver.\n:param name: String. The name of the receiver. If not specified, it defaults to the name of the receiver function. Defaults to None.\n:param sender: Any. The sender object. If specified, the receiver will only be called when the signal is emitted by this sender. Defaults to None.\n:return: No return values."}, "tests": ["tests/signals.py::TestSignals::test_connect_disconnect"], "indent": 8}
{"namespace": "boto.cloudhsm.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudhsm/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudhsm.layer1.CloudHSMConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CloudHSMConnection class. It creates a connection with the specified parameters and returns the CloudHSMConnection object.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: CloudHSMConnection. The connection object for the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestConnectCloudHsm::test_connect_to_region"], "indent": 4}
{"namespace": "mssqlcli.packages.prioritization.PrevalenceCounter.update", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/packages/prioritization.py", "signature_position": [29, 29], "body_position": [30, 31], "dependency": {"intra_class": ["mssqlcli.packages.prioritization.PrevalenceCounter.update_keywords", "mssqlcli.packages.prioritization.PrevalenceCounter.update_names"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Update the PrevalenceCounter instance by updating the keywords and names based on the input text.", "Arguments": ":param self: PrevalenceCounter. An instance of the PrevalenceCounter class.\n:param text: String. The input text used to update the keywords and names.\n:return: No return values."}, "tests": ["tests/test_prioritization.py::PrioritizationTests::test_prevalence_counter"], "indent": 8}
{"namespace": "googleapiclient.channel.notification_from_headers", "type": "function", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/channel.py", "signature_position": [251, 251], "body_position": [267, 279], "dependency": {"intra_class": [], "intra_file": ["googleapiclient.errors", "googleapiclient.channel.Channel.id", "googleapiclient.channel.Notification", "googleapiclient.channel.Notification.__init__", "googleapiclient.channel.X_GOOG_CHANNEL_ID", "googleapiclient.channel.X_GOOG_MESSAGE_NUMBER", "googleapiclient.channel.X_GOOG_RESOURCE_ID", "googleapiclient.channel.X_GOOG_RESOURCE_STATE", "googleapiclient.channel.X_GOOG_RESOURCE_URI", "googleapiclient.channel._upper_header_keys"], "cross_file": ["googleapiclient.errors.InvalidNotificationError"]}, "requirement": {"Functionality": "This function parses a notification from the webhook request headers, validates the notification, and returns a Notification object. It will raise invalid notification error if the notification is invalid.", "Arguments": ":param channel: Channel. The channel that the notification is associated with.\n:param headers: dict. A dictionary-like object that contains the request headers from the webhook HTTP request.\n:return: Notification. A Notification object."}, "tests": ["tests/test_channel.py::TestNotification::test_notification_from_headers"], "indent": 4}
{"namespace": "sacred.dependencies.Source.to_json", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/dependencies.py", "signature_position": [463, 463], "body_position": [464, 470], "dependency": {"intra_class": ["sacred.dependencies.Source.digest", "sacred.dependencies.Source.filename"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Convert the Source instance to a JSON-compatible format. If the base directory is provided, it returns the relative path of the filename with respect to the base directory and the digest. Otherwise, it returns the filename and the digest.", "Arguments": ":param self: Source. An instance of the Source class.\n:param base_dir: String. The base directory path. Defaults to None.\n:return: Tuple. If base_dir is provided, it returns a tuple containing the relative path of the filename and the digest. Otherwise, it returns a tuple containing the filename and the digest."}, "tests": ["tests/test_dependencies.py::test_source_to_json"], "indent": 8}
{"namespace": "boto.beanstalk.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/beanstalk/__init__.py", "signature_position": [41, 41], "body_position": [42, 45], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.beanstalk.layer1.Layer1", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the Elastic Beanstalk service using the provided region name and additional keyword parameters. It creates a Layer1 instance and establishes a connection to the specified region.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword parameters that can be passed to the connect function.\n:return: Connection. The connection object established with the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestConnectBeanstalk::test_connect_to_region"], "indent": 4}
{"namespace": "alembic.autogenerate.render._render_check_constraint", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/render.py", "signature_position": [1032, 1036], "body_position": [1037, 1069], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.render._render_gen_name", "alembic.autogenerate.render._render_potential_expr", "alembic.autogenerate.render._sqlalchemy_autogenerate_prefix", "alembic.autogenerate.render._user_defined_render"], "cross_file": ["alembic.autogenerate.api.AutogenContext"]}, "requirement": {"Functionality": "This function renders a check constraint in a specific format. It first tries to render the constraint using a user-defined rendering function. If that fails, it checks if the constraint is part of a parent type already present in the table. If it is, it returns None. Otherwise, it constructs a string representation of the check constraint with optional parameters.", "Arguments": ":param constraint: CheckConstraint. The check constraint to render.\n:param autogen_context: AutogenContext. The autogen context.\n:param namespace_metadata: Optional[MetaData]. The metadata of the namespace.\n:return: Optional[str]. The rendered check constraint string, or None if the constraint is part of a parent type."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_render_check_constraint_literal", "tests/test_autogen_render.py::RenderNamingConventionTest::test_render_check_constraint_renamed", "tests/test_autogen_render.py::AutogenRenderTest::test_render_check_constraint_literal_binds", "tests/test_autogen_render.py::AutogenRenderTest::test_render_check_constraint_sqlexpr"], "indent": 4}
{"namespace": "rows.fields.DateField.deserialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [367, 367], "body_position": [368, 375], "dependency": {"intra_class": ["rows.fields.DateField.INPUT_FORMAT", "rows.fields.DateField.TYPE"], "intra_file": ["rows.fields.Field", "rows.fields.Field.deserialize", "rows.fields.as_string"], "cross_file": []}, "requirement": {"Functionality": "Deserialize a value into a date instance. It first calls the parent class's deserialize method to convert the value into a date object. Then, it checks if the value is already None or an instance of allowed type in DateField class. If so, it returns the value as is. Otherwise, it converts the value into a string, and parse the string value into a datetime object and creates a new date object using the year, month, and day attributes of the datetime object.", "Arguments": ":param cls: Class. The DateField class.\n:param value: Object. The value to be deserialized into a DateField instance.\n:param args: Object. Additional positional arguments.\n:param kwargs: Object. Additional keyword arguments.\n:return: date. The deserialized date instance."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_DateField"], "indent": 8}
{"namespace": "sacred.utils.rel_path", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [529, 529], "body_position": [531, 534], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.is_prefix"], "cross_file": []}, "requirement": {"Functionality": "This function returns the relative path of a given path with respect to a base path. It checks if the base path is a prefix of the given path and returns the relative path by removing the base path from the given path. Otherwise, it raises a assert error message - \"{base} not a prefix of {path}\".", "Arguments": ":param base: String. The base path.\n:param path: String. The path for which the relative path needs to be calculated.\n:return: String. The relative path of the given path with respect to the base path."}, "tests": ["tests/test_utils.py::test_rel_path"], "indent": 4}
{"namespace": "pyramid.config.assets.PackageOverrides.filtered_sources", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/assets.py", "signature_position": [119, 119], "body_position": [120, 123], "dependency": {"intra_class": ["pyramid.config.assets.PackageOverrides.overrides"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function iterates over the overrides in the PackageOverrides instance and yields the filtered sources based on the given resource name. It will yield all possible resources based on different overrides.", "Arguments": ":param self: PackageOverrides. An instance of the PackageOverrides class.\n:param resource_name: str. The name of the resource to filter the sources.\n:return: Generator. Yields the filtered sources based on the given resource name."}, "tests": ["tests/test_config/test_assets.py::TestPackageOverrides::test_filtered_sources"], "indent": 8}
{"namespace": "chatette.cli.terminal_writer.TerminalWriter.write", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/cli/terminal_writer.py", "signature_position": [61, 61], "body_position": [62, 70], "dependency": {"intra_class": ["chatette.cli.terminal_writer.TerminalWriter._file_mode", "chatette.cli.terminal_writer.TerminalWriter.buffered_text", "chatette.cli.terminal_writer.TerminalWriter.redirection_file_path"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function writes the given text to the terminal. If a redirection file path is not specified and the file mode is not set to \"quiet\", it prints the text to the terminal. If the file mode is set to \"quiet\", it does nothing. If a redirection file path is specified, it buffers the text and appends it to the existing buffered text.", "Arguments": ":param self: TerminalWriter. An instance of the TerminalWriter class.\n:param text: String. The text to be written to the terminal.\n:return: No return values."}, "tests": ["tests/unit-testing/cli/test_terminal_writer.py::TestWrite::test_print", "tests/unit-testing/cli/test_terminal_writer.py::TestWrite::test_not_quiet"], "indent": 8}
{"namespace": "mopidy.config.types.Hostname.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [385, 385], "body_position": [386, 401], "dependency": {"intra_class": ["mopidy.config.types.Hostname._required"], "intra_file": ["mopidy.config.types.Path", "mopidy.config.types.Path.__init__", "mopidy.config.types.Path.deserialize", "mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_required", "mopidy.internal.path.get_unix_socket_path", "mopidy.config.validators", "mopidy.internal.path"]}, "requirement": {"Functionality": "This function deserializes a value and validates it to ensure it is a valid hostname or IP address. It first decodes the value and removes any leading or trailing whitespace. Then, it checks if the value is required and validates it accordingly. If the value is empty, it returns None. If the value is a valid Unix socket path, it converts it to a string representation and returns it. If the value is a valid hostname or IP address, it returns the value as is. Otherwise, it raises a ValueError.", "Arguments": ":param self: Hostname. An instance of the Hostname class.\n:param value: The value to deserialize and validate.\n:param display: Bool. Whether to display the value. Defaults to False.\n:return: The deserialized and validated value."}, "tests": ["tests/config/test_types.py::TestHostname::test_deserialize_with_unix_socket", "tests/config/test_types.py::TestHostname::test_deserialize_enforces_required", "tests/config/test_types.py::TestHostname::test_deserialize_conversion_failure", "tests/config/test_types.py::TestHostname::test_deserialize_conversion_success"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.NdarrayContainer.to_payload", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [275, 280], "body_position": [281, 306], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.Payload", "bentoml._internal.runner.container.np"], "cross_file": ["bentoml._internal.external_typing.NpNDArray", "bentoml._internal.utils.pickle.pep574_dumps", "bentoml._internal.external_typing", "bentoml._internal.runner.container.DataContainer.create_payload"]}, "requirement": {"Functionality": "This function converts a numpy ndarray into a Payload object. It first checks if the ndarray is not 0-dimensional. If it is not, it ensures that the ndarray is either C-contiguous or F-contiguous. Then, it converts the ndarray into a byte string using the dump function with PEP 574 support. The byte string is then encoded using base64 and stored in the \"pickle_bytes_str\" field of the Payload object. If the ndarray is 0-dimensional, it directly converts the ndarray into a byte string using the pickle.dumps function and stores it in the \"pickle_bytes_str\" field of the Payload object.", "Arguments": ":param cls: Class. The class itself.\n:param batch: NpNDArray. The numpy ndarray to be converted into a Payload object.\n:param batch_dim: Int. The dimension along which the ndarray will be split.\n:return: Payload. The created Payload object."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_ndarray_container"], "indent": 8}
{"namespace": "boto.opsworks.regions", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/opsworks/__init__.py", "signature_position": [27, 27], "body_position": [34, 36], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.opsworks.layer1.OpsWorksConnection", "boto.regioninfo.get_regions"]}, "requirement": {"Functionality": "This function retrieves all available regions for the Amazon OpsWorks service.", "Arguments": ":param: No input parameters.\n:return: List. A list of `boto.regioninfo.RegionInfo` objects representing the available regions for the Amazon OpsWorks service."}, "tests": ["tests/integration/opsworks/test_layer1.py::TestOpsWorksHelpers::test_regions"], "indent": 4}
{"namespace": "praw.exceptions.RedditErrorItem.__repr__", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/exceptions.py", "signature_position": [62, 62], "body_position": [64, 67], "dependency": {"intra_class": ["praw.exceptions.RedditErrorItem.error_type", "praw.exceptions.RedditErrorItem.field", "praw.exceptions.RedditErrorItem.message"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the RedditErrorItem instance. It includes the error type, message, and field of the instance like \"{class name}(error_type={error type}, message={message}, field={field})\".", "Arguments": ":param self: RedditErrorItem. An instance of the RedditErrorItem class.\n:return: str. The string representation of the RedditErrorItem instance."}, "tests": ["tests/unit/test_exceptions.py::TestRedditErrorItem::test_repr"], "indent": 8}
{"namespace": "praw.util.token_manager.SQLiteTokenManager._get", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/util/token_manager.py", "signature_position": [138, 138], "body_position": [139, 145], "dependency": {"intra_class": ["praw.util.token_manager.SQLiteTokenManager._connection", "praw.util.token_manager.SQLiteTokenManager.key"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the refresh token from the SQLite database based on the provided key. It executes a SQL query to fetch the refresh token from the \"tokens\" table using the given key. If the result is None, it raises a KeyError. Otherwise, it returns the first refresh token.", "Arguments": ":param self: SQLiteTokenManager. An instance of the SQLiteTokenManager class.\n:return: String. The refresh token retrieved from the database."}, "tests": ["tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_register", "tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_post_refresh_token_callback__sets_value", "tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_post_refresh_token_callback__updates_value"], "indent": 8}
{"namespace": "bplustree.memory.FileMemory.get_metadata", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [205, 205], "body_position": [206, 233], "dependency": {"intra_class": ["bplustree.memory.FileMemory._read_page", "bplustree.memory.FileMemory._tree_conf"], "intra_file": ["bplustree.memory.ReachedEndOfFile"], "cross_file": ["bplustree.serializer", "bplustree.const.ENDIAN", "bplustree.const.OTHERS_BYTES", "bplustree.const.PAGE_REFERENCE_BYTES", "bplustree.const.TreeConf"]}, "requirement": {"Functionality": "This function retrieves the metadata of a FileMemory instance. It reads the first page of the file and extracts the root node page, page size, order, key size, and value size. It then creates a TreeConf object with the extracted values and returns the root node page and the TreeConf object.", "Arguments": ":param self: FileMemory. An instance of the FileMemory class.\n:return: tuple. A tuple containing the root node page and the TreeConf object."}, "tests": ["tests/test_memory.py::test_file_memory_metadata"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage.sections", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [924, 924], "body_position": [930, 932], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch", "wikipediaapi.WikipediaPage._section"], "intra_file": ["wikipediaapi.WikipediaPageSection"], "cross_file": []}, "requirement": {"Functionality": "This function returns all sections of the current Wikipedia page. It first checks if the sections have been fetched. If not, it fetches that. Then, it returns the list of WikipediaPageSection objects representing each section.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: List of WikipediaPageSection. The list of all sections of the current Wikipedia page."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_section_count", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_top_level_section_titles", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_section_count", "tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_top_level_section_titles"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_only.rarest_window_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_only.py", "signature_position": [281, 290], "body_position": [324, 339], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_only.compute_likelihood_windows_in_session"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix"]}, "requirement": {"Functionality": "This function finds the rarest window in a given session and computes the likelihood of that window. It calculates the likelihoods of all sliding windows in the session.", "Arguments": ":param session: List[str]. A list of commands (strings) representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands (length 2).\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, the `start_token` and `end_token` will be added to the beginning and end of the session respectively before the calculations are done.\n:param start_token: str. A dummy command to signify the start of the session.\n:param end_token: str. A dummy command to signify the end of the session.\n:param use_geo_mean: bool. If True, each of the likelihoods of the sliding windows will be raised to the power of (1/`window_len`).\n:return: Tuple[List[str], float]. The rarest window part of the session and the likelihood of that window."}, "tests": ["tests/analysis/test_anom_seq_cmds_only.py::TestCmdsOnly::test_rarest_window_session"], "indent": 4}
{"namespace": "hl7.datatypes._UTCOffset.tzname", "type": "method", "project_path": "Communications/hl7", "completion_path": "Communications/hl7/hl7/datatypes.py", "signature_position": [19, 19], "body_position": [20, 23], "dependency": {"intra_class": ["hl7.datatypes._UTCOffset.minutes"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the time zone name for a given datetime object based on the UTC offset. It calculates the UTC offset in minutes and formats it as a string in the format \"+/-HHMM\".", "Arguments": ":param self: _UTCOffset. An instance of the _UTCOffset class.\n:param dt: datetime. The datetime object for which the time zone name is to be determined.\n:return: String. The time zone name in the format \"+/-HHMM\"."}, "tests": ["tests/test_datetime.py::DatetimeTest::test_tz"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.select_folder", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [802, 802], "body_position": [820, 821], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._command_and_check", "imapclient.imapclient.IMAPClient._imap", "imapclient.imapclient.IMAPClient._normalise_folder", "imapclient.imapclient.IMAPClient._process_select_response"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets the current folder on the server for the IMAPClient instance. It allows future calls to methods such as search and fetch to act on the selected folder.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param folder: String. The name of the folder to select on the server.\n:param readonly: Bool. Whether to open the folder in read-only mode. Defaults to False.\n:return: Dictionary. A dictionary containing the response from the server after selecting the folder. The keys \"EXISTS\", \"FLAGS\", and \"RECENT\" are guaranteed to exist in the dictionary."}, "tests": ["tests/test_imapclient.py::TestSelectFolder::test_normal"], "indent": 8}
{"namespace": "alembic.operations.ops.CreateTableOp.from_table", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [1177, 1179], "body_position": [1180, 1199], "dependency": {"intra_class": ["alembic.operations.ops.CreateTableOp.__init__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a CreateTableOp instance based on the given table. It takes the table name, columns, schema, metadata, constraints, comment, info, prefixes, and other parameters from the table object and constructs a CreateTableOp instance with these parameters.", "Arguments": ":param cls: Class. The class of the CreateTableOp instance.\n:param table: Table. The table object from which the parameters are extracted.\n:param _namespace_metadata: Optional MetaData. The metadata to be used for the CreateTableOp instance. If not specified, the metadata from the table object is used.\n:return: CreateTableOp. The created CreateTableOp instance."}, "tests": ["tests/test_postgresql.py::PostgresqlAutogenRenderTest::test_inline_exclude_constraint_literal_column", "tests/test_autogen_render.py::AutogenRenderTest::test_render_table_w_prefixes_schema", "tests/test_autogen_render.py::AutogenRenderTest::test_render_addtl_args", "tests/test_autogen_render.py::AutogenRenderTest::test_render_table_w_system", "tests/test_autogen_render.py::AutogenRenderTest::test_render_table_w_metadata_schema"], "indent": 8}
{"namespace": "mingus.containers.bar.Bar.determine_chords", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/bar.py", "signature_position": [188, 188], "body_position": [190, 193], "dependency": {"intra_class": ["mingus.containers.bar.Bar.bar"], "intra_file": [], "cross_file": ["mingus.containers.note_container.NoteContainer.determine"]}, "requirement": {"Functionality": "This function returns possible chord for each place in the bar.\n", "Arguments": ":param shorthand: bool. Whether or not to use shorthand notation when determining the chords. Defaults to False if not specified.\n:return: List of lists. Each inner list contains the place in the beat and the possible chords for that position in the bar.\n"}, "tests": ["tests/unit/containers/test_bar.py::test_Bar::test_determine_chords"], "indent": 8}
{"namespace": "capirca.aclgen.EntryPoint", "type": "function", "project_path": "Security/capirca", "completion_path": "Security/capirca/capirca/aclgen.py", "signature_position": [694, 694], "body_position": [696, 697], "dependency": {"intra_class": [], "intra_file": ["capirca.aclgen.SetupFlags", "capirca.aclgen.main"], "cross_file": []}, "requirement": {"Functionality": "This function serves as the entry point of the program. It reads in the flags and calls the main function to start the program.", "Arguments": ":param: No input parameters.\n:return: No return values."}, "tests": ["tests/integration/aclgen_test.py::TestAclGenDemo::test_entry_point"], "indent": 2}
{"namespace": "rest_framework.exceptions.server_error", "type": "function", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/exceptions.py", "signature_position": [249, 249], "body_position": [253, 256], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["rest_framework.status", "rest_framework.status.HTTP_500_INTERNAL_SERVER_ERROR"]}, "requirement": {"Functionality": "This function is a generic error handler for server errors. It creates a dictionary with an error message and returns it as a JSON response with a status code of 500.", "Arguments": ":param request: The HTTP request object.\n:param *args: Variable length argument list.\n:param **kwargs: Arbitrary keyword arguments.\n:return: JsonResponse. A JSON response containing the error message and a status code of 500."}, "tests": ["tests/test_exceptions.py::test_server_error"], "indent": 4}
{"namespace": "boto.swf.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/swf/__init__.py", "signature_position": [43, 43], "body_position": [44, 46], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.regioninfo.connect", "boto.swf", "boto.swf.layer1", "boto.swf.layer1.Layer1"]}, "requirement": {"Functionality": "Connect to a specific region in the AWS Simple Workflow Service (SWF). It creates a connection to the SWF service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: Connection. The connection object to the SWF service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestSwfConnection::test_connect_to_region"], "indent": 4}
{"namespace": "falcon.request.Request.uri", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [775, 775], "body_position": [776, 784], "dependency": {"intra_class": ["falcon.request.Request._cached_uri", "falcon.request.Request.netloc", "falcon.request.Request.relative_uri", "falcon.request.Request.scheme"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the URI of a Request instance. If the URI is not cached, it concatenates the scheme, netloc, and relative uri to form the URI and caches it for future use. The output format is \"{scheme}://{netloc}{relative uri}\".", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The URI of the Request instance."}, "tests": ["tests/test_request_forwarded.py::test_no_forwarded_headers_with_port", "tests/test_request_forwarded.py::test_no_forwarded_headers", "tests/test_request_attrs.py::TestRequestAttributes::test_reconstruct_url", "tests/test_request_attrs.py::TestRequestAttributes::test_uri_https", "tests/test_request_attrs.py::TestRequestAttributes::test_uri"], "indent": 8}
{"namespace": "mrjob.parse.is_s3_uri", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [43, 43], "body_position": [45, 49], "dependency": {"intra_class": [], "intra_file": ["mrjob.parse.parse_s3_uri"], "cross_file": []}, "requirement": {"Functionality": "This function checks whether a given URI can be parsed into an S3 URI and returns True if it can, otherwise it returns False.\nThis function uses a try-except block to handle any ValueError that may occur when trying to parse the URI.\n", "Arguments": ":param uri: String. The URI to be checked if it can be parsed into an S3 URI.\n:return: Boolean. True if the URI can be parsed into an S3 URI, False otherwise.\n"}, "tests": ["tests/test_parse.py::URITestCase::test_is_s3_uri"], "indent": 4}
{"namespace": "pycoin.message.PeerAddress.ip_bin_to_ip4_addr", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/message/PeerAddress.py", "signature_position": [16, 16], "body_position": [17, 18], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pycoin.intbytes.iterbytes"]}, "requirement": {"Functionality": "Convert a binary representation of an IPv4 address to a string representation. It takes the last 4 bytes of the binary representation and converts them to decimal values separated by periods.", "Arguments": ":param ip_bin: bytes. The binary representation of the IPv4 address.\n:return: str. The string representation of the IPv4 address."}, "tests": ["tests/message_test.py::MessageTest::test_ipv4"], "indent": 4}
{"namespace": "mingus.containers.bar.Bar.get_range", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/bar.py", "signature_position": [151, 151], "body_position": [153, 160], "dependency": {"intra_class": ["mingus.containers.bar.Bar.bar"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates and returns the highest and lowest notes from a list of notes.\n", "Arguments": ":param self: Bar, an instance of the Bar class.\n:return: tuple of ints. A tuple containing the highest and lowest notes.\n"}, "tests": ["tests/unit/containers/test_bar.py::test_Bar::test_get_range"], "indent": 8}
{"namespace": "datasette.utils.parse_metadata", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [977, 977], "body_position": [980, 986], "dependency": {"intra_class": [], "intra_file": ["datasette.utils.BadMetadataError"], "cross_file": []}, "requirement": {"Functionality": "This function takes a string as input and detects if the content is in JSON or YAML format. It then parses the content accordingly and returns a dictionary.", "Arguments": ":param content: str. The content to be parsed, which can be in JSON or YAML format.\n:return: dict. The parsed content as a dictionary."}, "tests": ["tests/test_utils.py::test_parse_metadata"], "indent": 4}
{"namespace": "rest_framework.fields.ChoiceField.iter_options", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [1390, 1390], "body_position": [1394, 1398], "dependency": {"intra_class": ["rest_framework.fields.ChoiceField.grouped_choices", "rest_framework.fields.ChoiceField.html_cutoff", "rest_framework.fields.ChoiceField.html_cutoff_text", "rest_framework.fields.ChoiceField.iter_options"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a helper method used for rendering select widgets in templates. It returns an iterator of options based on the grouped choices, cutoff value, and cutoff text.", "Arguments": ":param self: ChoiceField. An instance of the ChoiceField class.\n:return: Iterator. An iterator of options for rendering select widgets."}, "tests": ["tests/test_fields.py::TestChoiceField::test_iter_options"], "indent": 8}
{"namespace": "trailscraper.iam.parse_policy_document", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/iam.py", "signature_position": [163, 163], "body_position": [165, 170], "dependency": {"intra_class": [], "intra_file": ["trailscraper.iam.PolicyDocument", "trailscraper.iam.PolicyDocument.__init__", "trailscraper.iam._parse_statements"], "cross_file": []}, "requirement": {"Functionality": "This function takes a stream of JSON data and parses it into a PolicyDocument object. It first checks if the stream is a string, and if so, it loads the JSON data into a dictionary. Otherwise, it loads the JSON data as file stream. Finally, it creates a PolicyDocument object using the parsed statements and version from the JSON dictionary.", "Arguments": ":param stream: The input stream of JSON data.\n:return: PolicyDocument. The parsed PolicyDocument object."}, "tests": ["tests/integration/cli_guess_test.py::test_should_guess_all_matching_statements", "tests/iam/policy_document_test.py::test_json_parses_to_policy_document", "tests/integration/cli_guess_test.py::test_should_guess_only_specific_actions_and_fix_upper_lowercase"], "indent": 4}
{"namespace": "sacred.config.config_files.load_config_file", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/config_files.py", "signature_position": [59, 59], "body_position": [60, 62], "dependency": {"intra_class": [], "intra_file": ["sacred.config.config_files.Handler.load", "sacred.config.config_files.Handler.mode", "sacred.config.config_files.get_handler"], "cross_file": []}, "requirement": {"Functionality": "Load a configuration file by getting the appropriate handler based on the file extension, opening the file, and using the handler to load the configuration data.", "Arguments": ":param filename: str. The name of the configuration file to load.\n:return: The loaded configuration data."}, "tests": ["tests/test_config/test_config_files.py::test_load_config_file_exception_msg_invalid_ext", "tests/test_config/test_config_files.py::test_load_config_file"], "indent": 4}
{"namespace": "mopidy.config.types.Boolean.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [202, 202], "body_position": [203, 211], "dependency": {"intra_class": ["mopidy.config.types.Boolean._required", "mopidy.config.types.Boolean.false_values", "mopidy.config.types.Boolean.true_values"], "intra_file": ["mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_required", "mopidy.config.validators"]}, "requirement": {"Functionality": "Deserialize a boolean value from a serialized string representation. It decodes the input value, validates if it is required, and then checks if it matches any of the true or false values. If it doesn't match any, it raises a ValueError.", "Arguments": ":param self: Boolean. An instance of the Boolean class.\n:param value: String. The serialized string representation of the boolean value.\n:return: Bool. The deserialized boolean value."}, "tests": ["tests/config/test_types.py::TestBoolean::test_deserialize_conversion_failure", "tests/config/test_types.py::TestBoolean::test_deserialize_conversion_success", "tests/config/test_types.py::TestBoolean::test_deserialize_enforces_required"], "indent": 8}
{"namespace": "googleapiclient.channel.new_webhook_channel", "type": "function", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/channel.py", "signature_position": [283, 283], "body_position": [300, 316], "dependency": {"intra_class": [], "intra_file": ["googleapiclient.channel.Channel", "googleapiclient.channel.Channel.__init__", "googleapiclient.channel.EPOCH"], "cross_file": []}, "requirement": {"Functionality": "This function creates a new webhook Channel instance with the given parameters. It calculates the expiration time in milliseconds and creates the Channel instance with the calculated expiration time and other input parameters, and the type of the instance is \"web_hook\".", "Arguments": ":param url: str. The URL to post notifications to.\n:param token: str. An arbitrary string associated with the channel that is delivered to the target address with each notification delivered over this channel.\n:param expiration: datetime.datetime. A time in the future when the channel should expire. Can also be None if the subscription should use the default expiration.\n:param params: dict. Extra parameters to pass on channel creation. Currently not used for webhook channels.\n:return: Channel. The created webhook Channel instance."}, "tests": ["tests/test_channel.py::TestChannel::test_new_webhook_channel"], "indent": 4}
{"namespace": "kinto.core.utils.dict_merge", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [187, 187], "body_position": [189, 194], "dependency": {"intra_class": [], "intra_file": ["kinto.core.utils.dict_merge"], "cross_file": []}, "requirement": {"Functionality": "Merge two dictionaries together. It creates a new dictionary by merging the key-value pairs from both input dictionaries. If a key exists in both dictionaries and the value is a Mapping, it recursively merges the nested dictionaries.", "Arguments": ":param a: Dictionary. The first dictionary to merge.\n:param b: Dictionary. The second dictionary to merge.\n:return: Dictionary. The merged dictionary."}, "tests": ["tests/core/test_utils.py::DictMergeTest::test_merge"], "indent": 4}
{"namespace": "kinto.core.resource.Resource.timestamp", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/resource/__init__.py", "signature_position": [233, 233], "body_position": [238, 250], "dependency": {"intra_class": ["kinto.core.resource.Resource.model"], "intra_file": ["kinto.core.resource.logger"], "cross_file": ["kinto.core.resource.model.Model.timestamp", "kinto.core.errors.ERRORS", "kinto.core.errors.ERRORS.BACKEND", "kinto.core.errors.http_error", "kinto.core.storage.exceptions", "kinto.core.storage.exceptions.ReadonlyError"]}, "requirement": {"Functionality": "This function returns the current timestamp of a resource. It first tries to get the timestamp from the model associated with the resource. If fails it raises an read only error exception and save the error information into http error, raise a JSON formated response matching the error HTTP API.", "Arguments": ":param self: Resource. An instance of the Resource class.\n:return: int. The current timestamp of the resource."}, "tests": ["tests/core/resource/test_preconditions.py::NotModifiedTest::test_single_object_last_modified_is_returned"], "indent": 8}
{"namespace": "sacred.config.custom_containers.make_read_only", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/custom_containers.py", "signature_position": [220, 220], "body_position": [227, 234], "dependency": {"intra_class": [], "intra_file": ["sacred.config.custom_containers.ReadOnlyDict", "sacred.config.custom_containers.ReadOnlyDict.__init__", "sacred.config.custom_containers.ReadOnlyList", "sacred.config.custom_containers.ReadOnlyList.__init__", "sacred.config.custom_containers.make_read_only"], "cross_file": []}, "requirement": {"Functionality": "This function takes an object and converts every list and dict into its read-only counterpart in a nested structure of lists, dicts, and tuples. It does not modify the original object but returns the converted structure.", "Arguments": ":param o: Any data type. The object to be made read-only.\n:return: Any data type. The converted read-only structure."}, "tests": ["tests/test_config/test_readonly_containers.py::test_copy_on_nested_readonly_dict_still_list", "tests/test_config/test_readonly_containers.py::test_copy_on_readonly_dict", "tests/test_config/test_readonly_containers.py::test_deepcopy_on_nested_readonly_dict_can_be_mutated", "tests/test_config/test_readonly_containers.py::test_deepcopy_on_nested_readonly_list", "tests/test_config/test_readonly_containers.py::test_nested_readonly_containers"], "indent": 4}
{"namespace": "gunicorn.config.Config.address", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [127, 127], "body_position": [128, 129], "dependency": {"intra_class": ["gunicorn.config.Config.settings"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the bind address from settings and returns a list of parsed addresses.", "Arguments": ":param self: Config. An instance of the Config class.\n:return: List of addresses. The parsed addresses from settings."}, "tests": ["tests/test_config.py::test_property_access"], "indent": 8}
{"namespace": "wikipediaapi.WikipediaPage._fetch", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [1062, 1062], "body_position": [1064, 1066], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage.wiki"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function fetches some data from the Wikipedia API based on the given call. It calls the specified method on the `wiki` object with the current instance of `WikipediaPage` as an argument. It also updates a dictionary to indicate which methods have been called.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:param call: String. The name of the method to be called on the `wiki` object.\n:return: WikipediaPage. The current instance of WikipediaPage."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_title_after_fetching", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_title_after_fetching"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.LibtoolPrerequisite.darwin_installer", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [331, 331], "body_position": [332, 333], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pythonforandroid.logger.info"]}, "requirement": {"Functionality": "This function installs Libtool on a macOS system using the Homebrew package manager.", "Arguments": ":param self: LibtoolPrerequisite. An instance of the LibtoolPrerequisite class.\n:return: No return values."}, "tests": ["tests/test_prerequisites.py::TestLibtoolPrerequisite::test_darwin_installer"], "indent": 8}
{"namespace": "diffprivlib.models.linear_regression.LinearRegression.fit", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/linear_regression.py", "signature_position": [240, 240], "body_position": [260, 317], "dependency": {"intra_class": ["diffprivlib.models.linear_regression.LinearRegression._obj_coefs", "diffprivlib.models.linear_regression.LinearRegression._preprocess_data", "diffprivlib.models.linear_regression.LinearRegression.accountant", "diffprivlib.models.linear_regression.LinearRegression.bounds_X", "diffprivlib.models.linear_regression.LinearRegression.bounds_y", "diffprivlib.models.linear_regression.LinearRegression.coef_", "diffprivlib.models.linear_regression.LinearRegression.epsilon", "diffprivlib.models.linear_regression.LinearRegression.random_state"], "intra_file": ["diffprivlib.models.linear_regression._construct_regression_obj"], "cross_file": ["diffprivlib.accountant.BudgetAccountant.check", "diffprivlib.accountant.BudgetAccountant.spend", "diffprivlib.utils.PrivacyLeakWarning", "diffprivlib.utils.check_random_state", "diffprivlib.validation.DiffprivlibMixin._check_bounds", "diffprivlib.validation.DiffprivlibMixin._validate_params", "diffprivlib.validation.DiffprivlibMixin._warn_unused_args"]}, "requirement": {"Functionality": "This function fits a linear regression model to the given training data. It preprocesses the data, determines the bounds, constructs regression objects, and optimizes the coefficients using the minimize function. It also sets the intercept and updates the accountant's spending.", "Arguments": ":param self: LinearRegression. An instance of the LinearRegression class.\n:param X: array-like or sparse matrix. The training data with shape (n_samples, n_features).\n:param y: array_like. The target values with shape (n_samples, n_targets).\n:param sample_weight: ignored. Ignored by diffprivlib. Present for consistency with sklearn API.\n:return: self. An instance of the LinearRegression class."}, "tests": ["tests/models/test_LinearRegression.py::TestLinearRegression::test_large_data", "tests/models/test_LinearRegression.py::TestLinearRegression::test_simple", "tests/models/test_LinearRegression.py::TestLinearRegression::test_accountant", "tests/models/test_LinearRegression.py::TestLinearRegression::test_multiple_targets", "tests/models/test_LinearRegression.py::TestLinearRegression::test_sample_weight_warning"], "indent": 8}
{"namespace": "boto.elasticache.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/elasticache/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.elasticache.layer1.ElastiCacheConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region in the Elasticache service. It creates a connection to the Elasticache service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: ElasticacheConnection. The connection object to the Elasticache service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestElasticacheConnection::test_connect_to_region"], "indent": 4}
{"namespace": "bentoml._internal.utils.analytics.usage_stats.get_serve_info", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/utils/analytics/usage_stats.py", "signature_position": [93, 94], "body_position": [95, 98], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.utils.analytics.usage_stats.ServeInfo"], "cross_file": []}, "requirement": {"Functionality": "This function generates a safe token for serving and returns the serve information, including the serve ID and the timestamp when the token was created.", "Arguments": ":param: No input parameters.\n:return: ServeInfo. An instance of the ServeInfo class, containing the serve ID and the timestamp of token creation."}, "tests": ["tests/unit/_internal/utils/test_analytics.py::test_track_serve_init", "tests/unit/_internal/utils/test_analytics.py::test_track_serve_init_no_bento"], "indent": 4}
{"namespace": "boto.s3.lifecycle.Lifecycle.add_rule", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/lifecycle.py", "signature_position": [280, 281], "body_position": [310, 311], "dependency": {"intra_class": [], "intra_file": ["boto.s3.lifecycle.Rule", "boto.s3.lifecycle.Rule.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function adds a rule to the Lifecycle configuration of an object.", "Arguments": ":param self: Lifecycle. An instance of Lifecycle class\n:param id: str [optional]. Unique identifier for the rule. The value cannot be longer than 255 characters. This value is optional. The server will generate a unique value for the rule if no value is provided.\n:param prefix: str. Prefix identifying one or more objects to which the rule applies.\n:param status: str. If 'Enabled', the rule is currently being applied. If 'Disabled', the rule is not currently being applied.\n:param expiration: int. Indicates the lifetime, in days, of the objects that are subject to the rule. The value must be a non-zero positive integer. An Expiration object instance is also perfect.\n:param transition: Transitions. Indicates when an object transitions to a different storage class.\n:return: No return values."}, "tests": ["tests/unit/s3/test_lifecycle.py::TestS3LifeCycle::test_expiration_with_no_transition"], "indent": 8}
{"namespace": "sacred.dependencies.is_local_source", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/dependencies.py", "signature_position": [552, 552], "body_position": [576, 589], "dependency": {"intra_class": [], "intra_file": ["sacred.dependencies.convert_path_to_module_parts"], "cross_file": []}, "requirement": {"Functionality": "This function checks if a module comes from a specific experiment path. It compares the absolute filename and the experiment path to determine if the module is a local source file or a package dependency.", "Arguments": ":param filename: str. The absolute filename of the module in question.\n:param modname: str. The full name of the module including parent namespaces.\n:param experiment_path: str. The base path of the experiment.\n:return: bool. True if the module was imported locally from (a subdir of) the experiment_path, and False otherwise."}, "tests": ["tests/test_dependencies.py::test_is_local_source"], "indent": 4}
{"namespace": "asyncssh.public_key.SSHKey.verify", "type": "method", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/public_key.py", "signature_position": [569, 569], "body_position": [572, 581], "dependency": {"intra_class": ["asyncssh.public_key.SSHKey.all_sig_algorithms", "asyncssh.public_key.SSHKey.verify_ssh"], "intra_file": [], "cross_file": ["asyncssh.packet.PacketDecodeError", "asyncssh.packet.SSHPacket", "asyncssh.packet.SSHPacket.get_string"]}, "requirement": {"Functionality": "This function verifies an SSH signature of the specified data using the SSHKey instance. It decodes the signature packet, checks if the signature algorithm is supported, and performs the actual verification.", "Arguments": ":param self: SSHKey. An instance of the SSHKey class.\n:param data: bytes. The data to be verified.\n:param sig: bytes. The SSH signature to be verified.\n:return: bool. True if the signature is valid, False otherwise."}, "tests": ["tests/test_agent.py::_TestAgent::test_reconnect", "tests/test_agent.py::_TestAgent::test_lock", "tests/test_agent.py::_TestAgent::test_confirm", "tests/test_agent.py::_TestAgent::test_sign"], "indent": 8}
{"namespace": "fs._url_tools.url_quote", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/_url_tools.py", "signature_position": [13, 14], "body_position": [25, 35], "dependency": {"intra_class": [], "intra_file": ["fs._url_tools._WINDOWS_PLATFORM", "fs._url_tools._has_drive_letter"], "cross_file": []}, "requirement": {"Functionality": "This function quotes a URL, excluding the Windows drive letter if present. On Windows, it separates the drive letter and quotes the Windows path separately. On Unix-like systems, it uses the `~urllib.request.pathname2url` function.", "Arguments": ":param path_snippet: Text. A file path, either relative or absolute.\n:return: Text. The quoted URL."}, "tests": ["tests/test_url_tools.py::TestBase::test_quote"], "indent": 4}
{"namespace": "bentoml._internal.resource.system_resources", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/resource.py", "signature_position": [43, 43], "body_position": [44, 47], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.resource._RESOURCE_REGISTRY"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves system resources and returns them as a dictionary. It iterates over the items in the resource registry dictionary, retrieves the corresponding resource for each resource kind, and adds it to the result dictionary.", "Arguments": ":param: No input parameters.\n:return: dict[str, t.Any]. A dictionary containing the system resources, where the keys are the resource kinds and the values are the corresponding resources."}, "tests": ["tests/unit/_internal/test_resource.py::test_system_resources"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox._stream_box_autocomplete", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [462, 464], "body_position": [465, 475], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._process_typeaheads", "zulipterminal.ui_tools.boxes.WriteBox.view"], "intra_file": [], "cross_file": ["zulipterminal.helper.match_stream"]}, "requirement": {"Functionality": "This function is a private method that is used for stream box autocomplete. It takes a text and a state as input parameters and returns a string or None. It retrieves a list of stream names from the view's corresponding attributes. Then, it matches the input text with the stream names. Finally, it processes the matched streams and returns the result.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param text: String. The input text to match with stream names.\n:param state: Optional integer. The state of the autocomplete. Defaults to None.\n:return: Optional string. The processed typeaheads or None."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test__stream_box_autocomplete"], "indent": 8}
{"namespace": "playhouse.sqlite_changelog.ChangeLog.install", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/sqlite_changelog.py", "signature_position": [114, 115], "body_position": [116, 128], "dependency": {"intra_class": ["playhouse.sqlite_changelog.ChangeLog._actions", "playhouse.sqlite_changelog.ChangeLog.db", "playhouse.sqlite_changelog.ChangeLog.drop_trigger_sql", "playhouse.sqlite_changelog.ChangeLog.model", "playhouse.sqlite_changelog.ChangeLog.trigger_sql"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to install a change log for a model. It creates a table for the change log if the \"create_table\" parameter is set to True. It then generates and executes SQL statements to create triggers for insert, update, and delete actions on the model.", "Arguments": ":param self: ChangeLog. An instance of the ChangeLog class.\n:param model: The model for which the change log is being installed.\n:param skip_fields: List of strings. The fields to skip when generating triggers. Defaults to None.\n:param drop: Bool. Whether to drop existing triggers before installing new ones. Defaults to True.\n:param insert: Bool. Whether to create triggers for insert actions. Defaults to True.\n:param update: Bool. Whether to create triggers for update actions. Defaults to True.\n:param delete: Bool. Whether to create triggers for delete actions. Defaults to True.\n:param create_table: Bool. Whether to create a table for the change log. Defaults to True.\n:return: No return values."}, "tests": ["tests/sqlite_changelog.py::TestChangeLog::test_changelog_details", "tests/sqlite_changelog.py::TestChangeLog::test_changelog_jsonfield"], "indent": 8}
{"namespace": "wikipediaapi.Wikipedia.article", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [237, 239], "body_position": [250, 254], "dependency": {"intra_class": ["wikipediaapi.Wikipedia.page"], "intra_file": ["wikipediaapi.Namespace", "wikipediaapi.Namespace.MAIN", "wikipediaapi.WikiNamespace"], "cross_file": []}, "requirement": {"Functionality": "This function constructs a Wikipedia page with the given title.", "Arguments": ":param self: Wikipedia. An instance of the Wikipedia class.\n:param title: String. The title of the Wikipedia page as used in the URL.\n:param ns: WikiNamespace. The namespace of the Wikipedia page. It defaults to Namespace.MAIN if not specified.\n:param unquote: Bool. Whether to unquote the title. It defaults to False if not specified.\n:return: WikipediaPage. An object representing the Wikipedia page."}, "tests": ["tests/wikipedia_page_test.py::TestWikipediaPage::test_article_title_unquote", "tests/wikipedia_page_test.py::TestWikipediaPage::test_article_method"], "indent": 8}
{"namespace": "bentoml._internal.resource.CpuResource.from_spec", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/resource.py", "signature_position": [79, 79], "body_position": [89, 102], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["bentoml.exceptions.BentoMLConfigException"]}, "requirement": {"Functionality": "This function converts a given specification to a CpuResource value. The specification can be a float, int, or string. It handles different formats of the specification and returns the corresponding CpuResource value. Note to check ValueError.", "Arguments": ":param cls: Class. The class itself.\n:param spec: Any. The specification to be converted to CpuResource.\n:return: float. The converted CpuResource value."}, "tests": ["tests/unit/_internal/test_resource.py::test_CpuResource"], "indent": 8}
{"namespace": "mmcv.transforms.wrappers.TransformBroadcaster.__repr__", "type": "method", "project_path": "Utilities/mmcv", "completion_path": "Utilities/mmcv/mmcv/transforms/wrappers.py", "signature_position": [531, 531], "body_position": [532, 539], "dependency": {"intra_class": ["mmcv.transforms.wrappers.TransformBroadcaster.share_random_params"], "intra_file": ["mmcv.transforms.wrappers.KeyMapper.allow_nonexist_keys", "mmcv.transforms.wrappers.KeyMapper.auto_remap", "mmcv.transforms.wrappers.KeyMapper.mapping", "mmcv.transforms.wrappers.KeyMapper.remapping", "mmcv.transforms.wrappers.KeyMapper.transforms"], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the TransformBroadcaster instance. It includes information about the transforms, mapping, remapping, auto remap, allow nonexist keys, and share random params attributes of the instance. The output format is \"{class name}(transforms = {transforms}, mapping = {mapping}, remapping = {remapping}, auto_remap = {auto_remap}, allow_nonexist_keys = {allow nonexist keys}, share_random_params = {share random params})\".", "Arguments": ":param self: TransformBroadcaster. An instance of the TransformBroadcaster class.\n:return: str. The string representation of the TransformBroadcaster instance."}, "tests": ["tests/test_transforms/test_transforms_wrapper.py::test_random_apply", "tests/test_transforms/test_transforms_wrapper.py::test_transform_broadcaster", "tests/test_transforms/test_transforms_wrapper.py::test_random_choice"], "indent": 8}
{"namespace": "rows.fields.EmailField.deserialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [445, 445], "body_position": [446, 454], "dependency": {"intra_class": ["rows.fields.EmailField.EMAIL_REGEXP"], "intra_file": ["rows.fields.TextField", "rows.fields.TextField.deserialize", "rows.fields.value_error"], "cross_file": []}, "requirement": {"Functionality": "Deserialize the input value and validate it as an email field. It first calls the superclass's deserialize method to perform the initial deserialization. Then, it checks if the deserialized value is None or empty. If it is, it returns None. Otherwise, it uses a regular expression to validate the email format. If the email is valid, it returns the first match. If not, it raises a value error.", "Arguments": ":param cls: Class. The class object itself.\n:param value: Any. The value to be deserialized and validated as an email field.\n:param *args: Any. Additional positional arguments.\n:param **kwargs: Any. Additional keyword arguments.\n:return: Object. The deserialized and validated email value, or None if the input value is None or empty."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_EmailField"], "indent": 8}
{"namespace": "mopidy.config.schemas.ConfigSchema.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/schemas.py", "signature_position": [54, 54], "body_position": [59, 82], "dependency": {"intra_class": ["mopidy.config.schemas.ConfigSchema.deserialize"], "intra_file": ["mopidy.config.schemas._did_you_mean"], "cross_file": ["mopidy.config.types.Deprecated", "mopidy.config.types"]}, "requirement": {"Functionality": "This function validates the given `values` using the config schema. It iterates through each key-value pair in the `values` dictionary and tries to deserialize the value using the corresponding schema in the config. If the key is not found in the schema, it adds an error message to the `errors` dictionary. If the deserialization fails, it adds the error message to the `errors` dictionary and sets the value to None in the `result` dictionary. After iterating through all the keys in the schema, it checks for any deprecated keys and removes them from the `result` dictionary. Finally, it returns a tuple containing the cleaned values in the `result` dictionary and the errors in the `errors` dictionary.", "Arguments": ":param self: ConfigSchema. An instance of the ConfigSchema class.\n:param values: dict. A dictionary containing the values to be validated against the config schema.\n:return: tuple. A tuple containing the cleaned values in the `result` dictionary and the errors in the `errors` dictionary."}, "tests": ["tests/config/test_schemas.py::ConfigSchemaTest::test_deserialize_deserialization_unknown_and_missing_errors", "tests/config/test_config.py::ValidateTest::test_config_single_schema_config_error", "tests/config/test_schemas.py::ConfigSchemaTest::test_deserialize_with_missing_value", "tests/config/test_schemas.py::ConfigSchemaTest::test_deserialize_deprecated_value", "tests/config/test_schemas.py::ConfigSchemaTest::test_deserialize_with_deserialization_error"], "indent": 8}
{"namespace": "twitter.models.TwitterModel.AsDict", "type": "method", "project_path": "Internet/python-twitter", "completion_path": "Internet/python-twitter/twitter/models.py", "signature_position": [43, 43], "body_position": [46, 76], "dependency": {"intra_class": ["twitter.models.TwitterModel.param_defaults", "twitter.models.TwitterModel.AsDict"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function creates a dictionary representation of a TwitterModel instance. It iterates through all attributes of the object and constructs a dictionary based on the values of those attributes. If an attribute is a list, tuple, or set, it checks if the elements of the list supprts the dict format. If they do, it creates a list of dictionaries on each element. If an attribute is a subclass of TwitterModel, it directly assigns the dictionary representation of that attribute. If an attribute does not support the dict format, it assigns the value directly to the dictionary.", "Arguments": ":param self: TwitterModel. An instance of the TwitterModel class.\n:return: dict. A dictionary representation of the TwitterModel object."}, "tests": ["tests/test_models.py::ModelsTest::test_url", "tests/test_models.py::ModelsTest::test_hashtag", "tests/test_models.py::ModelsTest::test_media"], "indent": 8}
{"namespace": "pyramid.request.RequestLocalCache.get_or_create", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/request.py", "signature_position": [403, 403], "body_position": [414, 425], "dependency": {"intra_class": ["pyramid.request.RequestLocalCache.NO_VALUE", "pyramid.request.RequestLocalCache._creator", "pyramid.request.RequestLocalCache._store", "pyramid.request.RequestLocalCache.set"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a value from the cache based on the given request. If the value is not found in the cache, it executes the creator function to compute the value, caches the result, and returns it.", "Arguments": ":param self: RequestLocalCache. An instance of the RequestLocalCache class.\n:param request: The request object used as the key to retrieve the value from the cache.\n:param creator: Function. The function used to compute the value if it is not found in the cache. If not provided, it defaults to the creator function bound to the cache.\n:return: The value retrieved from the cache or computed by the creator function."}, "tests": ["tests/test_request.py::TestRequestLocalCache::test_get_or_create_overrides_creator", "tests/test_request.py::TestRequestLocalCache::test_creator_in_constructor", "tests/test_request.py::TestRequestLocalCache::test_get_or_create_with_no_creator", "tests/test_request.py::TestRequestLocalCache::test_decorator_overrides_creator"], "indent": 8}
{"namespace": "boltons.funcutils.FunctionBuilder.get_defaults_dict", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/funcutils.py", "signature_position": [951, 951], "body_position": [955, 960], "dependency": {"intra_class": ["boltons.funcutils.FunctionBuilder.defaults", "boltons.funcutils.FunctionBuilder.args", "boltons.funcutils.FunctionBuilder.kwonlydefaults"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a dictionary that contains the function arguments along with their default values.", "Arguments": ":param self: FunctionBuilder. An instance of the FunctionBuilder class.\n:return: dict. A dictionary that contains the function arguments as keys and their default values as values."}, "tests": ["tests/test_funcutils_fb_py3.py::test_defaults_dict", "tests/test_funcutils_fb_py3.py::test_remove_kwonly_arg", "tests/test_funcutils_fb.py::test_defaults_dict"], "indent": 8}
{"namespace": "mrjob.step._Step.description", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/step.py", "signature_position": [408, 408], "body_position": [411, 418], "dependency": {"intra_class": ["mrjob.step._Step._STEP_ATTRS", "mrjob.step._Step._STEP_TYPE"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a dictionary representation of a step object. It includes all the attributes of the step object except for the hidden attributes. It also includes the type of the step with the key 'type'.", "Arguments": ":param self: _Step. An instance of the _Step class.\n:param step_num: int. The step number. Defaults to 0.\n:return: dict. A dictionary representation of the step object."}, "tests": ["tests/test_step.py::SparkStepTestCase::test_all_args", "tests/test_step.py::SparkScriptStepTestCase::test_defaults", "tests/test_step.py::JarStepTestCase::test_some", "tests/test_step.py::SparkScriptStepTestCase::test_all_args", "tests/test_step.py::JarStepTestCase::test_all"], "indent": 8}
{"namespace": "boltons.iterutils.remap", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [1035, 1036], "body_position": [1135, 1199], "dependency": {"intra_class": [], "intra_file": ["boltons.iterutils._REMAP_EXIT", "boltons.iterutils._orig_default_visit", "boltons.iterutils.default_enter", "boltons.iterutils.default_exit", "boltons.iterutils.default_visit"], "cross_file": []}, "requirement": {"Functionality": "This function recursively transform nested structures and returns the transformed object.\n", "Arguments": ":param root: The target object to traverse. By default, support iterables like list, tuple, dict, and set. Any object traversable by \"enter\" will work.\n:param visit: callable. This function is called on every item in \"root\". It accepts three positional arguments: path, key, and value, where \"path\" is a tuple of parents' keys, key is the key or index in parent, and value is the element itself. \"visit\" returns the new key-value pair. It may also return \"True\" as shorthand to keep the old item unmodified, or \"False\" to drop the item from the new structure. \"visit\" is called after \"enter\", on the new parent. It is called for every item in root, including duplicate items. For traversable values, it is called on the new parent object, after all its children have been visited. Defaults to default_visit.\n:param enter: callable. This function controls which items in \"root\" are traversed. It accepts the same arguments as \"visit\". It returns a pair of the blank new parent and an iterator over the items which should be visited. If \"False\" is returned instead of an iterator, the value will not be traversed. It is only called once per unique value. Defaults to default_enter.\n:param exit: callable. This function determines how to handle items once they have been visited. It gets the same three arguments as the other functions: path, key, value, plus two more: the blank new parent object returned from \"enter\" and a list of the new items, as remapped by \"visit\". It returns the new parent object. It is only called once per unique value. Defaults to default_exit.\n:param reraise_visit: bool. A pragmatic convenience for the \"visit\" callable. When set to \"False\", ignore any errors raised by the \"visit\" callback. Items causing exceptions are kept. Defaults to True.\n"}, "tests": ["tests/test_iterutils.py::TestRemap::test_drop_nones", "tests/test_iterutils.py::TestRemap::test_dict_to_omd", "tests/test_iterutils.py::TestRemap::test_sort_all_lists", "tests/test_iterutils.py::TestRemap::test_duperef", "tests/test_iterutils.py::TestRemap::test_prepop"], "indent": 4}
{"namespace": "boto.dynamodb2.table.BatchTable.flush", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1663, 1663], "body_position": [1664, 1690], "dependency": {"intra_class": ["boto.dynamodb2.table.BatchTable._to_delete", "boto.dynamodb2.table.BatchTable._to_put", "boto.dynamodb2.table.BatchTable.handle_unprocessed", "boto.dynamodb2.table.BatchTable.table"], "intra_file": ["boto.dynamodb2.table.Table._encode_keys", "boto.dynamodb2.table.Table.connection"], "cross_file": ["boto.dynamodb2.items.Item", "boto.dynamodb2.items.Item.prepare_full", "boto.dynamodb2.layer1.DynamoDBConnection.batch_write_item"]}, "requirement": {"Functionality": "This function flushes the batch data by preparing the data to be inserted or deleted. It also handles any unprocessed items.", "Arguments": ":param self: BatchTable. An instance of the BatchTable class.\n:return: bool. Returns True after flushing the batch data."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write_unprocessed_items"], "indent": 8}
{"namespace": "pythonforandroid.recommendations.check_target_api", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/recommendations.py", "signature_position": [151, 151], "body_position": [157, 166], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.recommendations.ARMEABI_MAX_TARGET_API", "pythonforandroid.recommendations.MIN_TARGET_API", "pythonforandroid.recommendations.OLD_API_MESSAGE", "pythonforandroid.recommendations.UNSUPPORTED_NDK_API_FOR_ARMEABI_MESSAGE"], "cross_file": ["pythonforandroid.logger.warning", "pythonforandroid.util.BuildInterruptingException"]}, "requirement": {"Functionality": "This function checks if the user's target API is less than the current minimum recommendation. If it is, a warning message is displayed.", "Arguments": ":param api: Integer. The target API version.\n:param arch: String. The architecture type.\n:return: No return values."}, "tests": ["tests/test_recommendations.py::TestRecommendations::test_check_target_api_warning_target_api", "tests/test_recommendations.py::TestRecommendations::test_check_target_api_error_arch_armeabi"], "indent": 4}
{"namespace": "pycoin.contrib.bech32m.decode", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/contrib/bech32m.py", "signature_position": [115, 115], "body_position": [117, 129], "dependency": {"intra_class": [], "intra_file": ["pycoin.contrib.bech32m.Encoding", "pycoin.contrib.bech32m.bech32_decode", "pycoin.contrib.bech32m.convertbits"], "cross_file": ["pycoin.contrib.bech32m.Encoding.BECH32", "pycoin.contrib.bech32m.Encoding.BECH32M"]}, "requirement": {"Functionality": "This function decodes a segwit address. It takes a human-readable part (hrp) and an address as input. It decodes the address and performs various checks on the decoded data. If any of the checks fail, it returns (None, None). Otherwise, it returns the version byte and the decoded data.", "Arguments": ":param hrp: String. The human-readable part of the address.\n:param addr: String. The address to decode.\n:return: Tuple. The version byte and the decoded data."}, "tests": ["tests/bech32_test.py::Bech32Test::test_bip350_vectors"], "indent": 4}
{"namespace": "pythonforandroid.prerequisites.HomebrewPrerequisite.darwin_helper", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [142, 142], "body_position": [143, 147], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pythonforandroid.logger.info"]}, "requirement": {"Functionality": "This function displays a message informing the user that the installer for Homebrew is not supported on macOS and provides a link to further instructions for the installation process.", "Arguments": ":param self: HomebrewPrerequisite. An instance of the HomebrewPrerequisite class.\n:return: No return values."}, "tests": ["tests/test_prerequisites.py::TestBrewPrerequisite::test_darwin_helper"], "indent": 8}
{"namespace": "pyramid.csrf.SessionCSRFStoragePolicy.get_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [78, 78], "body_position": [81, 84], "dependency": {"intra_class": ["pyramid.csrf.SessionCSRFStoragePolicy.key", "pyramid.csrf.SessionCSRFStoragePolicy.new_csrf_token"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the currently active CSRF token from the session. If the token is not found in the session, a new one is generated and returned.", "Arguments": ":param self: SessionCSRFStoragePolicy. An instance of the SessionCSRFStoragePolicy class.\n:param request: The request object.\n:return: The CSRF token from the session."}, "tests": ["tests/test_csrf.py::TestSessionCSRFStoragePolicy::test_it_creates_a_new_token", "tests/test_csrf.py::TestSessionCSRFStoragePolicy::test_get_csrf_token_returns_the_new_token"], "indent": 8}
{"namespace": "kinto.core.statsd.load_from_config", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/statsd.py", "signature_position": [45, 48], "body_position": [49, 62], "dependency": {"intra_class": [], "intra_file": ["kinto.core.statsd.Client", "kinto.core.statsd.Client.__init__", "kinto.core.statsd.statsd_module"], "cross_file": []}, "requirement": {"Functionality": "Load the configuration settings and create a StatsD client based on the specified settings. It checks if the statsd module is installed and raises an error if it is not. Then, it retrieves the statsd URL from the settings and parses it. Finally, it creates a StatsD client with the hostname, port, and prefix specified in the settings.", "Arguments": ":param config: The configuration object.\n:return: Client. The created StatsD client."}, "tests": ["tests/core/test_statsd.py::StatsDMissing::test_client_instantiation_raises_properly"], "indent": 4}
{"namespace": "principalmapper.querying.local_policy_simulation._statement_matches_resource", "type": "function", "project_path": "Security/principalmapper", "completion_path": "Security/principalmapper/principalmapper/querying/local_policy_simulation.py", "signature_position": [873, 873], "body_position": [875, 888], "dependency": {"intra_class": [], "intra_file": ["principalmapper.querying.local_policy_simulation._listify_string", "principalmapper.querying.local_policy_simulation._matches_after_expansion"], "cross_file": ["principalmapper.util.case_insensitive_dict.CaseInsensitiveDict"]}, "requirement": {"Functionality": "This function is a helper function that checks if a given resource is present in a policy statement. It checks if the resource matches any of the resources listed in the 'Resource' field of the statement. If it does, it returns True. If 'Resource' not in statement and the 'NotResource' field is present, it checks if the resource matches any of the resources listed in that field. If it does, it returns False. If neither 'Resource' nor 'NotResource' fields are present, it returns True.", "Arguments": ":param statement: dict. The policy statement to check.\n:param resource: str. The resource to check for.\n:param condition_keys: Optional[CaseInsensitiveDict]. A dictionary of condition keys. Defaults to None.\n:return: bool. True if the resource is in the policy statement, False otherwise."}, "tests": ["tests/test_local_policy_sim.py::TestLocalPolicyStatementMatching::test_resource_matching"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_only.compute_likelihood_window", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_only.py", "signature_position": [224, 233], "body_position": [268, 315], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_only.compute_prob_setofparams_given_cmd"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the likelihood of a given window of commands. It calculates the probability of the window based on prior probabilities, transition probabilities, and parameter conditional command probabilities.", "Arguments": ":param window: List[Cmd]. A list of commands representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands.\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the parameters conditional on the commands.\n:param use_start_token: Bool. Whether to prepend the start_token to the window before calculating the likelihood.\n:param use_end_token: Bool. Whether to append the end_token to the window before calculating the likelihood.\n:param start_token: Str. A dummy command to signify the start of the session. Defaults to None.\n:param end_token: Str. A dummy command to signify the end of the session. Defaults to None.\n:return: Float. The likelihood of the window."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_only.py::TestCmdsParamsOnly::test_compute_likelihood_window"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledStringIO.seek", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [450, 450], "body_position": [452, 472], "dependency": {"intra_class": ["boltons.ioutils.SpooledStringIO._tell", "boltons.ioutils.SpooledStringIO._traverse_codepoints", "boltons.ioutils.SpooledStringIO.buffer", "boltons.ioutils.SpooledStringIO.len", "boltons.ioutils.SpooledStringIO.tell"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed"], "cross_file": []}, "requirement": {"Functionality": "This function is used to traverse to a specified codepoint in the SpooledStringIO instance. It updates the current position based on the given offset and mode. If the mode is not valid, it raise a ValueError: 'Invalid whence ({mode}, should be 0, 1, or 2)'. It returns the updated current position.", "Arguments": ":param self: SpooledStringIO. An instance of the SpooledStringIO class.\n:param pos: int. The offset or position to traverse to.\n:param mode: int. The mode of seeking. It can be os.SEEK_SET (0) to seek from the start of the file, os.SEEK_CUR (1) to seek relative to the current position, or os.SEEK_END (2) to seek from the end of the file. Defaults to 0.\n:return: int. The updated current position after seeking."}, "tests": ["tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_large_SEEK_END", "tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_SEEK_CUR", "tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_large_SEEK_CUR", "tests/test_ioutils.py::TestSpooledStringIO::test_seek_codepoints_SEEK_END", "tests/test_ioutils.py::TestSpooledStringIO::test_iter"], "indent": 8}
{"namespace": "mopidy.config.format_initial", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/__init__.py", "signature_position": [125, 125], "body_position": [126, 148], "dependency": {"intra_class": [], "intra_file": ["mopidy.config._INITIAL_HELP", "mopidy.config._format", "mopidy.config._load", "mopidy.config._schemas", "mopidy.config._validate", "mopidy.config.read"], "cross_file": ["mopidy.internal.versioning", "mopidy.internal.versioning.get_version", "mopidy.ext.ExtensionData.extension", "mopidy.ext.ExtensionData.extension.version", "mopidy.ext.ExtensionData.extension.dist_name"]}, "requirement": {"Functionality": "This function formats the initial configuration for a set of extensions. It reads the default configuration file, gets the default configuration for each extension, and loads the raw configuration. It then validates the configuration against the schemas. After that, it creates a header with version information for each extension and formats the configuration. Finally, it returns the formatted initial configuration.", "Arguments": ":param extensions_data: The data of the extensions. It is a list of extension data objects.\n:return: String. The formatted initial configuration."}, "tests": ["tests/config/test_config.py::test_format_initial"], "indent": 4}
{"namespace": "sslyze.plugins.certificate_info._symantec.SymantecDistructTester.get_distrust_timeline", "type": "method", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/certificate_info/_symantec.py", "signature_position": [102, 104], "body_position": [105, 124], "dependency": {"intra_class": ["sslyze.plugins.certificate_info._symantec.SymantecDistructTester._CA_KEYS_BLACKLIST", "sslyze.plugins.certificate_info._symantec.SymantecDistructTester._CA_KEYS_WHITELIST"], "intra_file": ["sslyze.plugins.certificate_info._symantec.SymantecDistrustTimelineEnum", "sslyze.plugins.certificate_info._symantec.SymantecDistrustTimelineEnum.MARCH_2018", "sslyze.plugins.certificate_info._symantec.SymantecDistrustTimelineEnum.SEPTEMBER_2018"], "cross_file": ["sslyze.plugins.certificate_info._certificate_utils.get_public_key_sha256"]}, "requirement": {"Functionality": "This function checks the given list of verified certificates for the presence of Symantec root certificates. It determines the distrust timeline based on the presence of blacklisted and whitelisted certificates in the chain.", "Arguments": ":param cls: The class object of SymantecDistructTester.\n:param verified_certificate_chain: List of Certificate. A list of verified certificates.\n:return: Optional[SymantecDistrustTimelineEnum]. The distrust timeline enum value, which can be either \"MARCH_2018\" or \"SEPTEMBER_2018\", or None if no distrust is detected."}, "tests": ["tests/plugins_tests/certificate_info/test_symantec.py::TestSymantecDistrust::test_march_2018", "tests/plugins_tests/certificate_info/test_symantec.py::TestSymantecDistrust::test_september_2018"], "indent": 8}
{"namespace": "falcon.response.Response.get_header", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/response.py", "signature_position": [583, 583], "body_position": [608, 613], "dependency": {"intra_class": ["falcon.response.Response._headers"], "intra_file": [], "cross_file": ["falcon.errors.HeaderNotSupported"]}, "requirement": {"Functionality": "This function retrieves the raw string value for a given header in the Response instance. It checks if the header has multiple values and returns them as a single, comma-delimited string. However, if the header is \"Set-Cookie\", it raises an error because it does not support this format.", "Arguments": ":param self: Response. An instance of the Response class.\n:param name: String. The name of the header to retrieve, case-insensitive.\n:param default: Any. The value to return if the header is not found. Defaults to None.\n:return: String. The value of the specified header if set, or the default value if not set."}, "tests": ["tests/test_headers.py::TestHeaders::test_set_cookie_disallowed"], "indent": 8}
{"namespace": "playhouse.db_url.connect", "type": "function", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/db_url.py", "signature_position": [91, 91], "body_position": [92, 105], "dependency": {"intra_class": [], "intra_file": ["playhouse.db_url.parseresult_to_dict", "playhouse.db_url.schemes"], "cross_file": []}, "requirement": {"Functionality": "Connect to a database using the given URL and connection parameters. It parses the URL, converts it to a dictionary of connection parameters, updates it with additional parameters, and then creates an instance of the appropriate database class using the connection parameters.", "Arguments": ":param url: String. The URL of the database to connect to.\n:param unquote_password: Bool. Whether to unquote the password in the URL. Defaults to False.\n:param **connect_params: Additional connection parameters as keyword arguments.\n:return: The instance of the database class created using the connection parameters."}, "tests": ["tests/db_url.py::TestDBUrl::test_db_url"], "indent": 4}
{"namespace": "alembic.operations.ops.DropColumnOp.reverse", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [2190, 2190], "body_position": [2191, 2199], "dependency": {"intra_class": ["alembic.operations.ops.DropColumnOp._reverse"], "intra_file": ["alembic.operations.ops.AddColumnOp", "alembic.operations.ops.AddColumnOp.from_column_and_tablename", "alembic.operations.ops.AlterTableOp.schema", "alembic.operations.ops.AlterTableOp.table_name"], "cross_file": ["alembic.operations.ops.AddColumnOp.column"]}, "requirement": {"Functionality": "This function reverses the operation performed by the DropColumnOp. It checks if the reverse operation is available and raises a ValueError if it is not.", "Arguments": ":param self: DropColumnOp. An instance of the DropColumnOp class.\n:return: AddColumnOp."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_drop_column"], "indent": 8}
{"namespace": "zxcvbn.scoring.date_guesses", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [318, 318], "body_position": [319, 324], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.scoring.MIN_YEAR_SPACE", "zxcvbn.scoring.REFERENCE_YEAR"], "cross_file": []}, "requirement": {"Functionality": "Calculate the number of possible date guesses based on the given match. It calculates the number of possible guesses by taking into account the year difference and the presence of a separator.", "Arguments": ":param match: Dictionary. A dictionary containing information about the date match, including the year and separator.\n:return: Integer. The number of possible date guesses."}, "tests": ["tests/scoring_test.py::test_calc_guesses", "tests/scoring_test.py::test_date_guesses", "tests/scoring_test.py::test_estimate_guesses"], "indent": 4}
{"namespace": "boltons.iterutils.research", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [1281, 1281], "body_position": [1323, 1338], "dependency": {"intra_class": [], "intra_file": ["boltons.iterutils.remap"], "cross_file": []}, "requirement": {"Functionality": "The function recursively searches for values in any data nested in `root` that match a given criterion specified by the `query` callable. The results are returned as a list of `(path, value)` pairs.\n", "Arguments": ":param root: The target object to search. Supports the same types of objects as `remap`, including list, tuple, dict, and set.\n:param query: Callable. The function called on every object to determine whether to include it in the search results. The callable must accept three arguments: `path`, `key`, and `value`, commonly abbreviated as `p`, `k`, and `v`. Defaults to `lambda p, k, v: True`.\n:param reraise: bool. Whether to reraise exceptions raised by the `query` callable or to simply drop the result that caused the error. Defaults to False.\n:return: List of `(path, value)` pairs. The pairs represent the paths to matching values and the values themselves in the nested data structure.\n"}, "tests": ["tests/test_iterutils.py::test_research"], "indent": 4}
{"namespace": "playhouse.dataset.DataSet.freeze", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/dataset.py", "signature_position": [162, 163], "body_position": [164, 172], "dependency": {"intra_class": ["playhouse.dataset.DataSet._check_arguments", "playhouse.dataset.DataSet._export_formats"], "intra_file": ["playhouse.dataset.TSVExporter.export", "playhouse.dataset.open_file"], "cross_file": []}, "requirement": {"Functionality": "Freeze the dataset by exporting it to a file in the specified format. It checks the arguments, opens the file if a filename is provided, creates an exporter instance based on the format, and exports the dataset to the file. Finally, it closes the file if it was opened.", "Arguments": ":param self: DataSet. An instance of the DataSet class.\n:param query: The query to export.\n:param format: String. The format in which to export the dataset. Defaults to 'csv'.\n:param filename: String. The name of the file to export to. If provided, the file will be opened and closed automatically.\n:param file_obj: File object. The file object to export to. If provided, the file will not be opened or closed automatically.\n:param encoding: String. The encoding to use when opening the file. Defaults to 'utf8'.\n:param kwargs: Additional keyword arguments to pass to the exporter's export method.\n:return: No return values."}, "tests": ["tests/dataset.py::TestDataSet::test_export", "tests/dataset.py::TestDataSet::test_freeze_thaw"], "indent": 8}
{"namespace": "sacred.arg_parser._convert_value", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/arg_parser.py", "signature_position": [206, 206], "body_position": [208, 216], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["sacred.serializer.restore", "sacred.settings.SETTINGS"]}, "requirement": {"Functionality": "This function takes a string as input and tries to parse it as a Python literal. If successful, it returns the parsed value. If parsing fails, if the exception is a ValueError or Syntaxerror and strict parsing setting is not enabled, it returns the input string as is. Otherwise, the exception is raised.", "Arguments": ":param value: The input string to be parsed.\n:return: The parsed value if successful, or the input string if parsing fails."}, "tests": ["tests/test_arg_parser.py::test_convert_value"], "indent": 4}
{"namespace": "chatette.parsing.ChoiceBuilder.create_concrete", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [80, 80], "body_position": [81, 86], "dependency": {"intra_class": ["chatette.parsing.ChoiceBuilder.leading_space", "chatette.parsing.ChoiceBuilder.rules"], "intra_file": ["chatette.parsing.ItemBuilder._build_modifiers_repr", "chatette.parsing.ItemBuilder._check_information"], "cross_file": ["chatette.units.modifiable.choice.Choice"]}, "requirement": {"Functionality": "The function creates a concrete Choice instance based on the current state of the ChoiceBuilder object. It first checks if all the necessary information is provided, and then constructs a Choice object using the leading space, modifiers representation, and rules of the ChoiceBuilder object.", "Arguments": ":param self: ChoiceBuilder. An instance of the ChoiceBuilder class.\n:return: Choice. The created Choice instance."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestChoiceBuilder::test_create_concrete"], "indent": 8}
{"namespace": "mrjob.conf.combine_cmds", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [416, 416], "body_position": [425, 432], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.combine_values"], "cross_file": ["mrjob.py2.string_types", "mrjob.util.shlex_split"]}, "requirement": {"Functionality": "This function takes zero or more commands to run on the command line and returns the last one that is not None. Each command can be a list containing the command plus switches or a string, which will be parsed with shlex.split. The string must be a byte string or a Unicode string containing no non-ASCII characters.\nGet the last command. If the command is None, returns None. If the command is a string, it is splited using shell-like syntax. Otherwise, the command is converted to a list and returned.\n", "Arguments": ":param cmds: Variable number of arguments. Each argument can be a list or string representing a command.\n:return: List or None. Either a list containing the last non-None command or None.\n"}, "tests": ["tests/test_conf.py::CombineCmdsTestCase::test_unicode", "tests/test_conf.py::CombineCmdsTestCase::test_convert_to_list", "tests/test_conf.py::CombineCmdsTestCase::test_parse_string", "tests/test_conf.py::CombineCmdsTestCase::test_picks_last_value", "tests/test_conf.py::CombineCmdsTestCase::test_parse_empty_string"], "indent": 4}
{"namespace": "googleapiclient._helpers._add_query_parameter", "type": "function", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/_helpers.py", "signature_position": [191, 191], "body_position": [204, 207], "dependency": {"intra_class": [], "intra_file": ["googleapiclient._helpers.update_query_params"], "cross_file": []}, "requirement": {"Functionality": "This function adds a query parameter to a URL. If the query parameter already exists in the URL, it replaces the current value with the new value. If the value is None, the URL remains unchanged.", "Arguments": ":param url: string. The URL to add the query parameter to.\n:param name: string. The name of the query parameter.\n:param value: string. The value of the query parameter.\n:return: string. The updated URL with the added query parameter. If the value is None, the original URL is returned."}, "tests": ["tests/test__helpers.py::AddQueryParameterTests::test__add_query_parameter"], "indent": 4}
{"namespace": "mrjob.job.MRJob.parse_output", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [1299, 1299], "body_position": [1303, 1306], "dependency": {"intra_class": ["mrjob.job.MRJob.output_protocol"], "intra_file": [], "cross_file": ["mrjob.protocol.BytesValueProtocol.read", "mrjob.util.to_lines"]}, "requirement": {"Functionality": "This function takes a stream of byte chunks as input and parses it into a stream of (key, value) pairs. It uses the output protocol to read each line of the input and yields the result.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:param chunks: List of byte chunks. The input stream of byte chunks to be parsed.\n:return: Generator. A generator that yields (key, value) pairs from the parsed output."}, "tests": ["tests/test_local.py::SortBinTestCase::test_empty_sort_bin_means_default", "tests/test_sim.py::NoMRJobConfTestCase::test_no_mrjob_confs", "tests/test_inline.py::InlineRunnerStepsTestCase::test_adding_2", "tests/test_sim.py::SimRunnerJobConfTestCase::test_jobconf_simulated_by_runner", "tests/test_sim.py::FileURIsAsInputTestCase::test_file_uris_as_input"], "indent": 8}
{"namespace": "zulipterminal.config.themes.add_pygments_style", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/config/themes.py", "signature_position": [222, 222], "body_position": [237, 274], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.config.themes.ThemeSpec"], "cross_file": ["zulipterminal.config.color.term16"]}, "requirement": {"Functionality": "This function adds Pygments styles for syntax highlighting of code blocks and inline code. It takes the theme metadata and the Urwid theme as input, and modifies the Pygments styles and Urwid theme accordingly.", "Arguments": ":param theme_meta: Dict. The theme metadata containing Pygments styles, background color, and overrides.\n:param urwid_theme: ThemeSpec. The Urwid theme to which the Pygments styles will be added.\n:return: No return values."}, "tests": ["tests/config/test_themes.py::test_add_pygments_style"], "indent": 4}
{"namespace": "ydata_profiling.report.presentation.flavours.html.frequency_table.HTMLFrequencyTable.render", "type": "method", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/report/presentation/flavours/html/frequency_table.py", "signature_position": [6, 6], "body_position": [7, 21], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["ydata_profiling.report.presentation.flavours.html.templates", "ydata_profiling.report.presentation.flavours.html.templates.template"]}, "requirement": {"Functionality": "This function renders an HTML frequency table based on the content provided. It checks if the content is a list of rows or a single row, and then uses a template to generate the HTML code for the frequency table.", "Arguments": ":param self: HTMLFrequencyTable. An instance of the HTMLFrequencyTable class.\n:return: str. The rendered HTML code for the frequency table."}, "tests": ["tests/unit/test_renderable.py::test_html_frequency_table"], "indent": 8}
{"namespace": "trailscraper.iam.known_iam_actions", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/iam.py", "signature_position": [179, 179], "body_position": [182, 186], "dependency": {"intra_class": [], "intra_file": ["trailscraper.iam._parse_action", "trailscraper.iam.all_known_iam_permissions"], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of known IAM actions for a given prefix. It retrieves all known IAM permissions, parses the actions, and groups them by prefix. It then returns the list of actions corresponding to the given prefix.", "Arguments": ":param prefix: String. The prefix for which known IAM actions are to be retrieved.\n:return: List of String. The list of known IAM actions for the given prefix."}, "tests": ["tests/iam/known_iam_actions_test.py::test_known_iam_action_for_prefix", "tests/iam/known_iam_actions_test.py::test_known_iam_action_for_prefix_does_not_fail_if_action_not_found"], "indent": 4}
{"namespace": "asyncssh.asn1.der_decode", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/asn1.py", "signature_position": [752, 752], "body_position": [781, 786], "dependency": {"intra_class": [], "intra_file": ["asyncssh.asn1.ASN1DecodeError", "asyncssh.asn1.der_decode_partial"], "cross_file": []}, "requirement": {"Functionality": "This function decodes a byte string in DER format and converts it into a corresponding set of Python objects.\nIt first decodes a value in DER format partially to get the consumed value and the end which is the byte length of the content that has been decoded, plus the offset at which the content begins. If the end index is less than the total length of the value in DER format, the function raise error in format \"Data contains unexpected bytes at end\". Otherwise, the decoded value is returned.", "Arguments": ":param data: bytes. The byte string in DER format to be decoded.\n:return: object. The decoded value from the DER format."}, "tests": ["tests/test_asn1.py::_TestASN1::test_asn1"], "indent": 4}
{"namespace": "dash.fingerprint.build_fingerprint", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/fingerprint.py", "signature_position": [7, 7], "body_position": [8, 13], "dependency": {"intra_class": [], "intra_file": ["dash.fingerprint.version_clean"], "cross_file": []}, "requirement": {"Functionality": "This function builds a fingerprint for a file based on the given path, version, and hash value. It extracts the filename and extension from the path, constructs a file path without the filename, replaces the version with underscores, and concatenates all the parts to form the fingerprint. The format of a fingerprint is \"{file_path}.v{v_str}m{hash_value}.{extension}\".", "Arguments": ":param path: String. The path of the file.\n:param version: Any data type. The version of the file.\n:param hash_value: Any data type. The hash value of the file.\n:return: String. The fingerprint of the file."}, "tests": ["tests/unit/test_fingerprint.py::test_fingerprint"], "indent": 4}
{"namespace": "pycoin.contrib.bech32m.bech32_encode", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/contrib/bech32m.py", "signature_position": [69, 69], "body_position": [71, 72], "dependency": {"intra_class": [], "intra_file": ["pycoin.contrib.bech32m.bech32_create_checksum"], "cross_file": []}, "requirement": {"Functionality": "This function takes an HRP (Human Readable Part), data, and a specification as input and computes a Bech32 string. It combines the data with a checksum generated and returns the Bech32 string.", "Arguments": ":param hrp: String. The Human Readable Part of the Bech32 string.\n:param data: List of integers. The data values to be encoded.\n:param spec: String. The specification to be used for encoding.\n:return: String. The computed Bech32 string."}, "tests": ["tests/bech32_test.py::Bech32Test::test_bip350_vectors"], "indent": 4}
{"namespace": "pyramid.config.actions.ActionInfo.__str__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/actions.py", "signature_position": [537, 537], "body_position": [538, 540], "dependency": {"intra_class": ["pyramid.config.actions.ActionInfo.file", "pyramid.config.actions.ActionInfo.line", "pyramid.config.actions.ActionInfo.src"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of an ActionInfo object. It formats the source code of the object by adding line number, file name, and indented source code.. The output format is 'Line {line numbers} of file {file name}:\\n{source code}'.", "Arguments": ":param self: ActionInfo. An instance of the ActionInfo class.\n:return: String. A formatted string representation of the ActionInfo object, including line number, file name, and indented source code."}, "tests": ["tests/test_config/test_actions.py::TestActionInfo::test___str__"], "indent": 8}
{"namespace": "pythonforandroid.bootstrap.expand_dependencies", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/bootstrap.py", "signature_position": [403, 403], "body_position": [412, 439], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pythonforandroid.recipe.Recipe", "pythonforandroid.recipe.Recipe.get_recipe"]}, "requirement": {"Functionality": "This function expands the lists of all different available alternative recipe combinations. It adds the dependencies for the recipes that do not have alternatives. It split up lists by available alternatives. This function is used for basic bootstrap compatibility checks.", "Arguments": ":param recipes: List. The list of recipes to expand.\n:param ctx: Context. The context object.\n:return: List of lists. The expanded recipe combinations with added dependencies."}, "tests": ["tests/test_bootstrap.py::TestBootstrapBasic::test_expand_dependencies", "tests/test_bootstrap.py::TestBootstrapBasic::test_expand_dependencies_with_pure_python_package"], "indent": 4}
{"namespace": "falcon.routing.static._BoundedFile.read", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/routing/static.py", "signature_position": [77, 77], "body_position": [79, 85], "dependency": {"intra_class": ["falcon.routing.static._BoundedFile.fh", "falcon.routing.static._BoundedFile.remaining"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Read data from the underlying file object within the specified bounds. It reads the data from the file object and updates the remaining size accordingly.", "Arguments": ":param self: _BoundedFile. An instance of the _BoundedFile class.\n:param size: Integer. The number of bytes to read from the file object. If size is less than 0, it reads the remaining bytes. Defaults to -1.\n:return: String. The data read from the file object."}, "tests": ["tests/test_static.py::test_bounded_file_wrapper"], "indent": 8}
{"namespace": "twilio.base.serialize.iso8601_datetime", "type": "function", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/base/serialize.py", "signature_position": [22, 22], "body_position": [27, 32], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["twilio.base.values", "twilio.base.values.unset"]}, "requirement": {"Functionality": "This function takes a date object and returns a string representation of the date in the format \"%Y-%m-%dT%H:%M:%SZ\" that is compatible with the Twilio API. If the input is not a string, datetime, or date object, it returns None.", "Arguments": ":param d: The date object to be converted to a string representation.\n:return: String. The string representation of the date in the format \"YYYY-MM-DD\" or None if the input is not a valid date object."}, "tests": ["tests/unit/base/test_serialize.py::Iso8601DateTimeTestCase::test_unset", "tests/unit/base/test_serialize.py::Iso8601DateTimeTestCase::test_str", "tests/unit/base/test_serialize.py::Iso8601DateTimeTestCase::test_date", "tests/unit/base/test_serialize.py::Iso8601DateTimeTestCase::test_datetime_without_time", "tests/unit/base/test_serialize.py::Iso8601DateTimeTestCase::test_datetime"], "indent": 4}
{"namespace": "sslyze.cli.server_string_parser.CommandLineServerStringParser.parse_server_string", "type": "method", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/cli/server_string_parser.py", "signature_position": [22, 23], "body_position": [24, 45], "dependency": {"intra_class": ["sslyze.cli.server_string_parser.CommandLineServerStringParser._parse_ipv4_server_string", "sslyze.cli.server_string_parser.CommandLineServerStringParser._parse_ipv6_server_string"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function parses a server string and extracts the host, ip, and port information from it. It first checks if the server string contains curly braces, indicating the presence of an ip address. If so, it extracts the ip address and removes it from the server string. Then, it checks if the server string contains square brackets, indicating the presence of an ipv6 hint. If so, it calls a helper function to parse the ipv6 server string. If not, it checks if the extracted ip address contains square brackets, indicating the presence of an ipv6 hint. If so, it calls the helper function to parse the ipv6 ip address. Finally, if none of the above conditions are met, it calls the helper function to parse the ipv4 server string. The function returns the host, ip, and port extracted from the server string.", "Arguments": ":param cls: The class object.\n:param server_str: String. The server string to be parsed.\n:return: Tuple. The host, ip, and port extracted from the server string."}, "tests": ["tests/cli_tests/test_server_string_parser.py::TestCommandLineServerStringParser::test_ipv6_as_hint", "tests/cli_tests/test_server_string_parser.py::TestCommandLineServerStringParser::test_with_port", "tests/cli_tests/test_server_string_parser.py::TestCommandLineServerStringParser::test_ipv6_with_port", "tests/cli_tests/test_server_string_parser.py::TestCommandLineServerStringParser::test_ipv4_as_hint_with_port", "tests/cli_tests/test_server_string_parser.py::TestCommandLineServerStringParser::test_ipv4_as_hint"], "indent": 8}
{"namespace": "kinto.plugins.accounts.utils.get_cached_validation_key", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/accounts/utils.py", "signature_position": [93, 93], "body_position": [95, 99], "dependency": {"intra_class": [], "intra_file": ["kinto.plugins.accounts.utils.ACCOUNT_VALIDATION_CACHE_KEY"], "cross_file": ["kinto.core.utils.hmac_digest", "kinto.core.cache", "kinto.core.utils"]}, "requirement": {"Functionality": "This function retrieves the validation key for a given username from the cache. It first generates a cache key using the username and a secret key. Then, it retrieves the validation key from the cache using the cache key.", "Arguments": ":param username: String. The username for which the validation key is to be retrieved.\n:param registry: Dictionary. The registry containing the settings and cache.\n:return: The validation key for the given username."}, "tests": ["tests/plugins/test_accounts.py::AccountValidationCreationTest::test_validation_fail_bad_activation_key", "tests/plugins/test_accounts.py::AccountValidationCreationTest::test_validation_validates_user", "tests/plugins/test_accounts.py::AccountValidationCreationTest::test_create_account_stores_activated_field"], "indent": 4}
{"namespace": "sacred.config.signature.Signature.construct_arguments", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/signature.py", "signature_position": [70, 70], "body_position": [83, 91], "dependency": {"intra_class": ["sacred.config.signature.Signature._assert_no_duplicate_args", "sacred.config.signature.Signature._assert_no_missing_args", "sacred.config.signature.Signature._assert_no_unexpected_args", "sacred.config.signature.Signature._assert_no_unexpected_kwargs", "sacred.config.signature.Signature._fill_in_options", "sacred.config.signature.Signature._get_expected_args"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function constructs the arguments list and keyword arguments dictionary for a Signature instance. It ensures that the original explicit call arguments are preserved, missing arguments are filled in by name using options (if possible), default arguments are overridden by options, and it ensures that there are no unexpected arguments, conflicting values for a parameter in both args and kwargs, or unfilled parameters at the end of the process.", "Arguments": ":param self: Signature. An instance of the Signature class.\n:param args: list. The original explicit call arguments.\n:param kwargs: dict. The original explicit call keyword arguments.\n:param options: dict. The options to fill in missing arguments and override default arguments.\n:param bound: bool. Whether the Signature instance is bound to an object.\n:return: Tuple[list, dict]. The constructed args list and kwargs dictionary."}, "tests": ["tests/test_config/test_signature.py::test_construct_arguments_with_duplicate_args_raises_typeerror", "tests/test_config/test_signature.py::test_construct_arguments_with_unexpected_args_raises_typeerror", "tests/test_config/test_signature.py::test_construct_arguments_for_bound_method", "tests/test_config/test_signature.py::test_construct_arguments_does_not_overwrite_args_and_kwargs", "tests/test_config/test_signature.py::test_construct_arguments_overwrites_defaults"], "indent": 8}
{"namespace": "boto.dynamodb2.fields.GlobalIncludeIndex.schema", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/fields.py", "signature_position": [332, 333], "body_position": [334, 337], "dependency": {"intra_class": [], "intra_file": ["boto.dynamodb2.fields.GlobalBaseIndexField", "boto.dynamodb2.fields.GlobalBaseIndexField.schema", "boto.dynamodb2.fields.IncludeIndex", "boto.dynamodb2.fields.IncludeIndex.schema"], "cross_file": []}, "requirement": {"Functionality": "This function returns the schema data for the GlobalIncludeIndex class. It first retrieves the schema data from the its superclass and then updates it with the schema data from the GlobalBaseIndexField superclass.", "Arguments": ":param self: GlobalIncludeIndex. An instance of the GlobalIncludeIndex class.\n:return: Dictionary. The schema data for the GlobalIncludeIndex class."}, "tests": ["tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_include_index_throughput", "tests/unit/dynamodb2/test_table.py::IndexFieldTestCase::test_global_include_index"], "indent": 8}
{"namespace": "gunicorn.config.Config.set", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/config.py", "signature_position": [74, 74], "body_position": [75, 77], "dependency": {"intra_class": ["gunicorn.config.Config.settings", "gunicorn.config.Setting.set"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Set the value of a configuration setting in the Config instance. It checks if the setting exists in the instance and then sets the value.", "Arguments": ":param self: Config. An instance of the Config class.\n:param name: String. The name of the configuration setting to be set.\n:param value: Any. The value to be set for the configuration setting.\n:return: No return values."}, "tests": ["tests/test_config.py::test_statsd_changes_logger", "tests/test_config.py::test_post_request", "tests/test_statsd.py::test_dogstatsd_tags", "tests/test_config.py::test_bool_validation", "tests/test_statsd.py::test_prefix_multiple_dots"], "indent": 8}
{"namespace": "sacred.config.custom_containers.DogmaticDict.revelation", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/config/custom_containers.py", "signature_position": [108, 108], "body_position": [109, 117], "dependency": {"intra_class": ["sacred.config.custom_containers.DogmaticDict.fixed", "sacred.config.custom_containers.DogmaticDict.revelation"], "intra_file": ["sacred.config.custom_containers.DogmaticList", "sacred.config.custom_containers.DogmaticList.revelation"], "cross_file": []}, "requirement": {"Functionality": "This function returns a set of missing keys in the DogmaticDict instance. A key is missing if it is in the fixed set but not in the instance. These keys are added back to the instance with their corresponding values from the fixed set. If the value corresponding to a key is dogmatic, it recursively finds the missing keys in that value and adds them as '{key}.{subkey}' to the set of missing keys.", "Arguments": ":param self: DogmaticDict. An instance of the DogmaticDict class.\n:return: Set. The set of missing keys in the dictionary."}, "tests": ["tests/test_config/test_dogmatic_dict.py::test_revelation"], "indent": 8}
{"namespace": "datasette.utils.check_connection", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [953, 953], "body_position": [954, 969], "dependency": {"intra_class": [], "intra_file": ["datasette.utils.ConnectionProblem", "datasette.utils.SpatialiteConnectionProblem", "datasette.utils.escape_sqlite"], "cross_file": []}, "requirement": {"Functionality": "Check the connection to a SQLite database by executing a query to retrieve the names of all tables in the database. Then, for each table, it executes another query to retrieve the table information using the `PRAGMA` statement. If any error occurs during the execution of these queries, it raises specific exceptions based on the error message.", "Arguments": ":param conn: SQLite connection object. The connection to the SQLite database.\n:return: None."}, "tests": ["tests/test_utils.py::test_check_connection_spatialite_raises"], "indent": 4}
{"namespace": "wikipediaapi.WikipediaPage.langlinks", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [983, 983], "body_position": [994, 996], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch", "wikipediaapi.WikipediaPage._langlinks"], "intra_file": ["wikipediaapi.PagesDict"], "cross_file": []}, "requirement": {"Functionality": "This function returns all language links to pages in other languages. It is a wrapper for the MediaWiki API's query+langlinks module and the API:Langlinks page.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: PagesDict. A dictionary containing language links to pages in other languages."}, "tests": ["tests/langlinks_test.py::TestLangLinks::test_langlinks_urls", "tests/langlinks_test.py::TestLangLinks::test_langlinks_count", "tests/langlinks_test.py::TestLangLinks::test_langlinks_lang_keys", "tests/langlinks_test.py::TestLangLinks::test_jump_between_languages", "tests/langlinks_test.py::TestLangLinks::test_langlinks_no_langlink_count"], "indent": 8}
{"namespace": "boltons.dictutils.ManyToMany.remove", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [975, 975], "body_position": [976, 981], "dependency": {"intra_class": ["boltons.dictutils.ManyToMany.data", "boltons.dictutils.ManyToMany.inv"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Remove a key-value pair from the ManyToMany instance. It removes the value from the set associated with the key. If the list becomes empty after removal, the key is also removed from the dictionary. It also removes the key from the set associated with the value. If the list becomes empty after removal, the value is also removed from the dictionary.", "Arguments": ":param self: ManyToMany. An instance of the ManyToMany class.\n:param key: The key to remove from the `data` dictionary.\n:param val: The value to remove from the list associated with the key in the `data` dictionary.\n:return: No return values."}, "tests": ["tests/test_dictutils.py::test_many_to_many"], "indent": 8}
{"namespace": "litecli.packages.parseutils.extract_tables", "type": "function", "project_path": "Database/litecli", "completion_path": "Database/litecli/litecli/packages/parseutils.py", "signature_position": [149, 149], "body_position": [155, 165], "dependency": {"intra_class": [], "intra_file": ["litecli.packages.parseutils.extract_from_part", "litecli.packages.parseutils.extract_table_identifiers"], "cross_file": []}, "requirement": {"Functionality": "This function extracts the table names from an SQL statement. It uses the sqlparse library to parse the SQL statement and then extracts the table names from the parsed result.", "Arguments": ":param sql: String. The SQL statement to extract table names from.\n:return: List of tuples. Each tuple contains the schema, table, and alias of a table mentioned in the SQL statement."}, "tests": ["tests/test_parseutils.py::test_simple_select_multiple_tables", "tests/test_parseutils.py::test_select_with_hanging_comma_multiple_tables", "tests/test_parseutils.py::test_simple_update_table_with_schema", "tests/test_parseutils.py::test_simple_update_table", "tests/test_parseutils.py::test_simple_select_with_cols_multiple_tables"], "indent": 4}
{"namespace": "pymorphy2.opencorpora_dict.compile._to_paradigm", "type": "function", "project_path": "Text-Processing/pymorphy2", "completion_path": "Text-Processing/pymorphy2/pymorphy2/opencorpora_dict/compile.py", "signature_position": [241, 241], "body_position": [247, 270], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pymorphy2.utils.longest_common_substring"]}, "requirement": {"Functionality": "This function extracts a stem and paradigm pair from a given lexeme. The lexeme is a list of tuples, where each tuple contains a word form and its corresponding tag. The paradigm is a list of suffixes with associated tags and prefixes. It also extracts prefixes from each word form and checks if they are in the list of paradigm prefixes. If any prefix is not in the paradigm prefixes, the function sets the stem to an empty string and assigns empty prefixes to all word forms. Finally, the function extracts suffixes from each word form and creates a tuple of suffixes, tags, and prefixes.", "Arguments": ":param lexeme: List of tuples. A list of (word_form, tag) tuples representing a lexeme.\n:param paradigm_prefixes: List of strings. A list of prefixes that are allowed in the paradigm.\n:return: Tuple. A tuple containing the stem and a tuple of suffixes, tags, and prefixes."}, "tests": ["tests/test_opencorpora_dict.py::TestToParadigm::test_simple", "tests/test_opencorpora_dict.py::TestToParadigm::test_platina", "tests/test_opencorpora_dict.py::TestToParadigm::test_single_prefix", "tests/test_opencorpora_dict.py::TestToParadigm::test_multiple_prefixes_2", "tests/test_opencorpora_dict.py::TestToParadigm::test_no_prefix"], "indent": 4}
{"namespace": "pyramid.threadlocal.ThreadLocalManager.pop", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/threadlocal.py", "signature_position": [21, 21], "body_position": [22, 23], "dependency": {"intra_class": ["pyramid.threadlocal.ThreadLocalManager.stack"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function removes and returns the topmost item from the stack in the ThreadLocalManager instance.", "Arguments": ":param self: ThreadLocalManager. An instance of the ThreadLocalManager class.\n:return: The topmost item from the stack."}, "tests": ["tests/test_threadlocal.py::TestThreadLocalManager::test_push_and_pop"], "indent": 8}
{"namespace": "sqlite_utils.utils.suggest_column_types", "type": "function", "project_path": "Database/sqlite-utils", "completion_path": "Database/sqlite-utils/sqlite_utils/utils.py", "signature_position": [88, 88], "body_position": [89, 93], "dependency": {"intra_class": [], "intra_file": ["sqlite_utils.utils.types_for_column_types"], "cross_file": []}, "requirement": {"Functionality": "This function suggests the column types for a given set of records. It iterates over each record and its key-value pairs, and creates a dictionary of column types. It then calls another function to determine the suggested types for each column.", "Arguments": ":param records: List of dictionaries. The set of records for which column types need to be suggested.\n:return: The suggested column types for the given records."}, "tests": ["tests/test_suggest_column_types.py::test_suggest_column_types"], "indent": 4}
{"namespace": "sacred.utils.get_package_version", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [698, 698], "body_position": [700, 701], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.parse_version"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the version string of a package and parses it into a version object.", "Arguments": ":param name: String. The name of the package.\n:return: Version. The parsed version object of the package."}, "tests": ["tests/test_utils.py::test_get_package_version", "tests/test_utils.py::test_get_package_version_comparison"], "indent": 4}
{"namespace": "pyramid.i18n.Translations.merge", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/i18n.py", "signature_position": [309, 309], "body_position": [321, 326], "dependency": {"intra_class": ["pyramid.i18n.Translations._catalog", "pyramid.i18n.Translations.files"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Merge a Translations instance into the catalog of the input Translations instance. It updates the catalog and files with the same identifiers of the Translations instance to be merged.", "Arguments": ":param self: Translations. An instance of the Translations class.\n:param translations: Translations. A Translations instance containing the messages to be merged into the catalog.\n:return: Translations. The updated `Translations` instance (`self`) to allow for easy chaining of `merge` calls."}, "tests": ["tests/test_i18n.py::TestTranslations::test_merge_gnutranslations_not_translations", "tests/test_i18n.py::TestTranslations::test_merge_not_gnutranslations", "tests/test_i18n.py::TestTranslations::test_merge_gnutranslations"], "indent": 8}
{"namespace": "oletools.ooxml.get_type", "type": "function", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/ooxml.py", "signature_position": [172, 172], "body_position": [174, 217], "dependency": {"intra_class": [], "intra_file": ["oletools.ooxml.BadOOXML", "oletools.ooxml.CONTENT_TYPES_EXCEL", "oletools.ooxml.CONTENT_TYPES_PPT", "oletools.ooxml.CONTENT_TYPES_WORD", "oletools.ooxml.DOCTYPE_EXCEL", "oletools.ooxml.DOCTYPE_EXCEL_XML", "oletools.ooxml.DOCTYPE_MIXED", "oletools.ooxml.DOCTYPE_NONE", "oletools.ooxml.DOCTYPE_POWERPOINT", "oletools.ooxml.DOCTYPE_WORD", "oletools.ooxml.DOCTYPE_WORD_XML", "oletools.ooxml.EXCEL_XML_PROG_ID", "oletools.ooxml.FILE_CONTENT_TYPES", "oletools.ooxml.OFFICE_XML_PROGID_REGEX", "oletools.ooxml.WORD_XML_PROG_ID", "oletools.ooxml.XmlParser", "oletools.ooxml.XmlParser.__init__", "oletools.ooxml.XmlParser.is_single_xml", "oletools.ooxml.XmlParser.iter_xml", "oletools.ooxml.debug_str", "oletools.ooxml.logger"], "cross_file": ["oletools.common.io_encoding.uopen"]}, "requirement": {"Functionality": "This function determines the type of a file based on its content. It checks the file's XML structure and content types to identify if it is a Word document, Excel spreadsheet, PowerPoint presentation, or none of these.", "Arguments": ":param filename: String. The name of the file to be checked.\n:return: Integer. One of the DOCTYPE_* constants indicating the type of the file."}, "tests": ["tests/ooxml/test_basic.py::TestOOXML::test_rough_doctype"], "indent": 4}
{"namespace": "gunicorn.http.body.EOFReader.read", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/http/body.py", "signature_position": [145, 145], "body_position": [146, 174], "dependency": {"intra_class": ["gunicorn.http.body.EOFReader.buf", "gunicorn.http.body.EOFReader.finished", "gunicorn.http.body.EOFReader.unreader"], "intra_file": [], "cross_file": ["gunicorn.http.unreader.Unreader.read"]}, "requirement": {"Functionality": "Read a specified number of bytes from the input stream. It reads the data from the input stream and returns the requested number of bytes. If the end of the stream is reached, it returns an empty byte string.\nThe function first checks if the size parameter is an integer. If it's not, it raises a TypeError \"size must be an integral type\". Then it checks if the size is negative. If it is, it raises a ValueError \"Size must be positive.\". If the size is 0, the function returns an empty bytes string b\"\".\nIf all the data has been read from the stream, the function retrieves the data from the buffer, splits it into two parts - one with the requested size and the other with the rest of the data. It then resets the buffer, writes the remaining data to it, and returns the first part.\nElse, it reads data from the unreader and writes it to the buffer until the buffer's size exceeds the requested size. Then it stops reading and checks if there's more data to read. If there isn't, it sets a finish flag to True.\nFinally, the function retrieves the data from the buffer, splits it into two parts - one with the requested size and the other with the rest of the data. It then resets the buffer, writes the remaining data to it, and returns the first part.", "Arguments": ":param self: EOFReader. An instance of the EOFReader class.\n:param size: int. The number of bytes to read from the input stream.\n:return: bytes. The data read from the input stream."}, "tests": ["tests/test_http.py::test_eof_reader_read_invalid_size", "tests/test_http.py::test_eof_reader_read"], "indent": 8}
{"namespace": "flower.command.apply_options", "type": "function", "project_path": "System/flower", "completion_path": "System/flower/flower/command.py", "signature_position": [82, 82], "body_position": [84, 93], "dependency": {"intra_class": [], "intra_file": ["flower.command.is_flower_option"], "cross_file": ["flower.options.DEFAULT_CONFIG_FILE"]}, "requirement": {"Functionality": "This function applies options passed through the configuration file. It filters the options that are specific to the application and parses the command line to get the \"--conf\" option. It then parses the configuration file and the command line again to update the options. It will stop IOError during parsing if the configuration file's name is the same as the default configuration file's name.", "Arguments": ":param prog_name: String. The name of the program.\n:param argv: List of strings. The command line arguments passed to the program.\n:return: No return values."}, "tests": ["tests/unit/test_command.py::TestFlowerCommand::test_port", "tests/unit/test_command.py::TestConfOption::test_empty_conf", "tests/unit/test_command.py::TestFlowerCommand::test_task_runtime_metric_buckets_read_from_cmd_line", "tests/unit/test_command.py::TestConfOption::test_conf_abs", "tests/unit/test_command.py::TestFlowerCommand::test_address"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.model.Model.compute_rarest_windows", "type": "method", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/model.py", "signature_position": [517, 522], "body_position": [558, 617], "dependency": {"intra_class": ["msticpy.analysis.anomalous_sequence.model.Model.prior_probs", "msticpy.analysis.anomalous_sequence.model.Model.rare_window_likelihoods", "msticpy.analysis.anomalous_sequence.model.Model.rare_window_likelihoods_geo", "msticpy.analysis.anomalous_sequence.model.Model.rare_windows", "msticpy.analysis.anomalous_sequence.model.Model.rare_windows_geo", "msticpy.analysis.anomalous_sequence.model.Model.session_type", "msticpy.analysis.anomalous_sequence.model.Model.sessions"], "intra_file": ["msticpy.analysis.anomalous_sequence.model.SessionType", "msticpy.analysis.anomalous_sequence.model.SessionType.cmds_only", "msticpy.analysis.anomalous_sequence.model.SessionType.cmds_params_only"], "cross_file": ["msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the rarest windows and corresponding likelihood for each session. It uses a sliding window approach to identify the rarest window and its likelihood in each session. The function takes into account the length of the sliding window, whether to use start and end tokens, and whether to use the geometric mean for likelihood calculations.", "Arguments": ":param self: Model. An instance of the Model class.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, start and end tokens will be added to each session before calculations.\n:param use_geo_mean: bool. If True, the likelihoods of the sliding windows will be raised to the power of (1/window_len).\n:return: None. The function updates the rarest windows and corresponding likelihoods in the Model instance."}, "tests": ["tests/analysis/test_anom_seq_model.py::TestModel::test_compute_rarest_windows"], "indent": 8}
{"namespace": "fs.permissions.Permissions.parse", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/permissions.py", "signature_position": [174, 175], "body_position": [177, 180], "dependency": {"intra_class": ["fs.permissions.Permissions.__init__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function parses permissions in Linux notation and returns an instance of the Permissions class with the parsed permissions.", "Arguments": ":param cls: Class. The class object of the Permissions class.\n:param ls: Text. The string containing the permissions in Linux notation.\n:return: Permissions. An instance of the Permissions class with the parsed permissions."}, "tests": ["tests/test_permissions.py::TestPermissions::test_parse"], "indent": 8}
{"namespace": "alembic.testing.env.three_rev_fixture", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/testing/env.py", "signature_position": [305, 305], "body_position": [306, 379], "dependency": {"intra_class": [], "intra_file": ["alembic.testing.env.write_script"], "cross_file": ["alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.generate_revision", "alembic.util", "alembic.util.rev_id"]}, "requirement": {"Functionality": "This function generates three revision fixtures for a given configuration. It creates three revision IDs and generates corresponding revision scripts using the `ScriptDirectory` class. Each revision script contains an upgrade and downgrade function that execute SQL statements. The generated revision scripts are written to files.", "Arguments": ":param cfg: The configuration object used by the `ScriptDirectory` class.\n:return: Tuple of three revision IDs (a, b, c)"}, "tests": ["tests/test_command.py::RevisionEnvironmentTest::test_merge_cmd_revision_environment"], "indent": 4}
{"namespace": "boto.dynamodb2.table.Table.has_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [713, 713], "body_position": [745, 751], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.get_item"], "intra_file": [], "cross_file": ["boto.dynamodb2.exceptions.ItemNotFound", "boto.exception.JSONResponseError", "boto.dynamodb2.exceptions"]}, "requirement": {"Functionality": "This function checks whether an item (record) exists within a table in DynamoDB. It takes the key attributes as keyword arguments and optionally accepts a \"consistent\" parameter to perform a consistent read from DynamoDB. It also accepts an \"attributes\" parameter to specify the fields to fetch. It returns True if the item is present and False if not.", "Arguments": ":param self: Table. An instance of the Table class.\n:param kwargs: Key attributes of the item to check. (1) consistent [Optional]: Bool. Whether to perform a consistent read from DynamoDB. Defaults to False. (2) attributes [Optional]: List of strings. The fields to fetch. Defaults to None, which means all fields should be fetched.\n:return: Bool. True if the item is present, False if not."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_has_item"], "indent": 8}
{"namespace": "mopidy.internal.playlists.parse", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/playlists.py", "signature_position": [8, 8], "body_position": [9, 18], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.playlists.detect_asx_header", "mopidy.internal.playlists.detect_extm3u_header", "mopidy.internal.playlists.detect_pls_header", "mopidy.internal.playlists.detect_xspf_header", "mopidy.internal.playlists.parse_asx", "mopidy.internal.playlists.parse_extm3u", "mopidy.internal.playlists.parse_pls", "mopidy.internal.playlists.parse_urilist", "mopidy.internal.playlists.parse_xspf"], "cross_file": []}, "requirement": {"Functionality": "This function parses the given data and returns a list of parsed items. It uses a dictionary of handlers, where each handler is associated with a specific detector function. It iterates through the handlers and checks if the detector function returns True for the given data. If a match is found, it calls the corresponding parser function and returns the parsed items as a list. If no match is found, it parses the result as uris and returns the parsed items as a list.", "Arguments": ":param data: The data to be parsed.\n:return: List. The list of parsed items."}, "tests": ["tests/internal/test_playlists.py::test_parse_any_format_from_valid_data", "tests/internal/test_playlists.py::test_parse_from_invalid_data"], "indent": 4}
{"namespace": "boltons.funcutils.FunctionBuilder.from_func", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/funcutils.py", "signature_position": [868, 868], "body_position": [875, 898], "dependency": {"intra_class": ["boltons.funcutils.FunctionBuilder.__init__", "boltons.funcutils.FunctionBuilder._argspec_to_dict"], "intra_file": ["boltons.funcutils._IS_PY2", "boltons.funcutils._inspect_iscoroutinefunction"], "cross_file": []}, "requirement": {"Functionality": "This function creates a new instance of the FunctionBuilder class based on an existing function. The original function is not modified or stored. It also takes into account whether the function is a partial object or not.", "Arguments": ":param cls: type. The FunctionBuilder class.\n:param func: Callable object. The existing function to base the new instance on.\n:return: FunctionBuilder. The newly created instance of the FunctionBuilder class."}, "tests": ["tests/test_funcutils_fb.py::test_get_arg_names", "tests/test_funcutils_fb.py::test_defaults_dict", "tests/test_funcutils_fb_py3.py::test_remove_kwonly_arg", "tests/test_funcutils_fb_py3.py::test_get_arg_names", "tests/test_funcutils_fb_py3.py::test_defaults_dict"], "indent": 8}
{"namespace": "bentoml._internal.resource.CpuResource.validate", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/resource.py", "signature_position": [112, 112], "body_position": [113, 120], "dependency": {"intra_class": ["bentoml._internal.resource.CpuResource.from_system"], "intra_file": [], "cross_file": ["bentoml.exceptions.BentoMLConfigException"]}, "requirement": {"Functionality": "This function validates a CPU resource limit value. It checks if the value is negative and raises an exception if it is. It also compares the value with the system's available CPU resources and raises an exception if the value is greater than the system's available resources.", "Arguments": ":param cls: Class. The class itself.\n:param val: Float. The CPU resource limit value to validate.\n:return: No return values."}, "tests": ["tests/unit/_internal/test_resource.py::test_CpuResource"], "indent": 8}
{"namespace": "jwt.algorithms.HMACAlgorithm.prepare_key", "type": "method", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/algorithms.py", "signature_position": [254, 254], "body_position": [255, 265], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["jwt.exceptions.InvalidKeyError", "jwt.utils.force_bytes", "jwt.utils.is_pem_format", "jwt.utils.is_ssh_key"]}, "requirement": {"Functionality": "This function prepares the key for use in HMAC algorithm. It converts the key to bytes and checks if it is in PEM or SSH format. If it is, it raises an invalid key error \"The specified key is an asymmetric key or x509 certificate and should not be used as an HMAC secret.\" Otherwise, the key is returned as bytes.", "Arguments": ":param self: HMACAlgorithm. An instance of the HMACAlgorithm class.\n:param key: str or bytes. The key to be prepared for HMAC algorithm.\n:return: bytes. The prepared key for HMAC algorithm."}, "tests": ["tests/test_algorithms.py::TestAlgorithms::test_hmac_should_reject_nonstring_key", "tests/test_algorithms.py::TestAlgorithmsRFC7520::test_hmac_verify_should_return_true_for_test_vector", "tests/test_algorithms.py::TestAlgorithms::test_hmac_should_throw_exception"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.du", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [36, 36], "body_position": [37, 38], "dependency": {"intra_class": ["mrjob.fs.local.LocalFilesystem.ls"], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the total size of files in a given path.\nFirst converts the input path to a local file path format. Then, it iterate through all the files in the given path and get the file size. Finally, it sums up all the file sizes.\n", "Arguments": ":param self: LocalFilesystem, an instance of the LocalFilesystem class.\n:param path_glob: String. The file path or path pattern for which the total size needs to be calculated.\n:return: Integer. The total size of files in the given path.\n"}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_du"], "indent": 8}
{"namespace": "twilio.jwt.access_token.AccessToken.add_grant", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/access_token/__init__.py", "signature_position": [58, 58], "body_position": [60, 62], "dependency": {"intra_class": ["twilio.jwt.access_token.AccessToken.grants"], "intra_file": ["twilio.jwt.access_token.AccessTokenGrant"], "cross_file": []}, "requirement": {"Functionality": "This function adds a grant to the AccessToken instance. It checks if the grant is an instance of AccessTokenGrant and raises a ValueError if it is not.", "Arguments": ":param self: AccessToken. An instance of the AccessToken class.\n:param grant: The grant to be added to the AccessToken instance.\n:return: No return values."}, "tests": ["tests/unit/jwt/test_access_token.py::AccessTokenTest::test_playback_grant", "tests/unit/jwt/test_access_token.py::AccessTokenTest::test_video_grant", "tests/unit/jwt/test_access_token.py::AccessTokenTest::test_chat_grant", "tests/unit/jwt/test_access_token.py::AccessTokenTest::test_task_router_grant", "tests/unit/jwt/test_access_token.py::AccessTokenTest::test_conversations_grant"], "indent": 8}
{"namespace": "jinja2.utils.LRUCache.clear", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/utils.py", "signature_position": [480, 480], "body_position": [482, 484], "dependency": {"intra_class": ["jinja2.utils.LRUCache._mapping", "jinja2.utils.LRUCache._queue", "jinja2.utils.LRUCache._wlock"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Clear the LRUCache instance by removing all the items from the cache.", "Arguments": ":param self: LRUCache. An instance of the LRUCache class.\n:return: No return values."}, "tests": ["tests/test_utils.py::TestLRUCache::test_clear"], "indent": 8}
{"namespace": "falcon.util.structures.ETag.dumps", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/util/structures.py", "signature_position": [265, 265], "body_position": [275, 280], "dependency": {"intra_class": ["falcon.util.structures.ETag.is_weak"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function serializes the ETag object into a string that can be used in a precondition header. It checks if the ETag is weak and adds a weakness indicator if necessary.", "Arguments": ":param self: ETag. The current ETag instance.\n:return: str. The serialized ETag string, possibly prefixed by a weakness indicator \"W/\"."}, "tests": ["tests/test_utils.py::TestFalconUtils::test_etag_dumps_to_header_format"], "indent": 8}
{"namespace": "fs.path.isbase", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [443, 444], "body_position": [459, 461], "dependency": {"intra_class": [], "intra_file": ["fs.path.abspath", "fs.path.forcedir"], "cross_file": []}, "requirement": {"Functionality": "Take two paths - `path1` and `path2` as input. Check if `path1` is a base of `path2` by comparing their absolute paths. \n", "Arguments": ":param path1: String, a PyFilesytem path, e.g., ``'a/b/c'``.\n:param path2: String, a PyFilesytem path, e.g., ``'a/b/c'``.\n:return: Bool, True if path2 starts with path1. False otherwise.\n"}, "tests": ["tests/test_path.py::TestPathFunctions::test_isbase"], "indent": 4}
{"namespace": "kinto.core.openapi.OpenAPI.generate", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/openapi.py", "signature_position": [66, 66], "body_position": [67, 73], "dependency": {"intra_class": ["kinto.core.openapi.OpenAPI.request", "kinto.core.openapi.OpenAPI.security_definitions", "kinto.core.openapi.OpenAPI.settings"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates an OpenAPI specification based on the given conditions. It creates a base specification dictionary with the host, schemes, and \"securityDefinitions\". Then, it calls the generate method of the parent class, passing the base specification as the \"swagger\" parameter.", "Arguments": ":param self: OpenAPI. An instance of the OpenAPI class.\n:return: CorniceSwagger. The generated OpenAPI specification."}, "tests": ["tests/core/test_openapi.py::OpenAPITest::test_security_extensions"], "indent": 8}
{"namespace": "rest_framework.utils.mediatypes._MediaType.match", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/utils/mediatypes.py", "signature_position": [50, 50], "body_position": [52, 62], "dependency": {"intra_class": ["rest_framework.utils.mediatypes._MediaType.main_type", "rest_framework.utils.mediatypes._MediaType.params", "rest_framework.utils.mediatypes._MediaType.sub_type"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if a given MediaType object satisfies another MediaType object. It compares the parameters, subtypes, and main types of the two objects and returns True if they match.", "Arguments": ":param self: _MediaType. An instance of the _MediaType class.\n:param other: _MediaType. The MediaType object to compare with.\n:return: bool. True if the self MediaType satisfies the other MediaType, False otherwise."}, "tests": ["tests/test_negotiation.py::TestAcceptedMediaType::test_match_is_false_if_main_types_not_match", "tests/test_negotiation.py::TestAcceptedMediaType::test_mediatype_match_is_false_if_keys_not_match"], "indent": 8}
{"namespace": "pyramid.registry.Introspector.related", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [201, 201], "body_position": [202, 206], "dependency": {"intra_class": ["pyramid.registry.Introspector._categories", "pyramid.registry.Introspector._refs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the related introspectors based on the given introspector. It first retrieves the category name and discriminator from the input introspector. Then, it searches for the corresponding introspector in the categories dictionary. If the introspector is found, it returns the list of references associated with that introspector. If the introspector is not found, it raises a KeyError with the category name and discriminator.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param intr: The input introspectable to find related introspectors for.\n:return: List. The list of references associated with the input introspectable."}, "tests": ["tests/test_registry.py::TestIntrospector::test_related_fail", "tests/test_registry.py::TestIntrospector::test_related"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.delete_global_secondary_index", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [515, 515], "body_position": [535, 555], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.update_table", "boto.log", "boto"]}, "requirement": {"Functionality": "This function deletes a global secondary index in DynamoDB for a Table instance. It takes the name of the global secondary index as input and uses it to delete the index from a Table instance. If the global_index_name is not provided, this function logs a error message - \"You need to provide the global index name to delete_global_secondary_index method\" and return False.", "Arguments": ":param self: Table. An instance of the Table class.\n:param global_index_name: String. The name of the global secondary index to be deleted.\n:return: Bool. Returns True if the index is successfully deleted, False otherwise."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_delete_global_secondary_index"], "indent": 8}
{"namespace": "diffprivlib.tools.histograms.histogram", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/histograms.py", "signature_position": [57, 58], "body_position": [129, 158], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["diffprivlib.accountant.BudgetAccountant", "diffprivlib.accountant.BudgetAccountant.check", "diffprivlib.accountant.BudgetAccountant.load_default", "diffprivlib.accountant.BudgetAccountant.spend", "diffprivlib.utils.PrivacyLeakWarning", "diffprivlib.utils.check_random_state", "diffprivlib.utils.warn_unused_args", "diffprivlib.mechanisms.geometric.GeometricTruncated.randomise"]}, "requirement": {"Functionality": "This function computes the differentially private histogram of a set of data. It computes the histogram and adds noise to satisfy differential privacy. It also handles various parameters such as epsilon, bins, range, weights, density, random_state, and accountant.", "Arguments": ":param sample: array_like. The input data for which the histogram needs to be computed.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon to be applied.\n:param bins: int or sequence of scalars or str, default: 10. The number of equal-width bins in the given range. It can also be a sequence defining a monotonically increasing array of bin edges.\n:param range: (float, float), optional. The lower and upper range of the bins. Values outside the range are ignored.\n:param weights: array_like, optional. An array of weights, of the same shape as the input data. Each value in the input data contributes its associated weight towards the bin count.\n:param density: bool, optional. If False, the result will contain the number of samples in each bin. If True, the result is the value of the probability density function at the bin, normalized such that the integral over the range is 1.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. Accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: hist: array. The values of the histogram. bin_edges: array of dtype float. The bin edges."}, "tests": ["tests/tools/test_histogram.py::TestHistogram::test_no_params", "tests/tools/test_histogram.py::TestHistogram::test_different_result", "tests/tools/test_histogram.py::TestHistogram::test_accountant", "tests/tools/test_histogram.py::TestHistogram::test_default_accountant", "tests/tools/test_histogram.py::TestHistogram::test_density"], "indent": 4}
{"namespace": "fs.info.Info.suffixes", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/info.py", "signature_position": [229, 230], "body_position": [239, 242], "dependency": {"intra_class": ["fs.info.Info.get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of any suffixes in the name of an instance of the Info class. It checks if the name starts with a dot and only contains one dot, in which case it returns an empty list. Otherwise, it splits the name by dots and returns a list of the suffixes.", "Arguments": ":param self: Info. An instance of the Info class.\n:return: List[Text]. A list of any suffixes in the name."}, "tests": ["tests/test_info.py::TestInfo::test_suffix"], "indent": 8}
{"namespace": "googleapiclient.model.BaseModel._build_query", "type": "method", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/model.py", "signature_position": [164, 164], "body_position": [173, 185], "dependency": {"intra_class": ["googleapiclient.model.BaseModel.alt_param"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function builds a query string by encoding the given query parameters into an HTTP URI query string. It first checks if there is an alternate parameter and adds it to the parameters dictionary. Then, it iterates through the key-value pairs in the parameters dictionary. If the value is a list, it iterates through the elements of the list, encodes them into UTF-8, and adds them to the list of tuples. If the value is a string and callable, it encodes it into UTF-8 and adds it to the list of tuples. Finally, it returns the query string with the encoded parameters.", "Arguments": ":param self: BaseModel. An instance of the BaseModel class.\n:param params: dict. The query parameters as a dictionary.\n:return: str. The query parameters properly encoded into an HTTP URI query string."}, "tests": ["tests/test_model.py::TestBaseModel::test_build_query"], "indent": 8}
{"namespace": "mssqlcli.mssqlbuffer._is_query_executable", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/mssqlbuffer.py", "signature_position": [24, 27], "body_position": [28, 50], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mssqlcli.packages.parseutils.utils.is_open_quote"]}, "requirement": {"Functionality": "Check if an SQL statement is executable. It checks if the statement is a complete command by verifying if it ends with 'GO' (unless it is surrounded by an open quote). It also removes comments and checks for open comments in the statement.", "Arguments": ":param sql: String. The SQL statement to be checked.\n:return: Bool. True if the SQL statement is executable, False otherwise."}, "tests": ["tests/test_multiline.py::TestMssqlCliMultiline::test_multiline_completeness"], "indent": 4}
{"namespace": "boltons.ioutils.MultiFileReader.read", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [576, 576], "body_position": [582, 591], "dependency": {"intra_class": ["boltons.ioutils.MultiFileReader._fileobjs", "boltons.ioutils.MultiFileReader._index", "boltons.ioutils.MultiFileReader._joiner"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function reads data from multiple files seamlessly. It reads up to the specified amount of data and returns in the appropriate type of string (bytes or text) for the input. If the files are exhausted, it returns an empty string.", "Arguments": ":param self: MultiFileReader. An instance of the MultiFileReader class.\n:param amt: int. The maximum amount of data to read. If not specified, it reads all the data from the files. Defaults to None.\n:return: str. The read data from the files."}, "tests": ["tests/test_ioutils.py::TestMultiFileReader::test_open", "tests/test_ioutils.py::TestMultiFileReader::test_read_seek_text", "tests/test_ioutils.py::TestMultiFileReader::test_read_seek_bytes"], "indent": 8}
{"namespace": "zulipterminal.platform_code.normalized_file_path", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/platform_code.py", "signature_position": [71, 71], "body_position": [76, 79], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.platform_code.PLATFORM"], "cross_file": []}, "requirement": {"Functionality": "This function normalizes file paths based on the platform. If the platform is WSL (Windows Subsystem for Linux), it converts Unix-style paths to Windows-style paths by replacing forward slashes with backslashes.", "Arguments": ":param path: str. The file path to be normalized.\n:return: str. The normalized file path."}, "tests": ["tests/platform_code/test_platform_code.py::test_normalized_file_path"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledStringIO.len", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [514, 514], "body_position": [516, 525], "dependency": {"intra_class": ["boltons.ioutils.SpooledStringIO.buffer", "boltons.ioutils.SpooledStringIO.len", "boltons.ioutils.SpooledStringIO.read"], "intra_file": ["boltons.ioutils.READ_CHUNK_SIZE"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the number of codepoints in the file by reading the file in chunks and counting the length of each chunk.", "Arguments": ":param self: SpooledStringIO. An instance of the SpooledStringIO class.\n:return: int. The number of codepoints in the file."}, "tests": ["tests/test_ioutils.py::TestSpooledStringIO::test_len_rollover", "tests/test_ioutils.py::TestSpooledStringIO::test_len_no_rollover"], "indent": 8}
{"namespace": "alembic.script.write_hooks._invoke", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/write_hooks.py", "signature_position": [42, 44], "body_position": [53, 60], "dependency": {"intra_class": [], "intra_file": ["alembic.script.write_hooks._registry"], "cross_file": ["alembic.util", "alembic.util.exc.CommandError"]}, "requirement": {"Functionality": "This function invokes the formatter registered for the given name. It retrieves the formatter from the registry based on the name, and then calls the formatter with the provided revision and options.", "Arguments": ":param name: str. The name of a formatter in the registry. If no formatter with the given name is registered, it raises a command error \"No formatter with name '{name}' registered\".\n:param revision: str. An instance of the MigrationRevision class.\n:param options: Mapping[str, Union[str, int]]. A dictionary containing keyword arguments passed to the specified formatter.\n:return: No return values."}, "tests": ["tests/test_post_write.py::HookTest::test_invoke"], "indent": 4}
{"namespace": "prometheus_client.multiprocess.MultiProcessCollector.collect", "type": "method", "project_path": "System/prometheus-client", "completion_path": "System/prometheus-client/prometheus_client/multiprocess.py", "signature_position": [156, 156], "body_position": [157, 158], "dependency": {"intra_class": ["prometheus_client.multiprocess.MultiProcessCollector._path", "prometheus_client.multiprocess.MultiProcessCollector.merge"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Collect data from multiple files and merge them into a single result. It first retrieves a list of file paths that match the pattern \"*.db\" in the specified directory. Then, it merge files in accumulate mode.", "Arguments": ":param self: MultiProcessCollector. An instance of the MultiProcessCollector class.\n:return: The merged result of the collected data."}, "tests": ["tests/test_multiprocess.py::TestMultiProcess::test_collect_preserves_help", "tests/test_multiprocess.py::TestMultiProcess::test_collect"], "indent": 8}
{"namespace": "boltons.tableutils.Table.to_text", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tableutils.py", "signature_position": [575, 575], "body_position": [583, 600], "dependency": {"intra_class": ["boltons.tableutils.Table._data", "boltons.tableutils.Table._width", "boltons.tableutils.Table.headers", "boltons.tableutils.Table.to_text"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the textual representation of a Table object. It includes the header row at the top and formats the data in a table-like structure. Each cell is first tried to be converted to a string. If that fails, it is converted to a repr string. If it exceeds the maximum length, it is truncated and an ellipsis is added. The text is padded with spaces to be centered in the cell. Each column is separated by ' | '. The header row is separated from the data by a line of dashes, where the intersection of each column and the header row is '-|-'.", "Arguments": ":param self: Table. An instance of the Table class.\n:param with_headers: bool. Whether to include a header row at the top. It defaults to True if not specified.\n:param maxlen: int. The maximum length of data in each cell. It defaults to None if not specified.\n:return: str. The textual representation of the Table object."}, "tests": ["tests/test_tableutils.py::test_table_dicts"], "indent": 8}
{"namespace": "mrjob.setup.UploadDirManager.uri", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/setup.py", "signature_position": [332, 332], "body_position": [335, 341], "dependency": {"intra_class": ["mrjob.setup.UploadDirManager._path_to_name", "mrjob.setup.UploadDirManager.prefix"], "intra_file": [], "cross_file": ["mrjob.parse.is_uri"]}, "requirement": {"Functionality": "This function returns the URI for a given path. If the path is already a URI, it is returned as is. If the path is a known local file, the URI is constructed using the prefix and the corresponding name. If the path is neither a URI nor a known local file, a ValueError is raised with the error message '%r is not a URI or a known local file'.", "Arguments": ":param self: UploadDirManager. An instance of the UploadDirManager class.\n:param path: str. The path for which the URI is to be obtained.\n:return: str. The URI corresponding to the given path."}, "tests": ["tests/test_setup.py::UploadDirManagerTestCase::test_unknown_uri", "tests/test_setup.py::UploadDirManagerTestCase::test_uri"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table._put_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [824, 824], "body_position": [831, 837], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.put_item"]}, "requirement": {"Functionality": "This function is used by the Item instances to save themselves to a Table instance.", "Arguments": ":param self: Table. An instance of the Table class.\n:param item_data: Item. Several Item instances to be saved.\n:param expects: Optional. The expected conditions for the save operation.\n:return: Bool. Returns True after saving the item to the table."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_private_put_item"], "indent": 8}
{"namespace": "mingus.core.intervals.measure", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [253, 253], "body_position": [263, 267], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mingus.core.notes", "mingus.core.notes.note_to_int"]}, "requirement": {"Functionality": "This function takes two musical notes as input and returns an integer representing the number of half-note steps (0 - 11) between them.\n", "Arguments": ":param note1: str. The first musical note.\n:param note2: str. The second musical note.\n:return: int. The number of half-note steps between note1 and note2.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_valid_measure"], "indent": 4}
{"namespace": "boto.ec2containerservice.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2containerservice/__init__.py", "signature_position": [39, 39], "body_position": [40, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.ec2containerservice.layer1.EC2ContainerServiceConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the EC2ContainerServiceConnection class from the boto library. It creates an instance of the EC2ContainerServiceConnection class with the specified region name and additional keyword parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword parameters that can be passed to the EC2ContainerServiceConnection class.\n:return: EC2ContainerServiceConnection. An instance of the EC2ContainerServiceConnection class connected to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestEc2ContainerserviceConnection::test_connect_to_region"], "indent": 4}
{"namespace": "mopidy.config.types.Integer.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [155, 155], "body_position": [156, 164], "dependency": {"intra_class": ["mopidy.config.types.Integer._choices", "mopidy.config.types.Integer._maximum", "mopidy.config.types.Integer._minimum", "mopidy.config.types.Integer._required"], "intra_file": ["mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators", "mopidy.config.validators.validate_choice", "mopidy.config.validators.validate_maximum", "mopidy.config.validators.validate_minimum", "mopidy.config.validators.validate_required"]}, "requirement": {"Functionality": "Deserialize a value into an Integer object. It decodes the input value, validates it based on the specified constraints, and returns the deserialized integer value.", "Arguments": ":param self: Integer. An instance of the Integer class.\n:param value: The value to be deserialized.\n:return: int. The deserialized integer value."}, "tests": ["tests/config/test_types.py::TestInteger::test_deserialize_enforces_choices", "tests/config/test_types.py::TestInteger::test_deserialize_enforces_maximum", "tests/config/test_types.py::TestInteger::test_deserialize_enforces_minimum", "tests/config/test_types.py::TestPort::test_invalid_ports", "tests/config/test_types.py::TestPort::test_valid_ports"], "indent": 8}
{"namespace": "alembic.autogenerate.api.AutogenContext._within_batch", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/api.py", "signature_position": [398, 398], "body_position": [399, 401], "dependency": {"intra_class": ["alembic.autogenerate.api.AutogenContext._has_batch"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a generator that sets a flag indicating that the context is within a batch, performs some operations, and then resets the flag.", "Arguments": ":param self: AutogenContext. An instance of the AutogenContext class.\n:return: Iterator[None]. An iterator that yields None."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_add_unique_constraint_batch", "tests/test_autogen_render.py::AutogenRenderTest::test_render_add_index_batch", "tests/test_autogen_render.py::AutogenRenderTest::test_add_unique_constraint_schema_batch", "tests/test_autogen_render.py::AutogenRenderTest::test_render_add_index_schema_batch", "tests/test_autogen_render.py::AutogenRenderTest::test_drop_index_schema_batch"], "indent": 8}
{"namespace": "oletools.msodde.field_is_blacklisted", "type": "function", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/msodde.py", "signature_position": [559, 559], "body_position": [571, 641], "dependency": {"intra_class": [], "intra_file": ["oletools.msodde.FIELD_BLACKLIST", "oletools.msodde.FIELD_BLACKLIST_CMDS", "oletools.msodde.FIELD_SWITCH_REGEX", "oletools.msodde.FIELD_WORD_REGEX", "oletools.msodde.logger"], "cross_file": []}, "requirement": {"Functionality": "This function checks if the given field contents match any of the contents in the field black_list. It also checks the number of arguments and switches in the contents to determine if it matches the blacklist.", "Arguments": ":param contents: String. The field contents to be checked.\n:return: Bool. True if the contents match the blacklist, False otherwise."}, "tests": ["tests/msodde/test_blacklist.py::TestBlacklist::test_matches"], "indent": 4}
{"namespace": "pycoin.satoshi.stackops.do_OP_HASH160", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/satoshi/stackops.py", "signature_position": [126, 126], "body_position": [127, 128], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pycoin.encoding.hash.hash160"]}, "requirement": {"Functionality": "Pop the top item from the stack, calculate its hash160 value, and append the result back to the stack.\n", "Arguments": ":param stack: List, a stack containing items on which to perform the operation.\n:return: No return values.\n"}, "tests": ["tests/script/stackops_test.py::StackOpsTest::test_do_OP_HASH160"], "indent": 4}
{"namespace": "kinto.core.authorization.RouteFactory.fetch_shared_objects", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/authorization.py", "signature_position": [213, 213], "body_position": [226, 234], "dependency": {"intra_class": ["kinto.core.authorization.RouteFactory._get_accessible_objects", "kinto.core.authorization.RouteFactory._object_id_match", "kinto.core.authorization.RouteFactory.shared_ids"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function fetches objects that are readable or writable for the current principals based on the given permissions. It sets shared ids to the context with the fetched object IDs. If no object is shared, it returns None.", "Arguments": ":param self: RouteFactory. An instance of the RouteFactory class.\n:param perm: The permission to check for the objects.\n:param principals: The current principals.\n:param get_bound_permissions: Bool. Whether to get bound permissions for the object ID match.\n:return: List of object IDs that are readable or writable for the current principals."}, "tests": ["tests/core/test_authorization.py::RouteFactoryTest::test_fetch_shared_objects_uses_pattern_if_on_plural_endpoint", "tests/core/test_authorization.py::RouteFactoryTest::test_fetch_shared_objects_uses_get_bound_permission_callback", "tests/core/test_authorization.py::RouteFactoryTest::test_fetch_shared_objects_sets_shared_ids_from_results", "tests/core/test_authorization.py::RouteFactoryTest::test_fetch_shared_objects_sets_shared_ids_if_empty"], "indent": 8}
{"namespace": "diffprivlib.models.naive_bayes.GaussianNB._noisy_class_counts", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/naive_bayes.py", "signature_position": [280, 280], "body_position": [281, 299], "dependency": {"intra_class": ["diffprivlib.models.naive_bayes.GaussianNB.epsilon"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the noisy class counts for each unique class label in the given target variable. It uses a privacy mechanism to add noise to the actual class counts in order to protect privacy.", "Arguments": ":param self: GaussianNB. An instance of the GaussianNB class.\n:param y: numpy array. The target variable containing class labels.\n:param random_state: int or RandomState instance. The random state used for generating noise.\n:return: numpy array. The noisy class counts for each unique class label."}, "tests": ["tests/models/test_GaussianNB.py::TestGaussianNB::test_noisy_count"], "indent": 8}
{"namespace": "gunicorn.http.unreader.Unreader.read", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/http/unreader.py", "signature_position": [20, 20], "body_position": [21, 50], "dependency": {"intra_class": ["gunicorn.http.unreader.Unreader.buf", "gunicorn.http.unreader.Unreader.chunk"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to read a specific size of data from a buffer. The function first checks if the size parameter is an integer or long. If it is not, it raises a TypeError \"size parameter must be an int or long.\". Then it checks if the size is zero, in which case it returns an empty byte string. If the size is negative, it sets the size to None.\nNext, the function seeks to the end of the buffer. If the size is None and there is data in the buffer, it reads the data from the buffer, resets the buffer, and returns the data. If the size is None and there is no data in the buffer, it get chunk data and returns it.\nIf the size is not None, the function enters a loop that continues until the amount of data in the buffer is more than the specified size. In each iteration, it get chunk data and writes it to the buffer if there is any data. If there is no data in the chunk, it reads the data from the buffer, resets the buffer, and returns the data. Finally, it reads the data from the buffer, writes the remaining data to a new buffer, and returns the desired amount of data.", "Arguments": ":param self: Unreader. An instance of the Unreader class.\n:param size: Integer. The number of bytes to read from the buffer. If not provided, it reads all the remaining bytes.\n:return: Bytes. The read bytes from the buffer."}, "tests": ["tests/test_http.py::test_unreader_read_zero_size", "tests/test_http.py::test_unreader_read_when_size_is_none", "tests/test_http.py::test_unreader_raises_excpetion_on_invalid_size", "tests/test_http.py::test_unreader_unread", "tests/test_http.py::test_unreader_read_with_nonzero_size"], "indent": 8}
{"namespace": "boltons.urlutils.URL.navigate", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/urlutils.py", "signature_position": [657, 657], "body_position": [675, 704], "dependency": {"intra_class": ["boltons.urlutils.URL.__init__", "boltons.urlutils.URL.fragment", "boltons.urlutils.URL.from_parts", "boltons.urlutils.URL.host", "boltons.urlutils.URL.normalize", "boltons.urlutils.URL.password", "boltons.urlutils.URL.path", "boltons.urlutils.URL.path_parts", "boltons.urlutils.URL.port", "boltons.urlutils.URL.query_params", "boltons.urlutils.URL.scheme", "boltons.urlutils.URL.username"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a factory method that returns a new URL object based on a given destination. It is used to navigate relative links easily. The newly created URL is normalized before being returned.", "Arguments": ":param self: URL. An instance of the URL class.\n:param dest: str or URL. The destination to navigate to. It can be a string or a URL object.\n:return: URL. The newly created URL object."}, "tests": ["tests/test_urlutils.py::test_chained_navigate", "tests/test_urlutils.py::test_navigate", "tests/test_urlutils.py::test_rel_navigate"], "indent": 8}
{"namespace": "trailscraper.iam.Statement.merge", "type": "method", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/iam.py", "signature_position": [90, 90], "body_position": [92, 104], "dependency": {"intra_class": ["trailscraper.iam.Statement.Action", "trailscraper.iam.Statement.Effect", "trailscraper.iam.Statement.Resource", "trailscraper.iam.Statement.__init__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Merge two Statement instances into one. It checks if the effects of the two statements are the same. If not, it raises a ValueError \"Trying to combine two statements with differing effects: {self effect} {other's effect}\". Then, it merges the actions and resources of the two statements, sort them and save them into a new Statement instance.", "Arguments": ":param self: Statement. The first Statement instance to be merged.\n:param other: Statement. The second Statement instance to be merged.\n:return: Statement. The merged Statement instance."}, "tests": ["tests/iam/statement_test.py::test_should_merge_deny_statments", "tests/iam/statement_test.py::test_should_merge_two_identical_statements", "tests/iam/statement_test.py::test_should_merge_two_statements_with_different_actions_and_resources", "tests/iam/statement_test.py::test_should_fail_if_effects_arent_the_same"], "indent": 8}
{"namespace": "threatingestor.Ingestor.run", "type": "method", "project_path": "Security/threatingestor", "completion_path": "Security/threatingestor/threatingestor/__init__.py", "signature_position": [99, 99], "body_position": [101, 107], "dependency": {"intra_class": ["threatingestor.Ingestor.config", "threatingestor.Ingestor.run_forever", "threatingestor.Ingestor.run_once", "threatingestor.Ingestor.statsd"], "intra_file": [], "cross_file": ["threatingestor.config.Config.daemon"]}, "requirement": {"Functionality": "This function runs the Ingestor instance either once or forever, depending on the configuration. If the configuration specifies to run as a daemon, it runs the instance in a loop. Otherwise, it runs the instance once to completion.", "Arguments": ":param self: Ingestor. An instance of the Ingestor class.\n:return: No return values."}, "tests": ["tests/test_ingestor.py::TestIngestor::test_run_checks_config_daemon"], "indent": 8}
{"namespace": "jinja2.idtracking.symbols_for_node", "type": "function", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/idtracking.py", "signature_position": [22, 24], "body_position": [25, 27], "dependency": {"intra_class": [], "intra_file": ["jinja2.idtracking.Symbols", "jinja2.idtracking.Symbols.__init__", "jinja2.idtracking.Symbols.analyze_node"], "cross_file": []}, "requirement": {"Functionality": "This function creates a Symbols instance for a given node and parent symbols.", "Arguments": ":param node: nodes.Node. The node for which symbols need to be created.\n:param parent_symbols: Optional[Symbols]. The parent symbols to be used as the parent of the created Symbols instance. Defaults to None.\n:return: Symbols. The created Symbols instance."}, "tests": ["tests/test_idtracking.py::test_if_branching_multi_scope", "tests/test_idtracking.py::test_basics", "tests/test_idtracking.py::test_if_branching_stores_undefined", "tests/test_idtracking.py::test_complex", "tests/test_idtracking.py::test_if_branching_stores"], "indent": 4}
{"namespace": "boto.redshift.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/redshift/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.redshift.layer1.RedshiftConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the RedshiftConnection class from the boto library. It creates a connection to the specified region using the connect function.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: RedshiftConnection. The connection object to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestRedshiftConnection::test_connect_to_region"], "indent": 4}
{"namespace": "jinja2.bccache.MemcachedBytecodeCache.dump_bytecode", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/bccache.py", "signature_position": [395, 395], "body_position": [396, 406], "dependency": {"intra_class": ["jinja2.bccache.MemcachedBytecodeCache.client", "jinja2.bccache.MemcachedBytecodeCache.ignore_memcache_errors", "jinja2.bccache.MemcachedBytecodeCache.prefix", "jinja2.bccache.MemcachedBytecodeCache.timeout"], "intra_file": ["jinja2.bccache.Bucket.bytecode_to_string", "jinja2.bccache.Bucket.key", "jinja2.bccache._MemcachedClient.set"], "cross_file": []}, "requirement": {"Functionality": "This function is used to dump the bytecode of a bucket into the Memcached cache. The key is generated by concatenating the prefix and the bucket key, and the bytecode is converted into a string. If the timeout is specified, it is used to set the timeout for the key-value pair. If an exception occurs during the process and the flag to ignore errors is not set, the exception is re-raised.", "Arguments": ":param self: MemcachedBytecodeCache. An instance of the MemcachedBytecodeCache class.\n:param bucket: Bucket. The bucket containing the bytecode to be dumped into the cache.\n:return: None."}, "tests": ["tests/test_bytecode_cache.py::TestMemcachedBytecodeCache::test_exception", "tests/test_bytecode_cache.py::TestMemcachedBytecodeCache::test_dump_load"], "indent": 8}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.touchz", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [340, 340], "body_position": [341, 344], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem.invoke_hadoop"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create an empty file at the specified path in the Hadoop filesystem. It invokes the Hadoop command to perform the operation and raises an IOError \"Could not touchz path\" if the operation fails.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:param path: String. The path where the empty file should be created.\n:return: No return values."}, "tests": ["tests/fs/test_hadoop.py::HadoopFSTestCase::test_touchz"], "indent": 8}
{"namespace": "kinto.core.storage.generators.Generator.match", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/storage/generators.py", "signature_position": [23, 23], "body_position": [30, 32], "dependency": {"intra_class": ["kinto.core.storage.generators.Generator._regexp", "kinto.core.storage.generators.Generator.regexp"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function validates whether the given object id matches the expected format defined by the generator. It checks if the object id matches the regular expression pattern defined by the generator.", "Arguments": ":param self: Generator. An instance of the Generator class.\n:param object_id: The object id to be validated.\n:return: bool. Returns True if the object id matches the expected format, otherwise False."}, "tests": ["tests/core/test_storage.py::GeneratorTest::test_uuid_generator_pattern_is_not_restricted_to_uuid4", "tests/core/test_storage.py::GeneratorTest::test_uuid_generator_pattern_allows_uuid_only"], "indent": 8}
{"namespace": "boltons.funcutils.FunctionBuilder.get_sig_str", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/funcutils.py", "signature_position": [822, 822], "body_position": [828, 839], "dependency": {"intra_class": ["boltons.funcutils.FunctionBuilder.varkw", "boltons.funcutils.FunctionBuilder.annotations", "boltons.funcutils.FunctionBuilder.args", "boltons.funcutils.FunctionBuilder.varargs", "boltons.funcutils.FunctionBuilder.kwonlyargs"], "intra_file": ["boltons.funcutils.inspect_formatargspec"], "cross_file": []}, "requirement": {"Functionality": "This function returns the signature of a function as a string. The signature includes the function arguments and annotations if specified.", "Arguments": ":param self: FunctionBuilder. An instance of the FunctionBuilder class.\n:param with_annotations: bool. Whether to include annotations in the signature. Defaults to True.\n:return: str. The function signature as a string."}, "tests": ["tests/test_funcutils_fb.py::test_get_invocation_sig_str", "tests/test_funcutils_fb_py3.py::test_get_invocation_sig_str"], "indent": 12}
{"namespace": "authlib.common.encoding.json_b64encode", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/common/encoding.py", "signature_position": [63, 63], "body_position": [64, 66], "dependency": {"intra_class": [], "intra_file": ["authlib.common.encoding.json_dumps", "authlib.common.encoding.to_bytes", "authlib.common.encoding.urlsafe_b64encode"], "cross_file": []}, "requirement": {"Functionality": "Encode the given text as JSON and then base64 encode it. If the input text is already a dictionary, it is first converted to JSON format. Then, the resulting JSON string is encoded.", "Arguments": ":param text: The text to be encoded. It can be either a string or a dictionary.\n:return: The base64 encoded string."}, "tests": ["tests/jose/test_ecdh_1pu.py::ECDH1PUTest::test_ecdh_1pu_key_agreement_computation_appx_b", "tests/jose/test_jwe.py::JWETest::test_deserialize_json_fails_if_protected_header_contains_unknown_field_while_private_fields_restricted"], "indent": 4}
{"namespace": "chatette.cli.interactive_commands.command_strategy.CommandStrategy.get_unit_type_from_str", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/cli/interactive_commands/command_strategy.py", "signature_position": [122, 122], "body_position": [128, 139], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["chatette.parsing.utils.ALIAS_SYM", "chatette.parsing.utils.INTENT_SYM", "chatette.parsing.utils.SLOT_SYM", "chatette.utils.UnitType", "chatette.utils.UnitType.alias", "chatette.utils.UnitType.intent", "chatette.utils.UnitType.slot"]}, "requirement": {"Functionality": "This function takes a string of unit_type as input and transforms it into the corresponding the value of the unit type. It checks if the input string matches any of the predefined values for UnitType and returns the corresponding value. If there is no match, it returns None.", "Arguments": ":param unit_type_str: String. The input string to be transformed into a `UnitType` value.\n:return: UnitType. The corresponding `UnitType` value for the input string, or `None` if there is no match."}, "tests": ["tests/unit-testing/cli/interactive_commands/test_command_strategy.py::TestGetUnitTypeFromStr::test_correct_str"], "indent": 8}
{"namespace": "boto.dynamodb2.items.Item.save", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [415, 415], "body_position": [445, 458], "dependency": {"intra_class": ["boto.dynamodb2.items.Item.build_expects", "boto.dynamodb2.items.Item.mark_clean", "boto.dynamodb2.items.Item.needs_save", "boto.dynamodb2.items.Item.prepare_full", "boto.dynamodb2.items.Item.table"], "intra_file": [], "cross_file": ["boto.dynamodb2.table.Table._put_item"]}, "requirement": {"Functionality": "This function saves all data of an Item instance to DynamoDB. By default, it checks if any fields have changed since the Item was constructed, and if so, it fails to save in order to prevent data loss. If the overwrite parameter is set to True, the item will be forcibly overwritten in DynamoDB, even if the data has changed.", "Arguments": ":param self: Item. An instance of the Item class.\n:param overwrite: Bool. Whether to forcibly overwrite the item in DynamoDB, even if the data has changed. Defaults to False.\n:return: Bool. True if the save is successful, False if no save was performed."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_save_with_changes_overwrite", "tests/unit/dynamodb2/test_table.py::ItemTestCase::test_save_with_changes"], "indent": 8}
{"namespace": "exodus_bundler.bundling.Bundle.hash", "type": "method", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [876, 876], "body_position": [878, 880], "dependency": {"intra_class": ["exodus_bundler.bundling.Bundle.files"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function computes a hash based on the current contents of the bundle. It first retrieves the hashes of all the files in the bundle, sorts them, combines them into a single string, encodes it in UTF-8, and then computes the SHA256 hash of the combined string. Finally, it returns the hexadecimal representation of the computed hash.", "Arguments": ":param self: Bundle. An instance of the Bundle class.\n:return: str. The computed hash based on the contents of the bundle."}, "tests": ["tests/test_bundling.py::test_bundle_hash", "tests/test_bundling.py::test_bundle_root"], "indent": 8}
{"namespace": "twilio.jwt.client.ClientCapabilityToken.allow_client_outgoing", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/client/__init__.py", "signature_position": [52, 52], "body_position": [59, 63], "dependency": {"intra_class": ["twilio.jwt.client.ClientCapabilityToken.capabilities"], "intra_file": ["twilio.jwt.client.ScopeURI", "twilio.jwt.client.ScopeURI.__init__", "twilio.jwt.client.ScopeURI.add_param"], "cross_file": []}, "requirement": {"Functionality": "This function allows the user of the ClientCapabilityToken to make outgoing connections. It creates a scope URI with the given application SID and any additional keyword arguments provided. If there are additional keyword arguments, they are added as parameters to the scope URI. Finally, the scope URI is added to the capabilities dictionary of the ClientCapabilityToken instance.", "Arguments": ":param self: ClientCapabilityToken. An instance of the ClientCapabilityToken class.\n:param application_sid: str. The application SID to contact.\n:param kwargs: Additional keyword arguments to be passed to the application.\n:return: No return values."}, "tests": ["tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_outbound_permissions", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_outbound_permissions_params", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_decode"], "indent": 8}
{"namespace": "kinto.core.resource.schema.ResourceReponses.get_and_bind", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/resource/schema.py", "signature_position": [485, 485], "body_position": [489, 504], "dependency": {"intra_class": ["kinto.core.resource.schema.ResourceReponses.default_schemas"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function wraps resource colander response schemas for a specific endpoint and method. It creates a dictionary of status codes mapping cloned and binded responses based on the default schemas, endpoint-specific schemas, and method-specific schemas. The response include type responses, method args and endpoint args, finded from this instance.", "Arguments": ":param self: ResourceReponses. An instance of the ResourceReponses class.\n:param endpoint_type: String. The type of endpoint.\n:param method: String. The HTTP method.\n:param **kwargs: Additional keyword arguments.\n:return: Dict. A dictionary of status codes mapping cloned and binded responses."}, "tests": ["tests/core/resource/test_schema.py::ResourceReponsesTest::test_get_and_bind_assign_resource_schema_to_plural_endpoint", "tests/core/resource/test_schema.py::ResourceReponsesTest::test_responses_doesnt_have_permissions_if_not_bound", "tests/core/resource/test_schema.py::ResourceReponsesTest::test_get_and_bind_assign_resource_schema_to_object_endpoint"], "indent": 8}
{"namespace": "bplustree.memory.FileMemory.set_metadata", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [235, 235], "body_position": [236, 246], "dependency": {"intra_class": ["bplustree.memory.FileMemory._tree_conf", "bplustree.memory.FileMemory._write_page_in_tree"], "intra_file": [], "cross_file": ["bplustree.const.ENDIAN", "bplustree.const.OTHERS_BYTES", "bplustree.const.PAGE_REFERENCE_BYTES", "bplustree.const.TreeConf"]}, "requirement": {"Functionality": "Set the metadata of the FileMemory instance. It sets the root node page and tree configuration parameters in the instance.", "Arguments": ":param self: FileMemory. An instance of the FileMemory class.\n:param root_node_page: Integer. The page number of the root node.\n:param tree_conf: TreeConf. The tree configuration object containing page size, order, key size, and value size.\n:return: No return values."}, "tests": ["tests/test_memory.py::test_file_memory_metadata"], "indent": 8}
{"namespace": "mrjob.conf.load_opts_from_mrjob_conf", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [233, 234], "body_position": [256, 260], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf._expanded_mrjob_conf_path", "mrjob.conf._load_opts_from_mrjob_conf"], "cross_file": []}, "requirement": {"Functionality": "This function loads a list of dictionaries representing the options in the mrjob.conf file for a specific runner. It resolves includes and returns [(path, values)]. If the conf_path is not found, it returns [(None, {})].\nFirst checks if already_loaded is None and assigns an empty list to it if it is. Then it expands the conf path. Finally, it load options.\n", "Arguments": ":param runner_alias: str. String identifier of the runner type, e.g. \"emr\", \"local\", etc.\n:param conf_path: str. Location of the file to load.\n:param already_loaded: list. List of real (according to os.path.realpath()) conf paths that have already been loaded. (used by load_opts_from_mrjob_confs() function).\n:return: list. A list of dictionaries representing the options in the mrjob.conf file for a specific runner. [(path, values)]\n"}, "tests": ["tests/test_conf.py::MRJobBasicConfTestCase::test_include_order_beats_include", "tests/test_conf.py::MRJobBasicConfTestCase::test_relative_include", "tests/test_conf.py::MRJobBasicConfTestCase::test_include_relative_to_real_path", "tests/test_conf.py::MRJobBasicConfTestCase::test_doubly_recursive_include", "tests/test_conf.py::MRJobBasicConfTestCase::test_load_mrjob_conf_and_load_opts"], "indent": 4}
{"namespace": "datasette.utils.escape_fts", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [885, 886], "body_position": [887, 893], "dependency": {"intra_class": [], "intra_file": ["datasette.utils._escape_fts_re"], "cross_file": []}, "requirement": {"Functionality": "This function escapes a full-text search query by adding double quotes around each individual term. It also handles cases where the query has unbalanced double quotes by adding an extra double quote at the end. The function splits the query into individual terms using a regular expression, removes any empty or duplicate terms, and then joins the terms back together with double quotes around each term.", "Arguments": ":param query: String. The full-text search query to be escaped.\n:return: String. The escaped full-text search query."}, "tests": ["tests/test_utils.py::test_escape_fts"], "indent": 4}
{"namespace": "pyramid.renderers.render_to_response", "type": "function", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [72, 74], "body_position": [117, 132], "dependency": {"intra_class": [], "intra_file": ["pyramid.renderers.RendererHelper", "pyramid.renderers.RendererHelper.__init__", "pyramid.renderers.RendererHelper.render_to_response"], "cross_file": ["pyramid.path.caller_package", "pyramid.util.hide_attrs", "pyramid.request.Request.response", "pyramid.request.Request.registry"]}, "requirement": {"Functionality": "This function uses a renderer to render the value (or set of values), and uses the result of the renderer's ``__call__`` method (usually a string or Unicode) as the response body.", "Arguments": ":param renderer_name: String. The name of the renderer to be used. It can be a template or a static renderer.\n:param value: Any. For template renderings, this should be a dictionary.  For other renderers, this will need to be whatever sort of value the renderer expects.\n:param request: Request. The request object that provides system values to the renderer. It is used to provide the most correct 'system' values such as `request` and `context`.\n:param package: String. The name of the package to be used for resolving relative asset specifications. If not provided, the package name of the caller of this function will be used as the package.\n:param response: Response. The response object to be used for rendering. If not provided, a new response object will be created for each call.\n:return: String. The result of the renderer's ``__call__`` method (usually a string or Unicode)."}, "tests": ["tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_add_renderer", "tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_add_template", "tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_add_renderer_explicitrenderer", "tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_add_renderer_twice"], "indent": 4}
{"namespace": "mopidy.config.types.Pair.serialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [261, 261], "body_position": [262, 280], "dependency": {"intra_class": ["mopidy.config.types.Pair._optional_pair", "mopidy.config.types.Pair._separator", "mopidy.config.types.Pair._subtypes"], "intra_file": ["mopidy.config.types.String.serialize"], "cross_file": []}, "requirement": {"Functionality": "Serialize a pair of values into a string representation. It first serializes the first value using the appropriate subtype's serialization, then serializes the second value using the appropriate subtype's serialization. If the display flag is False and the pair is optional and the serialized values are the same, it returns only the serialized first value. Otherwise, it returns a string representation of the pair with the separator between the serialized values.", "Arguments": ":param self: Pair. An instance of the Pair class.\n:param value: The pair of values to be serialized.\n:param display: Bool. Whether to display the serialized values. Defaults to False.\n:return: String. The serialized representation of the pair."}, "tests": ["tests/config/test_types.py::TestPair::test_serialize_with_custom_separator", "tests/config/test_types.py::TestPair::test_serialize_nested_pair", "tests/config/test_types.py::TestPair::test_serialize_returns_single_value_with_optional_pair", "tests/config/test_types.py::TestPair::test_serialize"], "indent": 8}
{"namespace": "boto.s3.key.Key.get_contents_to_filename", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/key.py", "signature_position": [1668, 1673], "body_position": [1722, 1739], "dependency": {"intra_class": ["boto.s3.key.Key.get_contents_to_file", "boto.s3.key.Key.last_modified", "boto.s3.key.Key.open"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves an object from S3 using the name of the Key object as the key in S3 and stores the contents of the object to a file specified by 'filename'. It provides various options for customization such as specifying additional headers, using a callback function to report progress, setting the granularity of the callback, retrieving a torrent file, using a resumable download handler, overriding response headers, and specifying a particular version of the object.", "Arguments": ":param self: Key. An instance of the Key class.\n:param filename: String. The filename of where to put the file contents.\n:param headers: Dict. Any additional headers to send in the request.\n:param cb: Function. A callback function that will be called to report progress on the upload.\n:param num_cb: Int. If a callback is specified with the cb parameter, this parameter determines the granularity of the callback by defining the maximum number of times the callback will be called during the file transfer.\n:param torrent: Bool. If True, returns the contents of a torrent file as a string.\n:param res_download_handler: ResumableDownloadHandler. If provided, this handler will perform the download.\n:param response_headers: Dict. A dictionary containing HTTP headers/values that will override any headers associated with the stored object in the response.\n:param version_id: Str. The ID of a particular version of the object. If this parameter is not supplied but the Key object has a \"version_id\" attribute, that value will be used when retrieving the object. You can set the Key object's \"version_id\" attribute to None to always grab the latest version from a version-enabled bucket.\n:return: No return values."}, "tests": ["tests/unit/s3/test_key.py::TestFileError::test_file_error"], "indent": 8}
{"namespace": "zulipterminal.config.themes.parse_themefile", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/config/themes.py", "signature_position": [191, 193], "body_position": [194, 219], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.config.themes.REQUIRED_STYLES", "zulipterminal.config.themes.StyleSpec", "zulipterminal.config.themes.ThemeSpec"], "cross_file": []}, "requirement": {"Functionality": "This function takes a dictionary of theme styles and a color depth including 1, 16, 256 and 2^24 as input and returns a list of theme specifications in the urwid format. It iterates over the theme styles dictionary and converts the color codes and properties based on the specified color depth. The converted theme specifications are then added to the list.", "Arguments": ":param theme_styles: Dict[Optional[str], Tuple[Any, Any]]. A dictionary containing the theme styles where the keys are style names and the values are tuples of foreground and background colors.\n:param color_depth: int. The color depth to be used for converting the color codes. It can be 1, 16, 256, or 2^24.\n:return: ThemeSpec. A list of theme specifications in the urwid format."}, "tests": ["tests/config/test_themes.py::test_parse_themefile"], "indent": 4}
{"namespace": "boltons.strutils.asciify", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/strutils.py", "signature_position": [431, 431], "body_position": [448, 461], "dependency": {"intra_class": [], "intra_file": ["boltons.strutils.DEACCENT_MAP"], "cross_file": []}, "requirement": {"Functionality": "This function converts a given string, `text`, into a bytestring with only ASCII characters. It also performs basic deaccenting for European characters.", "Arguments": ":param text: str or unicode. The string to be converted into an ASCII bytestring.\n:param ignore: bool. Configures the final encoding to either ignore remaining unasciified unicode or replace it. Defaults to False.\n:return: byte. The converted ASCII bytestring."}, "tests": ["tests/test_strutils.py::test_asciify"], "indent": 4}
{"namespace": "boto.ec2.address.Address.disassociate", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/address.py", "signature_position": [116, 116], "body_position": [121, 130], "dependency": {"intra_class": ["boto.ec2.address.Address.association_id", "boto.ec2.address.Address.connection", "boto.ec2.address.Address.public_ip"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.disassociate_address"]}, "requirement": {"Functionality": "Disassociate this Elastic IP address from a currently running instance. If the address has an allocation ID, it disassociates the address using the allocation ID. Otherwise, it disassociates the address using the public IP.", "Arguments": ":param self: Address. An instance of the Address class.\n:param dry_run: Bool. Whether to perform a dry run of the disassociation. Defaults to False.\n:return: The result of the disassociation operation."}, "tests": ["tests/unit/ec2/test_address.py::AddressTest::test_disassociate_calls_connection_disassociate_address_with_correct_args", "tests/unit/ec2/test_address.py::AddressWithAllocationTest::test_disassociate_calls_connection_disassociate_address_with_correct_args", "tests/unit/ec2/test_address.py::AddressWithNetworkInterfaceTest::test_disassociate_calls_connection_disassociate_address_with_correct_args"], "indent": 8}
{"namespace": "datasette.utils.asgi.Request.post_body", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/asgi.py", "signature_position": [113, 113], "body_position": [114, 121], "dependency": {"intra_class": ["datasette.utils.asgi.Request.receive"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function reads the body of a POST request asynchronously. It continuously receives messages from the request until there is no more body to read, and appends the body content to a byte string. It then returns the complete body content.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: bytes. The body content of the POST request."}, "tests": ["tests/test_internals_request.py::test_request_post_body"], "indent": 8}
{"namespace": "folium.features.VegaLite.vegalite_major_version", "type": "method", "project_path": "Scientific-Engineering/folium", "completion_path": "Scientific-Engineering/folium/folium/features.py", "signature_position": [323, 323], "body_position": [324, 329], "dependency": {"intra_class": ["folium.features.VegaLite.data"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the major version number of the Vega-Lite schema used in the VegaLite instance. It extracts the major version number from the \"$schema\" attribute in the instance's data.", "Arguments": ":param self: VegaLite. An instance of the VegaLite class.\n:return: int. The major version number of the Vega-Lite schema used in the instance."}, "tests": ["tests/test_features.py::test_vegalite_major_version"], "indent": 8}
{"namespace": "faker.providers.credit_card.Provider._generate_number", "type": "method", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/providers/credit_card/__init__.py", "signature_position": [190, 190], "body_position": [197, 213], "dependency": {"intra_class": ["faker.providers.credit_card.Provider.luhn_lookup"], "intra_file": [], "cross_file": ["faker.providers.BaseProvider.numerify"]}, "requirement": {"Functionality": "This function generates a credit card number based on the given prefix and length. It first initializes the number with the prefix and then generates random digits to fill the remaining length. It then calculates the check digit using the Luhn algorithm and appends it to the number.", "Arguments": ":param self: Provider. An instance of the Provider class.\n:param prefix: String. The start of the credit card number.\n:param length: Integer. The length of the credit card number to generate.\n:return: String. The generated credit card number."}, "tests": ["tests/providers/test_credit_card.py::TestCreditCardProvider::test_jcb16", "tests/providers/test_credit_card.py::TestCreditCardProvider::test_jcb15", "tests/providers/test_credit_card.py::TestCreditCardProvider::test_diners_club", "tests/providers/test_credit_card.py::TestCreditCardProvider::test_visa13", "tests/providers/test_credit_card.py::TestCreditCardProvider::test_discover"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem._cat_file", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [52, 52], "body_position": [53, 57], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": ["mrjob.cat.decompress"]}, "requirement": {"Functionality": "Reads a file from the local filesystem and yields its content in chunks of bytes.\nFirst converts the file path from a file URI format to a local file path format. Then, it iterates over the file content in chunks.\n", "Arguments": ":param self: LocalFilesystem, an instance of the LocalFilesystem class.\n:param path: String, the URI or path of the file to be read.\n:return: bytes. Yields chunks of content from the file.\n"}, "tests": ["tests/fs/test_local.py::CatTestCase::test_cat_gz", "tests/fs/test_local.py::CatTestCase::test_yields_lines", "tests/fs/test_local.py::CatTestCase::test_cat_uncompressed", "tests/fs/test_local.py::CatTestCase::test_cat_file_uri", "tests/fs/test_local.py::CatTestCase::test_cat_bz2"], "indent": 8}
{"namespace": "falcon.asgi.reader.BufferedReader.peek", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/asgi/reader.py", "signature_position": [242, 242], "body_position": [243, 256], "dependency": {"intra_class": ["falcon.asgi.reader.BufferedReader._buffer", "falcon.asgi.reader.BufferedReader._buffer_len", "falcon.asgi.reader.BufferedReader._buffer_pos", "falcon.asgi.reader.BufferedReader._chunk_size", "falcon.asgi.reader.BufferedReader._source", "falcon.asgi.reader.BufferedReader._trim_buffer"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function peeks into the buffered data and returns the specified number of bytes. It first checks if the specified size is valid, and then trims the buffer if necessary. If the buffer does not have enough data, it reads from the source asynchronously and adds the chunks to the buffer until the desired size is reached. Finally, it returns the requested number of bytes from the buffer.", "Arguments": ":param self: BufferedReader. An instance of the BufferedReader class.\n:param size: Integer. The number of bytes to peek into the buffer. Defaults to -1, which means peeking the entire buffer.\n:return: Bytes. The peeked bytes from the buffer."}, "tests": ["tests/asgi/test_buffered_reader.py::test_read_until_shared_boundary", "tests/asgi/test_buffered_reader.py::test_peek_at_eof"], "indent": 8}
{"namespace": "threatingestor.state.State.get_state", "type": "method", "project_path": "Security/threatingestor", "completion_path": "Security/threatingestor/threatingestor/state.py", "signature_position": [31, 31], "body_position": [33, 36], "dependency": {"intra_class": ["threatingestor.state.State.cursor"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the state string for a given plugin from the database. It executes a SQL query to fetch the state from the \"states\" table based on the provided plugin name.", "Arguments": ":param self: State. An instance of the State class.\n:param name: String. The name of the plugin for which the state is to be retrieved.\n:return: String. The state string for the given plugin. If no state is found, it returns None."}, "tests": ["tests/test_state.py::TestState::test_state_updates_known_state", "tests/test_state.py::TestState::test_state_saves"], "indent": 8}
{"namespace": "mingus.core.value.determine", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/value.py", "signature_position": [237, 237], "body_position": [254, 281], "dependency": {"intra_class": [], "intra_file": ["mingus.core.value.base_values"], "cross_file": []}, "requirement": {"Functionality": "This function analyzes the given value and returns a tuple containing its parts. The tuple respectively consists of the base note value, the number of\ndots, and the ratio.\nThis function recognizes all the base values, triplets, quintuplets, septuplets and up to four dots. The values are matched on range.\n", "Arguments": ":param value: Int. The value to be analyzed.\n:return: Tuple. The tuple consists of the base note value, the number of dots, and the ratio.\n"}, "tests": ["tests/unit/core/test_value.py::test_value::test_determine", "tests/unit/core/test_value.py::test_value::test_determine_imperfect"], "indent": 4}
{"namespace": "twilio.jwt.client.ScopeURI.to_payload", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/client/__init__.py", "signature_position": [107, 107], "body_position": [108, 114], "dependency": {"intra_class": ["twilio.jwt.client.ScopeURI.params", "twilio.jwt.client.ScopeURI.privilege", "twilio.jwt.client.ScopeURI.service"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts the instance into a payload string. It first checks if there are any parameters in the instance. If there are, it sorts the parameters alphabetically and encodes them. Then, it constructs the parameter string by adding a \"?\" at the beginning. If there are no parameters, an empty string is used. Finally, it returns the payload string by formatting the service, privilege, and parameter string into a specific format - \"scope:{service}:{privilege}{parameter string}\".", "Arguments": ":param self: ScopeURI. An instance of the ScopeURI class.\n:return: String."}, "tests": ["tests/unit/jwt/test_client.py::ScopeURITest::test_to_payload_with_params_encoded", "tests/unit/jwt/test_client.py::ScopeURITest::test_to_payload_with_params", "tests/unit/jwt/test_client.py::ScopeURITest::test_to_payload_no_params"], "indent": 8}
{"namespace": "pythonforandroid.prerequisites.CmakePrerequisite.darwin_checker", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [357, 357], "body_position": [358, 361], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.prerequisites.Prerequisite._darwin_get_brew_formula_location_prefix"], "cross_file": []}, "requirement": {"Functionality": "Check if the prerequisite for CMake on macOS is met. It checks if the brew formula for CMake is installed on the system.", "Arguments": ":param self: CmakePrerequisite. An instance of the CmakePrerequisite class.\n:return: Bool. True if the brew formula for CMake is installed, False otherwise."}, "tests": ["tests/test_prerequisites.py::TestCmakePrerequisite::test_darwin_checker"], "indent": 8}
{"namespace": "hbmqtt.codecs.encode_string", "type": "function", "project_path": "Communications/hbmqtt", "completion_path": "Communications/hbmqtt/hbmqtt/codecs.py", "signature_position": [90, 90], "body_position": [91, 93], "dependency": {"intra_class": [], "intra_file": ["hbmqtt.codecs.int_to_bytes"], "cross_file": []}, "requirement": {"Functionality": "Encode the given string into bytes using utf-8 encoding. Add the length of the encoded data as a prefix of 2 bytes before the actual data.\n", "Arguments": ":param string: String, a string to be encoded.\n:return: Bytes, the encoded string as bytes.\n"}, "tests": ["tests/test_codecs.py::TestCodecs::test_encode_string"], "indent": 4}
{"namespace": "pycorrector.en_spell.EnSpell.candidates", "type": "method", "project_path": "Text-Processing/pycorrector", "completion_path": "Text-Processing/pycorrector/pycorrector/en_spell.py", "signature_position": [90, 90], "body_position": [96, 97], "dependency": {"intra_class": ["pycorrector.en_spell.EnSpell.check_init", "pycorrector.en_spell.EnSpell.edits1", "pycorrector.en_spell.EnSpell.edits2", "pycorrector.en_spell.EnSpell.known"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates possible spelling corrections for a given word. It checks whether zero, one, or two edits are needed to correct the word. If zero edit is needed, it returns the set of the given words. If one edit is needed, it returns the set of known words by applying one edit. If two edits are needed, it returns the set of known words by applying two edits. If no corrections are found, it returns the original word. It checks if the EnSpell instance has been initialized before performing the operation.", "Arguments": ":param self: EnSpell. An instance of the EnSpell class.\n:param word: String. The word for which spelling corrections need to be generated.\n:return: Set of strings. The set of possible spelling corrections for the word."}, "tests": ["tests/en_spell_bug_fix_test.py::EnBugTestCase::test_en_bug_correct2", "tests/en_spell_dict_test.py::TestEnSpell::test_candidates"], "indent": 8}
{"namespace": "ehforwarderbot.chat.PrivateChat.verify", "type": "method", "project_path": "Communications/ehforwarderbot", "completion_path": "Communications/ehforwarderbot/ehforwarderbot/chat.py", "signature_position": [675, 675], "body_position": [676, 678], "dependency": {"intra_class": [], "intra_file": ["ehforwarderbot.chat.Chat", "ehforwarderbot.chat.ChatMember", "ehforwarderbot.chat.Chat.members", "ehforwarderbot.chat.BaseChat.verify"], "cross_file": []}, "requirement": {"Functionality": "This function verifies the validity of a PrivateChat instance. It first calls the same method of the superclass, and then checks if all members of the chat are valid chat member. If any member is not valid, an assertion error is raised.", "Arguments": ":param self: PrivateChat. An instance of the PrivateChat class.\n:return: No return values."}, "tests": ["tests/test_chat.py::test_verify_missing_uid"], "indent": 8}
{"namespace": "pythonforandroid.bootstrap.Bootstrap.get_bootstrap", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/bootstrap.py", "signature_position": [298, 298], "body_position": [304, 317], "dependency": {"intra_class": ["pythonforandroid.bootstrap.Bootstrap.bootstraps"], "intra_file": [], "cross_file": ["pythonforandroid.logger.logger"]}, "requirement": {"Functionality": "This function returns an instance of a bootstrap with the given name. It sets the bootstrap directory correctly and ensures that the bootstrap class is accessed in the correct way.", "Arguments": ":param cls: Class. The Bootstrap class.\n:param name: String. The name of the bootstrap to retrieve.\n:param ctx: Context. The context object.\n:return: Instance of a bootstrap with the given name."}, "tests": ["tests/test_bootstrap.py::TestBootstrapBasic::test_attributes", "tests/test_distribution.py::TestDistribution::test_folder_exist", "tests/test_bootstrap.py::TestBootstrapBasic::test_build_dist_dirs", "tests/test_distribution.py::TestDistribution::test_get_distributions_error_ndk_api", "tests/test_distribution.py::TestDistribution::test_delete"], "indent": 8}
{"namespace": "twilio.jwt.client.ClientCapabilityToken.allow_event_stream", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/client/__init__.py", "signature_position": [76, 76], "body_position": [80, 84], "dependency": {"intra_class": ["twilio.jwt.client.ClientCapabilityToken.capabilities"], "intra_file": ["twilio.jwt.client.ScopeURI", "twilio.jwt.client.ScopeURI.__init__", "twilio.jwt.client.ScopeURI.add_param"], "cross_file": []}, "requirement": {"Functionality": "This function allows the user of the ClientCapabilityToken instance to access their event stream. It creates a scope URI with the necessary parameters and adds it to the capabilities dictionary of the instance.", "Arguments": ":param self: ClientCapabilityToken. An instance of the ClientCapabilityToken class.\n:param kwargs: Keyword arguments that can be used to specify additional parameters for the event stream.\n:return: No return values."}, "tests": ["tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_encode_full_payload", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_events", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_events_with_filters", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_decode"], "indent": 8}
{"namespace": "alembic.operations.ops.CreatePrimaryKeyOp.to_constraint", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [281, 283], "body_position": [284, 292], "dependency": {"intra_class": ["alembic.operations.ops.CreatePrimaryKeyOp.columns", "alembic.operations.ops.CreatePrimaryKeyOp.constraint_name", "alembic.operations.ops.CreatePrimaryKeyOp.kw", "alembic.operations.ops.CreatePrimaryKeyOp.schema", "alembic.operations.ops.CreatePrimaryKeyOp.table_name"], "intra_file": [], "cross_file": ["alembic.operations.schemaobj", "alembic.operations.schemaobj.SchemaObjects", "alembic.operations.schemaobj.SchemaObjects.primary_key_constraint", "alembic.runtime.migration.MigrationContext"]}, "requirement": {"Functionality": "This function converts the CreatePrimaryKeyOp object into a PrimaryKeyConstraint object. It creates a schema object based on the given migration context and uses it to create the primary key constraint.", "Arguments": ":param self: CreatePrimaryKeyOp. An instance of the CreatePrimaryKeyOp class.\n:param migration_context: Optional. The migration context to be used. Defaults to None.\n:return: PrimaryKeyConstraint. The created PrimaryKeyConstraint object."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_add_pk_no_orig"], "indent": 8}
{"namespace": "kinto.core.authorization.RouteFactory.get_permission_object_id", "type": "method", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/authorization.py", "signature_position": [236, 236], "body_position": [245, 261], "dependency": {"intra_class": ["kinto.core.authorization.RouteFactory.on_plural_endpoint", "kinto.core.authorization.RouteFactory.resource_name"], "intra_file": [], "cross_file": ["kinto.core.utils", "kinto.core.utils.instance_uri", "kinto.core.utils.strip_uri_prefix"]}, "requirement": {"Functionality": "This function returns the permission object id for the current request. It determines the object URI based on the request path and the specified object_id. If the request is on a plural endpoint and object_id is provided, it finds the object URI by inspecting the \"plural\" service and its sibling \"object\" service.", "Arguments": ":param self: RouteFactory. An instance of the RouteFactory class.\n:param request: The current request object.\n:param object_id: The object id to be used in the object URI. Defaults to None.\n:return: The permission object id for the current request."}, "tests": ["tests/core/test_authorization.py::GuestAuthorizationPolicyTest::test_perm_object_id_is_naive_if_no_object_path_exists"], "indent": 8}
{"namespace": "wal_e.worker.pg.wal_transfer.WalSegment.from_ready_archive_status", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/worker/pg/wal_transfer.py", "signature_position": [68, 68], "body_position": [69, 87], "dependency": {"intra_class": ["wal_e.worker.pg.wal_transfer.WalSegment.__init__", "wal_e.worker.pg.wal_transfer.WalSegment.path"], "intra_file": [], "cross_file": ["wal_e.storage"]}, "requirement": {"Functionality": "This function generates WalSegment instances based on the files in the archive_status directory of the given xlog_dir. It iterates through the files in the directory, filters out non-segment files, and creates a WalSegment instance for each segment file.", "Arguments": ":param xlog_dir: String. The directory path where the xlog files are stored.\n:return: Generator. Yields WalSegment instances for each segment file in the archive_status directory."}, "tests": ["tests/test_wal_segment.py::test_multi_search", "tests/test_wal_segment.py::test_simple_search"], "indent": 8}
{"namespace": "mopidy.config._load", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/__init__.py", "signature_position": [151, 151], "body_position": [152, 181], "dependency": {"intra_class": [], "intra_file": ["mopidy.config._load_file", "mopidy.config.logger"], "cross_file": ["mopidy.internal.path", "mopidy.internal.path.expand_path"]}, "requirement": {"Functionality": "This function loads configuration settings from multiple sources and returns a dictionary containing the loaded configuration. It first creates a `configparser.RawConfigParser` instance and sets the inline comment prefixes. Then, it loads the configuration from the builtin defaults by reading the strings in the `defaults` list. Next, it iterates over the `files` list and loads the configuration from each file. If a file is a directory, it iterates over the files in the directory and loads the configuration from each file with the \".conf\" suffix. After loading the configuration from all sources, it creates a dictionary `raw_config` where each section is a key and the corresponding value is a dictionary of key-value pairs for that section. Finally, it updates the `raw_config` dictionary with any command line overrides specified in the `overrides` list.", "Arguments": ":param files: List of strings. A list of file paths or directories containing configuration files.\n:param defaults: List of strings. A list of default configuration strings.\n:param overrides: List of tuples. A list of tuples where each tuple contains the section, key, and value for a command line override.\n:return: Dictionary. A dictionary containing the loaded configuration settings."}, "tests": ["tests/config/test_config.py::LoadConfigTest::test_load_directory_only_conf_files", "tests/config/test_config.py::LoadConfigTest::test_load_single_default", "tests/config/test_config.py::LoadConfigTest::test_load_single_file", "tests/config/test_config.py::LoadConfigTest::test_load_ignore_inline_comment", "tests/config/test_config.py::LoadConfigTest::test_load_missing_file"], "indent": 4}
{"namespace": "diffprivlib.mechanisms.base.bernoulli_neg_exp", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/mechanisms/base.py", "signature_position": [234, 234], "body_position": [254, 269], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.mechanisms.base.bernoulli_neg_exp"], "cross_file": ["diffprivlib.utils.check_random_state"]}, "requirement": {"Functionality": "This function samples from the Bernoulli distribution with parameter exp(-gamma). It generates a random number based on the given gamma value and returns either 0 or 1.", "Arguments": ":param gamma: Float. The parameter to sample from Bernoulli(exp(-gamma)). Must be non-negative.\n:param random_state: Int or RandomState, optional. Controls the randomness of the mechanism. To obtain a deterministic behavior during randomization, \"random_state\" has to be fixed to an integer.\n:return: Int. One sample from the Bernoulli(exp(-gamma)) distribution."}, "tests": ["tests/mechanisms/test_BernoulliNegExp.py::TestBernoulliNegExp::test_output_domain", "tests/mechanisms/test_BernoulliNegExp.py::TestBernoulliNegExp::test_bad_rng", "tests/mechanisms/test_BernoulliNegExp.py::TestBernoulliNegExp::test_zero_gamma", "tests/mechanisms/test_BernoulliNegExp.py::TestBernoulliNegExp::test_bad_gamma", "tests/mechanisms/test_BernoulliNegExp.py::TestBernoulliNegExp::test_infinite_gamma"], "indent": 4}
{"namespace": "boltons.statsutils.Stats.get_histogram_counts", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/statsutils.py", "signature_position": [557, 557], "body_position": [575, 610], "dependency": {"intra_class": ["boltons.statsutils.Stats._get_bin_bounds", "boltons.statsutils.Stats.data", "boltons.statsutils.Stats.min"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function produces a list of (bin, count) pairs that represents a histogram of the Stats object's data using fixed-width bins.\n", "Arguments": ":param self: Stats. An instance of the Stats class.\n:param bins: int or list of float. The maximum number of bins or the list of floating-point bin boundaries. Defaults to the output of Freedman's algorithm.\n:param bin_digits: int. Number of digits used to round down the bin boundaries. Defaults to 1.\n:return: list of (bin, count) pairs. The histogram counts of the Stats object's data.\n"}, "tests": ["tests/test_statsutils_histogram.py::test_check_sum"], "indent": 8}
{"namespace": "boto.dynamodb.types.Dynamizer.encode", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb/types.py", "signature_position": [267, 267], "body_position": [273, 279], "dependency": {"intra_class": ["boto.dynamodb.types.Dynamizer._get_dynamodb_type"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function encodes a Python type to the format expected by DynamoDB. It determines the DynamoDB type of the input attribute and uses the corresponding encoder method to encode the attribute.", "Arguments": ":param self: Dynamizer. An instance of the Dynamizer class.\n:param attr: The attribute to be encoded.\n:return: Dictionary. The encoded attribute in the format expected by DynamoDB."}, "tests": ["tests/unit/dynamodb/test_types.py::TestDynamizer::test_float_conversion_errors", "tests/unit/dynamodb/test_types.py::TestDynamizer::test_non_boolean_conversions", "tests/unit/dynamodb/test_types.py::TestDynamizer::test_encoding_to_dynamodb", "tests/unit/dynamodb/test_types.py::TestDynamizer::test_lossy_float_conversions"], "indent": 8}
{"namespace": "dominate.util.unescape", "type": "function", "project_path": "Text-Processing/dominate", "completion_path": "Text-Processing/dominate/dominate/util.py", "signature_position": [85, 85], "body_position": [89, 107], "dependency": {"intra_class": [], "intra_file": ["dominate.util._unescape", "dominate.util.unichr"], "cross_file": []}, "requirement": {"Functionality": "This function unescapes HTML entities in the given data. It searches for HTML entities in the data and replaces them with their corresponding characters.", "Arguments": ":param data: String. The input data containing HTML entities to be unescaped.\n:return: String. The unescaped data."}, "tests": ["tests/test_utils.py::test_unescape"], "indent": 2}
{"namespace": "mingus.containers.instrument.Guitar.can_play_notes", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/instrument.py", "signature_position": [119, 119], "body_position": [120, 122], "dependency": {"intra_class": [], "intra_file": ["mingus.containers.instrument.Instrument", "mingus.containers.instrument.Instrument.can_play_notes"], "cross_file": []}, "requirement": {"Functionality": "Check if the guitar can play the given notes. It checks if the number of notes is greater than 6, and if so, returns False. Otherwise, it just returns the parent method.", "Arguments": ":param self: Guitar. An instance of the Guitar class.\n:param notes: List of strings. The notes to be played.\n:return: Bool. True if the guitar can play the notes, False otherwise."}, "tests": ["tests/unit/containers/test_instrument.py::test_Instrument::test_can_play_notes"], "indent": 8}
{"namespace": "pyramid.util.InstancePropertyMixin.set_property", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [196, 196], "body_position": [248, 250], "dependency": {"intra_class": [], "intra_file": ["pyramid.util.InstancePropertyHelper", "pyramid.util.InstancePropertyHelper.set_property"], "cross_file": []}, "requirement": {"Functionality": "This function adds a callable or a property descriptor to an instance.", "Arguments": ":param self: InstancePropertyMixin. An instance of the InstancePropertyMixin class.\n:param callable: Callable or property descriptor. The callable or property descriptor to be added to the instance.\n:param name: String. The name of the property. If None, the name will be computed from the name of the callable. Defaults to None.\n:param reify: Bool. Whether the property should be reified. If True, the value of the property is cached and computed only once. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_util.py::Test_InstancePropertyMixin::test_callable_with_name", "tests/test_util.py::Test_InstancePropertyMixin::test_reset_reify", "tests/test_util.py::Test_InstancePropertyMixin::test_property_with_name", "tests/test_util.py::Test_InstancePropertyMixin::test_callable", "tests/test_util.py::Test_InstancePropertyMixin::test_property_with_reify"], "indent": 8}
{"namespace": "diffprivlib.tools.utils.nansum", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [657, 658], "body_position": [709, 712], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._sum"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function calculates the sum of array elements over a given axis with differential privacy, while ignoring NaN values.", "Arguments": ":param array: array_like. The elements to be summed.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: None or int or tuple of ints, optional. The axis or axes along which the sum is performed. If None, the sum is performed on all elements. If negative, it counts from the last to the first axis. If a tuple of ints, the sum is performed on the specified axes.\n:param dtype: dtype, optional. The type of the returned array and accumulator. If not specified, the dtype of the input array is used.\n:param keepdims: bool, default: False. If True, the reduced axes are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. Accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. An array with the same shape as the input array, with the specified axis removed. If the input array is 0-d or if axis is None, a scalar is returned."}, "tests": ["tests/tools/test_nansum.py::TestNansum::test_clipped_output", "tests/tools/test_nansum.py::TestNansum::test_int_output", "tests/tools/test_nansum.py::TestNansum::test_missing_bounds", "tests/tools/test_nansum.py::TestNansum::test_array_like", "tests/tools/test_nansum.py::TestNansum::test_no_bounds"], "indent": 4}
{"namespace": "databases.importer.import_from_string", "type": "function", "project_path": "Internet/databases", "completion_path": "Internet/databases/databases/importer.py", "signature_position": [9, 9], "body_position": [10, 35], "dependency": {"intra_class": [], "intra_file": ["databases.importer.ImportFromStringError", "databases.importer.ImportFromStringError.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function imports a module and retrieves an attribute from it based on the given import string. The import string should be in the format \"<module>:<attribute>\". It raises an exception if the module or attribute is not found.", "Arguments": ":param import_str: String. The import string in the format \"<module>:<attribute>\".\n:return: Any. The retrieved attribute from the imported module."}, "tests": ["tests/test_importer.py::test_internal_import_error", "tests/test_importer.py::test_invalid_format", "tests/test_importer.py::test_valid_import", "tests/test_importer.py::test_invalid_attr", "tests/test_importer.py::test_invalid_module"], "indent": 4}
{"namespace": "alembic.autogenerate.render._render_constraint", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/render.py", "signature_position": [884, 888], "body_position": [889, 895], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.render._constraint_renderers"], "cross_file": ["alembic.autogenerate.api.AutogenContext", "alembic.langhelpers.Dispatcher.dispatch", "alembic.util", "alembic.util.warn"]}, "requirement": {"Functionality": "This function renders a constraint object based on its type. It first tries to find a renderer for the constraint object using dispatch. If a renderer is found, it calls the renderer function with the constraint object, autogen_context, and namespace_metadata as arguments and returns the result. If no renderer is found, it returns a string indicating that the Python object is unknown.", "Arguments": ":param constraint: Constraint. The constraint object to be rendered.\n:param autogen_context: AutogenContext. The autogen context object.\n:param namespace_metadata: Optional MetaData. The metadata associated with the namespace.\n:return: Optional string. The rendered constraint string or a string indicating that the Python object is unknown."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_render_fk_constraint_link_to_name", "tests/test_autogen_render.py::AutogenRenderTest::test_render_fk_constraint_resolve_key", "tests/test_autogen_render.py::AutogenRenderTest::test_render_fk_constraint_use_alter", "tests/test_autogen_render.py::AutogenRenderTest::test_render_fk_constraint_kwarg", "tests/test_autogen_render.py::AutogenRenderTest::test_render_fk_constraint_bad_table_resolve_dont_get_confused"], "indent": 4}
{"namespace": "boltons.listutils.BarrelList.insert", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/listutils.py", "signature_position": [144, 144], "body_position": [145, 154], "dependency": {"intra_class": ["boltons.listutils.BarrelList._balance_list", "boltons.listutils.BarrelList._translate_index", "boltons.listutils.BarrelList.lists"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Insert an item at the specified index in the BarrelList instance.\n", "Arguments": ":param self: BarrelList, an instance of BarrelList class.\n:param index: Int, the index at which the item will be inserted.\n:param item: The item to be inserted.\n:return: No return values.\n"}, "tests": ["tests/test_listutils.py::test_barrel_list"], "indent": 8}
{"namespace": "alembic.script.revision.RevisionMap.add_revision", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [414, 414], "body_position": [421, 468], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._add_branches", "alembic.script.revision.RevisionMap._add_depends_on", "alembic.script.revision.RevisionMap._map_branch_labels", "alembic.script.revision.RevisionMap._normalize_depends_on", "alembic.script.revision.RevisionMap._real_bases", "alembic.script.revision.RevisionMap._real_heads", "alembic.script.revision.RevisionMap._revision_map", "alembic.script.revision.RevisionMap.bases", "alembic.script.revision.RevisionMap.heads"], "intra_file": ["alembic.script.revision.Revision", "alembic.script.revision.Revision._all_down_revisions", "alembic.script.revision.Revision._is_real_base", "alembic.script.revision.Revision._is_real_head", "alembic.script.revision.Revision.is_base", "alembic.script.revision.Revision.is_head", "alembic.script.revision.Revision.revision"], "cross_file": ["alembic.util", "alembic.util.not_none.add_nextrev", "alembic.util.warn"]}, "requirement": {"Functionality": "This function adds a single revision to an existing revision map. It performs various operations such as adding the revision to the map, adding branches, mapping branch labels, adding dependencies, updating bases and real bases, checking and adding referenced revisions, normalizing dependencies, and updating real heads and heads.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param revision: Revision. The revision to be added to the map.\n:param _replace: Bool. Whether to replace an existing revision with the same key. Defaults to False.\n:return: No return values."}, "tests": ["tests/test_revision.py::APITest::test_add_revision_two_head", "tests/test_revision.py::APITest::test_add_revision_one_head"], "indent": 8}
{"namespace": "imapclient.datetime_util.parse_to_datetime", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/datetime_util.py", "signature_position": [14, 14], "body_position": [23, 36], "dependency": {"intra_class": [], "intra_file": ["imapclient.datetime_util._munge", "imapclient.datetime_util.datetime_to_native"], "cross_file": ["imapclient.fixed_offset.FixedOffset"]}, "requirement": {"Functionality": "Convert an IMAP datetime string to a datetime object. \n", "Arguments": ":param timestamp: String, the IMAP datetime string to be converted.\n:param normalise: Bool, whether to adjust the converted datetime to the local time. If `normalise` is True (default), the returned datetime object will be timezone-naive but adjusted to the local time. If `normalise` is False, the returned datetime object will be unadjusted but will contain timezone information as per the input.\n:return: datetime, the converted datetime object from the IMAP datetime string.\n"}, "tests": ["tests/test_datetime_util.py::TestParsing::test_invalid"], "indent": 4}
{"namespace": "authlib.oauth2.rfc6749.parameters.parse_authorization_code_response", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/oauth2/rfc6749/parameters.py", "signature_position": [102, 102], "body_position": [140, 150], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["authlib.oauth2.rfc6749.errors.MismatchingStateException", "authlib.oauth2.rfc6749.errors.MissingCodeException"]}, "requirement": {"Functionality": "This function parses the authorization grant response URI into a dictionary. It extracts the authorization code and state parameters from the URI and returns them as a dictionary. If an authorization code is used more than once, the authorization server MUST deny the request and SHOULD raise Exception. if the \"state\" parameter was present in the client authorization request.  The exact value received from the client.", "Arguments": ":param uri: String. The full redirect URL back to the client.\n:param state: String. The state parameter from the authorization request. Defaults to None.\n:return: Dictionary. A dictionary containing the extracted authorization code and state parameters."}, "tests": ["tests/core/test_oauth2/test_rfc6749_misc.py::OAuth2ParametersTest::test_parse_authorization_code_response"], "indent": 4}
{"namespace": "rest_framework.parsers.JSONParser.parse", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/parsers.py", "signature_position": [54, 54], "body_position": [58, 67], "dependency": {"intra_class": ["rest_framework.parsers.JSONParser.strict"], "intra_file": [], "cross_file": ["rest_framework.exceptions.ParseError", "rest_framework.utils.json.load", "rest_framework.utils.json.strict_constant", "rest_framework.settings", "rest_framework.utils.json"]}, "requirement": {"Functionality": "This function parses an incoming bytestream as JSON and returns the resulting data. It decodes the stream using the specified encoding and parses the decoded stream into a Python object.", "Arguments": ":param self: JSONParser. An instance of the JSONParser class.\n:param stream: The bytestream to be parsed as JSON.\n:param media_type: [optional] The media type of the stream. Defaults to None.\n:param parser_context: [optional] Additional context for the parser. Defaults to None.\n:return: The parsed data as a Python object."}, "tests": ["tests/test_parsers.py::TestJSONParser::test_float_strictness"], "indent": 8}
{"namespace": "jwt.utils.base64url_decode", "type": "function", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/utils.py", "signature_position": [25, 25], "body_position": [26, 33], "dependency": {"intra_class": [], "intra_file": ["jwt.utils.force_bytes"], "cross_file": []}, "requirement": {"Functionality": "Decode a base64url-encoded input string or bytes and return the decoded bytes. It first converts the input to bytes if it is a string, then pads the input with \"=\" characters if necessary, and finally decodes the input using the base64.urlsafe_b64decode() function.", "Arguments": ":param input: Union[bytes, str]. The base64url-encoded input string or bytes to be decoded.\n:return: bytes. The decoded bytes."}, "tests": ["tests/test_api_jws.py::TestJWS::test_custom_json_encoder", "tests/test_api_jws.py::TestJWS::test_encode_with_typ_without_keywords", "tests/test_api_jws.py::TestJWS::test_encode_with_typ_empty_string", "tests/test_algorithms.py::TestAlgorithmsRFC7520::test_hmac_verify_should_return_true_for_test_vector", "tests/test_api_jws.py::TestJWS::test_encode_with_typ"], "indent": 4}
{"namespace": "alembic.script.revision.RevisionMap.iterate_revisions", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [774, 782], "body_position": [794, 809], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._collect_downgrade_revisions", "alembic.script.revision.RevisionMap._collect_upgrade_revisions", "alembic.script.revision.RevisionMap._topological_sort", "alembic.script.revision.RevisionMap.get_revision"], "intra_file": ["alembic.script.revision.Revision", "alembic.script.revision._RevisionIdentifierType"], "cross_file": []}, "requirement": {"Functionality": "This function iterates through script revisions starting from the upper revision identifier and ending at the lower revision identifier. It uses the `down_revision` marker inside each migration script to determine the traversal order.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param upper: _RevisionIdentifierType. The upper revision identifier to start the iteration from.\n:param lower: _RevisionIdentifierType. The lower revision identifier to end the iteration at.\n:param implicit_base: Bool. Whether to include the implicit base revision in the iteration. Defaults to False.\n:param inclusive: Bool. Whether to include the upper revision in the iteration. Defaults to False.\n:param assert_relative_length: Bool. Whether to assert that the number of revisions between the upper and lower is the same as the number of revisions returned. Defaults to True.\n:param select_for_downgrade: Bool. Whether to select revisions for downgrade instead of upgrade. Defaults to False.\n:return: Iterator[Revision]. An iterator that yields `Revision` objects."}, "tests": ["tests/test_revision.py::MultipleBaseCrossDependencyTestOne::test_different_branch_not_wrong_direction", "tests/test_revision.py::MultipleBranchTest::test_wrong_direction_to_base_as_none", "tests/test_revision.py::MultipleBranchTest::test_wrong_direction_to_base_as_empty", "tests/test_revision.py::MultipleBranchTest::test_same_branch_wrong_direction", "tests/test_revision.py::BranchTravellingTest::test_detect_invalid_head_selection"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox.update_recipients", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [273, 273], "body_position": [274, 278], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox._set_regular_and_typing_recipient_user_ids", "zulipterminal.ui_tools.boxes.WriteBox.recipient_emails"], "intra_file": [], "cross_file": ["zulipterminal.config.regexes.REGEX_RECIPIENT_EMAIL"]}, "requirement": {"Functionality": "Update the recipients of the WriteBox instance based on the input from the ReadlineEdit instance. It extracts the recipient emails from the input text and sets the corresponding user IDs in the WriteBox instance.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param write_box: ReadlineEdit. An instance of the ReadlineEdit class that contains the input text.\n:return: No return values."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test_update_recipients"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.touchz", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [83, 83], "body_position": [84, 90], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "Create an empty file at the specified path. If the file already exists and is not empty, raise an OSError.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param path: String. The path where the empty file should be created.\n:return: No return values."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_touchz_file_uri", "tests/fs/test_local.py::LocalFSTestCase::test_touchz"], "indent": 8}
{"namespace": "boltons.formatutils.infer_positional_format_args", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/formatutils.py", "signature_position": [123, 123], "body_position": [131, 145], "dependency": {"intra_class": [], "intra_file": ["boltons.formatutils._pos_farg_re"], "cross_file": []}, "requirement": {"Functionality": "This function takes format strings with anonymous positional arguments (e.g., \"{}\" and {:d}) and converts them into numbered ones for explicitness and compatibility with Python 2.6. It replaces the anonymous positional arguments with numbered ones and returns the modified string.", "Arguments": ":param fstr: String. The format string with anonymous positional arguments.\n:return: String. The modified format string with numbered positional arguments."}, "tests": ["tests/test_formatutils.py::test_pos_infer", "tests/test_formatutils.py::test_get_fstr_args"], "indent": 4}
{"namespace": "sacred.dependencies.Source.create", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/dependencies.py", "signature_position": [455, 455], "body_position": [456, 461], "dependency": {"intra_class": ["sacred.dependencies.Source.__init__"], "intra_file": ["sacred.dependencies.get_commit_if_possible", "sacred.dependencies.get_digest", "sacred.dependencies.get_py_file_if_possible"], "cross_file": []}, "requirement": {"Functionality": "Create a Source instance based on the given filename. It first checks if the filename is valid and exists. Otherwise, it raises a error message - \"invalid filename or file not found {filename}\". Then it retrieves the main file, repository information, commit information, and dirty status using helper functions. Finally, it creates a Source instance with the obtained information.", "Arguments": ":param filename: String. The name of the file to create the Source instance from.\n:param save_git_info: Bool. Whether to save the git information in the Source instance. Defaults to True.\n:return: Source. The created Source instance."}, "tests": ["tests/test_ingredients.py::test_create_ingredient", "tests/test_dependencies.py::test_source_create_py", "tests/test_dependencies.py::test_custom_base_dir", "tests/test_dependencies.py::test_source_to_json", "tests/test_dependencies.py::test_source_create_empty"], "indent": 8}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.start", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [31, 31], "body_position": [37, 48], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.REQUEST_THREAD_NAME", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.RESPONSE_THREAD_NAME", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient._listen_for_request", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient._listen_for_response", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.request_thread", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.response_thread"], "intra_file": ["mssqlcli.jsonrpc.jsonrpcclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function starts the background threads to listen for responses and requests from the underlying streams. It creates two threads, one for listening to requests and one for listening to responses.", "Arguments": ":param self: JsonRpcClient. An instance of the JsonRpcClient class.\n:return: No return values."}, "tests": ["tests/jsonrpc/test_json_rpc_contracts.py::JSONRPCContractsTests::test_query_retrieve_correct_response", "tests/jsonrpc/test_json_rpc_contracts.py::JSONRPCContractsTests::test_query_subset_response_AdventureWorks2014", "tests/jsonrpc/test_json_rpc_contracts.py::JSONRPCContractsTests::test_query_execute_response_AdventureWorks2014", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_submit_simple_request", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_response_dequeued"], "indent": 8}
{"namespace": "alembic.command.downgrade", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [401, 406], "body_position": [421, 444], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.runtime.environment.EnvironmentContext", "alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.run_env", "alembic.util", "alembic.util.CommandError"]}, "requirement": {"Functionality": "This function is used to revert to a previous version of a database schema. It takes in a configuration object, a revision string, a boolean flag indicating whether to use SQL mode, and an optional tag. It creates a script directory based on the configuration, determines the starting revision if a range is specified, and performs the downgrade operation using the script directory. The downgrade operation is executed within an environment context, which handles the execution of the downgrade script.", "Arguments": ":param config: Config. An instance of the Config class.\n:param revision: str. The target revision or range for --sql mode.\n:param sql: bool. If True, use --sql mode.\n:param tag: Optional[str]. An arbitrary tag that can be intercepted by custom env.py scripts.\n:return: None."}, "tests": ["tests/test_command.py::UpgradeDowngradeStampTest::test_version_to_middle", "tests/test_postgresql.py::PGOfflineEnumTest::test_offline_inline_enum_drop", "tests/test_postgresql.py::PGOfflineEnumTest::test_offline_distinct_enum_drop", "tests/test_batch.py::OfflineTest::test_downgrade_batch_no_reflection", "tests/test_command.py::UpgradeDowngradeStampTest::test_version_to_none"], "indent": 4}
{"namespace": "boltons.socketutils.BufferedSocket.buffer", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [479, 479], "body_position": [481, 483], "dependency": {"intra_class": ["boltons.socketutils.BufferedSocket._send_lock", "boltons.socketutils.BufferedSocket.sbuf"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function buffers the given data bytes for the next send operation. It first acquires a lock to ensure thread safety, then appends the data to the send buffer of the BufferedSocket instance.", "Arguments": ":param self: BufferedSocket. An instance of the BufferedSocket class.\n:param data: Bytes. The data to be buffered for the next send operation.\n:return: None."}, "tests": ["tests/test_socketutils.py::test_client_disconnecting", "tests/test_socketutils.py::test_buffers"], "indent": 8}
{"namespace": "authlib.oauth2.rfc6749.parameters.prepare_grant_uri", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/oauth2/rfc6749/parameters.py", "signature_position": [7, 8], "body_position": [41, 58], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["authlib.common.encoding.to_unicode", "authlib.common.urls.add_params_to_uri", "authlib.oauth2.rfc6749.util.list_to_scope"]}, "requirement": {"Functionality": "This function prepares the authorization grant request URI by adding the necessary parameters to the query component of the authorization endpoint URI. It constructs the URI using the \"application/x-www-form-urlencoded\" format.", "Arguments": ":param uri: String. The authorization endpoint URI to fetch \"code\" or \"token\".\n:param client_id: String. The client identifier.\n:param response_type: String. The type of OAuth 2 grant/flow required (\"code\" or \"token\").\n:param redirect_uri: String. The client provided URI to redirect back to after authorization.\n:param scope: String or List. The scope of the access request.\n:param state: String. An opaque value used by the client to maintain state between the request and callback.\n:param kwargs: Extra arguments to embed in the grant/authorization URL.\n:return: String. The prepared authorization grant request URI."}, "tests": ["tests/core/test_oauth2/test_rfc6749_misc.py::OAuth2ParametersTest::test_prepare_grant_uri"], "indent": 4}
{"namespace": "diffprivlib.tools.histograms.histogram2d", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/histograms.py", "signature_position": [279, 280], "body_position": [352, 365], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.histograms.histogramdd"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the differentially private bi-dimensional histogram of two data samples. It takes in two arrays containing the x and y coordinates of the points to be histogrammed, along with other optional parameters such as privacy parameter, bin specification, range, density, weights, random state, and accountant. It returns the bi-dimensional histogram, along with the bin edges along the x and y dimensions.", "Arguments": ":param array_x: array_like. An array containing the x coordinates of the points to be histogrammed.\n:param array_y: array_like. An array containing the y coordinates of the points to be histogrammed.\n:param epsilon: float. Privacy parameter \u03b5 to be applied. Defaults to 1.0.\n:param bins: int or array_like or [int, int] or [array, array]. The bin specification. Defaults to 10.\n:param range: array_like, shape(2,2), optional. The leftmost and rightmost edges of the bins along each dimension. Defaults to None.\n:param density: bool, optional. If False, returns the number of samples in each bin. If True, returns the probability density function at the bin. Defaults to None.\n:param weights: array_like, shape(N,), optional. An array of values weighing each sample. Defaults to None.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm. Defaults to None.\n:param accountant: BudgetAccountant, optional. Accountant to keep track of privacy budget. Defaults to None.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: H: ndarray, shape(nx, ny). The bi-dimensional histogram of samples x and y. xedges: ndarray, shape(nx+1,). The bin edges along the first dimension. yedges: ndarray, shape(ny+1,). The bin edges along the second dimension."}, "tests": ["tests/tools/test_histogram2d.py::TestHistogram2d::test_different_result", "tests/tools/test_histogram2d.py::TestHistogram2d::test_no_params", "tests/tools/test_histogram2d.py::TestHistogram2d::test_custom_bins", "tests/tools/test_histogram2d.py::TestHistogram2d::test_accountant", "tests/tools/test_histogram2d.py::TestHistogram2d::test_missing_range"], "indent": 4}
{"namespace": "datasette.app.Datasette.get_database", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/app.py", "signature_position": [404, 404], "body_position": [405, 413], "dependency": {"intra_class": ["datasette.app.Datasette.databases"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a database from the Datasette instance based on the given conditions. It first checks if a specific route is provided, and if so, it returns the database that matches the route. If no route is provided, it returns the first database that is not named \"_internal\".", "Arguments": ":param self: Datasette. An instance of the Datasette class.\n:param name: String [optional]. The name of the database to retrieve. If not provided, the first database that isn't '_internal' is returned.\n:param route: String [optional]. The route of the database to retrieve. If provided, the database with the matching route is returned.\n:return: Database. The retrieved database instance."}, "tests": ["tests/test_utils.py::test_derive_named_parameters"], "indent": 8}
{"namespace": "asyncssh.public_key.SSHKey.generate_x509_user_certificate", "type": "method", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/public_key.py", "signature_position": [823, 830], "body_position": [888, 892], "dependency": {"intra_class": ["asyncssh.public_key.SSHKey._generate_x509_certificate"], "intra_file": ["asyncssh.public_key.X509CertPurposes", "asyncssh.public_key._CertPrincipals", "asyncssh.public_key._Comment", "asyncssh.public_key._Time"], "cross_file": ["asyncssh.misc.DefTuple"]}, "requirement": {"Functionality": "This function generates a new X.509 user certificate based on the given parameters. It uses the private key of the SSHKey instance to sign the certificate.", "Arguments": ":param self: SSHKey. An instance of the SSHKey class.\n:param user_key: SSHKey. The user's public key.\n:param subject: String. The subject name in the certificate, expressed as a comma-separated list of X.509 `name=value` pairs.\n:param issuer: String (optional). The issuer name in the certificate, expressed as a comma-separated list of X.509 `name=value` pairs. If not specified, the subject name will be used, creating a self-signed certificate.\n:param serial: Integer (optional). The serial number of the certificate, defaulting to a random 64-bit value.\n:param principals: List of strings (optional). The user names this certificate is valid for. By default, it can be used with any user name.\n:param valid_after: Integer (optional). The earliest time the certificate is valid for, defaulting to no restriction on when the certificate starts being valid.\n:param valid_before: Integer (optional). The latest time the certificate is valid for, defaulting to no restriction on when the certificate stops being valid.\n:param purposes: X509CertPurposes (optional). The allowed purposes for this certificate or `None` to not restrict the certificate's purpose, defaulting to 'secureShellClient'.\n:param hash_alg: Tuple of strings (optional). The hash algorithm to use when signing the new certificate, defaulting to SHA256.\n:param comment: Tuple of _Comment (optional). The comment to associate with this certificate. By default, the comment will be set to the comment currently set on user_key.\n:return: SSHX509Certificate. The generated X.509 user certificate."}, "tests": ["tests/test_public_key.py::_TestPublicKeyTopLevel::test_generate_errors"], "indent": 8}
{"namespace": "kinto.authorization._relative_object_uri", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/authorization.py", "signature_position": [81, 81], "body_position": [83, 91], "dependency": {"intra_class": [], "intra_file": ["kinto.authorization._resource_endpoint"], "cross_file": []}, "requirement": {"Functionality": "This function takes a resource name and an object URI as input and returns the object URI. It splits the object URI into parts and iterates through each part to find the parent URI. It then checks if the resource name matches the parent resource name. If a match is found, it returns the parent URI. If no match is found, it raises a ValueError with an error message.", "Arguments": ":param resource_name: String. The name of the resource.\n:param object_uri: String. The URI of the object.\n:return: String. The object URI."}, "tests": ["tests/test_authorization.py::RelativeObjectUri::test_related_object_uri_can_construct_parents_set_uris", "tests/test_authorization.py::PermissionInheritanceTest::test_relative_object_uri_fail_on_wrong_type", "tests/test_authorization.py::RelativeObjectUri::test_relative_object_uri_fail_construct_children_set_uris"], "indent": 4}
{"namespace": "mrjob.compat.translate_jobconf_for_all_versions", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/compat.py", "signature_position": [670, 670], "body_position": [673, 674], "dependency": {"intra_class": [], "intra_file": ["mrjob.compat._JOBCONF_MAP"], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of all known variants of a given jobconf variable. It retrieves the variants from a dictionary and sorts them.", "Arguments": ":param variable: str. The jobconf variable for which to retrieve the variants.\n:return: List. A list of all known variants of the given jobconf variable."}, "tests": ["tests/test_compat.py::TranslateJobConfForAllVersionsTestCase::test_translate_jobconf_for_all_versions"], "indent": 4}
{"namespace": "mrjob.util.to_lines", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/util.py", "signature_position": [257, 257], "body_position": [266, 269], "dependency": {"intra_class": [], "intra_file": ["mrjob.util._to_lines"], "cross_file": []}, "requirement": {"Functionality": "This function takes in data as a sequence of bytes and yields it one line at a time. It breaks lines only on \"\\n\" and does not add a trailing newline. If the input has a \"readline\" attribute, it is returned as is.", "Arguments": ":param chunks: The input data as a sequence of bytes.\n:return: The processed data, one line at a time."}, "tests": ["tests/test_local.py::FilterTestCase::test_pre_filter_failure", "tests/test_util.py::ToLinesTestCase::test_buffered_lines", "tests/test_util.py::ToLinesTestCase::test_long_lines", "tests/test_util.py::ToLinesTestCase::test_no_trailing_newline", "tests/test_local.py::FilterTestCase::test_pre_filter_on_compressed_data"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_only.rarest_window_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_only.py", "signature_position": [408, 418], "body_position": [457, 473], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_only.compute_likelihood_windows_in_session"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix"]}, "requirement": {"Functionality": "This function finds and computes the likelihood of the rarest window of a given length in a session. It calculates the likelihoods of all sliding windows in the session and returns the rarest window and its likelihood.", "Arguments": ":param session: List[Cmd]. A list of Cmd objects representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands (length 2).\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the params conditional on the command.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, the `start_token` and `end_token` will be added to the session before calculations.\n:param start_token: str. A dummy command to signify the start of the session.\n:param end_token: str. A dummy command to signify the end of the session.\n:param use_geo_mean: bool. If True, each likelihood of the sliding windows will be raised to the power of (1/`window_len`).\n:return: Tuple[List[Cmd], float]. The rarest window part of the session and the likelihood of the rarest window."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_only.py::TestCmdsParamsOnly::test_rarest_window_session"], "indent": 4}
{"namespace": "rows.fields.BoolField.deserialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [159, 159], "body_position": [160, 170], "dependency": {"intra_class": ["rows.fields.BoolField.FALSE_VALUES", "rows.fields.BoolField.TRUE_VALUES", "rows.fields.BoolField.TYPE"], "intra_file": ["rows.fields.Field", "rows.fields.Field.deserialize", "rows.fields.as_string"], "cross_file": []}, "requirement": {"Functionality": "Deserialize a value into a boolean field. It first calls the parent class's deserialize method to convert the value into a boolean. Then if the value is already None or an instance of the boolean field's type, it is returned as is. Otherwise, the value is converted to a string and checked against the true and false values defined in the class. If it matches a true value, True is returned. If it matches a false value, False is returned. If it doesn't match any of the defined values, a ValueError is raised with the error message \"Value is not boolean\".", "Arguments": ":param cls: Class. The class object of the boolean field.\n:param value: Any. The value to be deserialized into a boolean.\n:param *args: Any. Additional positional arguments.\n:param **kwargs: Any. Additional keyword arguments.\n:return: Bool. The deserialized boolean value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_BoolField"], "indent": 8}
{"namespace": "mopidy.config.types.String.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [98, 98], "body_position": [99, 112], "dependency": {"intra_class": ["mopidy.config.types.String._choices", "mopidy.config.types.String._required"], "intra_file": ["mopidy.config.types._TransformedValue", "mopidy.config.types._TransformedValue.__init__", "mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_choice", "mopidy.config.validators.validate_required", "mopidy.config.validators"]}, "requirement": {"Functionality": "Deserialize a string value based on the given conditions. It first decodes the value and removes any leading or trailing whitespace. Then, it validates the value based on whether it is required or not. If the value is empty, it returns None. If a transformer is defined, it applies the transformer to the value. Finally, it validates the value based on a list of choices and returns the deserialized value.", "Arguments": ":param self: String. An instance of the String class.\n:param value: The string value to be deserialized.\n:return: The deserialized value."}, "tests": ["tests/config/test_types.py::TestString::test_deserialize_does_not_double_encode_unicode", "tests/config/test_types.py::TestString::test_deserialize_enforces_choices", "tests/config/test_types.py::TestString::test_deserialize_invalid_encoding", "tests/config/test_types.py::TestString::test_deserialize_utilises_transformer", "tests/config/test_types.py::TestString::test_deserialize_decodes_utf8"], "indent": 8}
{"namespace": "backtrader.trade.Trade.update", "type": "method", "project_path": "Software-Development/backtrader", "completion_path": "Software-Development/backtrader/backtrader/trade.py", "signature_position": [213, 214], "body_position": [244, 304], "dependency": {"intra_class": ["backtrader.trade.Trade.Closed", "backtrader.trade.Trade.Open", "backtrader.trade.Trade.barclose", "backtrader.trade.Trade.barlen", "backtrader.trade.Trade.baropen", "backtrader.trade.Trade.commission", "backtrader.trade.Trade.data", "backtrader.trade.Trade.dtclose", "backtrader.trade.Trade.dtopen", "backtrader.trade.Trade.history", "backtrader.trade.Trade.historyon", "backtrader.trade.Trade.isclosed", "backtrader.trade.Trade.isopen", "backtrader.trade.Trade.justopened", "backtrader.trade.Trade.long", "backtrader.trade.Trade.pnl", "backtrader.trade.Trade.pnlcomm", "backtrader.trade.Trade.price", "backtrader.trade.Trade.size", "backtrader.trade.Trade.status", "backtrader.trade.Trade.value"], "intra_file": ["backtrader.trade.TradeHistory", "backtrader.trade.TradeHistory.__init__", "backtrader.trade.TradeHistory.doupdate"], "cross_file": []}, "requirement": {"Functionality": "This function updates the current trade based on the given parameters. It increases the commissions, updates the size. The size will carry the opposite sign if reducing. It checks if it has been currently opened. Any size means the trade was opened. It updatas current trade length and record if the position was closed (set to null), then it records last bar for the trade, updates the average price if the absolute size is bigger than the absolute old size or reduces or closes position if that condition is not met. Finally, it updates the attributes of the trade object and history if needed.", "Arguments": ":param self: Trade. An instance of the Trade class.\n:param order: The order object that generated this update.\n:param size: Integer. The amount to update the order. If the size has the same sign as the current trade, it will increase the position. If the size has the opposite sign, it will reduce/close the position.\n:param price: Float. The price of the trade. Always positive to ensure consistency.\n:param value: Float. Unused. The cost incurred in the new size/price operation.\n:param commission: Float. The incurred commission in the new size/price operation.\n:param pnl: Float. Unused. The profit and loss generated by the executed part.\n:return: No return values."}, "tests": ["tests/test_trade.py::test_run"], "indent": 8}
{"namespace": "ehforwarderbot.chat.Chat.add_system_member", "type": "method", "project_path": "Communications/ehforwarderbot", "completion_path": "Communications/ehforwarderbot/ehforwarderbot/chat.py", "signature_position": [567, 570], "body_position": [592, 596], "dependency": {"intra_class": ["ehforwarderbot.chat.Chat.make_system_member", "ehforwarderbot.chat.Chat.members"], "intra_file": ["ehforwarderbot.chat.SystemChatMember"], "cross_file": ["ehforwarderbot.middleware.Middleware", "ehforwarderbot.types.ChatID"]}, "requirement": {"Functionality": "This function adds a system member to the chat. It creates a system member with the given parameters and adds it to the list of members in the chat.", "Arguments": ":param self: Chat. An instance of the Chat class.\n:param name: String. The name of the system member.\n:param alias: Optional string. The alias of the system member.\n:param id: ChatID. The ID of the system member.\n:param uid: ChatID. The UID of the system member.\n:param vendor_specific: Dictionary. Any vendor specific attributes.\n:param description: String. A text description of the chat.\n:param middleware: Optional Middleware. Initialize this chat as a part of a middleware.\n:return: SystemChatMember. The created system member."}, "tests": ["tests/test_chat.py::test_add_system_member"], "indent": 8}
{"namespace": "sacred.ingredient.Ingredient.command", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/ingredient.py", "signature_position": [130, 130], "body_position": [145, 148], "dependency": {"intra_class": ["sacred.ingredient.Ingredient.capture", "sacred.ingredient.Ingredient.commands"], "intra_file": ["sacred.ingredient.Ingredient.capture.unobserved"], "cross_file": []}, "requirement": {"Functionality": "This function is a decorator used to define a new command for an Ingredient or Experiment. It captures the function and adds it to the commands dictionary of the Ingredient instance. The name of the command will be the name of the function. It can be called from the command-line or by using the run_command function.", "Arguments": ":param self: Ingredient. An instance of the Ingredient class.\n:param function: Function. The function to be decorated and added as a command.\n:param prefix: String. The prefix to restrict the configuration space of the command. Defaults to None.\n:param unobserved: Bool. Whether the command should be unobserved, i.e., ignoring all observers. Defaults to False.\n:return: The captured function."}, "tests": ["tests/test_ingredients.py::test_gather_commands"], "indent": 8}
{"namespace": "diffprivlib.models.forest._FittingTree.__getstate__", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/forest.py", "signature_position": [503, 503], "body_position": [505, 509], "dependency": {"intra_class": ["diffprivlib.models.forest._FittingTree.max_depth", "diffprivlib.models.forest._FittingTree.node_count", "diffprivlib.models.forest._FittingTree.nodes", "diffprivlib.models.forest._FittingTree.values_"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to get the state of the Fitting Tree object in including max depth, the count of nodes, nodes, values. The output format is a dictionary with these attributes mentioned before and their values.", "Arguments": ":param self: _FittingTree. An instance of the _FittingTree class.\n:return: Dictionary. The state of the _FittingTree object, including the maximum depth, node count, nodes, and values."}, "tests": ["tests/models/test_FittingTree.py::TestFittingTree::test_no_data"], "indent": 8}
{"namespace": "hl7.parser._ParsePlan.next", "type": "method", "project_path": "Communications/hl7", "completion_path": "Communications/hl7/hl7/parser.py", "signature_position": [412, 412], "body_position": [417, 430], "dependency": {"intra_class": ["hl7.parser._ParsePlan.containers", "hl7.parser._ParsePlan.esc", "hl7.parser._ParsePlan.factory", "hl7.parser._ParsePlan.separator", "hl7.parser._ParsePlan.separators"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates the next level of the plan by creating a copy of the current plan with the level of the container and the separator starting at the next index.", "Arguments": ":param self: _ParsePlan. An instance of the _ParsePlan class.\n:return: No return values."}, "tests": ["tests/test_parse.py::ParsePlanTest::test_parse_plan_next"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.idle", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [889, 889], "body_position": [904, 907], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._idle_tag", "imapclient.imapclient.IMAPClient._imap"], "intra_file": [], "cross_file": ["imapclient.exceptions.IMAPClientError", "imapclient.exceptions"]}, "requirement": {"Functionality": "Puts the server into IDLE mode, where the server will return unsolicited responses about changes to the selected mailbox. This method returns immediately. Other commands issued while the server is in IDLE mode will fail.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:return: No return values."}, "tests": ["tests/test_imapclient.py::TestIdleAndNoop::test_idle"], "indent": 8}
{"namespace": "boto.cloudformation.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudformation/__init__.py", "signature_position": [43, 43], "body_position": [54, 56], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudformation.connection.CloudFormationConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns a CloudFormationConnection object. It uses the connect function from the boto library to establish the connection.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param kw_params: keyword arguments. Additional parameters that can be passed to the connect function.\n:return: CloudFormationConnection or None. A connection to the given region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestConnectCloudformation::test_connect_to_region"], "indent": 4}
{"namespace": "wikipediaapi.WikipediaPageSection.__repr__", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [777, 777], "body_position": [778, 784], "dependency": {"intra_class": ["wikipediaapi.WikipediaPageSection._level", "wikipediaapi.WikipediaPageSection._section", "wikipediaapi.WikipediaPageSection._text", "wikipediaapi.WikipediaPageSection._title"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the WikipediaPageSection object. It includes the section title, level, text, number of subsections, and the string representation of each subsection.", "Arguments": ":param self: WikipediaPageSection. An instance of the WikipediaPageSection class.\n:return: String. The string representation of the WikipediaPageSection object."}, "tests": ["tests/extract_html_format_test.py::TestHtmlFormatExtracts::test_subsubsection", "tests/extract_wiki_format_test.py::TestWikiFormatExtracts::test_subsubsection"], "indent": 8}
{"namespace": "onlinejudge_command.pretty_printers._render_tokens", "type": "function", "project_path": "Text-Processing/online-judge-tools", "completion_path": "Text-Processing/online-judge-tools/onlinejudge_command/pretty_printers.py", "signature_position": [163, 171], "body_position": [175, 207], "dependency": {"intra_class": [], "intra_file": ["onlinejudge_command.pretty_printers._PrettyTokenType", "onlinejudge_command.pretty_printers._PrettyTokenType.BODY", "onlinejudge_command.pretty_printers._PrettyTokenType.BODY_HIGHLIGHT_LEFT", "onlinejudge_command.pretty_printers._PrettyTokenType.BODY_HIGHLIGHT_RIGHT", "onlinejudge_command.pretty_printers._PrettyTokenType.HINT", "onlinejudge_command.pretty_printers._PrettyTokenType.LINENO", "onlinejudge_command.pretty_printers._PrettyTokenType.NEWLINE", "onlinejudge_command.pretty_printers._PrettyTokenType.OTHERS", "onlinejudge_command.pretty_printers._PrettyTokenType.WHITESPACE", "onlinejudge_command.pretty_printers._replace_whitespace"], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of tokens and applies different formatting styles to each token based on its type. It then concatenates all the formatted tokens into a single string and returns it.", "Arguments": ":param tokens: List of _PrettyToken. A list of tokens to be formatted.\n:param font_bold: Optional Callable. A function that applies bold font style to a string. Defaults to None.\n:param font_dim: Optional Callable. A function that applies dim font style to a string. Defaults to None.\n:param font_red: Optional Callable. A function that applies red font color to a string. Defaults to None.\n:param font_blue: Optional Callable. A function that applies blue font color to a string. Defaults to None.\n:param font_normal: Optional Callable. A function that applies normal font style to a string. Defaults to None.\n:return: String. The formatted string generated from the tokens."}, "tests": ["tests/pretty_printers.py::MakePrettyDiffTest::test_file_difflib", "tests/pretty_printers.py::MakePrettyDiffTest::test_line_difflib", "tests/pretty_printers.py::MakePrettyDiffLimitTest::test_with_limit", "tests/pretty_printers.py::RenderTokensTest::test_simple", "tests/pretty_printers.py::RenderTokensTest::test_complicated"], "indent": 4}
{"namespace": "alembic.util.sqla_compat._connectable_has_table", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/util/sqla_compat.py", "signature_position": [275, 277], "body_position": [278, 283], "dependency": {"intra_class": [], "intra_file": ["alembic.util.sqla_compat.sqla_14"], "cross_file": []}, "requirement": {"Functionality": "Check if a table exists in a database using the given connectable object. It uses different methods depending on the version of SQLAlchemy being used.", "Arguments": ":param connectable: Connection. The connectable object representing the database connection.\n:param tablename: str. The name of the table to check for existence.\n:param schemaname: Union[str, None]. The name of the schema where the table is located. Defaults to None.\n:return: bool. True if the table exists, False otherwise."}, "tests": ["tests/test_command.py::EnureVersionTest::test_ensure_version", "tests/test_command.py::EnureVersionTest::test_ensure_version_called_twice"], "indent": 4}
{"namespace": "boto.dynamodb2.table.BatchTable.put_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [1645, 1645], "body_position": [1646, 1649], "dependency": {"intra_class": ["boto.dynamodb2.table.BatchTable._to_put", "boto.dynamodb2.table.BatchTable.flush", "boto.dynamodb2.table.BatchTable.should_flush"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds an item to the BatchTable instance. It appends the input data to the list of items to be put in the BatchTable. It also can flush the items.", "Arguments": ":param self: BatchTable. An instance of the BatchTable class.\n:param data: The data to be added to the BatchTable.\n:param overwrite: Bool. Whether to overwrite existing data with the same key. Defaults to False.\n:return: No return values."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write", "tests/unit/dynamodb2/test_table.py::TableTestCase::test_batch_write_flushing"], "indent": 8}
{"namespace": "pycoin.message.PeerAddress.PeerAddress.host", "type": "method", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/message/PeerAddress.py", "signature_position": [35, 35], "body_position": [36, 38], "dependency": {"intra_class": ["pycoin.message.PeerAddress.IP4_HEADER", "pycoin.message.PeerAddress.PeerAddress.ip_bin"], "intra_file": ["pycoin.message.PeerAddress.ip_bin_to_ip4_addr", "pycoin.message.PeerAddress.ip_bin_to_ip6_addr"], "cross_file": []}, "requirement": {"Functionality": "This function determines the host address based on the IP binary string. If the IP binary string starts with the IP4 header, it converts the last 4 characters of the IP binary string to an IP4 address. Otherwise, it converts the entire IP binary string to an IP6 address.", "Arguments": ":param self: PeerAddress. An instance of the PeerAddress class.\n:return: The host address based on the IP binary string."}, "tests": ["tests/message_test.py::MessageTest::test_PeerAddress"], "indent": 8}
{"namespace": "diffprivlib.tools.utils.sum", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [599, 600], "body_position": [651, 654], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._sum"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function calculates the sum of array elements over a given axis with differential privacy.", "Arguments": ":param array: array_like. The elements to be summed.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: None or int or tuple of ints, optional. The axis or axes along which the sum is performed. If None, it sums all elements of the input array. If negative, it counts from the last to the first axis. If a tuple of ints, it performs the sum on all specified axes.\n:param dtype: dtype, optional. The type of the returned array and accumulator in which the elements are summed. If not specified, the dtype of the input array is used.\n:param keepdims: bool, default: False. If True, the reduced axes are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm. To obtain deterministic behavior, fix the random_state to an integer.\n:param accountant: BudgetAccountant, optional. Accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: sum_along_axis : ndarray. An array with the same shape as the input array, with the specified axis removed. If the input array is 0-d or if axis is None, a scalar is returned."}, "tests": ["tests/tools/test_sum.py::TestSum::test_large_epsilon", "tests/tools/test_sum.py::TestSum::test_missing_bounds", "tests/tools/test_sum.py::TestSum::test_no_params", "tests/tools/test_sum.py::TestSum::test_nan", "tests/tools/test_sum.py::TestSum::test_no_bounds"], "indent": 4}
{"namespace": "boto.ec2.networkinterface.NetworkInterface.detach", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/networkinterface.py", "signature_position": [214, 214], "body_position": [225, 231], "dependency": {"intra_class": ["boto.ec2.networkinterface.NetworkInterface.attachment", "boto.ec2.networkinterface.NetworkInterface.connection"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.detach_network_interface"]}, "requirement": {"Functionality": "This function detaches a network interface (ENI) from an EC2 instance.", "Arguments": ":param self: NetworkInterface. An instance of the NetworkInterface class.\n:param force: Bool. Specifies whether to force detachment if the previous detachment attempt did not occur cleanly.\n:param dry_run: Bool. Specifies whether this is a dry run, meaning no actual detachment will occur.\n:return: Bool. Returns True if the detachment is successful."}, "tests": ["tests/unit/ec2/test_networkinterface.py::NetworkInterfaceTests::test_detach_calls_detach_network_interface", "tests/unit/ec2/test_networkinterface.py::NetworkInterfaceTests::test_detach_with_no_attach_data", "tests/unit/ec2/test_networkinterface.py::NetworkInterfaceTests::test_detach_with_force_calls_detach_network_interface_with_force"], "indent": 8}
{"namespace": "mingus.core.progressions.skip", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/progressions.py", "signature_position": [525, 525], "body_position": [536, 537], "dependency": {"intra_class": [], "intra_file": ["mingus.core.progressions.numerals"], "cross_file": []}, "requirement": {"Functionality": "This function takes a roman numeral and an optional skip count as input and returns the roman numeral that is a certain number of places behind in the sequence. \nAdd the skip count to the index of the given Roman numeral and divide the result by 7 to handle wraparound. The roman numeral at the calculated index is then returned as the output.\n", "Arguments": ":param roman_numeral: String. The roman numeral that needs to be skipped.\n:param skip_count: Int. The number of places to skip. It is optional and defaults to 1.\n:return: String. The roman numeral that is a certain number of places behind in the sequence.\n"}, "tests": ["tests/unit/core/test_progressions.py::test_progressions::test_skip"], "indent": 4}
{"namespace": "boltons.dictutils.OneToOne.clear", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [849, 849], "body_position": [850, 851], "dependency": {"intra_class": ["boltons.dictutils.OneToOne.inv"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function clears the OneToOne instance by clearing both the dictionary and its inverse dictionary.\n", "Arguments": ":param self: OneToOne. An instance of the OneToOne class.\n:return: No return values.\n"}, "tests": ["tests/test_dictutils.py::test_one_to_one"], "indent": 8}
{"namespace": "pyramid.authentication.RepozeWho1AuthenticationPolicy.unauthenticated_userid", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/authentication.py", "signature_position": [267, 267], "body_position": [269, 272], "dependency": {"intra_class": ["pyramid.authentication.RepozeWho1AuthenticationPolicy._get_identity"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the user ID from the detected identity in the request. It first gets the identity dictionary and then returns the value of the 'repoze.who.userid' key from the identity dictionary.", "Arguments": ":param self: RepozeWho1AuthenticationPolicy. An instance of the RepozeWho1AuthenticationPolicy class.\n:param request: The request object.\n:return: The value of the 'repoze.who.userid' key from the identity dictionary."}, "tests": ["tests/test_authentication.py::TestRepozeWho1AuthenticationPolicy::test_unauthenticated_userid"], "indent": 8}
{"namespace": "pyramid.config.assets.PackageOverrides.real_loader", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/assets.py", "signature_position": [161, 161], "body_position": [162, 164], "dependency": {"intra_class": ["pyramid.config.assets.PackageOverrides._real_loader"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the real loader of a PackageOverrides instance. If the real loader is not set, it raises a NotImplementedError.", "Arguments": ":param self: PackageOverrides. An instance of the PackageOverrides class.\n:return: Object. The real loader of the PackageOverrides instance."}, "tests": ["tests/test_config/test_assets.py::TestPackageOverrides::test_ctor_package_already_has_loader_of_different_type"], "indent": 8}
{"namespace": "falcon.inspect.InspectVisitor.process", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [552, 552], "body_position": [561, 566], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect._Traversable", "falcon.inspect._Traversable.__visit_name__"], "cross_file": []}, "requirement": {"Functionality": "This function processes an InspectVisitor instance by calling the appropriate visit method based on the visit name of the instance. It handles the case where the visit method is not found and raises a RuntimeError.", "Arguments": ":param self: InspectVisitor. An instance of the InspectVisitor class.\n:param instance: _Traversable. The instance to be processed.\n:return: The result of calling the appropriate visit method on the instance."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_middleware_tree_item", "tests/test_inspect.py::TestStringVisitor::test_middleware_tree_no_resource", "tests/test_inspect.py::TestStringVisitor::test_route_no_methods", "tests/test_inspect.py::TestStringVisitor::test_app_static_routes", "tests/test_inspect.py::TestStringVisitor::test_middleware_tree_response_only"], "indent": 8}
{"namespace": "mackup.utils.copy", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [71, 71], "body_position": [89, 112], "dependency": {"intra_class": [], "intra_file": ["mackup.utils.chmod"], "cross_file": []}, "requirement": {"Functionality": "This function copies a file or a folder (recursively) from the source path to the destination path. It first checks if the source and destination paths are valid and absolute paths. Then, it creates the necessary directories in the destination path if they do not exist. If the source is a file, it copies the file to the destination. If the source is a folder, it copies the entire folder to the destination. If the source is neither a file nor a folder, it raises a ValueError. Finally, it sets the appropriate file permissions for the copied file or folder.", "Arguments": ":param src: str. The source file or folder path.\n:param dst: str. The destination file or folder path.\n:return: No return values."}, "tests": ["tests/utils_test.py::TestMackup::test_copy_file", "tests/utils_test.py::TestMackup::test_copy_fail", "tests/utils_test.py::TestMackup::test_copy_file_to_dir", "tests/utils_test.py::TestMackup::test_copy_dir"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.DefaultContainer.batch_to_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [538, 543], "body_position": [544, 547], "dependency": {"intra_class": ["bentoml._internal.runner.container.DefaultContainer.batch_to_batches"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": []}, "requirement": {"Functionality": "This function converts a batch of data into a list of payloads. It first converts the batch into a list of batches based on the given indices and batch dimension. Then, it iterates over each subbatch and converts it into a payload.", "Arguments": ":param cls: DefaultContainer. The class itself.\n:param batch: List of any type. The input batch of data.\n:param indices: Sequence of integers. The indices to select from the batch for each subbatch.\n:param batch_dim: Integer. The dimension along which the batch is split. Defaults to 0.\n:return: List of Payload. The list of payloads created from the batch."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_default_container"], "indent": 8}
{"namespace": "boto.codedeploy.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/codedeploy/__init__.py", "signature_position": [37, 37], "body_position": [38, 41], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.codedeploy.layer1.CodeDeployConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CodeDeployConnection class from the boto library. It creates a connection to the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: CodeDeployConnection. The connection object to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCodeDeployConnection::test_connect_to_region"], "indent": 4}
{"namespace": "pyramid.csrf.LegacySessionCSRFStoragePolicy.check_csrf_token", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/csrf.py", "signature_position": [43, 43], "body_position": [45, 48], "dependency": {"intra_class": ["pyramid.csrf.LegacySessionCSRFStoragePolicy.get_csrf_token"], "intra_file": [], "cross_file": ["pyramid.util.bytes_", "pyramid.util.strings_differ"]}, "requirement": {"Functionality": "Check if the supplied CSRF token is valid by comparing it with the expected token. It converts both tokens to bytes and checks if they are equal.", "Arguments": ":param self: LegacySessionCSRFStoragePolicy. An instance of the LegacySessionCSRFStoragePolicy class.\n:param request: The request object.\n:param supplied_token: The CSRF token supplied by the client.\n:return: Bool. Returns True if the supplied token is valid, False otherwise."}, "tests": ["tests/test_csrf.py::TestLegacySessionCSRFStoragePolicy::test_check_csrf_token"], "indent": 8}
{"namespace": "authlib.jose.util.extract_header", "type": "function", "project_path": "Internet/Authlib", "completion_path": "Internet/Authlib/authlib/jose/util.py", "signature_position": [6, 6], "body_position": [7, 16], "dependency": {"intra_class": [], "intra_file": ["authlib.jose.util.extract_segment"], "cross_file": ["authlib.common.encoding.json_loads", "authlib.common.encoding.urlsafe_b64decode.decode"]}, "requirement": {"Functionality": "This function extracts the header from a given header segment. It first extracts the header segment. Then, it decodes the extracted header data using UTF-8 encoding and loads it as a JSON object. If the loaded header is not a dictionary, it raises an error. Finally, it returns the extracted header.", "Arguments": ":param header_segment: The header segment to extract the header from.\n:param error_cls: The error class to raise if there is an error during the extraction process.\n:return: The extracted header as a dictionary."}, "tests": ["tests/jose/test_jwe.py::JWETest::test_deserialize_json_fails_if_protected_header_contains_unknown_field_while_private_fields_restricted"], "indent": 4}
{"namespace": "imapclient.datetime_util.datetime_to_INTERNALDATE", "type": "function", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/datetime_util.py", "signature_position": [43, 43], "body_position": [49, 52], "dependency": {"intra_class": [], "intra_file": ["imapclient.datetime_util._SHORT_MONTHS"], "cross_file": ["imapclient.fixed_offset.FixedOffset", "imapclient.fixed_offset.FixedOffset.for_system"]}, "requirement": {"Functionality": "This function converts a datetime instance like \"-%Y %H:%M:%S %z\" to a string representation in the format required by IMAP INTERNALDATE. If the datetime instance does not have timezone information, the current system timezone is used.", "Arguments": ":param dt: datetime. The datetime instance to be converted.\n:return: str. The string representation of the datetime instance in the IMAP INTERNALDATE format."}, "tests": ["tests/test_datetime_util.py::TestDatetimeToINTERNALDATE::test_without_timezone", "tests/test_datetime_util.py::TestDatetimeToINTERNALDATE::test_with_timezone"], "indent": 4}
{"namespace": "twilio.twiml.voice_response.VoiceResponse.sms", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [391, 400], "body_position": [414, 424], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Sms", "twilio.twiml.voice_response.Sms.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a <Sms> element for a VoiceResponse instance. It takes in various parameters such as the message body, recipient number, sender number, action URL, method, status callback URL, and additional attributes. It then creates the <Sms> element with these parameters and returns it.", "Arguments": ":param self: VoiceResponse. An instance of the VoiceResponse class.\n:param message: String. The body of the SMS message.\n:param to: String. The number to send the message to.\n:param from_: String. The number to send the message from.\n:param action: String. The action URL.\n:param method: String. The method for the action URL.\n:param status_callback: String. The status callback URL.\n:param kwargs: Additional attributes.\n:return: <Sms> element. The created <Sms> element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestSms::test_body", "tests/unit/twiml/test_voice_response.py::TestSms::test_to_from_action", "tests/unit/twiml/test_voice_response.py::TestResponse::test_response_chain", "tests/unit/twiml/test_voice_response.py::TestResponse::test_response", "tests/unit/twiml/test_voice_response.py::TestSms::test_empty"], "indent": 8}
{"namespace": "mopidy.internal.network.try_ipv6_socket", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/network.py", "signature_position": [8, 8], "body_position": [10, 20], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.network.logger"], "cross_file": []}, "requirement": {"Functionality": "This function checks if the system supports IPv6 by attempting to create a socket with the AF_INET6 address family. If the socket creation is successful, it returns True. Otherwise, it returns False after logging a debug message.", "Arguments": ":param: No input parameters.\n:return: Bool. True if the system supports IPv6, False otherwise."}, "tests": ["tests/internal/test_network.py::TryIPv6SocketTest::test_with_working_ipv6"], "indent": 4}
{"namespace": "falcon.request.Request.headers", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [878, 880], "body_position": [881, 895], "dependency": {"intra_class": ["falcon.request.Request._cached_headers", "falcon.request.Request.env"], "intra_file": ["falcon.request.WSGI_CONTENT_HEADERS"], "cross_file": []}, "requirement": {"Functionality": "This function returns the headers of a Request instance. It first checks if the headers are already cached, and if not, it creates a new dictionary and populates it with the headers from the environment. The headers are then returned.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: Dictionary. The headers of the Request instance."}, "tests": ["tests/test_headers.py::TestHeaders::test_headers_as_list"], "indent": 8}
{"namespace": "diffprivlib.tools.utils.nanvar", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [364, 365], "body_position": [421, 424], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._var"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the differentially private variance of an array along a specified axis, while ignoring NaN values. It adds noise to the variance calculation to satisfy differential privacy. The function closely follows the behavior of the `numpy.var` function.", "Arguments": ":param array: array_like. The array containing numbers whose variance is desired.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. The bounds of the values of the array, in the form (min, max).\n:param axis: int or tuple of ints, optional. The axis or axes along which the variance is computed. The default is to compute the variance of the flattened array. If a tuple of ints is provided, the variance is performed over multiple axes.\n:param dtype: data-type, optional. The type to use in computing the variance. The default is `float32` for arrays of integer type, and the same as the array type for arrays of float types.\n:param keepdims: bool, default: False. If set to True, the axes which are reduced are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm. To obtain deterministic behavior, `random_state` should be fixed to an integer.\n:param accountant: BudgetAccountant, optional. An accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: variance : ndarray, see dtype parameter above. If `out=None`, returns a new array containing the variance; otherwise, a reference to the output array is returned."}, "tests": ["tests/tools/test_nanvar.py::TestNanVar::test_no_params", "tests/tools/test_nanvar.py::TestNanVar::test_no_bounds", "tests/tools/test_nanvar.py::TestNanVar::test_bad_bounds", "tests/tools/test_nanvar.py::TestNanVar::test_array_like", "tests/tools/test_nanvar.py::TestNanVar::test_large_epsilon_axis"], "indent": 4}
{"namespace": "oletools.oleobj.get_sane_embedded_filenames", "type": "function", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/oleobj.py", "signature_position": [550, 551], "body_position": [566, 610], "dependency": {"intra_class": [], "intra_file": ["oletools.oleobj.MAX_FILENAME_ATTEMPTS", "oletools.oleobj.sanitize_filename"], "cross_file": []}, "requirement": {"Functionality": "This function generates a list of sane filenames based on the given input parameters. It extracts the filename from the input paths, sanitizes it, and preserves the file suffix. It returns multiple candidates, first with suffix, then without, then random with suffix, and finally one last attempt ignoring the maximum length using the `noname_index` argument.", "Arguments": ":param filename: String. The original filename.\n:param src_path: String. The source path containing the filename.\n:param tmp_path: String. The temporary path containing the filename.\n:param max_len: Integer. The maximum length of the filename.\n:param noname_index: Integer. The index used to generate a name when all other attempts fail.\n:return: List of Strings. The generated sane filenames."}, "tests": ["tests/oleobj/test_basic.py::TestSaneFilenameCreation::test_with_empty_inputs", "tests/oleobj/test_basic.py::TestSaneFilenameCreation::test_realworld_lnk_example", "tests/oleobj/test_basic.py::TestSaneFilenameCreation::test_with_hardly_any_length", "tests/oleobj/test_basic.py::TestSaneFilenameCreation::test_that_first_has_priority", "tests/oleobj/test_basic.py::TestSaneFilenameCreation::test_with_mean_unicode"], "indent": 4}
{"namespace": "chatette.parsing.UnitRefBuilder.create_concrete", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [110, 110], "body_position": [111, 116], "dependency": {"intra_class": ["chatette.parsing.UnitRefBuilder._build_modifiers_repr", "chatette.parsing.UnitRefBuilder._check_information", "chatette.parsing.UnitRefBuilder.identifier", "chatette.parsing.UnitRefBuilder.leading_space", "chatette.parsing.UnitRefBuilder.type"], "intra_file": [], "cross_file": ["chatette.units.modifiable.unit_reference.UnitReference"]}, "requirement": {"Functionality": "Create a concrete UnitReference object based on the information stored in the UnitRefBuilder instance. It first checks if all the necessary information is available, and then uses that information to create the UnitReference object.", "Arguments": ":param self: UnitRefBuilder. An instance of the UnitRefBuilder class.\n:return: UnitReference. The created UnitReference object."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestUnitRefBuilder::test_create_concrete"], "indent": 8}
{"namespace": "pyramid.request.CallbackMethodsMixin._process_response_callbacks", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/request.py", "signature_position": [76, 76], "body_position": [77, 80], "dependency": {"intra_class": ["pyramid.request.CallbackMethodsMixin.response_callbacks"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function processes the response callbacks for a given response. It iterates through the response callbacks and calls each callback function with the given response and self as arguments.", "Arguments": ":param self: CallbackMethodsMixin. An instance of the CallbackMethodsMixin class.\n:param response: The response object to be passed to the callback functions.\n:return: No return values."}, "tests": ["tests/test_request.py::TestRequest::test__process_response_callbacks", "tests/test_request.py::TestRequest::test__process_response_callback_adding_response_callback"], "indent": 8}
{"namespace": "fs.path.join", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [210, 211], "body_position": [229, 241], "dependency": {"intra_class": [], "intra_file": ["fs.path.abspath", "fs.path.normpath"], "cross_file": []}, "requirement": {"Functionality": "This function joins any number of paths together. It takes multiple paths as input and returns a single joined path.", "Arguments": ":param *paths: Variable number of strings. Paths to join, given as positional arguments.\n:return: str. The joined path."}, "tests": ["tests/test_path.py::TestPathFunctions::test_pathjoin"], "indent": 4}
{"namespace": "rest_framework.fields.MultipleChoiceField.get_value", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [1429, 1429], "body_position": [1430, 1437], "dependency": {"intra_class": [], "intra_file": ["rest_framework.fields.Field.root", "rest_framework.fields.empty"], "cross_file": ["rest_framework.fields.ChoiceField.field_name", "rest_framework.utils.html", "rest_framework.utils.html.is_html_input"]}, "requirement": {"Functionality": "This function retrieves the value of a field from a dictionary. It first checks if the field name is present in the dictionary. If not, it checks if the form is partial and returns an empty value. Then, it checks if the input is in HTML form and returns a list of values if it is. Otherwise, it returns the value corresponding to the field name in the dictionary.", "Arguments": ":param self: MultipleChoiceField. An instance of the MultipleChoiceField class.\n:param dictionary: Dictionary. The dictionary from which to retrieve the field value.\n:return: The value of the field from the dictionary."}, "tests": ["tests/test_fields.py::TestMultipleChoiceField::test_against_partial_and_full_updates"], "indent": 8}
{"namespace": "mopidy.config._validate", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/__init__.py", "signature_position": [219, 220], "body_position": [221, 239], "dependency": {"intra_class": [], "intra_file": ["mopidy.config.logger"], "cross_file": []}, "requirement": {"Functionality": "This function validates a raw configuration against a set of schemas. It iterates through each schema and checks if the corresponding section exists in the raw configuration. If it does, it deserializes the values and adds the result to the validated config. If there are any errors during deserialization, they are stored in the errors dictionary. Any sections in the raw configuration that do not have a matching schema are ignored and a warning message is logged. The function returns the validated config and any errors encountered during validation.", "Arguments": ":param raw_config: Dictionary. The raw configuration to be validated.\n:param schemas: List of Schema objects. The schemas to validate the raw configuration against.\n:return: Tuple. The validated config dictionary and the errors dictionary."}, "tests": ["tests/config/test_config.py::ValidateTest::test_config_no_schemas", "tests/config/test_config.py::ValidateTest::test_config_single_schema_config_error", "tests/config/test_config.py::ValidateTest::test_config_single_schema", "tests/config/test_config.py::ValidateTest::test_empty_config_no_schemas", "tests/config/test_config.py::ValidateTest::test_empty_config_single_schema"], "indent": 4}
{"namespace": "pyramid.registry.Registry.registerSubscriptionAdapter", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [68, 68], "body_position": [69, 71], "dependency": {"intra_class": ["pyramid.registry.Registry.has_listeners"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function registers a subscription adapter in the Registry instance. It also sets the flag of the Registry instance to indicate that it has listeners.", "Arguments": ":param self: Registry. An instance of the Registry class.\n:param *arg: Variable length arguments. The arguments for the superclass method.\n:param **kw: Keyword arguments. The keyword arguments for the superclass method.\n:return: The result of the superclass method."}, "tests": ["tests/test_registry.py::TestRegistry::test_registerSubscriptionAdapter"], "indent": 8}
{"namespace": "trailscraper.cloudtrail.Record.to_statement", "type": "method", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/cloudtrail.py", "signature_position": [155, 155], "body_position": [157, 167], "dependency": {"intra_class": ["trailscraper.cloudtrail.Record._event_name_to_iam_action", "trailscraper.cloudtrail.Record._source_to_iam_prefix", "trailscraper.cloudtrail.Record._to_api_gateway_statement", "trailscraper.cloudtrail.Record.event_name", "trailscraper.cloudtrail.Record.event_source", "trailscraper.cloudtrail.Record.resource_arns"], "intra_file": [], "cross_file": ["trailscraper.iam.Action", "trailscraper.iam.Statement"]}, "requirement": {"Functionality": "This function converts a record into a matching IAM Policy Statement. It checks the event source and event name of the record and returns the corresponding IAM Policy Statement.", "Arguments": ":param self: Record. An instance of the Record class.\n:return: Statement or None. The IAM Policy Statement that matches the record, or None if the event source is \"sts.amazonaws.com\" and the event name is \"GetCallerIdentity\"."}, "tests": ["tests/cloudtrail/record_test.py::test_should_convert_special_event_sources_properly", "tests/cloudtrail/record_test.py::test_should_convert_special_actions_properly", "tests/cloudtrail/record_test.py::test_should_convert_api_gateway_events_properly", "tests/cloudtrail/record_test.py::test_should_convert_into_iam_statement", "tests/cloudtrail/record_test.py::test_should_convert_api_gateway_events_with_parameters_properly"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.get_key_fields", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [919, 919], "body_position": [939, 944], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.describe", "boto.dynamodb2.table.Table.schema"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the fields necessary to make a key for a table. If the table does not already have a populated schema, it requests it. It returns a list of field names.", "Arguments": ":param self: Table. An instance of the Table class.\n:return: List of field names (strings) that are necessary to make a key for the table."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_get_key_fields_no_schema_populated"], "indent": 8}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.submit_request", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [50, 50], "body_position": [54, 58], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcClient.request_queue"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function submits a JSON-RPC request to the input stream. It creates a request dictionary with the method, parameters, and request ID, and then puts the request into the request queue. If `method` or `params` is None, a ValueError is raised.", "Arguments": ":param self: JsonRpcClient. An instance of the JsonRpcClient class.\n:param method: String. The method to be called in the JSON-RPC request.\n:param params: Dictionary. The parameters to be passed in the JSON-RPC request.\n:param request_id: Any. The ID of the request. Defaults to None.\n:return: No return values."}, "tests": ["tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_submit_simple_request", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_request_enqueued", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_send_multiple_request", "tests/jsonrpc/test_jsonrpcclient.py::JsonRpcClientTests::test_send_invalid_request"], "indent": 8}
{"namespace": "dash.fingerprint.check_fingerprint", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/fingerprint.py", "signature_position": [16, 16], "body_position": [17, 25], "dependency": {"intra_class": [], "intra_file": ["dash.fingerprint.cache_regex"], "cross_file": []}, "requirement": {"Functionality": "This function checks if a resource file has a fingerprint in its name. If it does, it removes the fingerprint and returns the original file path along with a boolean value indicating that a fingerprint was found. If the file does not have a fingerprint, it returns the original file path along with a boolean value indicating that no fingerprint was found.", "Arguments": ":param path: String. The file path to check for a fingerprint.\n:return: Tuple. The modified file path and a boolean value indicating if a fingerprint was found."}, "tests": ["tests/unit/test_fingerprint.py::test_fingerprint"], "indent": 4}
{"namespace": "sacred.dependencies.gather_sources_and_dependencies", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/dependencies.py", "signature_position": [726, 726], "body_position": [728, 747], "dependency": {"intra_class": [], "intra_file": ["sacred.dependencies.PackageDependency", "sacred.dependencies.PackageDependency.create", "sacred.dependencies.dependency_discovery_strategies", "sacred.dependencies.get_main_file", "sacred.dependencies.source_discovery_strategies"], "cross_file": ["sacred.optional.has_numpy", "sacred.optional.np", "sacred.settings.SETTINGS"]}, "requirement": {"Functionality": "This function scans the given globals for modules and returns them as dependencies. It gather the soruces and dependencies based on the source discovery strategy and dependency discovery strategy. The main file is added to the sources set if it is not None. If numpy is available, it is added as a dependency. Finally, it returns the main file, sources set, and dependencies set.", "Arguments": ":param globs: dict. The globals to scan for modules.\n:param save_git_info: bool. Whether to save git information.\n:param base_dir: str. The base directory to use for gathering sources and dependencies. Defaults to None. If None, the experiment path is used.\n:return: The main file, sources set, and dependencies set."}, "tests": ["tests/test_dependencies.py::test_gather_sources_and_dependencies", "tests/test_dependencies.py::test_custom_base_dir"], "indent": 4}
{"namespace": "boto.dynamodb2.items.Item.build_expects", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [253, 253], "body_position": [259, 303], "dependency": {"intra_class": ["boto.dynamodb2.items.Item._data", "boto.dynamodb2.items.Item._dynamizer", "boto.dynamodb2.items.Item._orig_data"], "intra_file": ["boto.dynamodb2.items.NEWVALUE"], "cross_file": ["boto.dynamodb.types.Dynamizer.encode"]}, "requirement": {"Functionality": "This function builds up a dictionary of expectations to be passed to DynamoDB when saving an item. It iterates through the fields provided (or all fields if none are specified), checks their state (new, unchanged, modified, or deleted), and adds the corresponding expectation to the dictionary. It also encodes the value if necessary.", "Arguments": ":param self: Item. An instance of the Item class.\n:param fields: List of strings. The fields to include in the expectations. If None, all fields are included. Defaults to None.\n:return: Dictionary. A dictionary of expectations to be passed to DynamoDB."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_build_expects"], "indent": 8}
{"namespace": "boto.ec2.elb.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/elb/__init__.py", "signature_position": [51, 51], "body_position": [62, 64], "dependency": {"intra_class": [], "intra_file": ["boto.ec2.elb.ELBConnection"], "cross_file": ["boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns an instance of the ELBConnection class.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: boto.ec2.ELBConnection or None. A connection to the specified region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestElbConnection::test_connect_to_region"], "indent": 4}
{"namespace": "fs.time.epoch_to_datetime", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/time.py", "signature_position": [38, 39], "body_position": [41, 43], "dependency": {"intra_class": [], "intra_file": ["fs._tzcompat.timezone.utc"], "cross_file": ["fs._tzcompat.timezone"]}, "requirement": {"Functionality": "This function converts epoch time to a UTC datetime. It takes an optional integer parameter representing the epoch time and returns an optional datetime object in UTC.", "Arguments": ":param t: Optional[int]. The epoch time to be converted to datetime.\n:return: Optional[datetime]. The converted datetime object in UTC. If the input is None, the function returns None."}, "tests": ["tests/test_time.py::TestEpoch::test_epoch_to_datetime"], "indent": 4}
{"namespace": "bplustree.entry.Record.dump", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/entry.py", "signature_position": [96, 96], "body_position": [97, 118], "dependency": {"intra_class": ["bplustree.entry.Record._tree_conf", "bplustree.entry.Record.key", "bplustree.entry.Record.overflow_page", "bplustree.entry.Record.value"], "intra_file": [], "cross_file": ["bplustree.serializer", "bplustree.serializer.Serializer.serialize", "bplustree.const.ENDIAN", "bplustree.const.PAGE_REFERENCE_BYTES", "bplustree.const.USED_VALUE_LENGTH_BYTES"]}, "requirement": {"Functionality": "This function is used to convert the Record instance into a byte string representation. It first serializes the key and calculates the length of the key. Then, it determines whether there is an overflow page or not and sets the value accordingly. After that, it calculates the length of the value. Finally, it combines all the necessary information into a byte string and returns it.", "Arguments": ":param self: Record. An instance of the Record class.\n:return: bytes."}, "tests": ["tests/test_entry.py::test_record_str_serialization", "tests/test_entry.py::test_record_int_serialization", "tests/test_entry.py::test_record_int_serialization_overflow_value"], "indent": 8}
{"namespace": "pyramid.renderers.RendererHelper.render", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [445, 445], "body_position": [446, 464], "dependency": {"intra_class": ["pyramid.renderers.RendererHelper.name", "pyramid.renderers.RendererHelper.registry", "pyramid.renderers.RendererHelper.renderer"], "intra_file": [], "cross_file": ["pyramid.csrf.get_csrf_token", "pyramid.events.BeforeRender", "pyramid.registry.Registry.notify"]}, "requirement": {"Functionality": "This function renders a given value using the specified renderer. It first sets up the system values dictionary, which includes information about the view, renderer name, renderer info, context, request, and CSRF token. Then, it notifies the registry about the system values and calls the renderer function to process the value. The render result is returned.", "Arguments": ":param self: RendererHelper. An instance of the RendererHelper class.\n:param value: The value to be rendered.\n:param system_values: Dictionary. A dictionary containing system values such as view, renderer name, renderer info, context, request, and CSRF token.\n:param request: Optional. The request object.\n:return: The rendered result."}, "tests": ["tests/test_renderers.py::TestRendererHelper::test_render_explicit_registry", "tests/test_renderers.py::TestRendererHelper::test_render_system_values_is_None"], "indent": 8}
{"namespace": "boto.ec2.volume.Volume.detach", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/volume.py", "signature_position": [159, 159], "body_position": [176, 188], "dependency": {"intra_class": ["boto.ec2.volume.Volume.attach_data", "boto.ec2.volume.Volume.connection", "boto.ec2.volume.Volume.id"], "intra_file": ["boto.ec2.volume.AttachmentSet.device", "boto.ec2.volume.AttachmentSet.instance_id"], "cross_file": ["boto.ec2.connection.EC2Connection.detach_volume"]}, "requirement": {"Functionality": "Detach this EBS volume from an EC2 instance.", "Arguments": ":param self: Volume. An instance of the Volume class.\n:param force: bool. Specifies whether to force detachment if the previous detachment attempt was not clean. This option can result in data loss or a corrupted file system. Use with caution.\n:param dry_run: bool. Specifies whether to perform a dry run of the detachment. If set to True, no actual detachment will occur.\n:return: bool. True if the detachment was successful."}, "tests": ["tests/unit/ec2/test_volume.py::VolumeTests::test_detach_calls_detach_volume", "tests/unit/ec2/test_volume.py::VolumeTests::test_detach_with_force_calls_detach_volume_with_force", "tests/unit/ec2/test_volume.py::VolumeTests::test_detach_with_no_attach_data"], "indent": 8}
{"namespace": "falcon.request.Request.get_cookie_values", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [1207, 1207], "body_position": [1223, 1236], "dependency": {"intra_class": ["falcon.request.Request._cookies", "falcon.request.Request.get_header"], "intra_file": [], "cross_file": ["falcon.request_helpers.parse_cookie_header", "falcon.request_helpers"]}, "requirement": {"Functionality": "This function returns all values provided in the Cookie header for the named cookie. It first checks if the cookies are None, and if so, it parses the Cookie header and stores the result. Then, it retrieves the value for the specified cookie name and returns it.", "Arguments": ":param self: Request. An instance of the Request class.\n:param name: str. The name of the cookie to retrieve the values for.\n:return: list. An ordered list of all values specified in the Cookie header for the named cookie, or None if the cookie was not included in the request. If the cookie is specified more than once in the header, the returned list of values will preserve the ordering of the individual `cookie-pair`'s in the header."}, "tests": ["tests/test_cookies.py::test_request_cookie_parsing", "tests/test_cookies.py::test_duplicate_cookie"], "indent": 8}
{"namespace": "boto.dynamodb.types.Dynamizer.decode", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb/types.py", "signature_position": [330, 330], "body_position": [336, 347], "dependency": {"intra_class": [], "intra_file": ["boto.dynamodb.types.is_str"], "cross_file": []}, "requirement": {"Functionality": "This function decodes the format returned by DynamoDB and constructs the appropriate Python type. It checks the length of the attribute and if it is a string, it returns the attribute as is. Otherwise, it determines the DynamoDB type and calls the corresponding decoder method to convert the attribute to the appropriate Python type.", "Arguments": ":param self: Dynamizer. An instance of the Dynamizer class.\n:param attr: The attribute to decode, in the format returned by DynamoDB.\n:return: The decoded attribute in the appropriate Python type."}, "tests": ["tests/unit/dynamodb/test_types.py::TestDynamizer::test_lossy_float_conversions", "tests/unit/dynamodb/test_types.py::TestDynamizer::test_decoding_full_doc", "tests/unit/dynamodb/test_types.py::TestDynamizer::test_decoding_to_dynamodb"], "indent": 8}
{"namespace": "mrjob.logs.spark._parse_spark_log", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/spark.py", "signature_position": [30, 30], "body_position": [32, 38], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.spark._parse_spark_log_from_log4j_records"], "cross_file": []}, "requirement": {"Functionality": "Parses a Spark log, extracting errors and application ID. \n", "Arguments": ""}, "tests": ["tests/logs/test_spark.py::ParseSparkLogTestCase::test_multi_line_error", "tests/logs/test_spark.py::ParseSparkLogTestCase::test_multiple_errors", "tests/logs/test_spark.py::ParseSparkLogTestCase::test_application_id", "tests/logs/test_spark.py::ParseSparkLogTestCase::test_multi_line_warning", "tests/logs/test_spark.py::ParseSparkLogTestCase::test_empty"], "indent": 4}
{"namespace": "pysimplesoap.simplexml.SimpleXMLElement.add_child", "type": "method", "project_path": "Communications/PySimpleSOAP", "completion_path": "Communications/PySimpleSOAP/pysimplesoap/simplexml.py", "signature_position": [65, 65], "body_position": [67, 94], "dependency": {"intra_class": ["pysimplesoap.simplexml.SimpleXMLElement.__document", "pysimplesoap.simplexml.SimpleXMLElement.__init__", "pysimplesoap.simplexml.SimpleXMLElement.__jetty", "pysimplesoap.simplexml.SimpleXMLElement.__namespaces_map", "pysimplesoap.simplexml.SimpleXMLElement.__ns", "pysimplesoap.simplexml.SimpleXMLElement.__prefix", "pysimplesoap.simplexml.SimpleXMLElement._element"], "intra_file": ["pysimplesoap.simplexml.basestring"], "cross_file": []}, "requirement": {"Functionality": "This function adds a child tag to an XML node. It takes the name of the child tag (name), an optional text content (text), and a namespace indicator (ns). Depending on the namespace information provided, it creates a new XML element with the specified name and namespace and appends it as a child to the current node. If text content is provided, it is added as either a CDATA section or a text node to the new child element. The function then returns a new SimpleXMLElement representing the added child element along with the updated XML document and namespace information.", "Arguments": ":param self: SimpleXMLElement. An instance of the SimpleXMLElement class.\n:param name: String. The name of the child tag to be added.\n:param text: String or CDATASection. The text content of the child tag. It can be a regular string or a CDATASection object.\n:param ns: Bool or String. Whether to add a namespace to the child tag. If True, the namespace is added based on the instance's namespace. If False or the instance has no namespace, the child tag is added without a namespace. If a string is provided, it is used as the namespace for the child tag.\n:return: SimpleXMLElement. A new SimpleXMLElement instance representing the added child tag."}, "tests": ["tests/simplexmlelement_test.py::TestSimpleXMLElement::test_marshall_cdata"], "indent": 8}
{"namespace": "boltons.cacheutils.MinIDMap.get", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [839, 839], "body_position": [840, 852], "dependency": {"intra_class": ["boltons.cacheutils.MinIDMap._clean", "boltons.cacheutils.MinIDMap.free", "boltons.cacheutils.MinIDMap.mapping", "boltons.cacheutils.MinIDMap.ref_map"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the ID associated with the given object from the MinIDMap instance. If the object is already mapped, it returns the corresponding ID. If the object is not mapped, it assigns a new ID to the object and returns it.", "Arguments": ":param self: MinIDMap. An instance of the MinIDMap class.\n:param a: The object for which the ID needs to be retrieved or assigned.\n:return: int. The ID associated with the object."}, "tests": ["tests/test_cacheutils.py::test_min_id_map"], "indent": 8}
{"namespace": "pycoin.bloomfilter.murmur3", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/bloomfilter.py", "signature_position": [72, 72], "body_position": [73, 119], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pycoin.intbytes.indexbytes"]}, "requirement": {"Functionality": "Calculate the 32-bit MurmurHash3 hash value for the given data using the specified seed.\n", "Arguments": ":param data: Bytes or bytearray, the data to be hashed.\n:param seed: Int, the seed value to initialize the hash algorithm. It defaults to 0 if not specified.\n:return: Int, the 32-bit hash value.\n"}, "tests": ["tests/bloomfilter_test.py::BloomFilterTest::test_murmur3"], "indent": 4}
{"namespace": "boto.ec2.volume.Volume.update", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/volume.py", "signature_position": [105, 105], "body_position": [117, 126], "dependency": {"intra_class": ["boto.ec2.volume.Volume._update", "boto.ec2.volume.Volume.connection", "boto.ec2.volume.Volume.id", "boto.ec2.volume.Volume.status"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.get_all_volumes"]}, "requirement": {"Functionality": "This function updates the data associated with a volume by querying EC2. It first checks if the volume exists in EC2 and then updates the data if it does. If the volume does not exist and the validate parameter is set to True, it raises a ValueError exception.", "Arguments": ":param self: Volume. An instance of the Volume class.\n:param validate: bool. By default, if EC2 returns no data about the volume, the update method returns quietly. If the validate parameter is True, it will raise a ValueError exception if no data is returned from EC2.\n:param dry_run: bool. Whether to perform a dry run of the update operation. Defaults to False.\n:return: str. The status of the volume after the update."}, "tests": ["tests/unit/ec2/test_volume.py::VolumeTests::test_update_with_validate_true_raises_value_error", "tests/unit/ec2/test_volume.py::VolumeTests::test_update_with_result_set_greater_than_0_updates_dict", "tests/unit/ec2/test_volume.py::VolumeTests::test_update_returns_status"], "indent": 8}
{"namespace": "pyinfra.api.arguments.pop_global_arguments", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/arguments.py", "signature_position": [267, 272], "body_position": [292, 329], "dependency": {"intra_class": [], "intra_file": ["pyinfra.api.arguments.AllArguments", "pyinfra.api.arguments.ArgumentMeta.default", "pyinfra.api.arguments.ArgumentMeta.handler", "pyinfra.api.arguments.all_argument_meta", "pyinfra.api.arguments.default_sentinel"], "cross_file": ["pyinfra.api.host.Host.current_deploy_kwargs", "pyinfra.api.host.Host.data", "pyinfra.api.state.State.config", "pyinfra.context", "pyinfra.context.config", "pyinfra.context.ctx_config", "pyinfra.context.host", "pyinfra.context.state", "pyinfra.context.ContextManager.isset"]}, "requirement": {"Functionality": "This function pops and returns the global keyword arguments for an operation. It follows a specific order to retrieve the arguments from different sources such as the current context, deploy context, host data variables, and config variables. It also handles the translation between non-prefixed arguments used internally and prefixed arguments used by the user.", "Arguments": ":param kwargs: Dict[str, Any]. The keyword arguments passed to the function.\n:param state: Optional[\"State\"]. The state object representing the current state of the deployment. Defaults to None.\n:param host: Optional[\"Host\"]. The host object representing the target host. Defaults to None.\n:param keys_to_check: Optional. A list of specific keys to check for in the arguments. Defaults to None.\n:return: Tuple[AllArguments, list[str]]. A tuple containing the popped arguments and a list of the keys that were found."}, "tests": ["tests/test_api/test_api_arguments.py::TestOperationKwargs::test_get_from_config", "tests/test_api/test_api_arguments.py::TestOperationKwargs::test_get_from_state_deploy_kwargs", "tests/test_api/test_api_arguments.py::TestOperationKwargs::test_get_from_kwargs", "tests/test_api/test_api_arguments.py::TestOperationKwargs::test_get_from_host"], "indent": 4}
{"namespace": "pycoin.networks.registry.network_for_netcode", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/networks/registry.py", "signature_position": [15, 15], "body_position": [16, 26], "dependency": {"intra_class": [], "intra_file": ["pycoin.networks.registry.search_prefixes"], "cross_file": []}, "requirement": {"Functionality": "This function searches for a network module based on the given symbol. It iterates through a list of search prefixes and tries to import the module with the corresponding netcode. If the imported module has a network symbol that matches the given symbol, it sets the symbol attribute of the module and returns the network object. If no matching network is found, it raises a ValueError.", "Arguments": ":param symbol: String. The symbol of the network to search for.\n:return: Network. The network object that matches the given symbol."}, "tests": ["tests/sighash_single_test.py::SighashSingleTest::test_sighash_single", "tests/key_validate_test.py::KeyUtilsTest::test_is_public_private_bip32_valid"], "indent": 4}
{"namespace": "chatette.utils.Singleton.reset_instance", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/utils.py", "signature_position": [45, 45], "body_position": [51, 53], "dependency": {"intra_class": ["chatette.utils.Singleton._instance"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function completely resets the instance of the Singleton class, creates a new instance with the given arguments, and returns the new instance.", "Arguments": ":param cls: The Singleton class.\n:param *args: Variable length argument list. The arguments to be passed to the new instance of the class.\n:param **kwargs: Arbitrary keyword arguments. The keyword arguments to be passed to the new instance of the class.\n:return: The new instance of the Singleton class."}, "tests": ["tests/unit-testing/test_statistics.py::TestStats::test_remove_variation", "tests/unit-testing/test_statistics.py::TestStats::test_init", "tests/unit-testing/test_statistics.py::TestStats::test_new_units", "tests/unit-testing/test_statistics.py::TestStats::test_str", "tests/unit-testing/test_deprecations.py::TestDeprecations::test_warn_old_choice"], "indent": 8}
{"namespace": "mrjob.setup.UploadDirManager.path_to_uri", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/setup.py", "signature_position": [343, 343], "body_position": [346, 347], "dependency": {"intra_class": ["mrjob.setup.UploadDirManager._path_to_name", "mrjob.setup.UploadDirManager.uri"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a dictionary that maps each path to its corresponding URI for all the paths that were added.", "Arguments": ":param self: UploadDirManager. An instance of the UploadDirManager class.\n:return: Dictionary. A dictionary that maps each path to its corresponding URI."}, "tests": ["tests/test_setup.py::UploadDirManagerTestCase::test_underscores_only", "tests/test_setup.py::UploadDirManagerTestCase::test_dot_underscore", "tests/test_setup.py::UploadDirManagerTestCase::test_name_collision", "tests/test_setup.py::UploadDirManagerTestCase::test_empty", "tests/test_setup.py::UploadDirManagerTestCase::test_hidden_file_name_collision"], "indent": 8}
{"namespace": "viztracer.code_monkey.AstTransformer.get_assign_targets_with_attr", "type": "method", "project_path": "System/viztracer", "completion_path": "System/viztracer/src/viztracer/code_monkey.py", "signature_position": [109, 109], "body_position": [113, 121], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["viztracer.util.color_print"]}, "requirement": {"Functionality": "This function takes an AST node as input and returns a list of attribute nodes that are used as assignment targets. It recursively traverses the AST and checks the type of each node to determine if it is an attribute node. If it is, the node is added to the list of assignment targets. If the node is a name, subscript, or starred node, it is skipped. If the node is a tuple or list, the function is called recursively on each element of the tuple or list and the results are concatenated. If the node type is unexpected, a warning message is printed. The format of the message is \"WARNING Unexpected node type {node's type} for ast.Assign. Please report to the author github.com/gaogaotiantian/viztracer\".", "Arguments": ":param self: AstTransformer. An instance of the AstTransformer class.\n:param node: ast.Node. The AST node to process.\n:return: List[ast.Attribute]. A list of attribute nodes that are used as assignment targets."}, "tests": ["tests/test_codemonkey.py::TestAstTransformer::test_invalid"], "indent": 8}
{"namespace": "zulipterminal.config.themes.complete_and_incomplete_themes", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/config/themes.py", "signature_position": [140, 140], "body_position": [141, 150], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.config.themes.THEMES"], "cross_file": []}, "requirement": {"Functionality": "This function determines the complete and incomplete themes based on the predefined set of required styles and meta information. It iterates through the themes dictionary and checks if the styles and meta information of each theme match the required styles and meta. The themes that meet the requirements are considered complete, while the rest are considered incomplete.", "Arguments": ":param: No input parameters.\n:return: Tuple of two lists. The first list contains the names of the complete themes, sorted in alphabetical order. The second list contains the names of the incomplete themes, also sorted in alphabetical order."}, "tests": ["tests/config/test_themes.py::test_complete_and_incomplete_themes"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_values.get_params_to_model_values", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_values.py", "signature_position": [232, 234], "body_position": [253, 264], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix"]}, "requirement": {"Functionality": "This function determines which parameters should be modeled as categorical variables based on heuristics. It calculates the statistics of each parameter and its corresponding values, and then selects the parameters that meet certain criteria.", "Arguments": ":param param_counts: Union[StateMatrix, dict]. The counts of each individual parameter.\n:param param_value_counts: Union[StateMatrix, dict]. The counts of each value conditional on the parameters.\n:return: set. A set of parameters that have been determined to be categorical."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_values.py::TestCmdsParamsValues::test_get_params_to_model_values"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_values.compute_likelihood_window", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_values.py", "signature_position": [339, 350], "body_position": [393, 443], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_values.compute_prob_setofparams_given_cmd"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the likelihood of a given window of commands. It calculates the probability of the window based on the prior probabilities, transition probabilities, and conditional probabilities of parameters and values.", "Arguments": ":param window: List[Cmd]. A list of commands representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands.\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the parameters conditional on the commands.\n:param value_cond_param_probs: Union[StateMatrix, dict]. Computed probabilities of the values conditional on the parameters.\n:param modellable_params: set. A set of parameters for which the probabilities of their values will be included in the likelihood calculation.\n:param use_start_token: bool. Whether to prepend the start_token to the window before calculating the likelihood.\n:param use_end_token: bool. Whether to append the end_token to the window before calculating the likelihood.\n:param start_token: str. A dummy command to signify the start of the session. Defaults to None.\n:param end_token: str. A dummy command to signify the end of the session. Defaults to None.\n:return: float. The likelihood of the window."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_values.py::TestCmdsParamsValues::test_compute_likelihood_window"], "indent": 4}
{"namespace": "mingus.core.value.septuplet", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/value.py", "signature_position": [197, 197], "body_position": [216, 219], "dependency": {"intra_class": [], "intra_file": ["mingus.core.value.tuplet"], "cross_file": []}, "requirement": {"Functionality": "This function returns the value of a septuplet note. A septuplet is a musical notation where seven notes are played in the duration of either four or eighth notes. \nIf the \"in_fourths\" parameter is True, the function uses the tuplet function with parameters value, 7, and 4 to calculate the note value. Otherwise, it uses the tuplet function with parameters value, 7, and 8. \n", "Arguments": ":param value: Int. The value of the note.\n:param in_fourths: Bool. Whether to use the duration of four notes or eighth notes for the septuplet. Defaults to True.\n:return: Float. The value of the septuplet note.\n"}, "tests": ["tests/unit/core/test_value.py::test_value::test_septuplet"], "indent": 4}
{"namespace": "boltons.socketutils.BufferedSocket.getrecvbuffer", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/socketutils.py", "signature_position": [189, 189], "body_position": [191, 192], "dependency": {"intra_class": ["boltons.socketutils.BufferedSocket._recv_lock", "boltons.socketutils.BufferedSocket.rbuf"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the receive buffer of a BufferedSocket object as a bytestring.\n", "Arguments": ":param self: BufferedSocket. An instance of the BufferedSocket class.\n:return: bytes. The receive buffer of the BufferedSocket object.\n"}, "tests": ["tests/test_socketutils.py::test_client_disconnecting", "tests/test_socketutils.py::test_socketutils_netstring", "tests/test_socketutils.py::test_buffers"], "indent": 8}
{"namespace": "falcon.request.Request.client_accepts", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [1076, 1076], "body_position": [1088, 1099], "dependency": {"intra_class": ["falcon.request.Request.accept"], "intra_file": [], "cross_file": ["falcon.vendor.mimeparse", "falcon.vendor.mimeparse.quality"]}, "requirement": {"Functionality": "This function determines whether or not the client accepts a given media type. It checks the Accept header of the client and compares it with the specified media type.", "Arguments": ":param self: Request. An instance of the Request class.\n:param media_type: str. The media type to check if the client accepts.\n:return: bool. Returns True if the client accepts the specified media type, otherwise returns False."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_client_accepts"], "indent": 8}
{"namespace": "asyncssh.auth.get_supported_server_auth_methods", "type": "function", "project_path": "Security/asyncssh", "completion_path": "Security/asyncssh/asyncssh/auth.py", "signature_position": [954, 955], "body_position": [958, 964], "dependency": {"intra_class": [], "intra_file": ["asyncssh.auth._auth_methods", "asyncssh.auth._server_auth_handlers", "asyncssh.auth.ServerAuth.supported"], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of supported server authentication methods. It iterates through a list of authentication methods and checks if each method is supported by the server. If a method is supported, it is added to the list of supported methods.", "Arguments": ":param conn: SSHServerConnection. An instance of the SSHServerConnection class.\n:return: Sequence[bytes]. A list of supported server authentication methods."}, "tests": ["tests/test_auth.py::_TestAuth::test_server_auth_methods"], "indent": 4}
{"namespace": "diffprivlib.models.naive_bayes.GaussianNB._update_mean_variance", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/naive_bayes.py", "signature_position": [183, 183], "body_position": [226, 278], "dependency": {"intra_class": ["diffprivlib.models.naive_bayes.GaussianNB.bounds", "diffprivlib.models.naive_bayes.GaussianNB.epsilon"], "intra_file": [], "cross_file": ["diffprivlib.utils.PrivacyLeakWarning", "diffprivlib.utils.warn_unused_args", "diffprivlib.mechanisms.laplace.LaplaceTruncated.randomise"]}, "requirement": {"Functionality": "This function computes the online update of the Gaussian mean and variance. It takes the starting sample count, mean, and variance, and a new set of points X, and returns the updated mean and variance. Each dimension in X is treated as independent, so it calculates the variance, not the covariance. It can update a scalar mean and variance or a vector mean and variance to simultaneously update multiple independent Gaussians.", "Arguments": ":param self: GaussianNB. An instance of the GaussianNB class.\n:param n_past: int. The number of samples represented in the old mean and variance. If sample weights were given, this should contain the sum of sample weights represented in the old mean and variance.\n:param mu: array-like, shape (number of Gaussians,). The means for Gaussians in the original set.\n:param var: array-like, shape (number of Gaussians,). The variances for Gaussians in the original set.\n:param X: array-like, shape (n_samples, n_features). The new set of points to update the mean and variance with.\n:param random_state: RandomState. Controls the randomness of the model.\n:param sample_weight: ignored. Ignored in diffprivlib.\n:param n_noisy: int, optional. Noisy count of the given class, satisfying differential privacy.\n:return: (total_mu) array-like, shape (number of Gaussians,) and (total_var) array-like, shape (number of Gaussians,). The updated mean for each Gaussian over the combined set and the updated variance for each Gaussian over the combined set."}, "tests": ["tests/models/test_GaussianNB.py::TestGaussianNB::test_update_mean_variance"], "indent": 8}
{"namespace": "twilio.twiml.voice_response.Dial.conference", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [2009, 2033], "body_position": [2062, 2087], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Conference", "twilio.twiml.voice_response.Conference.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Conference>` element with the given parameters and returns it. It is used to configure various settings for a conference call.", "Arguments": ":param self: Dial. An instance of the Dial class.\n:param name: String. The name of the conference.\n:param muted: Bool. Whether participants should join the conference muted.\n:param beep: Bool. Whether a beep should be played when participants join the conference.\n:param start_conference_on_enter: Bool. Whether the conference should start when a participant enters.\n:param end_conference_on_exit: Bool. Whether the conference should end when a participant exits.\n:param wait_url: String. The URL to play while waiting for the conference to start.\n:param wait_method: String. The HTTP method to use for the wait URL.\n:param max_participants: Integer. The maximum number of participants allowed in the conference.\n:param record: Bool. Whether the conference should be recorded.\n:param region: String. The region for the conference.\n:param coach: Bool. Whether a call coach should be enabled.\n:param trim: Bool. Whether the conference recording should be trimmed.\n:param status_callback_event: String. The events to trigger the status callback URL.\n:param status_callback: String. The URL to call for status callbacks.\n:param status_callback_method: String. The HTTP method to use for the status callback URL.\n:param recording_status_callback: String. The URL to call for recording status callbacks.\n:param recording_status_callback_method: String. The HTTP method to use for the recording status callback URL.\n:param recording_status_callback_event: String. The events to trigger the recording status callback URL.\n:param event_callback_url: String. The URL to call for event callbacks.\n:param jitter_buffer_size: Integer. The size of the jitter buffer for participants.\n:param participant_label: String. A label for the participant.\n:param kwargs: Additional attributes.\n:return: `<Conference>` element. The created `<Conference>` element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestDial::test_add_conference", "tests/unit/twiml/test_voice_response.py::TestConference::test_conference", "tests/unit/twiml/test_voice_response.py::TestConference::test_muted_conference"], "indent": 8}
{"namespace": "bentoml._internal.configuration.helpers.load_config_file", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/configuration/helpers.py", "signature_position": [91, 91], "body_position": [93, 99], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["bentoml.exceptions.BentoMLConfigException"]}, "requirement": {"Functionality": "This function loads a configuration file from the given path. It checks if the file exists, and if not, raises an exception. Then, it opens the file and loads the configuration using the YAML library. Finally, it returns the loaded configuration.", "Arguments": ":param path: str. The path to the configuration file.\n:return: dict[str, t.Any]. The loaded configuration as a dictionary."}, "tests": ["tests/unit/_internal/configuration/test_helpers.py::test_invalid_load_config_file", "tests/unit/_internal/configuration/test_helpers.py::test_valid_load_config_file"], "indent": 4}
{"namespace": "rest_framework.relations.PrimaryKeyRelatedField.to_internal_value", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/relations.py", "signature_position": [295, 295], "body_position": [296, 306], "dependency": {"intra_class": ["rest_framework.relations.PrimaryKeyRelatedField.pk_field"], "intra_file": ["rest_framework.relations.RelatedField.get_queryset"], "cross_file": ["rest_framework.fields.Field.fail", "rest_framework.fields.Field.to_internal_value"]}, "requirement": {"Functionality": "This function is a method of the PrimaryKeyRelatedField class. It converts the input data into its internal representation. It first converts the data using the primary key field. Then, it retrieves the queryset and tries to get the object with the specified primary key (pk). If the object does not exist, it raises an exception. If the data is of incorrect type or value, it also raises an exception.", "Arguments": ":param self: PrimaryKeyRelatedField. An instance of the PrimaryKeyRelatedField class.\n:param data: The input data to be converted.\n:return: No return value."}, "tests": ["tests/test_relations.py::TestProxiedPrimaryKeyRelatedField::test_pk_related_lookup_exists", "tests/test_relations.py::TestProxiedPrimaryKeyRelatedField::test_pk_related_lookup_does_not_exist", "tests/test_relations.py::TestPrimaryKeyRelatedField::test_pk_related_lookup_does_not_exist", "tests/test_relations.py::TestPrimaryKeyRelatedField::test_pk_related_lookup_exists", "tests/test_relations.py::TestPrimaryKeyRelatedField::test_explicit_many_false"], "indent": 8}
{"namespace": "sacred.utils.iter_prefixes", "type": "function", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/utils.py", "signature_position": [503, 503], "body_position": [512, 514], "dependency": {"intra_class": [], "intra_file": ["sacred.utils.join_paths"], "cross_file": []}, "requirement": {"Functionality": "This function iterates through all non-empty prefixes of a dotted path. It splits the input path by \".\" and yields each prefix from the first element to the current element.", "Arguments": ":param path: String. The dotted path to iterate through.\n:return: Iterator. An iterator that yields each non-empty prefix of the input path."}, "tests": ["tests/test_utils.py::test_iter_prefixes"], "indent": 4}
{"namespace": "boto.ec2.elb.ELBConnection.get_all_load_balancers", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/elb/__init__.py", "signature_position": [109, 109], "body_position": [126, 135], "dependency": {"intra_class": ["boto.ec2.elb.ELBConnection.build_list_params"], "intra_file": [], "cross_file": ["boto.connection.AWSQueryConnection.get_list", "boto.ec2.elb.loadbalancer.LoadBalancer"]}, "requirement": {"Functionality": "This function retrieves all load balancers associated with the user's account. It allows for pagination of results and returns a ResultSet containing instances of the LoadBalancer class.", "Arguments": ":param self: ELBConnection. An instance of the ELBConnection class.\n:param load_balancer_names: List. An optional list of load balancer names.\n:param marker: String. Use this only when paginating results and only in a follow-up request after receiving a truncated response. Set this to the value of the Marker element in the response received.\n:return: ResultSet. A ResultSet containing instances of the LoadBalancer class."}, "tests": ["tests/unit/ec2/elb/test_loadbalancer.py::TestDescribeLoadBalancers::test_request_with_marker", "tests/unit/ec2/elb/test_loadbalancer.py::TestDescribeLoadBalancers::test_other_policy"], "indent": 8}
{"namespace": "jinja2.idtracking.Symbols.dump_stores", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/idtracking.py", "signature_position": [147, 147], "body_position": [148, 158], "dependency": {"intra_class": ["jinja2.idtracking.Symbols.find_ref", "jinja2.idtracking.Symbols.stores"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function dumps all symbols stored in this instance and its parent nodes.", "Arguments": ":param self: Symbols. An instance of the Symbols class.\n:return: Dict[str, str]. A dictionary containing all the symbols stored in this instance and its parent nodes."}, "tests": ["tests/test_idtracking.py::test_complex", "tests/test_idtracking.py::test_if_branching_stores_undefined", "tests/test_idtracking.py::test_if_branching_stores"], "indent": 8}
{"namespace": "rows.fields.TextField.deserialize", "type": "method", "project_path": "Text-Processing/rows", "completion_path": "Text-Processing/rows/rows/fields.py", "signature_position": [420, 420], "body_position": [421, 424], "dependency": {"intra_class": ["rows.fields.TextField.TYPE"], "intra_file": ["rows.fields.as_string"], "cross_file": []}, "requirement": {"Functionality": "Deserialize a value into a TextField instance. If the value is already of the TextField type or None, it is returned as is. Otherwise, the value is converted to a string.", "Arguments": ":param cls: TextField. The class object of the TextField.\n:param value: Any. The value to be deserialized.\n:param *args: Any. Additional positional arguments.\n:param **kwargs: Any. Additional keyword arguments.\n:return: Any. The deserialized value."}, "tests": ["tests/tests_fields.py::FieldsTestCase::test_TextField"], "indent": 8}
{"namespace": "litecli.packages.parseutils.queries_start_with", "type": "function", "project_path": "Database/litecli", "completion_path": "Database/litecli/litecli/packages/parseutils.py", "signature_position": [211, 211], "body_position": [213, 216], "dependency": {"intra_class": [], "intra_file": ["litecli.packages.parseutils.query_starts_with"], "cross_file": []}, "requirement": {"Functionality": "This function checks if any queries in the given list start with any item from the given list of prefixes. It splits the queries using the sqlparse library and then checks each query.", "Arguments": ":param queries: List of strings. The queries to check.\n:param prefixes: List of strings. The prefixes to check against.\n:return: Bool. True if any query starts with any prefix, False otherwise."}, "tests": ["tests/test_parseutils.py::test_queries_start_with"], "indent": 4}
{"namespace": "exodus_bundler.bundling.Bundle.bundle_root", "type": "method", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [870, 870], "body_position": [872, 873], "dependency": {"intra_class": ["exodus_bundler.bundling.Bundle.hash", "exodus_bundler.bundling.Bundle.working_directory"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the root directory of the bundle where the original file structure is mirrored. It constructs the path by joining the working directory, 'bundles' folder, and the hash of the bundle. Then it normalizes and returns the absolute path.", "Arguments": ":param self: Bundle. An instance of the Bundle class.\n:return: str. The root directory of the bundle."}, "tests": ["tests/test_bundling.py::test_file_symlink", "tests/test_bundling.py::test_bundle_root"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.update", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [381, 381], "body_position": [420, 458], "dependency": {"intra_class": ["boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name", "boto.dynamodb2.table.Table.throughput"], "intra_file": [], "cross_file": ["boto.dynamodb2.layer1.DynamoDBConnection.update_table", "boto.log", "boto"]}, "requirement": {"Functionality": "This function updates the attributes and global indexes of a table in DynamoDB. It accepts optional parameters for throughput and global indexes. If provided, the throughput parameter should be a dictionary with 'read' and 'write' keys, each associated with an integer value. The global_indexes parameter should also be a dictionary, where each key is the index name and the value is a dictionary with 'read' and 'write' keys, each associated with an integer value. The function returns True on success.", "Arguments": ":param self: Table. An instance of the Table class.\n:param throughput: Dictionary. Optional. Specifies the read and write capacity units for the table. Defaults to None.\n:param global_indexes: Dictionary. Optional. Specifies the read and write capacity units for the global indexes of the table. Defaults to None.\n:return: bool. True if the update is successful, False otherwise."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_update"], "indent": 8}
{"namespace": "boltons.dictutils.OneToOne.pop", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [856, 856], "body_position": [857, 862], "dependency": {"intra_class": ["boltons.dictutils.OneToOne.inv"], "intra_file": ["boltons.dictutils._MISSING"], "cross_file": []}, "requirement": {"Functionality": "Remove a key-value pair from the dictionary and return the value associated with the key. If the key doesn't exist, raise a KeyError.\n", "Arguments": ":param self: OneToOne, an instance of the \"OneToOne\" class.\n:param key: The key to be removed from the dictionary.\n:param default: The default value to be returned if the key doesn't exist. Defaults to \"_MISSING\" if not specified.\n:return: The value associated with the key, or the default value if provided. No return values if the key doesn't exist and no default value is provided.\n"}, "tests": ["tests/test_dictutils.py::test_one_to_one"], "indent": 8}
{"namespace": "mopidy.internal.log.get_verbosity_level", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/log.py", "signature_position": [120, 124], "body_position": [125, 135], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.log.LOG_LEVELS", "mopidy.internal.log.LoggingConfig"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the verbosity level based on the given logging configuration, base verbosity level, and arguments verbosity level. It first checks if the arguments verbosity level is provided, and if so, adds it to the base verbosity level. Otherwise, it adds the verbosity level from the logging configuration. Then, it checks if the calculated verbosity level is less than the minimum level in the predefined dictionary, and if so, sets it to the minimum level. Similarly, it checks if the calculated verbosity level is greater than the maximum level defined in the predefined dictionary, and if so, sets it to the maximum level.", "Arguments": ":param logging_config: LoggingConfig. The logging configuration dictionary.\n:param base_verbosity_level: int. The base verbosity level.\n:param args_verbosity_level: int. The verbosity level passed as arguments.\n:return: int. The calculated verbosity level."}, "tests": ["tests/internal/test_log.py::test_get_verbosity_level_min", "tests/internal/test_log.py::test_get_verbosity_level_args", "tests/internal/test_log.py::test_get_verbosity_level_config", "tests/internal/test_log.py::test_get_verbosity_level_max", "tests/internal/test_log.py::test_get_verbosity_level_config_none"], "indent": 4}
{"namespace": "alembic.script.revision.Revision._normalized_down_revisions", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [1611, 1611], "body_position": [1616, 1619], "dependency": {"intra_class": ["alembic.script.revision.Revision._normalized_resolved_dependencies", "alembic.script.revision.Revision.down_revision"], "intra_file": [], "cross_file": ["alembic.util", "alembic.util.langhelpers.dedupe_tuple", "alembic.util.langhelpers.to_tuple"]}, "requirement": {"Functionality": "This function returns the immediate down revisions for a given revision, excluding any dependencies that are still dependencies of ancestors.", "Arguments": ":param self: Revision. An instance of the Revision class.\n:return: Tuple of strings. The immediate down revisions for the given revision."}, "tests": ["tests/test_revision.py::NormalizedDownRevTest::test_normalized_down_revisions", "tests/test_revision.py::NormalizedDownRevTest::test_dupe_dependency"], "indent": 8}
{"namespace": "mrjob.parse.parse_mr_job_stderr", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [115, 115], "body_position": [130, 161], "dependency": {"intra_class": [], "intra_file": ["mrjob.parse._COUNTER_RE", "mrjob.parse._STATUS_RE"], "cross_file": ["mrjob.py2.to_unicode"]}, "requirement": {"Functionality": "This function parses counters and status messages from the MRJob output. It takes the stderr as input and returns a dictionary containing counters, statuses, and other lines.", "Arguments": ":param stderr: Filehandle, list of lines (bytes), or bytes. The stderr output from MRJob.\n:param counters: Dict[str, Dict[str, int]]. Counters so far, to update. It is a map from group (str) to counter name (str) to count (int).\n:return: Dict. A dictionary with keys 'counters', 'statuses', and 'other'. 'counters' contains the counters so far in the same format as described above. 'statuses' is a list of status messages encountered. 'other' is a list of lines (strings) that are neither counters nor status messages."}, "tests": ["tests/test_parse.py::ParseMRJobStderrTestCase::test_garbled_counters", "tests/test_parse.py::ParseMRJobStderrTestCase::test_update_counters", "tests/test_job.py::CountersAndStatusTestCase::test_counters_and_status", "tests/test_parse.py::ParseMRJobStderrTestCase::test_read_multiple_lines_from_buffer", "tests/test_parse.py::ParseMRJobStderrTestCase::test_read_single_line"], "indent": 4}
{"namespace": "twilio.twiml.voice_response.Dial.queue", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/twiml/voice_response.py", "signature_position": [2151, 2159], "body_position": [2172, 2181], "dependency": {"intra_class": [], "intra_file": ["twilio.twiml.voice_response.Queue", "twilio.twiml.voice_response.Queue.__init__"], "cross_file": ["twilio.twiml.TwiML.nest"]}, "requirement": {"Functionality": "This function creates a `<Queue>` element with the given parameters and returns it. It is used to create a queue for the Dial object.", "Arguments": ":param self: Dial. An instance of the Dial class.\n:param name: String. The name of the queue.\n:param url: String. The action URL.\n:param method: String. The action URL method.\n:param reservation_sid: String. The TaskRouter Reservation SID.\n:param post_work_activity_sid: String. The TaskRouter Activity SID.\n:param kwargs: Additional attributes.\n:return: `<Queue>` element. The created `<Queue>` element."}, "tests": ["tests/unit/twiml/test_voice_response.py::TestQueue::test_queue", "tests/unit/twiml/test_voice_response.py::TestDial::test_add_queue"], "indent": 8}
{"namespace": "boltons.iterutils.chunk_ranges", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [377, 377], "body_position": [405, 424], "dependency": {"intra_class": [], "intra_file": ["boltons.iterutils._validate_positive_int"], "cross_file": []}, "requirement": {"Functionality": "This function generates chunk ranges of a specified size for an input with a given length. The chunk ranges can have an optional overlap and their starts can be aligned to (chunk_size-overlap_size) within the input.\n", "Arguments": ":param input_size: int. The length of the input.\n:param chunk_size: int. The size of each chunk.\n:param input_offset: int [optional]. The start position of the input. Defaults to 0.\n:param overlap_size: int [optional]. The size of the overlap between chunks. Defaults to 0.\n:param align: bool [optional]. Whether to align starts of chunks to (chunk_size-overlap_size). Defaults to False.\n:return: Iterator of tuples. Each tuple contains the start and end positions of a chunk range.\n"}, "tests": ["tests/test_iterutils.py::test_chunk_ranges"], "indent": 4}
{"namespace": "mopidy.internal.xdg.get_dirs", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/xdg.py", "signature_position": [6, 6], "body_position": [19, 33], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.xdg._get_user_dirs"], "cross_file": []}, "requirement": {"Functionality": "This function returns a dictionary containing all the known XDG Base Directories for the current user. It retrieves the values of the environment variables related to XDG Base Directories and expands the paths using `pathlib.Path.expanduser()`. It also updates the dictionary with additional directories if the `user-dirs.dirs` file exists and is parseable.", "Arguments": ":param: No input parameters.\n:return: dict. A dictionary containing the XDG Base Directories for the current user. The keys are the names of the directories (e.g., \"XDG_CACHE_DIR\", \"XDG_CONFIG_DIR\") and the values are `pathlib.Path` objects representing the expanded paths."}, "tests": ["tests/internal/test_xdg.py::test_user_dirs", "tests/internal/test_xdg.py::test_data_dir_default", "tests/internal/test_xdg.py::test_cache_dir_default", "tests/internal/test_xdg.py::test_user_dirs_when_no_dirs_file", "tests/internal/test_xdg.py::test_cache_dir_from_env"], "indent": 4}
{"namespace": "twtxt.models.Tweet.relative_datetime", "type": "method", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/models.py", "signature_position": [75, 75], "body_position": [77, 83], "dependency": {"intra_class": ["twtxt.models.Tweet.created_at"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function calculates the relative time between the current time and the time when a tweet was created. It returns a human-readable string that represents the relative time. The output format \"{delta} {tense}\";", "Arguments": ":param self: Tweet. An instance of the Tweet class.\n:return: String. A human-readable relative time string."}, "tests": ["tests/test_models.py::test_tweet_relative_datetime"], "indent": 8}
{"namespace": "pyramid.registry.Registry.notify", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [100, 100], "body_position": [101, 103], "dependency": {"intra_class": ["pyramid.registry.Registry.has_listeners"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Notify the subscribers of the Registry instance about the occurrence of events.", "Arguments": ":param self: Registry. An instance of the Registry class.\n:param events: Variable number of events. The events to notify the subscribers about.\n:return: No return values."}, "tests": ["tests/test_config/test_adapters.py::AdaptersConfiguratorMixinTests::test_add_subscriber_with_default_type_predicates_True", "tests/test_config/test_adapters.py::AdaptersConfiguratorMixinTests::test_add_subscriber_iface_specified", "tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_add_subscriber_single", "tests/test_registry.py::TestRegistry::test_registerHandler_and_notify", "tests/test_config/test_testing.py::TestingConfiguratorMixinTests::test_testing_add_subscriber_defaults"], "indent": 8}
{"namespace": "mrjob.fs.base.Filesystem.join", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/base.py", "signature_position": [97, 97], "body_position": [99, 111], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.parse.is_uri", "mrjob.parse.urlparse"]}, "requirement": {"Functionality": "Join multiple paths onto a base path. If the base path is a URI, it only considers the URI and the paths that follow it. It extract the scheme, netloc, and path from the URI, and then join the URI path and the remaining paths. If the base path is not a URI, it join all the paths together.", "Arguments": ":param self: Filesystem. An instance of the Filesystem class.\n:param path: String. The base path to join the other paths onto.\n:param *paths: Tuple of strings. The paths to be joined onto the base path.\n:return: String. The joined path."}, "tests": ["tests/fs/test_ssh.py::SSHFSTestCase::test_cat_gz", "tests/fs/test_hadoop.py::HadoopFSTestCase::test_cat_bz2", "tests/fs/test_base.py::JoinTestCase::test_path_onto_uri", "tests/fs/test_base.py::JoinTestCase::test_local_paths", "tests/fs/test_ssh.py::SSHFSTestCase::test_cat_with_required_sudo"], "indent": 8}
{"namespace": "mopidy.config.types.LogLevel.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [367, 367], "body_position": [368, 370], "dependency": {"intra_class": ["mopidy.config.types.LogLevel.levels"], "intra_file": ["mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_choice", "mopidy.config.validators"]}, "requirement": {"Functionality": "Deserialize a value and return the corresponding log level. It decodes the input value, validates it against the available log levels, and returns the corresponding log level.", "Arguments": ":param self: LogLevel. An instance of the LogLevel class.\n:param value: The value to be deserialized.\n:return: The corresponding log level."}, "tests": ["tests/config/test_types.py::TestLogLevel::test_deserialize_conversion_failure", "tests/config/test_types.py::TestLogLevel::test_deserialize_conversion_success"], "indent": 8}
{"namespace": "zxcvbn.scoring.estimate_guesses", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/scoring.py", "signature_position": [222, 222], "body_position": [223, 247], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.scoring.MIN_SUBMATCH_GUESSES_MULTI_CHAR", "zxcvbn.scoring.MIN_SUBMATCH_GUESSES_SINGLE_CHAR", "zxcvbn.scoring.bruteforce_guesses", "zxcvbn.scoring.date_guesses", "zxcvbn.scoring.dictionary_guesses", "zxcvbn.scoring.regex_guesses", "zxcvbn.scoring.repeat_guesses", "zxcvbn.scoring.sequence_guesses", "zxcvbn.scoring.spatial_guesses"], "cross_file": []}, "requirement": {"Functionality": "Estimate the number of guesses required to crack a password based on the given match. It first checks if the number of guesses is already calculated and returns it if so. Otherwise, it calculates the minimum number of guesses based on the length of the match token compared to the password length. Then, it uses different estimation functions based on the pattern of the match to calculate the number of guesses. Finally, it updates the match dictionary with the calculated number of guesses and returns it.", "Arguments": ":param match: Dictionary. The match object containing information about the password match.\n:param password: String. The password to be cracked.\n:return: Decimal. The estimated number of guesses required to crack the password."}, "tests": ["tests/scoring_test.py::test_calc_guesses", "tests/scoring_test.py::test_estimate_guesses"], "indent": 4}
{"namespace": "rest_framework.fields.CharField.run_validation", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [743, 746], "body_position": [747, 751], "dependency": {"intra_class": ["rest_framework.fields.CharField.allow_blank", "rest_framework.fields.CharField.trim_whitespace"], "intra_file": ["rest_framework.fields.Field", "rest_framework.fields.Field.fail", "rest_framework.fields.Field.run_validation", "rest_framework.fields.empty"], "cross_file": []}, "requirement": {"Functionality": "This function is used to validate the input data for a CharField instance. It checks if the data is an empty string or if it consists only of whitespace characters. If the data is empty and the CharField does not allow blank values, an exception is raised. Otherwise, an empty string is returned. If the data is not empty, it calls the parent class's run_validation() method to perform further validation.", "Arguments": ":param self: CharField. An instance of the CharField class.\n:param data: Any. The input data to be validated.\n:return: str. An empty string if the data is empty and allowed, otherwise the input data itself."}, "tests": ["tests/test_fields.py::TestEmpty::test_allow_blank", "tests/test_fields.py::TestCharField::test_surrogate_characters", "tests/test_fields.py::TestEmpty::test_disallow_blank", "tests/test_fields.py::TestCharField::test_null_bytes", "tests/test_fields.py::TestCharField::test_disallow_blank_with_trim_whitespace"], "indent": 8}
{"namespace": "pyramid.config.Configurator.absolute_asset_spec", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/__init__.py", "signature_position": [739, 739], "body_position": [748, 750], "dependency": {"intra_class": ["pyramid.config.Configurator._make_spec"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a potentially relative asset specification string and resolves it into an absolute asset specification string. It uses the package of the Configurator instance as the reference package for generating the absolute asset specification. If the provided relative_spec argument is already absolute or not a string, it is simply returned.", "Arguments": ":param self: Configurator. An instance of the Configurator class.\n:param relative_spec: String. The potentially relative asset specification string to be resolved.\n:return: String. The resolved absolute asset specification string."}, "tests": ["tests/test_config/test_init.py::ConfiguratorTests::test_absolute_asset_spec_already_absolute", "tests/test_config/test_init.py::ConfiguratorTests::test_absolute_asset_spec_relative"], "indent": 8}
{"namespace": "boto.dynamodb2.items.Item.delete", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [460, 460], "body_position": [472, 473], "dependency": {"intra_class": ["boto.dynamodb2.items.Item.get_keys", "boto.dynamodb2.items.Item.table"], "intra_file": [], "cross_file": ["boto.dynamodb2.table.Table.delete_item"]}, "requirement": {"Functionality": "This function deletes the data of an item from DynamoDB. It retrieves the keys of the item, and then uses those keys to delete the item from the table.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: bool. Returns True if the deletion is successful."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_delete"], "indent": 8}
{"namespace": "pyramid.config.views.MultiView.__permitted__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/views.py", "signature_position": [132, 132], "body_position": [133, 136], "dependency": {"intra_class": ["pyramid.config.views.MultiView.match"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if the finded view is permitted based on the context and request. It first matches a view based on the context and request, and then try to determine if this view can be permitted, If the matched view does not have the '__permitted__', it returns True.", "Arguments": ":param self: MultiView. An instance of the MultiView class.\n:param context: The context in which the view is being checked for permission.\n:param request: The request object.\n:return: Bool. True if the view is permitted, False otherwise."}, "tests": ["tests/test_config/test_views.py::TestMultiView::test_permitted", "tests/test_config/test_views.py::TestMultiView::test_permitted_no_match_with__permitted__", "tests/test_config/test_views.py::TestMultiView::test_permitted_no_views"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient.multiappend", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1427, 1427], "body_position": [1439, 1456], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._normalise_folder", "imapclient.imapclient.IMAPClient._raw_command"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Append messages to a folder using the MULTIAPPEND feature. \n", "Arguments": ":param folder: String, the name of the folder to append the messages to.\n:param msgs: Iterable, an iterable containing the messages to be appended. Each item in the iterable can be either a string containing the full message including headers, or a dictionary containing the keys \"msg\" with the full message, \"flags\" with a sequence of message flags to set, and \"date\" with a datetime instance specifying the internal date to set.\n:return: The APPEND response from the server.\n"}, "tests": ["tests/test_imapclient.py::TestAppend::test_multiappend_with_flags_and_internaldate", "tests/test_imapclient.py::TestAppend::test_multiappend"], "indent": 8}
{"namespace": "alembic.autogenerate.render._render_server_default", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/autogenerate/render.py", "signature_position": [720, 726], "body_position": [727, 746], "dependency": {"intra_class": [], "intra_file": ["alembic.autogenerate.render._render_computed", "alembic.autogenerate.render._render_identity", "alembic.autogenerate.render._render_potential_expr", "alembic.autogenerate.render._user_defined_render"], "cross_file": ["alembic.autogenerate.api.AutogenContext", "alembic.util.sqla_compat", "alembic.util.sqla_compat._server_default_is_computed", "alembic.util.sqla_compat._server_default_is_identity"]}, "requirement": {"Functionality": "This function renders the server default value for a column in SQLAlchemy. It first tries to render the default value using a user-defined rendering function. If that returns a value other than False, it is returned as the rendered default value. Otherwise, it checks if the default value is a computed value or an identity value and renders it accordingly. If the default value is a DefaultClause object, it checks if the argument is a string and renders it as an expression if it is not. Finally, if the default value is a string and the repr_ parameter is True, it removes the surrounding quotes and returns the default value as a string.", "Arguments": ":param default: Optional. The server default value for the column. It can be a FetchedValue, a string, a TextClause, or a ColumnElement. Defaults to None.\n:param autogen_context: AutogenContext. The autogenerate context.\n:param repr_: bool. Whether to represent the default value as a string. Defaults to True.\n:return: Optional[str]. The rendered server default value as a string, or None if it cannot be rendered."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_render_unicode_server_default", "tests/test_autogen_render.py::AutogenRenderTest::test_render_quoted_server_default"], "indent": 4}
{"namespace": "mingus.containers.instrument.Instrument.note_in_range", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/instrument.py", "signature_position": [62, 62], "body_position": [67, 76], "dependency": {"intra_class": ["mingus.containers.instrument.Instrument.range"], "intra_file": [], "cross_file": ["mingus.containers.mt_exceptions.UnexpectedObjectError", "mingus.containers.note.Note"]}, "requirement": {"Functionality": "This function checks whether a given note is within the range of the Instrument. It first converts the note to a Note object if it is a string. Then, it checks if note has the name, raise an unexpected object error \"Unexpected object '%s'. Expecting a mingus.containers.Note object\" if not. Next, it checks if the note is within the range of the Instrument by comparing it with the minimum and maximum notes in the range attribute of the Instrument.", "Arguments": ":param self: Instrument. An instance of the Instrument class.\n:param note: The note to be checked. It can be a string or a Note object.\n:return: Bool. True if the note is within the range of the Instrument, False otherwise."}, "tests": ["tests/unit/containers/test_instrument.py::test_Instrument::test_note_in_range"], "indent": 8}
{"namespace": "sumy.evaluation.rouge._len_lcs", "type": "function", "project_path": "Internet/sumy", "completion_path": "Internet/sumy/sumy/evaluation/rouge.py", "signature_position": [42, 42], "body_position": [52, 54], "dependency": {"intra_class": [], "intra_file": ["sumy.evaluation.rouge._get_index_of_lcs", "sumy.evaluation.rouge._lcs"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the length of the Longest Common Subsequence (LCS) between two sequences of words. It first creates a table using a custom function to obtain the length of LCS at any position, then retrieves the length of two input as indices. Finally, it returns the length of the LCS from the table by indices.", "Arguments": ":param x: List of words. The first sequence of words.\n:param y: List of words. The second sequence of words.\n:return: Integer. The length of the LCS between x and y."}, "tests": ["tests/test_evaluation/test_evaluation_rouge.py::test_len_lcs"], "indent": 4}
{"namespace": "diffprivlib.accountant.BudgetAccountant.spend", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/accountant.py", "signature_position": [362, 362], "body_position": [381, 383], "dependency": {"intra_class": ["diffprivlib.accountant.BudgetAccountant.__spent_budget", "diffprivlib.accountant.BudgetAccountant.check"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function allows the BudgetAccountant to spend a given privacy budget. It checks if the target budget is not exceeded and updates the spent budget accordingly.", "Arguments": ":param self: BudgetAccountant. An instance of the BudgetAccountant class.\n:param epsilon: float. The epsilon privacy budget to spend.\n:param delta: float. The delta privacy budget to spend.\n:return: BudgetAccountant. The updated BudgetAccountant instance."}, "tests": ["tests/test_BudgetAccountant.py::TestBudgetAccountant::test_spend_errors", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_spend_exceed", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_inf_spend", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_small_epsilon", "tests/test_BudgetAccountant.py::TestBudgetAccountant::test_remaining_budget_implementation2"], "indent": 8}
{"namespace": "trailscraper.cloudtrail.filter_records", "type": "function", "project_path": "Security/trailscraper", "completion_path": "Security/trailscraper/trailscraper/cloudtrail.py", "signature_position": [257, 260], "body_position": [262, 266], "dependency": {"intra_class": [], "intra_file": ["trailscraper.cloudtrail.ALL_RECORDS_FILTERED", "trailscraper.cloudtrail._by_role_arns", "trailscraper.cloudtrail._by_timeframe"], "cross_file": []}, "requirement": {"Functionality": "This function filters a list of records based on the given conditions. It applies two filters to the records: one based on the timeframe (from_date and to_date) and another based on the role ARNs (arns_to_filter_for).", "Arguments": ":param records: List. The list of records to be filtered.\n:param arns_to_filter_for: List of strings. A list of role ARNs to filter the records for. Defaults to None.\n:param from_date: datetime. The starting date and time for the timeframe filter. Defaults to January 1, 1970.\n:param to_date: datetime. The ending date and time for the timeframe filter. Defaults to the current date and time.\n:return: List. The filtered list of records that match the given conditions."}, "tests": ["tests/cloudtrail/filter_test.py::test_should_warn_if_records_passed_but_filtered_away", "tests/cloudtrail/filter_test.py::test_should_filter_for_event_time"], "indent": 4}
{"namespace": "sqlite_utils.plugins.get_plugins", "type": "function", "project_path": "Database/sqlite-utils", "completion_path": "Database/sqlite-utils/sqlite_utils/plugins.py", "signature_position": [13, 13], "body_position": [14, 26], "dependency": {"intra_class": [], "intra_file": ["sqlite_utils.plugins.pm"], "cross_file": []}, "requirement": {"Functionality": "TThis function retrieves information about the installed plugins. It retrieves the plugins, iterates over them and creates a dictionary for each plugin containing its name and the names of the hooks it implements. It also checks if there is corresponding distribution information for the plugin and includes the version and project name in the dictionary if available. Finally, it appends each plugin dictionary to a list and returns the list.", "Arguments": ":param: No input parameters.\n:return: List of dictionaries. Each dictionary contains information about a plugin, including its name, hooks, version (if available), and project name (if available)."}, "tests": ["tests/test_plugins.py::test_prepare_connection", "tests/test_plugins.py::test_register_commands"], "indent": 4}
{"namespace": "datasette.utils.to_css_class", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [706, 706], "body_position": [715, 726], "dependency": {"intra_class": [], "intra_file": ["datasette.utils.css_class_re", "datasette.utils.css_invalid_chars_re"], "cross_file": []}, "requirement": {"Functionality": "This function takes a string as input (e.g. a table name) and returns a valid and unique CSS class. If the input string is already a valid CSS class, it is returned as is. If the input string is not a valid CSS class, invalid characters are stripped and a 6-character MD5 sum suffix is added to ensure uniqueness.", "Arguments": ":param s: String. The input string to be converted into a CSS class.\n:return: String. The valid and unique CSS class generated from the input string."}, "tests": ["tests/test_utils.py::test_to_css_class"], "indent": 4}
{"namespace": "benedict.dicts.keylist.keylist_util.get_item", "type": "function", "project_path": "Text-Processing/python-benedict", "completion_path": "Text-Processing/python-benedict/benedict/dicts/keylist/keylist_util.py", "signature_position": [50, 50], "body_position": [51, 52], "dependency": {"intra_class": [], "intra_file": ["benedict.dicts.keylist.keylist_util.get_items"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves the last item from a dictionary based on a list of keys, otherwise it returns a tuple of None values.", "Arguments": ":param d: Dictionary. The dictionary to retrieve items from.\n:param keys: List. A list of keys to traverse the dictionary and retrieve the items.\n:return: Tuple or last item. If items exist, it returns the last item in the list. Otherwise, it returns a tuple of None values."}, "tests": ["tests/dicts/keylist/test_keylist_util.py::keylist_util_test_case::test_get_item_with_valid_keys", "tests/dicts/keylist/test_keylist_util.py::keylist_util_test_case::test_get_item_with_empty_dict", "tests/dicts/keylist/test_keylist_util.py::keylist_util_test_case::test_get_item_with_empty_keys"], "indent": 4}
{"namespace": "pythonforandroid.util.move", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/util.py", "signature_position": [126, 126], "body_position": [127, 128], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.util.LOGGER"], "cross_file": []}, "requirement": {"Functionality": "This function moves a file or directory from the source location to the destination location. It first logs a debug message indicating the source and destination paths, and then perform the actual move operation.", "Arguments": ":param source: String. The path of the file or directory to be moved.\n:param destination: String. The path where the file or directory should be moved to.\n:return: No return values."}, "tests": ["tests/test_util.py::TestUtil::test_move"], "indent": 4}
{"namespace": "playhouse.dataset.DataSet.tables", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/dataset.py", "signature_position": [84, 84], "body_position": [85, 88], "dependency": {"intra_class": ["playhouse.dataset.DataSet._database", "playhouse.dataset.DataSet._include_views", "playhouse.dataset.DataSet.views"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a list of tables from the DataSet instance. It first gets the tables from the database and then adds any views if the include_views flag is set to True.", "Arguments": ":param self: DataSet. An instance of the DataSet class.\n:return: List. A list of tables in the DataSet, including views if include_views is True."}, "tests": ["tests/dataset.py::TestDataSet::test_update_cache", "tests/dataset.py::TestDataSet::test_case_insensitive", "tests/dataset.py::TestDataSet::test_with_views", "tests/dataset.py::TestDataSet::test_introspect"], "indent": 8}
{"namespace": "aiohappybase._util.camel_case_to_pep8", "type": "function", "project_path": "Database/happybase", "completion_path": "Database/happybase/aiohappybase/_util.py", "signature_position": [21, 21], "body_position": [23, 24], "dependency": {"intra_class": [], "intra_file": ["aiohappybase._util.CAPITALS"], "cross_file": []}, "requirement": {"Functionality": "Convert a camel cased name to PEP8 style. It replaces each capital letter in the input string with an underscore followed by the lowercase version of the letter (Do not underline the first letter).", "Arguments": ":param name: String. The camel cased name to be converted.\n:return: String. The PEP8 style converted name."}, "tests": ["tests/test_util.py::TestUtil::test_camel_case_to_pep8"], "indent": 4}
{"namespace": "kinto.core.utils.dict_subset", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/core/utils.py", "signature_position": [168, 168], "body_position": [170, 184], "dependency": {"intra_class": [], "intra_file": ["kinto.core.utils.dict_merge", "kinto.core.utils.dict_subset"], "cross_file": []}, "requirement": {"Functionality": "This function takes a dictionary and a list of keys as input and returns a new dictionary that contains only the specified keys and their corresponding values from the original dictionary. If a key contains a dot (.), it is treated as a nested key and the function retrieves the value of the nested key from the original dictionary.", "Arguments": ":param d: dict. The original dictionary.\n:param keys: list. A list of keys to include in the new dictionary.\n:return: dict. A new dictionary that contains only the specified keys and their corresponding values from the original dictionary."}, "tests": ["tests/core/test_utils.py::DictSubsetTest::test_ignores_duplicated_keys", "tests/core/test_utils.py::DictSubsetTest::test_can_filter_subobjects_recursively", "tests/core/test_utils.py::DictSubsetTest::test_ignores_if_subobject_is_not_dict", "tests/core/test_utils.py::DictSubsetTest::test_extract_by_keys", "tests/core/test_utils.py::DictSubsetTest::test_is_noop_if_no_keys"], "indent": 4}
{"namespace": "boltons.urlutils.QueryParamDict.to_text", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/urlutils.py", "signature_position": [1576, 1576], "body_position": [1584, 1592], "dependency": {"intra_class": [], "intra_file": ["boltons.urlutils.quote_query_part", "boltons.urlutils.to_unicode"], "cross_file": ["boltons.dictutils.OrderedMultiDict.iteritems"]}, "requirement": {"Functionality": "This function takes a QueryParamDict instance and converts it into a query string. It iterates over the key-value pairs in the instance and percent-quotes special characters if full_quote is set to True.", "Arguments": ":param self: QueryParamDict. An instance of the QueryParamDict class.\n:param full_quote: bool. Whether or not to percent-quote special characters in the query string. Defaults to False.\n:return: str. The query string representation of the QueryParamDict instance."}, "tests": ["tests/test_urlutils.py::test_iri_query", "tests/test_urlutils.py::test_query_params"], "indent": 8}
{"namespace": "mingus.core.progressions.substitute_diminished_for_dominant", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/progressions.py", "signature_position": [398, 400], "body_position": [401, 423], "dependency": {"intra_class": [], "intra_file": ["mingus.core.progressions.interval_diff", "mingus.core.progressions.parse_string", "mingus.core.progressions.skip", "mingus.core.progressions.tuple_to_string"], "cross_file": []}, "requirement": {"Functionality": "Substitutes a diminished chord for a dominant chord in a given progression at a specified index.\nThe function first parses the chord at the specified index in the given progression. It then checks if the chord suffix is 'dim7', 'dim', or an empty string with a Roman numeral 'VII'. If the ignore_suffix flag is set to True, the suffix is ignored. If any of the above conditions are met, the function adds a diminished chord to the result.The function iterates four times, each time skipping to the next chord based on the last chord's position and adding the appropriate accidentals. The resulting chords are appended to the result list.\n", "Arguments": ":param progression: List of strings. The chord progression.\n:param substitute_index: Int. The index of the chord in the progression to be substituted.\n:param ignore_suffix: Bool. Whether to ignore the suffix of the chord when determining if it is a dominant chord. Defaults to False.\n:return: List of strings. The modified chord progression with the substituted diminished chord.\n"}, "tests": ["tests/unit/core/test_progressions.py::test_progressions::test_substitute_diminished_for_dominant"], "indent": 4}
{"namespace": "wikipediaapi.WikipediaPage.links", "type": "method", "project_path": "Communications/Wikipedia-API", "completion_path": "Communications/Wikipedia-API/wikipediaapi/__init__.py", "signature_position": [999, 999], "body_position": [1010, 1012], "dependency": {"intra_class": ["wikipediaapi.WikipediaPage._called", "wikipediaapi.WikipediaPage._fetch", "wikipediaapi.WikipediaPage._links"], "intra_file": ["wikipediaapi.PagesDict"], "cross_file": []}, "requirement": {"Functionality": "This function returns all the pages that are linked from the current Wikipedia page. It is a wrapper for the MediaWiki API's query+links module and API:Links documentation.", "Arguments": ":param self: WikipediaPage. An instance of the WikipediaPage class.\n:return: PagesDict. A dictionary-like object that contains the linked pages."}, "tests": ["tests/links_test.py::TestLinks::test_links_multi_page_count", "tests/links_test.py::TestLinks::test_links_no_links_count", "tests/links_test.py::TestLinks::test_links_single_page_count", "tests/links_test.py::TestLinks::test_links_single_page_titles", "tests/links_test.py::TestLinks::test_links_multi_page_titles"], "indent": 8}
{"namespace": "mingus.containers.note.Note.to_shorthand", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note.py", "signature_position": [249, 249], "body_position": [262, 273], "dependency": {"intra_class": ["mingus.containers.note.Note.name", "mingus.containers.note.Note.octave"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the traditional Helmhotz pitch notation for a given note.\n", "Arguments": ":param self: Note, an instance of the Note class.\n:return: str. The Helmhotz pitch notation for the note.\n"}, "tests": ["tests/unit/containers/test_note.py::test_Note::test_to_shorthand"], "indent": 8}
{"namespace": "viztracer.code_monkey.SourceProcessor.process", "type": "method", "project_path": "System/viztracer", "completion_path": "System/viztracer/src/viztracer/code_monkey.py", "signature_position": [286, 286], "body_position": [287, 303], "dependency": {"intra_class": ["viztracer.code_monkey.SourceProcessor.re_patterns"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function processes the input source by applying a series of transformations to each line. It checks if the source is of type bytes and decodes it to utf-8 if necessary. If the source is not a string, directly return the source. It then iterates over each line in the source and checks if it matches any of the patterns defined in the SourceProcessor instance. If a match is found, the corresponding transformation function is applied to the line and the transformed line is added to a new list. If no match is found, the original line is added to the new list. Finally, the function joins all the lines in the new list with newline characters and returns the processed source.", "Arguments": ":param self: SourceProcessor. An instance of the SourceProcessor class.\n:param source: Any. The input source to be processed. It can be of type bytes or str.\n:return: str. The processed source with transformations applied to each line."}, "tests": ["tests/test_codemonkey.py::TestCodeMonkey::test_source_processor"], "indent": 8}
{"namespace": "mmcv.transforms.wrappers.KeyMapper.__repr__", "type": "method", "project_path": "Utilities/mmcv", "completion_path": "Utilities/mmcv/mmcv/transforms/wrappers.py", "signature_position": [343, 343], "body_position": [344, 350], "dependency": {"intra_class": ["mmcv.transforms.wrappers.KeyMapper.allow_nonexist_keys", "mmcv.transforms.wrappers.KeyMapper.auto_remap", "mmcv.transforms.wrappers.KeyMapper.mapping", "mmcv.transforms.wrappers.KeyMapper.remapping", "mmcv.transforms.wrappers.KeyMapper.transforms"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the KeyMapper instance. It includes the values of the transforms, mapping, remapping, auto_remap, and allow nonexist keys. The output format is \"{class name}(transforms = {transforms}, mapping = {mapping}, remapping = {remapping}, auto_remap = {auto_remap}, allow_nonexist_keys = {allow nonexist keys})\".", "Arguments": ":param self: KeyMapper. An instance of the KeyMapper class.\n:return: str. The string representation of the KeyMapper instance."}, "tests": ["tests/test_transforms/test_transforms_wrapper.py::test_key_mapper"], "indent": 8}
{"namespace": "mrjob.setup.WorkingDirManager.paths", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/setup.py", "signature_position": [490, 490], "body_position": [492, 502], "dependency": {"intra_class": ["mrjob.setup.WorkingDirManager._name_to_typed_path", "mrjob.setup.WorkingDirManager._typed_path_to_auto_name"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a set of all paths tracked by the WorkingDirManager instance. It iterates through the internal data structures and adds the paths to the set based on the specified type.", "Arguments": ":param self: WorkingDirManager. An instance of the WorkingDirManager class.\n:param type: str. The type of paths to filter. If not specified, all paths are included.\n:return: set. A set of paths tracked by the WorkingDirManager instance."}, "tests": ["tests/test_setup.py::WorkingDirManagerTestCase::test_auto_names_are_different_from_assigned_names", "tests/test_setup.py::WorkingDirManagerTestCase::test_empty", "tests/test_setup.py::WorkingDirManagerTestCase::test_basic"], "indent": 8}
{"namespace": "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcWriter.send_request", "type": "method", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/jsonrpc/jsonrpcclient.py", "signature_position": [201, 201], "body_position": [209, 225], "dependency": {"intra_class": ["mssqlcli.jsonrpc.jsonrpcclient.JsonRpcWriter.HEADER", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcWriter.encoding", "mssqlcli.jsonrpc.jsonrpcclient.JsonRpcWriter.stream"], "intra_file": ["mssqlcli.jsonrpc.jsonrpcclient.logger"], "cross_file": []}, "requirement": {"Functionality": "This function sends a JSON RPC request message. It creates a JSON content body with the given method, params, and request_id. It then converts the content body to JSON format and sends it through the stream. If the stream was closed externally, a ValueError will be raised.", "Arguments": ":param self: JsonRpcWriter. An instance of the JsonRpcWriter class.\n:param method: String. The method to be called in the JSON RPC request.\n:param params: Any. The parameters to be passed to the method.\n:param request_id: Any. The ID of the request. Defaults to None.\n:return: No return values."}, "tests": ["tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_stream_closes_during_read_and_write", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_basic_request", "tests/jsonrpc/test_jsonrpc.py::JsonRpcTest::test_nested_request"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_only.compute_likelihood_window", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_only.py", "signature_position": [124, 132], "body_position": [164, 194], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the likelihood of a given window of commands in a session. It calculates the probability of the window based on the prior probabilities of individual commands and the transition probabilities of sequences of commands.", "Arguments": ":param window: List[str]. A list of commands representing a window of a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands (length 2).\n:param use_start_token: bool. If set to True, the start_token will be prepended to the window before the likelihood calculation is done.\n:param use_end_token: bool. If set to True, the end_token will be appended to the window before the likelihood calculation is done.\n:param start_token: str. Dummy command to signify the start of the session. Defaults to None.\n:param end_token: str. Dummy command to signify the end of the session. Defaults to None.\n:return: float. The likelihood of the window."}, "tests": ["tests/analysis/test_anom_seq_cmds_only.py::TestCmdsOnly::test_compute_likelihood_window"], "indent": 4}
{"namespace": "falcon.request.Request.client_accepts_msgpack", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [581, 581], "body_position": [582, 584], "dependency": {"intra_class": ["falcon.request.Request.client_accepts"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the client accepts the message pack format. It checks the client's accepted content types and returns True if either 'application/x-msgpack' or 'application/msgpack' is present.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: Bool. True if the client accepts message pack format, False otherwise."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_client_accepts_props"], "indent": 8}
{"namespace": "boltons.urlutils.URL.to_text", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/urlutils.py", "signature_position": [753, 753], "body_position": [769, 799], "dependency": {"intra_class": ["boltons.urlutils.URL.fragment", "boltons.urlutils.URL.get_authority", "boltons.urlutils.URL.path_parts", "boltons.urlutils.URL.query_params", "boltons.urlutils.URL.scheme", "boltons.urlutils.URL.uses_netloc"], "intra_file": ["boltons.urlutils.QueryParamDict.to_text", "boltons.urlutils.quote_fragment_part"], "cross_file": []}, "requirement": {"Functionality": "This function returns a string representation of the current state of the URL object. It constructs the URL string by combining the different components of the URL object, such as scheme, authority, path, query string, and fragment.", "Arguments": ":param self: URL. An instance of the URL class.\n:param full_quote: bool. Whether to fully quote the URL or use minimal quoting. Defaults to False.\n:return: str. The string representation of the URL object."}, "tests": ["tests/test_urlutils.py::test_roundtrip", "tests/test_urlutils.py::test_basic", "tests/test_urlutils.py::test_mailto", "tests/test_urlutils.py::test_parse_equals_in_qp_value", "tests/test_urlutils.py::test_navigate"], "indent": 8}
{"namespace": "boltons.tbutils.ParsedException.from_string", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tbutils.py", "signature_position": [749, 749], "body_position": [763, 824], "dependency": {"intra_class": ["boltons.tbutils.ParsedException.__init__"], "intra_file": ["boltons.tbutils._frame_re", "boltons.tbutils._se_frame_re", "boltons.tbutils.text"], "cross_file": []}, "requirement": {"Functionality": "This function parses a traceback and exception from the given text. It expects the text to be decoded, otherwise it will interpret it as UTF-8. It handles different formats of tracebacks and extracts the relevant information such as frames, source lines, exception type, and exception message.", "Arguments": ":param cls: Class. The class that this method belongs to.\n:param tb_str: String. The traceback text to parse.\n:return: ParsedException. An instance of the ParsedException class containing the parsed traceback and exception information."}, "tests": ["tests/test_tbutils_parsed_exc.py::test_parsed_exc_basic", "tests/test_tbutils_parsed_exc.py::test_parsed_exc_nosrcline"], "indent": 8}
{"namespace": "pyramid.path.DottedNameResolver.maybe_resolve", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/path.py", "signature_position": [278, 278], "body_position": [292, 297], "dependency": {"intra_class": ["pyramid.path.DottedNameResolver._resolve"], "intra_file": ["pyramid.path.CALLER_PACKAGE", "pyramid.path.Resolver.package", "pyramid.path.caller_package"], "cross_file": []}, "requirement": {"Functionality": "This function is used to resolve a dotted name to its corresponding object. If the input is not a string, it is simply returned. It first checks if the input is a string, then it retrieves the package information and resolves the dotted name.", "Arguments": ":param self: DottedNameResolver. An instance of the DottedNameResolver class.\n:param dotted: The dotted name to be resolved.\n:return: The resolved object if the input is a string, otherwise the input itself."}, "tests": ["tests/test_path.py::TestDottedNameResolver::test_maybe_resolve_caller_package"], "indent": 8}
{"namespace": "zxcvbn.matching.reverse_dictionary_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [121, 122], "body_position": [123, 131], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.RANKED_DICTIONARIES", "zxcvbn.matching.dictionary_match"], "cross_file": []}, "requirement": {"Functionality": "This function takes a password as input and performs a reverse dictionary match on it. It reverses the password, performs a dictionary match on the reversed password, and then reverses the matched tokens back to their original order. Finally, it sorts the matches based on their positions in the original password.", "Arguments": ":param password: String. The password to perform reverse dictionary match on.\n:param _ranked_dictionaries: List of dictionaries. A list of ranked dictionaries to use for matching. Defaults to RANKED_DICTIONARIES.\n:return: List of matches. The matches found during the reverse dictionary match, sorted based on their positions in the original password."}, "tests": ["tests/matching_test.py::test_reverse_dictionary_matching"], "indent": 4}
{"namespace": "diffprivlib.models.k_means.KMeans.fit", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/k_means.py", "signature_position": [100, 100], "body_position": [119, 167], "dependency": {"intra_class": ["diffprivlib.models.k_means.KMeans._calc_iters", "diffprivlib.models.k_means.KMeans._distances_labels", "diffprivlib.models.k_means.KMeans._init_centers", "diffprivlib.models.k_means.KMeans._update_centers", "diffprivlib.models.k_means.KMeans.accountant", "diffprivlib.models.k_means.KMeans.bounds", "diffprivlib.models.k_means.KMeans.cluster_centers_", "diffprivlib.models.k_means.KMeans.epsilon", "diffprivlib.models.k_means.KMeans.inertia_", "diffprivlib.models.k_means.KMeans.labels_", "diffprivlib.models.k_means.KMeans.n_iter_"], "intra_file": [], "cross_file": ["diffprivlib.accountant.BudgetAccountant.check", "diffprivlib.accountant.BudgetAccountant.spend", "diffprivlib.utils.PrivacyLeakWarning", "diffprivlib.utils.check_random_state", "diffprivlib.validation.DiffprivlibMixin._check_bounds", "diffprivlib.validation.DiffprivlibMixin._clip_to_bounds", "diffprivlib.validation.DiffprivlibMixin._validate_params", "diffprivlib.validation.DiffprivlibMixin._warn_unused_args"]}, "requirement": {"Functionality": "This function performs k-means clustering with differential privacy. It takes the input data and clusters it into k clusters using the k-means algorithm. The function also ensures differential privacy by adding noise to the computation.", "Arguments": ":param self: KMeans. An instance of the KMeans class.\n:param X: array-like. The training instances to be clustered.\n:param y: Ignored. Not used in the function.\n:param sample_weight: Ignored. Not used in the function.\n:return: self. The class instance itself."}, "tests": ["tests/models/test_KMeans.py::TestKMeans::test_1d_array", "tests/models/test_KMeans.py::TestKMeans::test_no_bounds", "tests/models/test_KMeans.py::TestKMeans::test_too_many_clusters", "tests/models/test_KMeans.py::TestKMeans::test_sample_weights", "tests/models/test_KMeans.py::TestKMeans::test_simple"], "indent": 8}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.exists", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [300, 300], "body_position": [306, 314], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem.invoke_hadoop"], "intra_file": ["mrjob.fs.hadoop._HADOOP_LS_NO_SUCH_FILE"], "cross_file": []}, "requirement": {"Functionality": "Check if the given path exists in the Hadoop filesystem. If the path is a directory (ends with a '/'), it checks if there are any files starting with that path. It invokes Hadoop 'fs -ls' command to check if the path exists. If the command returns 0, it returns True. If the command returns -1 or 255, it returns False. If the command returns any other value or the stderr has any output except for 'No such file', it raises an IOError: 'Could not check path {path}'.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:param path_glob: str. The path to check in the Hadoop filesystem.\n:return: bool. True if the path exists, False otherwise."}, "tests": ["tests/fs/test_hadoop.py::HadoopFSTestCase::test_exists_no", "tests/fs/test_hadoop.py::HadoopFSTestCase::test_exists_yes"], "indent": 8}
{"namespace": "hypertools.datageometry.DataGeometry.transform", "type": "method", "project_path": "Multimedia/hypertools", "completion_path": "Multimedia/hypertools/hypertools/datageometry.py", "signature_position": [111, 111], "body_position": [129, 146], "dependency": {"intra_class": ["hypertools.datageometry.DataGeometry.align", "hypertools.datageometry.DataGeometry.corpus", "hypertools.datageometry.DataGeometry.normalize", "hypertools.datageometry.DataGeometry.reduce", "hypertools.datageometry.DataGeometry.semantic", "hypertools.datageometry.DataGeometry.vectorizer", "hypertools.datageometry.DataGeometry.xform_data"], "intra_file": [], "cross_file": ["hypertools.tools.align.align", "hypertools.tools.format_data.format_data", "hypertools.tools.normalize.normalize", "hypertools.tools.reduce.reduce"]}, "requirement": {"Functionality": "This function transforms the input data using a specified model. If no data is passed, it returns the transformed data stored in the DataGeometry object.", "Arguments": ":param self: DataGeometry. An instance of the DataGeometry class.\n:param data: Optional. The data to be transformed. It can be a numpy array, pandas dataframe, or a list of arrays/dataframes. If no data is passed, the xform_data from the DataGeometry object will be returned.\n:return: list of numpy arrays. The transformed data."}, "tests": ["tests/test_geo.py::test_geo_transform_dims", "tests/test_geo.py::test_geo_transform"], "indent": 8}
{"namespace": "mopidy.internal.network.format_hostname", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/network.py", "signature_position": [27, 27], "body_position": [29, 31], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.network.has_ipv6"], "cross_file": []}, "requirement": {"Functionality": "This function formats a hostname for display. If the hostname is an IPv6 address in the form of \"x:x:x:x:x:x:x:x\", it is converted to the IPv4-mapped IPv6 address format \"::ffff:x.x.x.x\".", "Arguments": ":param hostname: String. The hostname to be formatted.\n:return: String. The formatted hostname."}, "tests": ["tests/internal/test_network.py::FormatHostnameTest::test_format_hostname_does_nothing_when_only_ipv4_available", "tests/internal/test_network.py::FormatHostnameTest::test_format_hostname_prefixes_ipv4_addresses_when_ipv6_available"], "indent": 4}
{"namespace": "wal_e.worker.upload_pool.TarUploadPool.put", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/worker/upload_pool.py", "signature_position": [71, 71], "body_position": [78, 114], "dependency": {"intra_class": ["wal_e.worker.upload_pool.TarUploadPool._start", "wal_e.worker.upload_pool.TarUploadPool._wait", "wal_e.worker.upload_pool.TarUploadPool.closed", "wal_e.worker.upload_pool.TarUploadPool.concurrency_burden", "wal_e.worker.upload_pool.TarUploadPool.max_concurrency", "wal_e.worker.upload_pool.TarUploadPool.max_members", "wal_e.worker.upload_pool.TarUploadPool.member_burden"], "intra_file": [], "cross_file": ["wal_e.exception.UserCritical"]}, "requirement": {"Functionality": "This function is used to upload a tar volume. It checks if there is too much work outstanding already and raises errors of previously submitted greenlets that die unexpectedly. If there are not enough resources to start an upload, it raises an exception. Otherwise, it starts the upload.", "Arguments": ":param self: TarUploadPool. An instance of the TarUploadPool class.\n:param tpart: The tar volume to be uploaded.\n:return: No return values."}, "tests": ["tests/test_tar_upload_pool.py::test_pool_concurrent_failure", "tests/test_tar_upload_pool.py::test_fault_join", "tests/test_tar_upload_pool.py::test_not_enough_resources", "tests/test_tar_upload_pool.py::test_fault_midstream", "tests/test_tar_upload_pool.py::test_put_after_join"], "indent": 8}
{"namespace": "mingus.core.keys.get_notes", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/keys.py", "signature_position": [109, 109], "body_position": [118, 142], "dependency": {"intra_class": [], "intra_file": ["mingus.core.keys._key_cache", "mingus.core.keys.base_scale", "mingus.core.keys.get_key_signature", "mingus.core.keys.get_key_signature_accidentals", "mingus.core.keys.is_valid_key"], "cross_file": ["mingus.core.mt_exceptions.NoteFormatError"]}, "requirement": {"Functionality": "This function returns an ordered list of notes in the specified natural key.\n", "Arguments": ":param key: str. The natural key for which the notes are to be retrieved. It defaults to \"C\" if not specified.\n:return: List of str. An ordered list of notes in the specified natural key.\n"}, "tests": ["tests/unit/core/test_keys.py::test_keys::test_get_notes"], "indent": 4}
{"namespace": "msticpy.auth.msal_auth.MSALDelegatedAuth.get_token", "type": "method", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/auth/msal_auth.py", "signature_position": [77, 77], "body_position": [79, 88], "dependency": {"intra_class": ["msticpy.auth.msal_auth.MSALDelegatedAuth._app_auth", "msticpy.auth.msal_auth.MSALDelegatedAuth.app", "msticpy.auth.msal_auth.MSALDelegatedAuth.auth_type", "msticpy.auth.msal_auth.MSALDelegatedAuth.refresh_token", "msticpy.auth.msal_auth.MSALDelegatedAuth.result", "msticpy.auth.msal_auth.MSALDelegatedAuth.scopes", "msticpy.auth.msal_auth.MSALDelegatedAuth.username"], "intra_file": [], "cross_file": ["tests.auth.test_msal_auth.MSALAppMock.acquire_token_silent_with_error", "tests.auth.test_msal_auth.MSALAppMock.get_accounts"]}, "requirement": {"Functionality": "This function is a method of the MSALDelegatedAuth class. It is used to get an authentication token. It first tries to get the chosen account using the app's get_accounts method. If a chosen account is found, it acquires a token with the specified scopes and chosen account. If the result is empty, it then authenticates with the specified authentication type. Finally, it refreshs the token.", "Arguments": ":param self: MSALDelegatedAuth. An instance of the MSALDelegatedAuth class.\n:return: No return values."}, "tests": ["tests/auth/test_msal_auth.py::test_msal_auth_unkown_user", "tests/auth/test_msal_auth.py::test_msal_auth", "tests/auth/test_msal_auth.py::test_msal_auth_device"], "indent": 8}
{"namespace": "mackup.utils.delete", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [49, 49], "body_position": [59, 68], "dependency": {"intra_class": [], "intra_file": ["mackup.utils.remove_acl", "mackup.utils.remove_immutable_attribute"], "cross_file": []}, "requirement": {"Functionality": "This function deletes the given file, directory, or link. It first removes any ACLs (Access Control Lists) associated with the file, then removes any immutable attributes. Finally, it deletes the file or directory using the appropriate method based on its type.", "Arguments": ":param filepath: str. The absolute full path to the file, directory, or link to be deleted.\n:return: No return values."}, "tests": ["tests/utils_test.py::TestMackup::test_delete_folder_recursively", "tests/utils_test.py::TestMackup::test_delete_file"], "indent": 4}
{"namespace": "twitter.models.TwitterModel.NewFromJsonDict", "type": "method", "project_path": "Internet/python-twitter", "completion_path": "Internet/python-twitter/twitter/models.py", "signature_position": [79, 79], "body_position": [88, 95], "dependency": {"intra_class": ["twitter.models.TwitterModel.__init__", "twitter.models.TwitterModel._json"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Create a new instance of the TwitterModel class based on a JSON dictionary. It takes the JSON data and any additional keyword arguments and creates a new instance of the class with those values.", "Arguments": ":param cls: TwitterModel. The class itself.\n:param data: Dictionary. A JSON dictionary, as converted from the JSON in the Twitter API.\n:param **kwargs: Additional keyword arguments that should be supplied by the calling class.\n:return: TwitterModel. The newly created instance of the TwitterModel class."}, "tests": ["tests/test_models.py::ModelsTest::test_url", "tests/test_models.py::ModelsTest::test_hashtag", "tests/test_models.py::ModelsTest::test_media"], "indent": 8}
{"namespace": "pyramid.registry.Introspector.relate", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [185, 185], "body_position": [186, 191], "dependency": {"intra_class": ["pyramid.registry.Introspector._get_intrs_by_pairs", "pyramid.registry.Introspector._refs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function establishes relationships among introspectables based on the given category name and discriminator pairs. It creates relationships between each pair of introspectables by adding a reference from one introspectable to another.", "Arguments": ":param self: Introspector. An instance of the Introspector class.\n:param pairs: Variable number of arguments. Each argument is a pair of category name and discriminator to identify one introspectable.\n:return: No return values."}, "tests": ["tests/test_registry.py::TestIntrospector::test_relate_fail", "tests/test_registry.py::TestIntrospector::test_relate", "tests/test_registry.py::TestIntrospector::test_remove", "tests/test_registry.py::TestIntrospector::test_unrelate", "tests/test_registry.py::TestIntrospector::test_related"], "indent": 8}
{"namespace": "imapclient.imapclient.IMAPClient._consume_until_tagged_response", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [1642, 1642], "body_position": [1643, 1652], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._checkok", "imapclient.imapclient.IMAPClient._imap"], "intra_file": ["imapclient.imapclient._parse_untagged_response"], "cross_file": []}, "requirement": {"Functionality": "This function consumes responses from the IMAP server until a tagged response with the specified tag is received. It collects all untagged responses received before the tagged response and returns the tagged response and the collected untagged responses.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:param tag: String. The tag of the tagged response to wait for.\n:param command: String. The command associated with the tagged response.\n:return: Tuple. The first element is the data of the tagged response, and the second element is a list of untagged responses received before the tagged response."}, "tests": ["tests/test_imapclient.py::TestIdleAndNoop::test_consume_until_tagged_response", "tests/test_imapclient.py::TestProtocolError::test_tagged_response_with_parse_error"], "indent": 8}
{"namespace": "dash._get_paths.app_get_relative_path", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_get_paths.py", "signature_position": [66, 66], "body_position": [67, 78], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["dash.exceptions", "dash.exceptions.UnsupportedRelativePath"]}, "requirement": {"Functionality": "This function takes two parameters, the pathname and the path of requests, and returns the relative path based on the given conditions. It checks if the pathname of requests is equal to \"/\" and path is empty, and returns \"/\" in that case. If the pathname of requests is not equal to \"/\" and `path` is empty, it returns the pathname of requests. If the path does not start with \"/\", it raises an exception. Otherwise, it joins the pathname of requests (with trailing slashes removed) and path (with leading slashes removed) using \"/\" as the separator and returns the result.", "Arguments": ":param requests_pathname: String. The pathname from the request.\n:param path: String. The path to be joined with the requests_pathname.\n:return: String. The relative path based on the given conditions."}, "tests": ["tests/unit/test_configs.py::test_pathname_prefix_relative_url", "tests/unit/test_configs.py::test_invalid_get_relative_path"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.NdarrayContainer.batches_to_batch", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [228, 233], "body_position": [234, 239], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.np"], "cross_file": ["bentoml._internal.external_typing.NpNDArray", "bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function takes a sequence of numpy arrays (batches) and concatenates them along a specified axis to create a single batch. It also calculates the indices at which each original subbatch ends in the concatenated batch.", "Arguments": ":param cls: NdarrayContainer. The class itself.\n:param batches: Sequence of numpy arrays. The batches to be concatenated.\n:param batch_dim: Integer. The axis along which the batches should be concatenated. Defaults to 0.\n:return: Tuple of numpy array and list of integers. The concatenated batch and the indices indicating the end position of each original subbatch in the concatenated batch."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_ndarray_container"], "indent": 8}
{"namespace": "boto.rds.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/rds/__init__.py", "signature_position": [53, 53], "body_position": [67, 69], "dependency": {"intra_class": [], "intra_file": ["boto.rds.RDSConnection"], "cross_file": ["boto.rds.regioninfo.RDSRegionInfo", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "This function connects to a specific region and returns an instance of the RDSConnection class.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param **kw_params: Additional parameters to be passed to the connect method of the region object.\n:return: RDSConnection or None. A connection to the given region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestRdsConnection::test_connect_to_region"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.buttons.TopButton.update_widget", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [69, 71], "body_position": [72, 83], "dependency": {"intra_class": ["zulipterminal.ui_tools.buttons.TopButton._caption", "zulipterminal.ui_tools.buttons.TopButton._w", "zulipterminal.ui_tools.buttons.TopButton.button_prefix", "zulipterminal.ui_tools.buttons.TopButton.button_suffix", "zulipterminal.ui_tools.buttons.TopButton.prefix_character", "zulipterminal.ui_tools.buttons.TopButton.set_label"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Update the widget with the given count text and text color. It sets the prefix, label, suffix, and text color of the widget based on the input parameters according to the prefix format.", "Arguments": ":param self: TopButton. An instance of the TopButton class.\n:param count_text: Tuple of Optional[str] and str. The count text to be displayed on the widget. The first element is an optional prefix, and the second element is the main count text.\n:param text_color: Optional[str]. The color of the text on the widget. If not specified, the default color is used.\n:return: Any. No specific return value."}, "tests": ["tests/ui_tools/test_buttons.py::TestTopButton::test_update_widget"], "indent": 8}
{"namespace": "bplustree.memory.WAL.commit", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [418, 419], "body_position": [420, 421], "dependency": {"intra_class": ["bplustree.memory.WAL._add_frame", "bplustree.memory.WAL._not_committed_pages"], "intra_file": ["bplustree.memory.FrameType", "bplustree.memory.FrameType.COMMIT"], "cross_file": []}, "requirement": {"Functionality": "If there are uncommitted pages in the WAL, a commit frame is added.", "Arguments": ":param self: WAL. An instance of the WAL class.\n:return: No return values."}, "tests": ["tests/test_memory.py::test_wal_rollback", "tests/test_memory.py::test_wal_create_reopen_uncommitted", "tests/test_memory.py::test_wal_checkpoint"], "indent": 8}
{"namespace": "playhouse.dataset.DataSet.update_cache", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/dataset.py", "signature_position": [103, 103], "body_position": [104, 121], "dependency": {"intra_class": ["playhouse.dataset.DataSet._include_views", "playhouse.dataset.DataSet._introspector", "playhouse.dataset.DataSet._models", "playhouse.dataset.DataSet.get_table_dependencies"], "intra_file": [], "cross_file": ["playhouse.reflection.Introspector.generate_models"]}, "requirement": {"Functionality": "Update the cache of the DataSet instance based on the given table. If a table is specified, it updates the cache for that table and its related tables. If no table is specified, it updates the cache for all tables. It generates and updates the models in the cache based on the updated cache.", "Arguments": ":param self: DataSet. An instance of the DataSet class.\n:param table: String. The name of the table to update the cache for. Defaults to None.\n:return: No return values."}, "tests": ["tests/dataset.py::TestDataSet::test_update_cache"], "indent": 8}
{"namespace": "twtxt.parser.parse_tweets", "type": "function", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/parser.py", "signature_position": [32, 32], "body_position": [44, 56], "dependency": {"intra_class": [], "intra_file": ["twtxt.parser.logger", "twtxt.parser.parse_tweet"], "cross_file": []}, "requirement": {"Functionality": "This function takes a list of raw tweet lines from a twtxt file and parses them into a list of Tweet objects. It also handles any exceptions that occur during the parsing process.", "Arguments": ":param raw_tweets: list. A list of raw tweet lines.\n:param source: Source. The source of the given tweets.\n:param now: Datetime. The current datetime. Defaults to None.\n:return: list. A list of parsed tweets as Tweet objects."}, "tests": ["tests/test_parser.py::test_parse_tweets"], "indent": 4}
{"namespace": "mrjob.hadoop.HadoopJobRunner._find_hadoop_streaming_jar", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [237, 237], "body_position": [240, 259], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner._hadoop_streaming_jar_dirs", "mrjob.hadoop.HadoopJobRunner.fs"], "intra_file": ["mrjob.hadoop._HADOOP_STREAMING_JAR_RE", "mrjob.hadoop.log"], "cross_file": ["mrjob.fs.composite.CompositeFilesystem.ls", "mrjob.util.unique"]}, "requirement": {"Functionality": "This function searches for the Hadoop streaming jar file in the specified directories. It iterates through each directory and checks for the presence of the jar file. If found, it returns the path of the first jar file that matches the criteria. It logs an info message for each directory that is searched: \"Looking for Hadoop streaming jar in {directory}...\".", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:return: String or None. The path of the Hadoop streaming jar file if found, otherwise None."}, "tests": ["tests/test_hadoop.py::HadoopStreamingJarTestCase::test_directory_order_overrides_path_sort_order", "tests/test_hadoop.py::HadoopStreamingJarTestCase::test_hard_coded_emr_paths", "tests/test_hadoop.py::HadoopStreamingJarTestCase::test_hadoop_prefix", "tests/test_hadoop.py::HadoopStreamingJarTestCase::test_infer_from_hadoop_bin_realpath", "tests/test_hadoop.py::HadoopStreamingJarTestCase::test_hadoop_install"], "indent": 8}
{"namespace": "falcon.request.Request.bounded_stream", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [628, 628], "body_position": [629, 632], "dependency": {"intra_class": ["falcon.request.Request._bounded_stream", "falcon.request.Request._get_wrapped_wsgi_input"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the bounded stream of a Request instance. If the bounded stream is not yet initialized, it initializes it.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: The bounded stream of the Request instance."}, "tests": ["tests/test_request_body.py::TestRequestBody::test_bounded_stream_property_empty_body"], "indent": 8}
{"namespace": "pyramid.testing.DummyResource.__getitem__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [181, 181], "body_position": [183, 184], "dependency": {"intra_class": ["pyramid.testing.DummyResource.subs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a named subobject from the subs dictionary of a DummyResource instance.", "Arguments": ":param self: DummyResource. An instance of the DummyResource class.\n:param name: String. The name of the subobject to retrieve from the `subs` dictionary.\n:return: The named subobject from the `subs` dictionary."}, "tests": ["tests/test_testing.py::TestDummyResource::test__setitem__and__getitem__and__delitem__and__contains__and_get"], "indent": 8}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.rm", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [323, 323], "body_position": [324, 338], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem.get_hadoop_version", "mrjob.fs.hadoop.HadoopFilesystem.invoke_hadoop"], "intra_file": ["mrjob.fs.hadoop._HADOOP_RM_NO_SUCH_FILE"], "cross_file": ["mrjob.compat.uses_yarn", "mrjob.fs.base.Filesystem", "mrjob.fs.base.Filesystem.rm", "mrjob.parse.is_uri"]}, "requirement": {"Functionality": "Remove a file or directory from the Hadoop filesystem. It first checks if the path is a URI, and if not, it requires the superclass to remove that path. Then, it determines the version of Hadoop being used and constructs the appropriate command arguments (Depends on whether to use Yarn). Finally, it invokes Hadoop with the arguments and handles any exceptions that occur.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:param path_glob: String. The path or glob pattern of the file or directory to be removed.\n:return: No return values."}, "tests": ["tests/fs/test_hadoop.py::HadoopFSTestCase::test_rm", "tests/fs/test_hadoop.py::HadoopFSTestCase::test_rm_recursive"], "indent": 8}
{"namespace": "diffprivlib.models.forest._FittingTree.fit", "type": "method", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/models/forest.py", "signature_position": [556, 556], "body_position": [568, 594], "dependency": {"intra_class": ["diffprivlib.models.forest._FittingTree._TREE_LEAF", "diffprivlib.models.forest._FittingTree.apply", "diffprivlib.models.forest._FittingTree.classes", "diffprivlib.models.forest._FittingTree.epsilon", "diffprivlib.models.forest._FittingTree.node_count", "diffprivlib.models.forest._FittingTree.nodes", "diffprivlib.models.forest._FittingTree.random_state", "diffprivlib.models.forest._FittingTree.values_"], "intra_file": [], "cross_file": ["diffprivlib.mechanisms.exponential.PermuteAndFlip.randomise"]}, "requirement": {"Functionality": "This function fits a tree to the given training data. It first checks if the tree has been built, and then applies the tree to the input data to determine the leaves. It calculates the unique leaves and initializes an array to store the values for each leaf. It populates the values for the real leaves based on the target vector. It then populates the values for the empty leaves. Finally, it assigns the calculated values to the tree and returns the fitted tree.", "Arguments": ":param self: _FittingTree. An instance of the _FittingTree class.\n:param X: array-like. The training vector with shape (n_samples, n_features), where n_samples is the number of samples and n_features is the number of features.\n:param y: array-like. The target vector relative to X with shape (n_samples,).\n:return: The fitted tree."}, "tests": ["tests/models/test_FittingTree.py::TestFittingTree::test_fit_before_build"], "indent": 8}
{"namespace": "gunicorn.sock.create_sockets", "type": "function", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/sock.py", "signature_position": [143, 143], "body_position": [151, 205], "dependency": {"intra_class": [], "intra_file": ["gunicorn.sock._sock_type"], "cross_file": ["gunicorn.config.Config.address", "gunicorn.glogging.Logger.debug", "gunicorn.glogging.Logger.error"]}, "requirement": {"Functionality": "This function creates new sockets based on the configured addresses or file descriptors. It checks the type of address and creates either a TCP socket or a Unix socket accordingly. It also performs some error checking on the SSL configuration.", "Arguments": ":param conf: The configuration object.\n:param log: The logging object.\n:param fds: List of file descriptors. Optional. Default is None.\n:return: List of socket objects. The created sockets."}, "tests": ["tests/test_sock.py::test_create_sockets_unix_strings", "tests/test_sock.py::test_create_sockets_unix_bytes"], "indent": 4}
{"namespace": "mingus.core.intervals.minor_second", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [168, 168], "body_position": [169, 170], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.second"], "cross_file": []}, "requirement": {"Functionality": "This function calculates the minor second note above the given note.\n", "Arguments": ":param note: str. The note for which the minor second interval is calculated.\n:return: str. The modified note with the correct minor second interval.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_minor_seconds"], "indent": 4}
{"namespace": "mingus.core.intervals.determine", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [325, 325], "body_position": [346, 430], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.measure"], "cross_file": ["mingus.core.notes", "mingus.core.notes.fifths"]}, "requirement": {"Functionality": "This function determines the name of the interval between two musical notes.\n", "Arguments": ":param note1: str. The first note of the interval.\n:param note2: str. The second note of the interval.\n:param shorthand: bool. Whether to use the shorthand notation for the interval name. Defaults to False.\n:return: str. The name of the interval between note1 and note2.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_determine_shorthand", "tests/unit/core/test_intervals.py::test_intervals::test_determine"], "indent": 4}
{"namespace": "dash.development.component_loader.load_components", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/development/component_loader.py", "signature_position": [19, 19], "body_position": [34, 56], "dependency": {"intra_class": [], "intra_file": ["dash.development.component_loader._get_metadata"], "cross_file": ["dash.development._py_components_generation.generate_class", "dash.development.base_component.ComponentRegistry", "dash.development.base_component.ComponentRegistry.registry"]}, "requirement": {"Functionality": "This function loads React component metadata from a JSON file and converts it into a format that Dash can parse. It registers the component library for index inclusion and then iterates over each component in the metadata, extracting the component name and generating a class for each component. The generated classes are added to a list and returned.", "Arguments": ":param metadata_path: String. The path to the JSON file created by `react-docgen`.\n:param namespace: String. The namespace to register the component library under. It defaults to \"default_namespace\" if not specified.\n:return: List of component objects. Each component object has keys `type`, `valid_kwargs`, and `setup`."}, "tests": ["tests/unit/development/test_component_loader.py::test_loadcomponents"], "indent": 4}
{"namespace": "falcon.routing.util.map_http_methods", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/routing/util.py", "signature_position": [102, 102], "body_position": [123, 146], "dependency": {"intra_class": [], "intra_file": ["falcon.routing.util.SuffixedMethodNotFoundError", "falcon.routing.util.SuffixedMethodNotFoundError.__init__"], "cross_file": ["falcon.constants.COMBINED_METHODS", "falcon.constants"]}, "requirement": {"Functionality": "This function maps HTTP methods (e.g., GET, POST) to methods of a resource object. It iterates through the supported methods and checks if the resource object has a corresponding responder method. If a suffix is provided, it appends the suffix to the responder name. It returns a dictionary mapping the HTTP methods to the resource responders.", "Arguments": ":param resource: An object with *responder* methods, following the naming convention *on_\\\\**, that correspond to each method the resource supports.\n:param suffix: Optional string. A suffix to append to the responder name for this route.\n:return: dict. A mapping of HTTP methods to explicitly defined resource responders."}, "tests": ["tests/test_http_custom_method_routing.py::test_map_http_methods"], "indent": 4}
{"namespace": "zulipterminal.config.keys.commands_for_random_tips", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/config/keys.py", "signature_position": [452, 452], "body_position": [456, 460], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.config.keys.KEY_BINDINGS", "zulipterminal.config.keys.KeyBinding"], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of commands that can be displayed as random tips. It filters out the commands that are excluded from random tips.", "Arguments": ":param: No input parameters.\n:return: List of KeyBinding. A list of commands that can be displayed as random tips."}, "tests": ["tests/config/test_keys.py::test_HELP_is_not_allowed_as_tip", "tests/config/test_keys.py::test_commands_for_random_tips"], "indent": 4}
{"namespace": "boto.s3.bucket.Bucket.delete_key", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/bucket.py", "signature_position": [733, 734], "body_position": [758, 763], "dependency": {"intra_class": ["boto.s3.bucket.Bucket._delete_key_internal"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function deletes a key from the bucket. If a version ID is provided, only that version of the key will be deleted. It also provides the option to delete versioned objects from a bucket that has the MFADelete option enabled.", "Arguments": ":param self: Bucket. An instance of the Bucket class.\n:param key_name: string. The name of the key to be deleted.\n:param headers: dict. Additional headers to include in the request.\n:param version_id: string. The version ID of the key to be deleted (optional).\n:param mfa_token: tuple or list of strings. A tuple or list consisting of the serial number from the MFA device and the current value of the six-digit token associated with the device. This is required for deleting versioned objects from a bucket with MFADelete option enabled.\n:return: :class:`boto.s3.key.Key` or subclass. A key object holding information on what was deleted. The caller can see if a delete_marker was created or removed and what version_id the delete created or removed."}, "tests": ["tests/unit/s3/test_key.py::TestS3Key::test_delete_key_return_key"], "indent": 8}
{"namespace": "mrjob.conf._fix_clear_tags", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [156, 156], "body_position": [167, 187], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.ClearedValue", "mrjob.conf.ClearedValue.__init__", "mrjob.conf._fix_clear_tags", "mrjob.conf._strip_clear_tag"], "cross_file": []}, "requirement": {"Functionality": "This function recursively resolves ClearedValue wrappers in a given input. It ensures that ClearedValue(...) can only wrap values in dictionaries. In dictionaries, it treats ClearedValue(k): v or ClearedValue(k): ClearedValue(v) as equivalent to k: ClearedValue(v). ClearedValue(k): v1 overrides k: v2. In lists, any ClearedValue wrappers are simply stripped.\nChecks if the input is a list, dictionary or ClearedValue. If the input is a list, process each element separately. If the input is a dictionary, process each key-value pair separately and handle cleared keys. If the input is a ClearedValue, process and return the value of the ClearedValue.\n", "Arguments": ":param x: any data type. The input value to be processed.\n:return: any data type. The processed value.\n"}, "tests": ["tests/test_conf.py::FixClearTag::test_none", "tests/test_conf.py::FixClearTag::test_list", "tests/test_conf.py::FixClearTag::test_nesting", "tests/test_conf.py::FixClearTag::test_string", "tests/test_conf.py::FixClearTag::test_int"], "indent": 4}
{"namespace": "boto.cognito.identity.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cognito/identity/__init__.py", "signature_position": [39, 39], "body_position": [40, 43], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cognito.identity.layer1.CognitoIdentityConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CognitoIdentityConnection class. It calls the connect function with the specified parameters and returns the connection object.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: CognitoIdentityConnection. The connection object to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCognitoIdentityConnection::test_connect_to_region"], "indent": 4}
{"namespace": "rest_framework.fields.DecimalField.to_internal_value", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [1006, 1006], "body_position": [1012, 1032], "dependency": {"intra_class": ["rest_framework.fields.DecimalField.MAX_STRING_LENGTH", "rest_framework.fields.DecimalField.localize", "rest_framework.fields.DecimalField.quantize", "rest_framework.fields.DecimalField.validate_precision"], "intra_file": ["rest_framework.fields.Field.fail"], "cross_file": []}, "requirement": {"Functionality": "This function takes an input data and validates that it is a decimal number. It then returns a Decimal instance of the validated data.", "Arguments": ":param self: DecimalField. An instance of the DecimalField class.\n:param data: The input data to be validated as a decimal number.\n:return: Decimal. The validated Decimal instance of the input data."}, "tests": ["tests/test_fields.py::TestQuantizedValueForDecimal::test_part_precision_string_quantized_value_for_decimal", "tests/test_fields.py::TestQuantizedValueForDecimal::test_string_quantized_value_for_decimal", "tests/test_fields.py::TestQuantizedValueForDecimal::test_int_quantized_value_for_decimal", "tests/test_fields.py::TestLocalizedDecimalField::test_to_internal_value"], "indent": 8}
{"namespace": "boto.kinesis.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/kinesis/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.kinesis.layer1.KinesisConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the KinesisConnection class from the boto library. It creates a connection to the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: KinesisConnection. The connection object to the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestKinesisConnection::test_connect_to_region"], "indent": 4}
{"namespace": "praw.util.token_manager.SQLiteTokenManager.post_refresh_callback", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/util/token_manager.py", "signature_position": [167, 167], "body_position": [169, 174], "dependency": {"intra_class": ["praw.util.token_manager.SQLiteTokenManager._set"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function updates the refresh token in the database. It sets the refresh token in the SQLiteTokenManager instance and ensures that the refresh token is not used elsewhere by setting it to None.", "Arguments": ":param self: SQLiteTokenManager. An instance of the SQLiteTokenManager class.\n:param authorizer: The authorizer object that contains the refresh token.\n:return: No return values."}, "tests": ["tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_post_refresh_token_callback__sets_value", "tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_post_refresh_token_callback__updates_value"], "indent": 8}
{"namespace": "bentoml._internal.configuration.helpers.flatten_dict", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/configuration/helpers.py", "signature_position": [74, 78], "body_position": [80, 88], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.configuration.helpers.flatten_dict"], "cross_file": []}, "requirement": {"Functionality": "This function takes a nested dictionary as input and flattens it into a single-level dictionary. It iterates through the input dictionary and checks if each key contains any punctuation. If it does, the key is enclosed in double quotes. Then, it concatenates the parent key (if any) with the current key using the specified separator. If the value corresponding to the key is another dictionary, the function recursively calls itself with the nested dictionary as input. Otherwise, it yields the concatenated key and the corresponding value.", "Arguments": ":param d: MutableMapping[str, Any]. The nested dictionary to be flattened.\n:param parent: str. The parent key to be concatenated with the current key. Defaults to an empty string.\n:param sep: str. The separator used to concatenate the parent key and the current key. Defaults to \".\".\n:return: Generator[tuple[str, Any], None, None]. A generator that yields tuples of the flattened keys and their corresponding values."}, "tests": ["tests/unit/_internal/configuration/test_helpers.py::test_flatten_dict"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.PandasDataFrameContainer.batch_to_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [431, 436], "body_position": [437, 440], "dependency": {"intra_class": ["bentoml._internal.runner.container.PandasDataFrameContainer.batch_to_batches", "bentoml._internal.runner.container.PandasDataFrameContainer.to_payload"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function converts a batch of data in a Pandas DataFrame format into a list of payloads. It first converts the batch into smaller batches based on the specified indices and batch dimension. Then, it converts each subbatch into a payload.", "Arguments": ":param cls: PandasDataFrameContainer. The class itself.\n:param batch: ext.PdDataFrame. The batch of data in Pandas DataFrame format.\n:param indices: Sequence of integers. The indices used to split the batch into smaller batches.\n:param batch_dim: Integer. The dimension along which the batch is split. Defaults to 0.\n:return: list[Payload]. A list of payloads, where each payload represents a subbatch of data."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_pandas_container"], "indent": 8}
{"namespace": "twilio.base.deserialize.iso8601_datetime", "type": "function", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/base/deserialize.py", "signature_position": [27, 29], "body_position": [35, 40], "dependency": {"intra_class": [], "intra_file": ["twilio.base.deserialize.ISO8601_DATETIME_FORMAT"], "cross_file": []}, "requirement": {"Functionality": "This function parses an ISO 8601 datetime string and returns a UTC datetime object if the parsing is successful. If the parsing fails, it returns the original string.", "Arguments": ":param s: String. An ISO 8601-formatted datetime string (e.g., \"2015-01-25T12:34:56Z\").\n:return: Union[datetime.datetime, str]. A UTC datetime object if parsing is successful, or the original string if parsing fails."}, "tests": ["tests/unit/base/test_deserialize.py::Iso8601DateTimeTestCase::test_not_parsable", "tests/unit/base/test_deserialize.py::Iso8601DateTimeTestCase::test_parsable"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.boxes.PanelSearchBox.reset_search_text", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [2038, 2038], "body_position": [2039, 2040], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.PanelSearchBox.search_text"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Reset the search text in the PanelSearchBox instance. It sets the caption of the PanelSearchBox to the current search text and clears the edit text.", "Arguments": ":param self: PanelSearchBox. An instance of the PanelSearchBox class.\n:return: No return values."}, "tests": ["tests/ui_tools/test_boxes.py::TestPanelSearchBox::test_reset_search_text"], "indent": 8}
{"namespace": "boltons.setutils.IndexedSet.pop", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/setutils.py", "signature_position": [426, 426], "body_position": [428, 440], "dependency": {"intra_class": ["boltons.setutils.IndexedSet._add_dead", "boltons.setutils.IndexedSet._cull", "boltons.setutils.IndexedSet._get_real_index", "boltons.setutils.IndexedSet.item_index_map", "boltons.setutils.IndexedSet.item_list"], "intra_file": ["boltons.setutils._MISSING"], "cross_file": []}, "requirement": {"Functionality": "This function removes and returns an item from the IndexedSet instance at the given index. If the removed item is the last item, it simply pops it from the list and the map. Otherwise, it is replaced by a placeholder in the list and the map is updated accordingly. The list is then culled to maintain the integrity of the IndexedSet instance.", "Arguments": ":param self: IndexedSet. An instance of the IndexedSet class.\n:param index: int. The index of the item to be removed. Defaults to None, which removes the last item.\n:return: The item removed from the IndexedSet instance."}, "tests": ["tests/test_setutils.py::test_iset_index_method", "tests/test_setutils.py::test_indexed_set_mutate"], "indent": 8}
{"namespace": "mrjob.bin.MRJobBinRunner.get_spark_submit_bin", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/bin.py", "signature_position": [871, 871], "body_position": [874, 876], "dependency": {"intra_class": ["mrjob.bin.MRJobBinRunner._find_spark_submit_bin", "mrjob.bin.MRJobBinRunner._spark_submit_bin"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the location of the \"spark-submit\" binary. If the location is not already stored, it searches for it and stores it for future use.", "Arguments": ":param self: MRJobBinRunner. An instance of the MRJobBinRunner class.\n:return: str. The location of the \"spark-submit\" binary."}, "tests": ["tests/test_bin.py::GetSparkSubmitBinTestCase::test_default", "tests/test_bin.py::GetSparkSubmitBinTestCase::test_only_find_spark_submit_bin_once", "tests/test_bin.py::GetSparkSubmitBinTestCase::test_option_short_circuits_find"], "indent": 8}
{"namespace": "jc.parsers.os_release.parse", "type": "function", "project_path": "Utilities/jc", "completion_path": "Utilities/jc/jc/parsers/os_release.py", "signature_position": [92, 96], "body_position": [110, 113], "dependency": {"intra_class": [], "intra_file": ["jc.parsers.os_release._process", "jc.parsers.os_release.info", "jc.parsers.os_release.info.compatible"], "cross_file": ["jc.jc_types.JSONDictType", "jc.utils.compatibility", "jc.parsers.kv", "jc.parsers.kv.parse", "jc.parsers", "jc.utils"]}, "requirement": {"Functionality": "This function is the main text parsing function. It takes in a string of text data and parses it into structured data. It can return either the raw unprocessed output or the processed output.", "Arguments": ":param data: str. The text data to be parsed.\n:param raw: bool. Whether to return unprocessed output. Defaults to False.\n:param quiet: bool. Whether to suppress warning messages. Defaults to False.\n:return: JSONDictType. The parsed structured data, either raw or processed."}, "tests": ["tests/test_os_release.py::MyTests::test_os_release_ubuntu", "tests/test_os_release.py::MyTests::test_os_release_centos", "tests/test_os_release.py::MyTests::test_os_release_nodata"], "indent": 4}
{"namespace": "boto.sts.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/sts/__init__.py", "signature_position": [38, 38], "body_position": [50, 52], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.regioninfo.connect", "boto.sts.connection.STSConnection"]}, "requirement": {"Functionality": "This function connects to a specific region and returns an instance of the STSConnection class.", "Arguments": ":param region_name: str. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: STSConnection or None. A connection to the given region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestStsConnection::test_connect_to_region"], "indent": 4}
{"namespace": "alembic.operations.ops.AddColumnOp.reverse", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [2012, 2012], "body_position": [2013, 2015], "dependency": {"intra_class": ["alembic.operations.ops.AddColumnOp.column"], "intra_file": ["alembic.operations.ops.AlterTableOp.schema", "alembic.operations.ops.AlterTableOp.table_name", "alembic.operations.ops.DropColumnOp", "alembic.operations.ops.DropColumnOp.from_column_and_tablename"], "cross_file": []}, "requirement": {"Functionality": "This function reverses the operation performed by the AddColumnOp.", "Arguments": ":param self: AddColumnOp. An instance of the AddColumnOp class.\n:return: DropColumnOp."}, "tests": ["tests/test_autogen_diffs.py::OrigObjectTest::test_add_column"], "indent": 8}
{"namespace": "mrjob.conf.combine_jobconfs", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/conf.py", "signature_position": [510, 510], "body_position": [514, 516], "dependency": {"intra_class": [], "intra_file": ["mrjob.conf.combine_dicts", "mrjob.conf._to_java_str"], "cross_file": []}, "requirement": {"Functionality": "This function combines multiple job configuration dictionaries into a single dictionary. Non-string values are converted to Java-readable strings, and keys with a value of None are removed.", "Arguments": ":param jobconfs: Variable number of dictionaries. The job configuration dictionaries to be combined.\n:return: dict. The combined job configuration dictionary."}, "tests": ["tests/test_conf.py::CombineJobconfsTestCase::test_convert_non_string_values", "tests/test_conf.py::CombineJobconfsTestCase::test_cleared_value", "tests/test_conf.py::CombineJobconfsTestCase::test_deleted_value", "tests/test_conf.py::CombineJobconfsTestCase::test_skip_None", "tests/test_conf.py::CombineJobconfsTestCase::test_dont_accept_wrapped_dicts"], "indent": 4}
{"namespace": "mrjob.parse._parse_progress_from_resource_manager", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [197, 197], "body_position": [204, 209], "dependency": {"intra_class": [], "intra_file": ["mrjob.parse._RESOURCE_MANAGER_JS_RE"], "cross_file": []}, "requirement": {"Functionality": "This function parses the progress percentage of a running job from the HTML content of a job tracker. It searches for the first occurrence of the progress percentage in the HTML content and returns it as a float. If the progress percentage is not found, it returns None.", "Arguments": ":param html_bytes: bytes. The HTML content of the job tracker.\n:return: float or None. The progress percentage of the running job, or None if it is not found."}, "tests": ["tests/test_parse.py::ResourceManagerProgressTestCase::test_partially_complete_job"], "indent": 4}
{"namespace": "pyinfra.connectors.mech.MechInventoryConnector.make_names_data", "type": "method", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/connectors/mech.py", "signature_position": [150, 150], "body_position": [151, 190], "dependency": {"intra_class": [], "intra_file": ["pyinfra.connectors.mech._make_name_data", "pyinfra.connectors.mech.get_mech_config"], "cross_file": ["pyinfra.api.exceptions.InventoryError", "pyinfra.logger"]}, "requirement": {"Functionality": "This function retrieves Mech SSH information and processes it to create a list of host names and their corresponding data. It iterates through the Mech SSH information, extracts the host names and their data, and appends them to a list. Finally, it returns the list of host names and data.", "Arguments": ":param limit: Integer. The maximum number of Mech SSH information to retrieve. Defaults to None.\n:return: List of dictionaries. Each dictionary contains the host name and its corresponding data."}, "tests": ["tests/test_connectors/test_mech.py::TestMechConnector::test_make_names_data_no_matches", "tests/test_connectors/test_mech.py::TestMechConnector::test_make_names_data_with_limit", "tests/test_connectors/test_mech.py::TestMechConnector::test_make_names_data_with_options"], "indent": 8}
{"namespace": "praw.util.token_manager.SQLiteTokenManager.pre_refresh_callback", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/util/token_manager.py", "signature_position": [176, 176], "body_position": [178, 179], "dependency": {"intra_class": ["praw.util.token_manager.SQLiteTokenManager._get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is a callback method that is called before refreshing the token. It loads the refresh token from the database.", "Arguments": ":param self: SQLiteTokenManager. An instance of the SQLiteTokenManager class.\n:param authorizer: The authorizer object that contains the refresh token attribute.\n:return: None."}, "tests": ["tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_pre_refresh_token_callback__raises_key_error", "tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_pre_refresh_token_callback"], "indent": 8}
{"namespace": "exodus_bundler.bundling.run_ldd", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/bundling.py", "signature_position": [219, 219], "body_position": [221, 226], "dependency": {"intra_class": [], "intra_file": ["exodus_bundler.bundling.detect_elf_binary", "exodus_bundler.bundling.resolve_binary"], "cross_file": ["exodus_bundler.errors.InvalidElfBinaryError"]}, "requirement": {"Functionality": "This function runs the `ldd` command and retrieves the combined output of stdout and stderr as a list of lines. It first checks if the given binary is a valid ELF file. Then it executes the `ldd` command with the binary as an argument. It captures the stdout and stderr outputs and returns them as a list of lines.", "Arguments": ":param ldd: String. The path to the `ldd` command.\n:param binary: String. The path to the binary file to be analyzed.\n:return: List of strings. The combined stdout and stderr output as a list of lines."}, "tests": ["tests/test_bundling.py::test_run_ldd"], "indent": 4}
{"namespace": "gunicorn.instrument.statsd.Statsd.access", "type": "method", "project_path": "Utilities/gunicorn", "completion_path": "Utilities/gunicorn/gunicorn/instrument/statsd.py", "signature_position": [94, 94], "body_position": [98, 105], "dependency": {"intra_class": ["gunicorn.instrument.statsd.Statsd.histogram", "gunicorn.instrument.statsd.Statsd.increment"], "intra_file": [], "cross_file": ["gunicorn.glogging.Logger", "gunicorn.glogging.Logger.access"]}, "requirement": {"Functionality": "This function measures the duration of a request and logs it using the Statsd logger. It calculates the duration in milliseconds based on the request_time parameter and logs it as a histogram. It also increments the count of total requests and the count of requests with different status codes. The status code of the response is obtained from resp. If the status code is a string, it splits the string at the first occurrence of a non-None character and takes the first part, converting it to an integer. This ensures that the status code is always an integer.", "Arguments": ":param self: Statsd. An instance of the Statsd class.\n:param resp: The response object.\n:param req: The request object.\n:param environ: The environment variables.\n:param request_time: The duration of the request as a datetime.timedelta object.\n:return: No return values."}, "tests": ["tests/test_statsd.py::test_instrument"], "indent": 8}
{"namespace": "pyramid.renderers.RendererHelper.settings", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/renderers.py", "signature_position": [417, 417], "body_position": [418, 421], "dependency": {"intra_class": ["pyramid.renderers.RendererHelper.registry"], "intra_file": [], "cross_file": ["pyramid.registry.settings"]}, "requirement": {"Functionality": "This function retrieves the settings from the registry. If the settings are not available, it returns an empty dictionary.", "Arguments": ":param self: RendererHelper. An instance of the RendererHelper class.\n:return: Dictionary. The settings retrieved from the registry or an empty dictionary if the settings are not available."}, "tests": ["tests/test_renderers.py::TestRendererHelper::test_settings_registry_settings_is_None", "tests/test_renderers.py::TestRendererHelper::test_settings_registry_settings_is_not_None"], "indent": 8}
{"namespace": "pyramid.request.RequestLocalCache.set", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/request.py", "signature_position": [436, 436], "body_position": [441, 446], "dependency": {"intra_class": ["pyramid.request.RequestLocalCache._store"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function updates the cache with a new value for a given request. It first checks if the request is already in the cache. If not, it update the value of the request and then registers a callback function to remove the request from the cache when the request is finished.", "Arguments": ":param self: RequestLocalCache. An instance of the RequestLocalCache class.\n:param request: The request object for which the cache is being updated.\n:param value: The new value to be stored in the cache for the given request.\n:return: No return values."}, "tests": ["tests/test_request.py::TestRequestLocalCache::test_get_works"], "indent": 8}
{"namespace": "twtxt.mentions.format_mentions", "type": "function", "project_path": "Communications/twtxt", "completion_path": "Communications/twtxt/twtxt/mentions.py", "signature_position": [69, 69], "body_position": [81, 85], "dependency": {"intra_class": [], "intra_file": ["twtxt.mentions.format_mention", "twtxt.mentions.mention_re"], "cross_file": []}, "requirement": {"Functionality": "This function searches the given text for mentions generated and returns a human-readable form. It uses a regular expression to find mentions in the text and applies the the format callback mehod to format each mention.", "Arguments": ":param text: String. The text to search for mentions.\n:param format_callback: Function. The callback function used to format each mention. It takes the mention name and URL as input and returns the formatted mention.\n:return: String. The text with mentions formatted in a human-readable form."}, "tests": ["tests/test_mentions.py::test_format_mentions"], "indent": 4}
{"namespace": "csvs_to_sqlite.utils.refactor_dataframes", "type": "function", "project_path": "Database/csvs-to-sqlite", "completion_path": "Database/csvs-to-sqlite/csvs_to_sqlite/utils.py", "signature_position": [238, 238], "body_position": [239, 254], "dependency": {"intra_class": [], "intra_file": ["csvs_to_sqlite.utils.LookupTable", "csvs_to_sqlite.utils.LookupTable.__init__", "csvs_to_sqlite.utils.LookupTable.id_for_value"], "cross_file": []}, "requirement": {"Functionality": "This function takes in a database connection, a list of dataframes, a dictionary of foreign keys, and a boolean value indicating whether to create full-text search indexes on the index columns. It iterates over the foreign keys and applies the lookup table to each dataframe, replacing the foreign key column with the corresponding value from the lookup table.", "Arguments": ":param conn: The database connection object.\n:param dataframes: A list of pandas dataframes.\n:param foreign_keys: A dictionary where the keys are column names and the values are tuples of table names and value columns.\n:param index_fts: Bool. Whether to create full-text search indexes on the index columns.\n:return: The modified list of dataframes."}, "tests": ["tests/test_utils.py::test_refactor_dataframes"], "indent": 4}
{"namespace": "alembic.command.stamp", "type": "function", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/command.py", "signature_position": [623, 629], "body_position": [651, 685], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["alembic.config.Config", "alembic.runtime.environment.EnvironmentContext", "alembic.script.revision._RevIdType", "alembic.script.ScriptDirectory.from_config", "alembic.script.ScriptDirectory.run_env", "alembic.util", "alembic.util.CommandError", "alembic.util.to_tuple"]}, "requirement": {"Functionality": "This function is used to \"stamp\" the revision table with the given revision(s) without running any migrations. It creates a ScriptDirectory instance based on the provided configuration and then performs the stamping operation.", "Arguments": ":param config: Config. An instance of the Config class.\n:param revision: _RevIdType. The target revision(s) to be stamped. It can be a single revision or a list of revisions.\n:param sql: Bool. Whether to use \"--sql\" mode.\n:param tag: Optional[str]. An arbitrary tag that can be intercepted by custom \"env.py\" scripts.\n:param purge: Bool. Whether to delete all entries in the version table before stamping.\n:return: None."}, "tests": ["tests/test_command.py::StampMultipleHeadsTest::test_sql_stamp_different_multi_start", "tests/test_command.py::StampMultipleHeadsTest::test_online_stamp_multi_rev_from_real_ancestor", "tests/test_command.py::CurrentTest::test_two_heads", "tests/test_command.py::StampMultipleHeadsTest::test_online_stamp_multi_rev_nonsensical", "tests/test_command.py::EditTest::test_edit_current"], "indent": 4}
{"namespace": "boto.dynamodb2.items.Item.prepare_full", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/items.py", "signature_position": [314, 314], "body_position": [323, 331], "dependency": {"intra_class": ["boto.dynamodb2.items.Item._data", "boto.dynamodb2.items.Item._dynamizer", "boto.dynamodb2.items.Item._is_storable"], "intra_file": [], "cross_file": ["boto.dynamodb.types.Dynamizer.encode"]}, "requirement": {"Functionality": "This function prepares the data of an Item object to be saved in DynamoDB. It encodes each field of the Item object and returns the encoded data as a dictionary.", "Arguments": ":param self: Item. An instance of the Item class.\n:return: Dict. The encoded data of the Item object as a dictionary."}, "tests": ["tests/unit/dynamodb2/test_table.py::ItemTestCase::test_prepare_full", "tests/unit/dynamodb2/test_table.py::ItemTestCase::test_prepare_full_empty_set"], "indent": 8}
{"namespace": "googleapiclient.channel.Channel.update", "type": "method", "project_path": "Internet/google-api-python-client", "completion_path": "Internet/google-api-python-client/googleapiclient/channel.py", "signature_position": [235, 235], "body_position": [245, 248], "dependency": {"intra_class": [], "intra_file": ["googleapiclient.channel.CHANNEL_PARAMS"], "cross_file": []}, "requirement": {"Functionality": "This function updates a channel object with information from the response of the watch() method. When a request is sent to watch() a resource, the response returned from the watch() request is a dictionary with updated channel information, such as the resource_id, which is needed when stopping a subscription. This functions iterates through the channal params dictionary and sets the corresponding attribute of the channel object with the value from the response.", "Arguments": ":param self: Channel. An instance of the Channel class.\n:param resp: dict. The response from the watch() method.\n:return: No return values."}, "tests": ["tests/test_channel.py::TestChannel::test_basic"], "indent": 8}
{"namespace": "boto.ec2.volume.Volume.attachment_state", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/volume.py", "signature_position": [213, 213], "body_position": [217, 220], "dependency": {"intra_class": ["boto.ec2.volume.Volume.attach_data"], "intra_file": ["boto.ec2.volume.AttachmentSet.status"], "cross_file": []}, "requirement": {"Functionality": "Get the attachment state of a Volume instance.", "Arguments": ":param self: Volume. An instance of the Volume class.\n:return: The attachment state of the Volume instance."}, "tests": ["tests/unit/ec2/test_volume.py::VolumeTests::test_attachment_state_returns_state"], "indent": 8}
{"namespace": "gif_for_cli.display.display_txt_frames", "type": "function", "project_path": "Multimedia/gif-for-cli", "completion_path": "Multimedia/gif-for-cli/gif_for_cli/display.py", "signature_position": [22, 22], "body_position": [23, 47], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["gif_for_cli.constants.ANSI_CURSOR_UP", "gif_for_cli.constants.ANSI_RESET"]}, "requirement": {"Functionality": "This function displays a sequence of text frames on the standard output. It iterates through the given text frames and prints each frame on a new line. It also allows for a specified number of loops and a delay between frames. A KeyboardInterrupt will be raised if there is any exception.", "Arguments": ":param txt_frames: List of strings. The text frames to be displayed.\n:param stdout: Standard output. The output stream where the frames will be printed.\n:param num_loops: Integer. The number of times the frames should be displayed. If not specified, the frames will be displayed indefinitely.\n:param seconds_per_frame: Float. The delay in seconds between each frame.\n:return: No return values."}, "tests": ["tests/test_display.py::TestDisplayTxtFrames::test_0_loops", "tests/test_display.py::TestDisplayTxtFrames::test_3_loops"], "indent": 4}
{"namespace": "pythonforandroid.archs.ArchARM.target", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/archs.py", "signature_position": [244, 244], "body_position": [245, 249], "dependency": {"intra_class": ["pythonforandroid.archs.ArchARM.command_prefix"], "intra_file": ["pythonforandroid.archs.Arch.ctx"], "cross_file": ["recipe_ctx.RecipeCtx.ctx.ndk_api"]}, "requirement": {"Functionality": "This function returns the target architecture for the ARM platform. It extracts the necessary information from the command prefix of the ArchARM instance and combines it with the ndk api of the ctx object to form the target architecture string.", "Arguments": ":param self: ArchARM. An instance of the ArchARM class.\n:return: String. The target architecture for the ARM platform."}, "tests": ["tests/test_archs.py::TestArchARMv7a::test_arch_armv7a", "tests/test_archs.py::TestArchARM::test_arch_arm"], "indent": 8}
{"namespace": "wal_e.blobstore.file.calling_format.Bucket.delete_keys", "type": "method", "project_path": "System/wal-e", "completion_path": "System/wal-e/wal_e/blobstore/file/calling_format.py", "signature_position": [64, 64], "body_position": [65, 70], "dependency": {"intra_class": [], "intra_file": ["wal_e.blobstore.file.calling_format.common_dir_path", "wal_e.blobstore.file.calling_format.remove_empty_dirs"], "cross_file": []}, "requirement": {"Functionality": "Delete the specified keys in the Bucket instance. It iterates over the keys and removes the corresponding files from the file system. It also trims any empty directories that may be left after deleting the files.", "Arguments": ":param self: Bucket. An instance of the Bucket class.\n:param keys: List of strings. The keys to be deleted.\n:return: No return values."}, "tests": ["tests/test_file_blobstore.py::test_delete_keys"], "indent": 8}
{"namespace": "falcon.inspect.inspect_sinks", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [123, 123], "body_position": [133, 138], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect.SinkInfo", "falcon.inspect.SinkInfo.__init__", "falcon.inspect._get_source_info_and_name"], "cross_file": ["falcon.app.App", "falcon.app.App._sinks"]}, "requirement": {"Functionality": "This function inspects the sinks of an application. It iterates through the sinks of the given application and creates a list of SinkInfo objects that contain information about each sink.", "Arguments": ":param app: falcon.App. The application to inspect. It can be either a falcon.App or falcon.asgi.App instance.\n:return: List[SinkInfo]. A list of SinkInfo objects that represent the sinks used by the application."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_sink", "tests/test_inspect.py::TestInspectApp::test_sink", "tests/test_inspect.py::TestStringVisitor::test_sink_verbose"], "indent": 4}
{"namespace": "boltons.mathutils.Bits.from_hex", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/mathutils.py", "signature_position": [244, 244], "body_position": [245, 249], "dependency": {"intra_class": ["boltons.mathutils.Bits.__init__"], "intra_file": ["boltons.mathutils.bytes"], "cross_file": []}, "requirement": {"Functionality": "This function creates a new instance of the Bits class based on a hexadecimal input. It first checks if the input is of type bytes and converts it to a string if necessary. Then, it checks if the input starts with '0x' and adds it if not. Finally, it creates a new instance of the Bits class using the modified hexadecimal input.", "Arguments": ":param cls: Class. The class object of the Bits class.\n:param hex: String or bytes. The hexadecimal input to create the Bits instance.\n:return: Bits. The created instance of the Bits class."}, "tests": ["tests/test_mathutils.py::test_bits"], "indent": 8}
{"namespace": "falcon.request.Request.prefix", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [815, 815], "body_position": [816, 819], "dependency": {"intra_class": ["falcon.request.Request._cached_prefix", "falcon.request.Request.app", "falcon.request.Request.netloc", "falcon.request.Request.scheme"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the prefix of the request URL. It concatenates the scheme, netloc, and app of a Request instance to form the prefix. The output format is \"{scheme}://{netloc}{app}\".", "Arguments": ":param self: Request. An instance of the Request class.\n:return: String. The prefix of the request URL."}, "tests": ["tests/test_request_attrs.py::TestRequestAttributes::test_reconstruct_url", "tests/test_request_attrs.py::TestRequestAttributes::test_uri"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.rm", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [73, 73], "body_position": [74, 81], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri", "mrjob.fs.local.log"], "cross_file": []}, "requirement": {"Functionality": "Remove files or directories from the local filesystem based on the given path pattern. It first converts the path pattern from a file URI format to a local filesystem format. Then, it finds all matching paths. For each path, if it is a directory, it recursively deletes the directory. If it is a file, it deletes the file.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param path_glob: String. The path pattern to match files or directories to be removed.\n:return: No return values."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_rm_file_by_uri", "tests/fs/test_local.py::LocalFSTestCase::test_rm_file", "tests/fs/test_local.py::LocalFSTestCase::test_rm_dir"], "indent": 8}
{"namespace": "pythonforandroid.archs.Arch.target", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/archs.py", "signature_position": [72, 76], "body_position": [77, 79], "dependency": {"intra_class": ["pythonforandroid.archs.Arch.command_prefix", "pythonforandroid.archs.Arch.ctx"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the target architecture for the Android NDK build. It combines the command prefix and the NDK API version to form the target architecture string.", "Arguments": ":param self: Arch. An instance of the Arch class.\n:return: String. The target architecture string."}, "tests": ["tests/test_archs.py::TestArchX86::test_arch_x86", "tests/test_archs.py::TestArch::test_arch", "tests/test_archs.py::TestArchAArch64::test_arch_aarch_64", "tests/test_archs.py::TestArchX86_64::test_arch_x86_64"], "indent": 8}
{"namespace": "pycoin.services.providers.set_default_providers_for_netcode", "type": "function", "project_path": "Security/pycoin", "completion_path": "Security/pycoin/pycoin/services/providers.py", "signature_position": [145, 145], "body_position": [146, 148], "dependency": {"intra_class": [], "intra_file": ["pycoin.services.providers.THREAD_LOCALS"], "cross_file": []}, "requirement": {"Functionality": "This function sets the default providers for a given netcode. It checks if the thread locals object has a \"providers\" attribute. If not, it creates an empty dictionary. Then, it adds the provider_list to the dictionary with the netcode as the key.", "Arguments": ":param netcode: The netcode for which the default providers are being set.\n:param provider_list: The list of providers to be set as the default for the netcode.\n:return: No return values."}, "tests": ["tests/services/services_test.py::ServicesTest::test_thread_provider"], "indent": 4}
{"namespace": "boltons.dictutils.ManyToMany.update", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/dictutils.py", "signature_position": [945, 945], "body_position": [947, 965], "dependency": {"intra_class": ["boltons.dictutils.ManyToMany.add", "boltons.dictutils.ManyToMany.data", "boltons.dictutils.ManyToMany.inv"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function updates the ManyToMany instance with the given iterable. It adds all the key-value pairs from the iterable to the instance's data. If the iterable is of type ManyToMany, it merges the data and inverse data of the two instances. If the iterable is a dictionary-like object, it adds all the keys and values from the iterable to the instance's data. If the iterable is a list of tuples, it adds each key-value pair to the instance's data.", "Arguments": ":param self: ManyToMany. An instance of the ManyToMany class.\n:param iterable: Iterable. The iterable containing key-value pairs to be added to the instance's data.\n:return: None."}, "tests": ["tests/test_dictutils.py::test_many_to_many"], "indent": 8}
{"namespace": "boltons.tableutils.Table.from_object", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/tableutils.py", "signature_position": [343, 343], "body_position": [349, 351], "dependency": {"intra_class": ["boltons.tableutils.Table.from_data"], "intra_file": ["boltons.tableutils.InputType.__init__", "boltons.tableutils.ObjectInputType", "boltons.tableutils._MISSING"], "cross_file": []}, "requirement": {"Functionality": "Create a Table instance from an object.", "Arguments": ":param cls: type. The class of the Table instance.\n:param data: object. The data to create the Table from.\n:param headers: Iterable[str]. The headers of the Table. Defaults to _MISSING.\n:param max_depth: Integer. The level to which nested Tables should be created. Defaults to 1.\n:param metadata: Optional. Additional metadata for the Table. Defaults to None.\n:return: Table. The created Table instance."}, "tests": ["tests/test_tableutils.py::test_table_obj"], "indent": 8}
{"namespace": "mrjob.logs.mixin.LogInterpretationMixin._pick_error", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/mixin.py", "signature_position": [118, 118], "body_position": [120, 140], "dependency": {"intra_class": ["mrjob.logs.mixin.LogInterpretationMixin._interpret_history_log", "mrjob.logs.mixin.LogInterpretationMixin._interpret_step_logs", "mrjob.logs.mixin.LogInterpretationMixin._interpret_task_logs", "mrjob.logs.mixin.LogInterpretationMixin._logs_needed_to_pick_error", "mrjob.logs.mixin.LogInterpretationMixin._read_logs"], "intra_file": ["mrjob.logs.mixin.log"], "cross_file": ["mrjob.logs.errors._pick_error_attempt_ids", "mrjob.logs.errors._pick_error"]}, "requirement": {"Functionality": "This function is used to pick the probable cause of failure in a log interpretation. It checks if the necessary logs are available and then proceeds to interpret the logs to determine the cause of failure. It should log an info message before interpreting the logs: 'Scanning logs for probable cause of failure...'.", "Arguments": ":param self: LogInterpretationMixin. An instance of the LogInterpretationMixin class.\n:param log_interpretation: dict. The log interpretation containing different types of logs.\n:param step_type: str. The type of step being executed.\n:return: None."}, "tests": ["tests/test_hadoop.py::PickErrorTestCase::test_yarn_python_exception"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_only.laplace_smooth_counts", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_only.py", "signature_position": [92, 100], "body_position": [136, 162], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.analysis.anomalous_sequence.utils.laplace_smooth.laplace_smooth_cmd_counts", "msticpy.analysis.anomalous_sequence.utils.laplace_smooth.laplace_smooth_param_counts"]}, "requirement": {"Functionality": "This function applies Laplace smoothing to the counts of commands and parameters. It adds 1 to each count to shift some probability mass from very probable commands/parameters to unseen and unlikely commands/parameters. It also handles unseen commands, sequences of commands, and parameters using the `unk_token`.", "Arguments": ":param seq1_counts: DefaultDict[str, int]. The counts of individual commands.\n:param seq2_counts: DefaultDict[str, DefaultDict[str, int]]. The counts of sequence commands (length 2).\n:param param_counts: DefaultDict[str, int]. The counts of individual parameters.\n:param cmd_param_counts: DefaultDict[str, DefaultDict[str, int]]. The counts of parameters conditional on commands.\n:param start_token: str. The dummy command to signify the start of a session.\n:param end_token: str. The dummy command to signify the end of a session.\n:param unk_token: str. The dummy command to signify an unseen command.\n:return: tuple of StateMatrix counts:\n- seq1_counts_sm: StateMatrix. The smoothed counts of individual commands.\n- seq2_counts_sm: StateMatrix. The smoothed counts of sequence commands (length 2).\n- param_counts_sm: StateMatrix. The smoothed counts of individual parameters.\n- cmd_param_counts_sm: StateMatrix. The smoothed counts of parameters conditional on commands."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_only.py::TestCmdsParamsOnly::test_laplace_smooth_counts"], "indent": 4}
{"namespace": "zxcvbn.matching.l33t_match", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/matching.py", "signature_position": [215, 216], "body_position": [217, 246], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.matching.L33T_TABLE", "zxcvbn.matching.RANKED_DICTIONARIES", "zxcvbn.matching.dictionary_match", "zxcvbn.matching.enumerate_l33t_subs", "zxcvbn.matching.relevant_l33t_subtable", "zxcvbn.matching.translate"], "cross_file": []}, "requirement": {"Functionality": "This function performs a l33t match on a given password. It checks for possible substitutions in the password and matches it against a ranked dictionary. It returns a list of matches sorted by their positions in the password.", "Arguments": ":param password: String. The password to perform the l33t match on.\n:param _ranked_dictionaries: List of dictionaries. A list of ranked dictionaries to match against. Defaults to RANKED_DICTIONARIES.\n:param _l33t_table: Dictionary. A dictionary containing l33t character substitutions. Defaults to L33T_TABLE.\n:return: List of matches. A list of dictionaries representing the matches found in the password. Each dictionary contains information about the matched word, its position, l33t substitutions, and the original token. The list is sorted by the positions of the matches."}, "tests": ["tests/matching_test.py::test_l33t_matching"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledBytesIO.write", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [317, 317], "body_position": [318, 327], "dependency": {"intra_class": ["boltons.ioutils.SpooledBytesIO.buffer", "boltons.ioutils.SpooledBytesIO.len", "boltons.ioutils.SpooledBytesIO.rollover", "boltons.ioutils.SpooledBytesIO.tell"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed", "boltons.ioutils.SpooledIOBase._max_size", "boltons.ioutils.binary_type"], "cross_file": []}, "requirement": {"Functionality": "Write the input bytes to the SpooledBytesIO instance. It first checks if the instance is closed. Then, it checks if the input string is of binary type. If not, it raises a TypeError: 'bytes expected, got {type of s}'. If writing the input string exceeds the maximum size of the instance, it will roll the instance over to a temp file. Finally, it writes the input string to the buffer.", "Arguments": ":param self: SpooledBytesIO. An instance of the SpooledBytesIO class.\n:param s: bytes. The string to be written to the instance.\n:return: No return values."}, "tests": ["tests/test_ioutils.py::TestSpooledBytesIO::test_invalid_type", "tests/test_ioutils.py::TestSpooledBytesIO::test_len_rollover", "tests/test_ioutils.py::TestSpooledBytesIO::test_iter", "tests/test_ioutils.py::TestSpooledBytesIO::test_use_as_context_mgr", "tests/test_ioutils.py::TestSpooledBytesIO::test_len_no_rollover"], "indent": 8}
{"namespace": "peewee.Index.where", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/peewee.py", "signature_position": [2890, 2890], "body_position": [2891, 2893], "dependency": {"intra_class": ["peewee.Index._where"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds conditions to the where clause of an SQL query. It takes multiple expressions as input and combines them.", "Arguments": ":param self: Index. An instance of the Index class.\n:param expressions: Multiple expressions to be added to the where clause.\n:return: No return values."}, "tests": ["tests/model_sql.py::TestModelIndex::test_model_index"], "indent": 8}
{"namespace": "datasette.utils.asgi.Response.json", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/asgi.py", "signature_position": [402, 402], "body_position": [403, 408], "dependency": {"intra_class": ["datasette.utils.asgi.Response.__init__", "datasette.utils.asgi.Response.json"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes in a body, status, headers, and default value and returns a Response instance with the JSON representation of the body. It also sets the status, headers, and content type of the response.", "Arguments": ":param cls: Class. The class of the Response instance.\n:param body: Any. The body of the response, which will be converted to JSON.\n:param status: Integer. The status code of the response. It defaults to 200 if not specified.\n:param headers: Dictionary. The headers of the response. It defaults to None if not specified.\n:param default: Any. The default value to use when encoding the body to JSON. It defaults to None if not specified.\n:return: Response. The created Response instance with the JSON representation of the body."}, "tests": ["tests/test_internals_response.py::test_response_json"], "indent": 8}
{"namespace": "pythonforandroid.graph.obvious_conflict_checker", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/graph.py", "signature_position": [146, 146], "body_position": [152, 240], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.graph.get_dependency_tuple_list_for_recipe", "pythonforandroid.graph.RecipeOrder.conflicts"], "cross_file": ["pythonforandroid.recipe.Recipe", "pythonforandroid.recipe.Recipe.get_recipe", "pythonforandroid.util.BuildInterruptingException"]}, "requirement": {"Functionality": "This function performs a pre-flight check to identify obvious conflicts in a set of multiple choice tuples/dependencies. It adds dependencies for all recipes, throws no obvious commitment into deps for later comparing against.\nThen, it gets recipe to add and who's ultimately adding it and collects the conflicts by seeing if the new deps conflict with things added before and See if what was added before conflicts with the new deps. It throws error on conflict by getting first conflict and see who added that one and prompting errors. Finally, it adds tuple to list and schedule dependencies to be added. If there were no obvious conflicts, it returns None.", "Arguments": ":param ctx: The context in which the check is performed.\n:param name_tuples: A list of multiple choice tuples/dependencies to check for conflicts.\n:param blacklist: A set of items to be excluded from the check. Defaults to None.\n:return: No return values."}, "tests": ["tests/test_graph.py::test_misc_obvious_conflict_checker", "tests/test_graph.py::test_multichoice_obvious_conflict_checker", "tests/test_graph.py::test_invalid_obvious_conflict_checker", "tests/test_graph.py::test_indirectconflict_obvious_conflict_checker"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.boxes.PanelSearchBox.valid_char", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [2042, 2043], "body_position": [2044, 2054], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.PanelSearchBox.edit_text"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks if a character is valid to be entered into the box. If the box already has text, it uses the regular validation method. If the box is empty, it checks if the character is a valid unicode character and not a control character or space separator.", "Arguments": ":param self: PanelSearchBox. An instance of the PanelSearchBox class.\n:param ch: String. The character to be checked for validity.\n:return: Bool. True if the character is valid, False otherwise."}, "tests": ["tests/ui_tools/test_boxes.py::TestPanelSearchBox::test_valid_char"], "indent": 8}
{"namespace": "pythonforandroid.archs.Arch.include_dirs", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/archs.py", "signature_position": [64, 64], "body_position": [65, 69], "dependency": {"intra_class": ["pythonforandroid.archs.Arch.ctx", "pythonforandroid.archs.Arch.include_dirs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of include directories for the Arch instance. It constructs the include directory paths by formatting the arch-specific include directories with the Arch instance.", "Arguments": ":param self: Arch. An instance of the Arch class.\n:return: List of strings. The list of include directories for the Arch instance."}, "tests": ["tests/test_archs.py::TestArch::test_arch"], "indent": 8}
{"namespace": "boto.cloudtrail.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/cloudtrail/__init__.py", "signature_position": [38, 38], "body_position": [39, 42], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["boto.cloudtrail.layer1.CloudTrailConnection", "boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region using the CloudTrail service. It creates a connection to the CloudTrail service in the specified region using the provided parameters.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param **kw_params: Additional keyword arguments that can be passed to the connection.\n:return: CloudTrailConnection. The connection object to the CloudTrail service in the specified region."}, "tests": ["tests/unit/test_connect_to_region.py::TestCloudTrailConnection::test_connect_to_region"], "indent": 4}
{"namespace": "imapclient.imapclient.IMAPClient.shutdown", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/imapclient.py", "signature_position": [527, 527], "body_position": [533, 534], "dependency": {"intra_class": ["imapclient.imapclient.IMAPClient._imap"], "intra_file": ["imapclient.imapclient.logger"], "cross_file": ["imapclient.tls.IMAP4_TLS.shutdown"]}, "requirement": {"Functionality": "Close the connection to the IMAP server without logging out. It shuts down the connection to the IMAP server and logs a message indicating that the connection has been closed.", "Arguments": ":param self: IMAPClient. An instance of the IMAPClient class.\n:return: None."}, "tests": ["tests/test_imapclient.py::TestShutdown::test_shutdown"], "indent": 8}
{"namespace": "pyramid.config.actions.ActionState.action", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/actions.py", "signature_position": [178, 189], "body_position": [192, 207], "dependency": {"intra_class": ["pyramid.config.actions.ActionState.actions"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function adds an action to the ActionState instancewith the given discriminator, callable, and arguments. It creates an action dictionary with these parameters and appends it to the list of actions in the instance.", "Arguments": ":param self: ActionState. An instance of the ActionState class.\n:param discriminator: The discriminator for the action.\n:param callable: The callable object to be executed as the action.\n:param args: Tuple. The arguments to be passed to the callable.\n:param kw: Dict. The keyword arguments to be passed to the callable.\n:param order: Integer. The order in which the action should be executed.\n:param includepath: Tuple. The include path for the action.\n:param info: Any additional information related to the action.\n:param introspectables: Tuple. The introspectables for the action.\n:param extra: Dict. Any extra parameters to be included in the action dictionary.\n:return: None."}, "tests": ["tests/test_config/test_actions.py::TestActionState::test_action_with_info", "tests/test_config/test_actions.py::TestActionState::test_action_simple", "tests/test_config/test_actions.py::TestActionState::test_action_with_includepath", "tests/test_config/test_actions.py::TestActionState::test_action_with_order", "tests/test_config/test_actions.py::TestActionState::test_action_with_includepath_and_info"], "indent": 8}
{"namespace": "oletools.oleid.OleID.check", "type": "method", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/oleid.py", "signature_position": [259, 259], "body_position": [265, 305], "dependency": {"intra_class": ["oletools.oleid.OleID.check_encrypted", "oletools.oleid.OleID.check_external_relationships", "oletools.oleid.OleID.check_flash", "oletools.oleid.OleID.check_macros", "oletools.oleid.OleID.check_object_pool", "oletools.oleid.OleID.check_properties", "oletools.oleid.OleID.data", "oletools.oleid.OleID.filename", "oletools.oleid.OleID.ftg", "oletools.oleid.OleID.indicators", "oletools.oleid.OleID.ole"], "intra_file": ["oletools.ftguess.CONTAINER.OLE", "oletools.ftguess.FTYPE.GENERIC_OLE", "oletools.ftguess.FileTypeGuesser.container", "oletools.ftguess.FileTypeGuesser.filetype", "oletools.ftguess.FileTypeGuesser.ftype", "oletools.ftguess.FileTypeGuesser.olefile", "oletools.ftguess.FileTypeGuesser.root_clsid", "oletools.ftguess.FileTypeGuesser.root_clsid_name", "oletools.oleid.Indicator", "oletools.oleid.Indicator.__init__", "oletools.oleid.RISK", "oletools.oleid.RISK.INFO"], "cross_file": ["oletools.ftguess", "oletools.ftguess.CONTAINER", "oletools.ftguess.FTYPE", "oletools.ftguess.FType_EXE_PE.container", "oletools.ftguess.FType_EXE_PE.longname", "oletools.ftguess.FileTypeGuesser"]}, "requirement": {"Functionality": "This function opens a file and runs various checks on it to determine its properties and characteristics. It creates a list of Indicator objects based on the results of the checks.", "Arguments": ":param self: OleID. An instance of the OleID class.\n:return: List of Indicator objects. The list contains all the Indicator objects created during the checks."}, "tests": ["tests/oleid/test_issue_166.py::TestEncryptedDocumentDetection::test_encrypted_document_detection"], "indent": 8}
{"namespace": "pyt.__main__.discover_files", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/__main__.py", "signature_position": [33, 33], "body_position": [34, 50], "dependency": {"intra_class": [], "intra_file": ["pyt.__main__.log"], "cross_file": []}, "requirement": {"Functionality": "This function discovers files based on the given targets and excluded files. It searches for files with the extension \".py\" in the target directories and appends them to the included_files list. It also logs the discovered files debug mode ('Discovered file: %s').", "Arguments": ":param targets: List of strings. The target directories or files to search for files.\n:param excluded_files: String. A comma-separated list of files to exclude from the search.\n:param recursive: Bool. Whether to search for files recursively in subdirectories. Defaults to False.\n:return: List of strings. The list of discovered files."}, "tests": ["tests/main_test.py::DiscoverFilesTest::test_targets_with_no_excluded", "tests/main_test.py::DiscoverFilesTest::test_targets_with_recursive", "tests/main_test.py::DiscoverFilesTest::test_targets_with_recursive_and_excluded", "tests/main_test.py::DiscoverFilesTest::test_targets_with_exluded"], "indent": 4}
{"namespace": "mingus.core.intervals.from_shorthand", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [433, 433], "body_position": [445, 486], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.major_fifth", "mingus.core.intervals.major_fourth", "mingus.core.intervals.major_second", "mingus.core.intervals.major_seventh", "mingus.core.intervals.major_sixth", "mingus.core.intervals.major_third", "mingus.core.intervals.major_unison", "mingus.core.intervals.minor_second", "mingus.core.intervals.minor_seventh", "mingus.core.intervals.minor_sixth", "mingus.core.intervals.minor_third"], "cross_file": ["mingus.core.notes", "mingus.core.notes.augment", "mingus.core.notes.diminish", "mingus.core.notes.is_valid_note"]}, "requirement": {"Functionality": "This function returns the note that is a certain interval up or down from the given note.\n", "Arguments": ":param note: str. The starting note.\n:param interval: str. The interval to move up or down. It should be a number between 1 to 7, along with optional \"#\" (sharp) or \"b\" (flat) symbols.\n:param up: bool. Whether to move up or down from the starting note. It defaults to True.\n:return: str. The resulting note after moving up or down by the specified interval. If the input is not valid, it returns False.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_from_shorthand"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.NdarrayContainer.from_payload", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [309, 312], "body_position": [313, 320], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.external_typing.NpNDArray", "bentoml._internal.runner.container.Payload.data", "bentoml._internal.runner.container.Payload.meta", "bentoml._internal.utils.pickle.pep574_loads", "bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function creates an NdarrayContainer instance from the given payload. It checks the format of the payload and if it is \"pickle5\", it decodes the pickle bytes and returns the deserialized ndarray. Otherwise, it uses the pickle module to load and return the deserialized ndarray.", "Arguments": ":param cls: Class. The class itself.\n:param payload: Payload. The payload containing the data and metadata of the ndarray.\n:return: ext.NpNDArray. The deserialized ndarray."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_ndarray_container"], "indent": 8}
{"namespace": "mingus.containers.note.Note.transpose", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note.py", "signature_position": [180, 180], "body_position": [192, 200], "dependency": {"intra_class": ["mingus.containers.note.Note.__init__", "mingus.containers.note.Note.name", "mingus.containers.note.Note.octave"], "intra_file": [], "cross_file": ["mingus.core.intervals", "mingus.core.intervals.from_shorthand"]}, "requirement": {"Functionality": "Transpose a note up or down by a given interval.\n", "Arguments": ":param self: Note. An instance of the Note class.\n:param interval: str. The interval to transpose the note by.\n:param up: bool. Whether to transpose the note up or down. It defaults to True if not specified.\n:return: no return values.\n"}, "tests": ["tests/unit/containers/test_note.py::test_Note::test_transpose"], "indent": 8}
{"namespace": "falcon.inspect.inspect_routes", "type": "function", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/inspect.py", "signature_position": [49, 49], "body_position": [59, 68], "dependency": {"intra_class": [], "intra_file": ["falcon.inspect._supported_routers"], "cross_file": ["falcon.app.App", "falcon.app.App._router"]}, "requirement": {"Functionality": "This function inspects the routes of an application. It takes an instance of the App class as input and returns a list of route descriptions for the application.", "Arguments": ":param app: App. The application to inspect. It can be an instance of either `falcon.App` or `falcon.asgi.App`.\n:return: List[RouteInfo]. A list of route descriptions for the application."}, "tests": ["tests/test_inspect.py::TestStringVisitor::test_route", "tests/test_inspect.py::TestStringVisitor::test_route_no_methods", "tests/test_cmd_inspect_app.py::TestMain::test_routes_only", "tests/test_inspect.py::TestStringVisitor::test_route_verbose", "tests/test_inspect.py::TestStringVisitor::test_route_method_verbose"], "indent": 4}
{"namespace": "pyramid.config.views.MultiView.get_views", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/views.py", "signature_position": [115, 115], "body_position": [116, 122], "dependency": {"intra_class": ["pyramid.config.views.MultiView.accepts", "pyramid.config.views.MultiView.media_views", "pyramid.config.views.MultiView.views"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of views based on the given request. It checks if both the request and this instance have accept. If both conditions are met, it iterates over the acceptable offers from the request's accept and appends the corresponding media views to a 'views' list. It then appends the regular views to the 'views' list. Finally, it returns the 'views' list. If the conditions are not met, it simply returns the regular views.", "Arguments": ":param self: MultiView. An instance of the MultiView class.\n:param request: The request object.\n:return: List. The list of views based on the given request."}, "tests": ["tests/test_config/test_views.py::TestMultiView::test_get_views", "tests/test_config/test_views.py::TestMultiView::test_get_views_request_has_no_accept", "tests/test_config/test_views.py::TestMultiView::test_get_views_best_match_returns_None", "tests/test_config/test_views.py::TestMultiView::test_get_views_no_self_accepts"], "indent": 8}
{"namespace": "oletools.ooxml.ZipSubFile.seek", "type": "method", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/ooxml.py", "signature_position": [328, 328], "body_position": [331, 360], "dependency": {"intra_class": ["oletools.ooxml.ZipSubFile._seek_skip", "oletools.ooxml.ZipSubFile.pos", "oletools.ooxml.ZipSubFile.reset", "oletools.ooxml.ZipSubFile.size"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to reposition the read pointer in a ZipSubFile instance. It calculates the new position based on the current position, the given position, and the offset. Then, it adjusts the read pointer accordingly.", "Arguments": ":param self: ZipSubFile. An instance of the ZipSubFile class.\n:param pos: Integer. The new position to set the read pointer to.\n:param offset: Integer. The offset to determine the new position. It defaults to io.SEEK_SET if not specified.\n:return: No return values."}, "tests": ["tests/ooxml/test_zip_sub_file.py::TestZipSubFile::test_check_size", "tests/ooxml/test_zip_sub_file.py::TestZipSubFile::test_seek_forward", "tests/ooxml/test_zip_sub_file.py::TestZipSubFile::test_error_read"], "indent": 8}
{"namespace": "mackup.utils.get_copy_folder_location", "type": "function", "project_path": "Utilities/mackup", "completion_path": "Utilities/mackup/mackup/utils.py", "signature_position": [256, 256], "body_position": [263, 281], "dependency": {"intra_class": [], "intra_file": ["mackup.utils.error"], "cross_file": ["mackup.constants.ERROR_UNABLE_TO_FIND_STORAGE", "mackup.constants"]}, "requirement": {"Functionality": "This function tries to locate the Copy folder by searching for the Copy settings file. It then connects to the settings database, executes a query to retrieve the value with the option that is csmRootPath from Copy folder path, and returns it.", "Arguments": ":param: No input parameters.\n:return: str. The full path to the current Copy folder."}, "tests": ["tests/utils_test.py::TestMackup::test_failed_backup_location"], "indent": 4}
{"namespace": "falcon.request.Request.forwarded", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/request.py", "signature_position": [559, 565], "body_position": [566, 574], "dependency": {"intra_class": ["falcon.request.Request._cached_forwarded", "falcon.request.Request.get_header"], "intra_file": [], "cross_file": ["falcon.forwarded._parse_forwarded_header"]}, "requirement": {"Functionality": "This function returns the value of the \"Forwarded\" header in a Request instance. It first checks if the value is already cached, and if not, it retrieves the header value, parses the value, and returns it.", "Arguments": ":param self: Request. An instance of the Request class.\n:return: The value of the \"Forwarded\" header, or None if it is not present."}, "tests": ["tests/test_request_forwarded.py::test_forwarded_missing_first_hop_host", "tests/test_request_forwarded.py::test_forwarded_host", "tests/test_request_forwarded.py::test_forwarded_quote_escaping", "tests/test_request_forwarded.py::test_forwarded_multiple_params", "tests/test_request_forwarded.py::test_forwarded_invalid"], "indent": 8}
{"namespace": "bentoml._internal.runner.container.PandasDataFrameContainer.from_batch_payloads", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [443, 447], "body_position": [448, 449], "dependency": {"intra_class": ["bentoml._internal.runner.container.PandasDataFrameContainer.batches_to_batch", "bentoml._internal.runner.container.PandasDataFrameContainer.from_payload"], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function creates a PandasDataFrameContainer instance from a sequence of payloads. It iterates over the payloads and creates batches. Then, it converts the batches into a single batch based on the specified batch dimension.", "Arguments": ":param cls: PandasDataFrameContainer. The class itself.\n:param payloads: Sequence of Payload. A sequence of payloads to create the PandasDataFrameContainer instance.\n:param batch_dim: int. The dimension along which the batches will be combined. It defaults to 0 if not specified.\n:return: tuple[ext.PdDataFrame, list[int]]. A tuple containing the PandasDataFrameContainer instance and a list of integers representing the batch dimensions."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_pandas_container"], "indent": 8}
{"namespace": "boto.dynamodb2.table.Table.get_item", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/dynamodb2/table.py", "signature_position": [654, 654], "body_position": [700, 711], "dependency": {"intra_class": ["boto.dynamodb2.table.Table._encode_keys", "boto.dynamodb2.table.Table.connection", "boto.dynamodb2.table.Table.table_name"], "intra_file": [], "cross_file": ["boto.dynamodb2.exceptions.ItemNotFound", "boto.dynamodb2.items.Item", "boto.dynamodb2.items.Item.load", "boto.dynamodb2.layer1.DynamoDBConnection.get_item", "boto.dynamodb2.exceptions"]}, "requirement": {"Functionality": "This function fetches an item (record) from a table in DynamoDB based on the specified key attributes. It can perform a consistent read if specified and can fetch specific fields if specified. It returns an Item instance containing all the data for that record.", "Arguments": ":param self: Table. An instance of the Table class.\n:param consistent: Bool. Whether to perform a consistent read from DynamoDB. Defaults to False.\n:param attributes: List of strings. The fields to fetch. Defaults to None, which means all fields should be fetched.\n:param kwargs: Key-value pairs representing the key attributes of the item to fetch.\n:return: Item. An Item instance containing the data for the fetched record.\n:raises: ItemNotFound. If the item is not found in the table."}, "tests": ["tests/unit/dynamodb2/test_table.py::TableTestCase::test_get_item"], "indent": 8}
{"namespace": "bentoml._internal.service.service.get_valid_service_name", "type": "function", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/service/service.py", "signature_position": [66, 66], "body_position": [67, 76], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.service.service.logger"], "cross_file": ["bentoml._internal.tag.Tag"]}, "requirement": {"Functionality": "This function takes a user-provided service name as input and returns a valid service name. It converts the input service name to lowercase if it is not already lowercase and logs a warning message if the conversion is made. It then creates a dummy tag using the lowercase service name to validate it and returns the lowercase service name.", "Arguments": ":param user_provided_svc_name: String. The user-provided service name.\n:return: String. The valid service name."}, "tests": ["tests/unit/_internal/test_service_api.py::test_get_valid_service_name"], "indent": 4}
{"namespace": "pyt.vulnerabilities.vulnerabilities.build_sanitiser_node_dict", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/vulnerabilities/vulnerabilities.py", "signature_position": [170, 173], "body_position": [185, 202], "dependency": {"intra_class": [], "intra_file": ["pyt.vulnerabilities.vulnerabilities.find_sanitiser_nodes"], "cross_file": ["pyt.vulnerabilities.vulnerability_helper.Sanitiser", "pyt.vulnerabilities.vulnerability_helper.TriggerNode.sanitisers"]}, "requirement": {"Functionality": "This function builds a dictionary of string -> TriggerNode pairs, where the string represents a sanitiser and the TriggerNode represents a TriggerNode of the sanitiser. It first extracts the sanitisers from the given list of sinks. Then, it searches for the sanitisers in the given CFG and creates a sanitiser instance for each sanitiser found. Finally, it creates a dictionary where the keys are the sanitisers and the values are lists of TriggerNodes associated with each sanitiser.", "Arguments": ":param cfg: CFG. The CFG to traverse.\n:param sinks_in_file: List of TriggerNode. A list of TriggerNodes containing the sinks in the file.\n:return: Dict. A dictionary mapping sanitiser strings to lists of TriggerNodes."}, "tests": ["tests/vulnerabilities/vulnerabilities_test.py::EngineTest::test_build_sanitiser_node_dict"], "indent": 4}
{"namespace": "boto.ec2.elb.ELBConnection.disable_availability_zones", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/elb/__init__.py", "signature_position": [368, 368], "body_position": [386, 391], "dependency": {"intra_class": ["boto.ec2.elb.ELBConnection.build_list_params"], "intra_file": [], "cross_file": ["boto.connection.AWSQueryConnection.get_object", "boto.ec2.elb.loadbalancer.LoadBalancerZones"]}, "requirement": {"Functionality": "This function disables availability zones for an existing Load Balancer. It removes the specified zones from the Load Balancer. If the zones are not registered with the Load Balancer, no changes are made. However, it is not possible to remove all zones from a Load Balancer.", "Arguments": ":param self: ELBConnection. An instance of the ELBConnection class.\n:param load_balancer_name: String. The name of the Load Balancer.\n:param zones_to_remove: List of strings. The names of the zones to remove.\n:return: List of strings. An updated list of zones for the Load Balancer."}, "tests": ["tests/unit/ec2/elb/test_loadbalancer.py::TestInstanceStatusResponseParsing::test_next_token"], "indent": 8}
{"namespace": "hl7.version.get_version", "type": "function", "project_path": "Communications/hl7", "completion_path": "Communications/hl7/hl7/version.py", "signature_position": [12, 12], "body_position": [20, 31], "dependency": {"intra_class": [], "intra_file": ["hl7.version.VERSION"], "cross_file": []}, "requirement": {"Functionality": "This function provides the version number of the software. It follows the verlib format specified in PEP 386. It constructs the version number based on the elements in the version list. If the length of version is less than four or the version type is final, it return the main version. If the type of version is dev, tht output format is \"{the main version}.dev\". In other condition, the ouput format is \"{the main version}{the type of version}\".", "Arguments": ":param: No input parameters.\n:return: String. The version number of the software."}, "tests": ["tests/test_version.py::GetVersionTest::test_empty_modifier", "tests/test_version.py::GetVersionTest::test_alpha", "tests/test_version.py::GetVersionTest::test_beta", "tests/test_version.py::GetVersionTest::test_no_modifier", "tests/test_version.py::GetVersionTest::test_final"], "indent": 4}
{"namespace": "zulipterminal.config.themes.validate_colors", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/config/themes.py", "signature_position": [167, 167], "body_position": [174, 188], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.config.themes.InvalidThemeColorCode", "zulipterminal.config.themes.THEMES", "zulipterminal.config.themes.valid_16_color_codes"], "cross_file": []}, "requirement": {"Functionality": "This function validates color codes for a given theme. It checks if the colors in the theme are in accordance with the urwid default 16-color codes. If any color is not valid, it raises an exception with the invalid colors.", "Arguments": ":param theme_name: String. The name of the theme to validate.\n:param color_depth: Integer. The color depth to validate against. It should be 16.\n:return: No return values."}, "tests": ["tests/config/test_themes.py::test_validate_colors"], "indent": 4}
{"namespace": "bplustree.memory.WAL.rollback", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/memory.py", "signature_position": [423, 424], "body_position": [425, 426], "dependency": {"intra_class": ["bplustree.memory.WAL._add_frame", "bplustree.memory.WAL._not_committed_pages"], "intra_file": ["bplustree.memory.FrameType", "bplustree.memory.FrameType.ROLLBACK"], "cross_file": []}, "requirement": {"Functionality": "If there are uncommitted pages in the WAL, a rollback frame is added.", "Arguments": ":param self: WAL. An instance of the WAL class.\n:return: No return values."}, "tests": ["tests/test_memory.py::test_wal_rollback"], "indent": 8}
{"namespace": "kinto.plugins.quotas.scripts.rebuild_quotas", "type": "function", "project_path": "Internet/kinto", "completion_path": "Internet/kinto/kinto/plugins/quotas/scripts.py", "signature_position": [17, 17], "body_position": [18, 50], "dependency": {"intra_class": [], "intra_file": ["kinto.plugins.quotas.scripts.OLDEST_FIRST", "kinto.plugins.quotas.scripts.logger", "kinto.plugins.quotas.scripts.rebuild_quotas_collection"], "cross_file": ["kinto.core.storage.utils.paginated", "kinto.plugins.quotas.listener.BUCKET_QUOTA_OBJECT_ID", "kinto.plugins.quotas.utils.record_size"]}, "requirement": {"Functionality": "This function rebuilds quotas for a given storage. It iterates through each bucket in the storage and calculates the total record count, storage size, and collection count for each bucket. It then updates the quota information for each bucket in the storage. Finally, it logs the final size of each bucket.", "Arguments": ":param storage: The storage object to rebuild quotas for.\n:param dry_run: Bool. Whether to perform a dry run without actually updating the quotas. Defaults to False.\n:return: No return values."}, "tests": ["tests/plugins/test_quotas.py::QuotasScriptsTest::test_rebuild_quotas_doesnt_update_if_dry_run", "tests/plugins/test_quotas.py::QuotasScriptsTest::test_rebuild_quotas_updates_records"], "indent": 4}
{"namespace": "litecli.packages.completion_engine.suggest_type", "type": "function", "project_path": "Database/litecli", "completion_path": "Database/litecli/litecli/packages/completion_engine.py", "signature_position": [10, 10], "body_position": [18, 89], "dependency": {"intra_class": [], "intra_file": ["litecli.packages.completion_engine.suggest_based_on_last_token", "litecli.packages.completion_engine.suggest_special"], "cross_file": ["litecli.encodingutils.text_type", "litecli.packages.parseutils.last_word"]}, "requirement": {"Functionality": "This function suggests the completion type and scope based on the text that has been typed so far and the text before the cursor.", "Arguments": ":param full_text: String. The full text that has been typed so far.\n:param text_before_cursor: String. The text before the cursor.\n:return: List of dictionaries. Each dictionary contains a \"type\" key with the type of entity ('table', 'column', etc) and a \"scope\" key with the corresponding scope."}, "tests": ["tests/test_completion_engine.py::test_specials_not_included_after_initial_token", "tests/test_completion_engine.py::test_cross_join", "tests/test_completion_engine.py::test_outer_table_reference_in_exists_subquery_suggests_columns", "tests/test_dbspecial.py::test_list_or_show_create_tables", "tests/test_completion_engine.py::test_insert_into_lparen_partial_text_suggests_cols"], "indent": 4}
{"namespace": "twilio.jwt.client.ClientCapabilityToken._generate_payload", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/client/__init__.py", "signature_position": [86, 86], "body_position": [87, 93], "dependency": {"intra_class": ["twilio.jwt.client.ClientCapabilityToken.capabilities", "twilio.jwt.client.ClientCapabilityToken.client_name", "twilio.jwt.client.ScopeURI.add_param"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function generates the payload for the ClientCapabilityToken. It checks if the \"outgoing\" capability is present in the capabilities dictionary and if the client name is not None. If both conditions are met, it adds a parameter \"clientName\" with the value of the client name to the \"outgoing\" capability. Then, it creates a list of payload values on each capability in the capabilities dictionary. Finally, it returns a dictionary with a single key \"scope\" and the value being a string of all the scope_uris joined by a space.", "Arguments": ":param self: ClientCapabilityToken. An instance of the ClientCapabilityToken class.\n:return: Dictionary. The generated payload for the ClientCapabilityToken."}, "tests": ["tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_no_permissions", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_outbound_permissions", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_inbound_permissions"], "indent": 8}
{"namespace": "sacred.observers.file_storage.FileStorageObserver.resource_event", "type": "method", "project_path": "Utilities/sacred", "completion_path": "Utilities/sacred/sacred/observers/file_storage.py", "signature_position": [291, 291], "body_position": [292, 294], "dependency": {"intra_class": ["sacred.observers.file_storage.FileStorageObserver.find_or_save", "sacred.observers.file_storage.FileStorageObserver.resource_dir", "sacred.observers.file_storage.FileStorageObserver.run_entry", "sacred.observers.file_storage.FileStorageObserver.save_json"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function handles a resource event by finding or saving the file, updating the 'resources' field of the running entry, and saving the updated running entry as 'run.json'.", "Arguments": ":param self: FileStorageObserver. An instance of the FileStorageObserver class.\n:param filename: str. The name of the file for the resource event.\n:return: No return values."}, "tests": ["tests/test_observers/test_file_storage_observer.py::test_fs_observer_resource_event_does_not_duplicate", "tests/test_observers/test_file_storage_observer.py::test_no_duplicate"], "indent": 8}
{"namespace": "music_dl.source.MusicSource.search", "type": "method", "project_path": "Utilities/pymusic-dl", "completion_path": "Utilities/pymusic-dl/music_dl/source.py", "signature_position": [32, 32], "body_position": [33, 93], "dependency": {"intra_class": ["music_dl.source.MusicSource.logger", "music_dl.source.MusicSource.search_thread"], "intra_file": [], "cross_file": ["music_dl.config.get", "music_dl.utils.colorize", "music_dl.config", "music_dl.song.BasicSong.singer", "music_dl.song.BasicSong.title"]}, "requirement": {"Functionality": "This function searches for a keyword in a list of music sources. It creates multiple threads to search for the keyword in each source concurrently. It then sorts and removes duplicates from the search results based on song title, singer, and file size.", "Arguments": ":param self: MusicSource. An instance of the MusicSource class.\n:param keyword: String. The keyword to search for in the music sources.\n:param sources_list: List of strings. The list of music sources to search in.\n:return: List of songs. The search results containing songs that match the keyword."}, "tests": ["tests/test_source.py::test_search"], "indent": 8}
{"namespace": "rest_framework.exceptions.bad_request", "type": "function", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/exceptions.py", "signature_position": [259, 259], "body_position": [263, 266], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["rest_framework.status", "rest_framework.status.HTTP_400_BAD_REQUEST"]}, "requirement": {"Functionality": "This function is a generic error handler for a bad request (HTTP 400). It creates a JSON response with an error message and a status code of 400.", "Arguments": ":param request: The HTTP request object.\n:param exception: The exception that occurred.\n:param *args: Additional positional arguments.\n:param **kwargs: Additional keyword arguments.\n:return: JsonResponse. A JSON response object with an error message and a status code of 400."}, "tests": ["tests/test_exceptions.py::test_bad_request"], "indent": 4}
{"namespace": "zulipterminal.ui_tools.boxes.WriteBox._set_stream_write_box_style", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/boxes.py", "signature_position": [416, 417], "body_position": [418, 429], "dependency": {"intra_class": ["zulipterminal.ui_tools.boxes.WriteBox.FOCUS_HEADER_PREFIX_STREAM", "zulipterminal.ui_tools.boxes.WriteBox.header_write_box", "zulipterminal.ui_tools.boxes.WriteBox.model"], "intra_file": [], "cross_file": ["zulipterminal.config.symbols.INVALID_MARKER", "zulipterminal.config.ui_mappings.STREAM_ACCESS_TYPE", "zulipterminal.model.Model.is_valid_stream", "zulipterminal.model.Model.stream_access_type", "zulipterminal.model.Model.stream_id_from_name"]}, "requirement": {"Functionality": "This function sets the style of the stream write box based on the input text. It checks if the input text is a valid stream name and retrieves the corresponding stream information. It then sets the color and stream marker in the header write box accordingly.", "Arguments": ":param self: WriteBox. An instance of the WriteBox class.\n:param widget: ReadlineEdit. The widget representing the stream write box.\n:param new_text: String. The new text entered in the stream write box.\n:return: No return values."}, "tests": ["tests/ui_tools/test_boxes.py::TestWriteBox::test__set_stream_write_box_style_markers"], "indent": 8}
{"namespace": "dash._grouping.flatten_grouping", "type": "function", "project_path": "Software-Development/dash", "completion_path": "Software-Development/dash/dash/_grouping.py", "signature_position": [20, 20], "body_position": [32, 47], "dependency": {"intra_class": [], "intra_file": ["dash._grouping.validate_grouping"], "cross_file": []}, "requirement": {"Functionality": "This function takes a grouping value and converts it into a list of scalar values. It recursively flattens the grouping value based on the provided schema.", "Arguments": ":param grouping: The grouping value to flatten.\n:param schema: Optional. A grouping value representing the expected structure of the input grouping value. If not provided, the grouping value is treated as its own schema. A schema is required to treat tuples and dicts in the input grouping as scalar values.\n:return: A list of scalar values in the input grouping."}, "tests": ["tests/unit/library/test_grouping.py::test_map_grouping_mixed", "tests/unit/library/test_grouping.py::test_flatten_dict", "tests/unit/library/test_grouping.py::test_flatten_dict_key_order", "tests/unit/library/test_grouping.py::test_flatten_odd_value", "tests/unit/library/test_grouping.py::test_flatten_mixed"], "indent": 4}
{"namespace": "twilio.jwt.client.ClientCapabilityToken.allow_client_incoming", "type": "method", "project_path": "Communications/twilio-fatisar", "completion_path": "Communications/twilio-fatisar/twilio/jwt/client/__init__.py", "signature_position": [65, 65], "body_position": [71, 74], "dependency": {"intra_class": ["twilio.jwt.client.ClientCapabilityToken.capabilities", "twilio.jwt.client.ClientCapabilityToken.client_name"], "intra_file": ["twilio.jwt.client.ScopeURI", "twilio.jwt.client.ScopeURI.__init__"], "cross_file": []}, "requirement": {"Functionality": "This function allows the user of the ClientCapabilityToken to accept incoming connections. It sets the client name and adds the corresponding capability to the capabilities dictionary.", "Arguments": ":param self: ClientCapabilityToken. An instance of the ClientCapabilityToken class.\n:param client_name: String. The name of the client to accept calls from.\n:return: No return values."}, "tests": ["tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_encode_full_payload", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_decode", "tests/unit/jwt/test_client.py::ClientCapabilityTokenTest::test_inbound_permissions"], "indent": 8}
{"namespace": "sqlitedict.SqliteDict.terminate", "type": "method", "project_path": "Database/sqlitedict", "completion_path": "Database/sqlitedict/sqlitedict.py", "signature_position": [399, 399], "body_position": [401, 414], "dependency": {"intra_class": ["sqlitedict.SqliteDict.close", "sqlitedict.SqliteDict.filename", "sqlitedict.SqliteDict.flag"], "intra_file": ["sqlitedict.logger"], "cross_file": []}, "requirement": {"Functionality": "This function deletes the underlying database file associated with the SqliteDict instance. It first checks if the instance is read-only, and if so, raises a RuntimeError. Then, it closes the instance. If the filename is not \":memory:\", it attempts to delete the file from the file system.", "Arguments": ":param self: SqliteDict. An instance of the SqliteDict class.\n:return: No return values."}, "tests": ["tests/test_core.py::SqliteDictTerminateTest::test_terminate_instead_close"], "indent": 8}
{"namespace": "mingus.core.intervals.minor_fourth", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/intervals.py", "signature_position": [188, 188], "body_position": [189, 190], "dependency": {"intra_class": [], "intra_file": ["mingus.core.intervals.augment_or_diminish_until_the_interval_is_right", "mingus.core.intervals.fourth"], "cross_file": []}, "requirement": {"Functionality": "This function generates a minor fourth note based on the given input note.\n", "Arguments": ":param note: str. The input note for generating the minor fourth.\n:return: str. The generated minor fourth note above the given note.\n"}, "tests": ["tests/unit/core/test_intervals.py::test_intervals::test_minor_fourth"], "indent": 4}
{"namespace": "mrjob.fs.hadoop.HadoopFilesystem.get_hadoop_bin", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/hadoop.py", "signature_position": [78, 78], "body_position": [80, 82], "dependency": {"intra_class": ["mrjob.fs.hadoop.HadoopFilesystem._find_hadoop_bin", "mrjob.fs.hadoop.HadoopFilesystem._hadoop_bin"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the path to the Hadoop binary. If the path is not already set, it searches for the Hadoop binary and sets the path.", "Arguments": ":param self: HadoopFilesystem. An instance of the HadoopFilesystem class.\n:return: str. The path to the Hadoop binary."}, "tests": ["tests/fs/test_hadoop.py::FindHadoopBinTestCase::test_two_part_path", "tests/fs/test_hadoop.py::FindHadoopBinTestCase::test_predefined_hadoop_bin", "tests/fs/test_hadoop.py::FindHadoopBinTestCase::test_other_environment_variable", "tests/fs/test_hadoop.py::FindHadoopBinTestCase::test_fallback"], "indent": 8}
{"namespace": "mrjob.fs.local.LocalFilesystem.mkdir", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/fs/local.py", "signature_position": [63, 63], "body_position": [64, 66], "dependency": {"intra_class": [], "intra_file": ["mrjob.fs.local._from_file_uri"], "cross_file": []}, "requirement": {"Functionality": "Create a new directory in the local filesystem. It first converts the input path from a file URI to a local path, and then checks if the directory already exists. If not, it creates the directory.", "Arguments": ":param self: LocalFilesystem. An instance of the LocalFilesystem class.\n:param path: String. The path of the directory to be created, in file URI format.\n:return: No return values."}, "tests": ["tests/fs/test_local.py::LocalFSTestCase::test_mkdir_file_uri", "tests/fs/test_local.py::LocalFSTestCase::test_mkdir"], "indent": 8}
{"namespace": "chatette.parsing.UnitRefBuilder._build_modifiers_repr", "type": "method", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/parsing/__init__.py", "signature_position": [104, 104], "body_position": [105, 108], "dependency": {"intra_class": ["chatette.parsing.UnitRefBuilder.arg_value", "chatette.parsing.UnitRefBuilder.variation"], "intra_file": ["chatette.parsing.ItemBuilder", "chatette.parsing.ItemBuilder._build_modifiers_repr"], "cross_file": ["chatette.modifiers.representation.ModifiersRepresentation.argument_value", "chatette.modifiers.representation.ModifiersRepresentation.variation_name"]}, "requirement": {"Functionality": "This function builds the representation of modifiers. It first build the representation of modifiers, then it sets the argument value and variation name for the modifiers, and finally returns the modified modifiers.", "Arguments": ":param self: UnitRefBuilder. An instance of the UnitRefBuilder class.\n:return: The modified modifiers."}, "tests": ["tests/unit-testing/parsing/test_init.py::TestUnitRefBuilder::test_create_concrete"], "indent": 8}
{"namespace": "sslyze.plugins.certificate_info._cli_connector._get_name_as_short_text", "type": "function", "project_path": "System/sslyze", "completion_path": "System/sslyze/sslyze/plugins/certificate_info/_cli_connector.py", "signature_position": [326, 326], "body_position": [329, 336], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["sslyze.plugins.certificate_info._certificate_utils.get_common_names"]}, "requirement": {"Functionality": "This function converts a name field returned by the cryptography module to a string that can be displayed to the user. It checks if there is a common name (CN) in the name field and returns it. If there is no CN, it returns the entire name field as a string.", "Arguments": ":param name_field: x509.Name. The name field returned by the cryptography module.\n:return: str. The converted name field as a string suitable for display."}, "tests": ["tests/plugins_tests/certificate_info/test_certificate_utils.py::TestCertificateUtils::test_get_name_as_short_text"], "indent": 4}
{"namespace": "boltons.cacheutils.LRI.clear", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [287, 287], "body_position": [288, 290], "dependency": {"intra_class": ["boltons.cacheutils.LRI._init_ll", "boltons.cacheutils.LRI._lock"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function clears the data stored in the LRI object.\n", "Arguments": ":param self: LRI, an instance of the LRI class.\n:return: no return values.\n"}, "tests": ["tests/test_cacheutils.py::test_callable_cached_dec", "tests/test_cacheutils.py::test_lru_basic"], "indent": 8}
{"namespace": "pycorrector.en_spell.EnSpell.check_init", "type": "method", "project_path": "Text-Processing/pycorrector", "completion_path": "Text-Processing/pycorrector/pycorrector/en_spell.py", "signature_position": [43, 43], "body_position": [44, 45], "dependency": {"intra_class": ["pycorrector.en_spell.EnSpell._init", "pycorrector.en_spell.EnSpell.word_freq_dict"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if the EnSpell instance has been initialized. If not, it initializes the instance.", "Arguments": ":param self: EnSpell. An instance of the EnSpell class.\n:return: No return values."}, "tests": ["tests/en_spell_dict_test.py::TestEnSpell::test_word_frequency", "tests/en_spell_dict_test.py::TestEnSpell::test_word_in"], "indent": 8}
{"namespace": "exodus_bundler.cli.configure_logging", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/cli.py", "signature_position": [99, 100], "body_position": [101, 131], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["exodus_bundler.root_logger"]}, "requirement": {"Functionality": "Configure the logging settings based on the input parameters. It sets the log level based on the values of `quiet` and `verbose`. It adds a stderr handler to log warning and error messages, and an optional stdout handler to log debug and info messages.", "Arguments": ":param quiet: Bool. Whether to suppress all log messages except for errors.\n:param verbose: Bool. Whether to include info log messages in addition to errors.\n:param suppress_stdout: Bool. Whether to suppress log messages from being printed to stdout.\n:return: No return values."}, "tests": ["tests/test_cli.py::test_logging_outputs"], "indent": 4}
{"namespace": "faker.utils.distribution.choices_distribution_unique", "type": "function", "project_path": "Software-Development/Faker", "completion_path": "Software-Development/Faker/faker/utils/distribution.py", "signature_position": [26, 33], "body_position": [34, 54], "dependency": {"intra_class": [], "intra_file": ["faker.utils.distribution.T", "faker.utils.distribution.cumsum", "faker.utils.distribution.random_sample"], "cross_file": ["faker.generator.random"]}, "requirement": {"Functionality": "This function generates a sequence of unique choices based on the given input sequence and their corresponding probabilities. It ensures that the generated choices are unique and takes into account the weight of each choice.", "Arguments": ":param a: Sequence[T]. The input sequence of elements to choose from.\n:param p: Optional[Sequence[float]]. The probabilities associated with each element in the input sequence.\n:param random: Optional[Random]. The random number generator to be used. If not provided, the default random generator is used.\n:param length: int. The number of unique choices to generate. Defaults to 1.\n:return: Sequence[T]. A sequence of unique choices based on the input sequence and their probabilities."}, "tests": ["tests/utils/test_utils.py::UtilsTestCase::test_choices_distribution_unique"], "indent": 4}
{"namespace": "jwt.utils.to_base64url_uint", "type": "function", "project_path": "Utilities/PyJWT", "completion_path": "Utilities/PyJWT/jwt/utils.py", "signature_position": [40, 40], "body_position": [41, 49], "dependency": {"intra_class": [], "intra_file": ["jwt.utils.base64url_encode", "jwt.utils.bytes_from_int"], "cross_file": []}, "requirement": {"Functionality": "This function takes an integer value and converts it to a base64url-encoded byte string. It first checks if the input value is a positive integer, and then converts the integer to bytes. If the resulting byte string is empty, it sets it to a single null byte. Finally, it returns the base64url-encoded byte string.", "Arguments": ":param val: int. The integer value to be converted to base64url-encoded byte string.\n:return: bytes. The base64url-encoded byte string representing the input integer value."}, "tests": ["tests/test_utils.py::test_to_base64url_uint"], "indent": 4}
{"namespace": "playhouse.signals.Signal.disconnect", "type": "method", "project_path": "Software-Development/peewee", "completion_path": "Software-Development/peewee/playhouse/signals.py", "signature_position": [25, 25], "body_position": [26, 38], "dependency": {"intra_class": ["playhouse.signals.Signal._receiver_list", "playhouse.signals.Signal._receivers"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Disconnect a receiver from the Signal instance. It removes the receiver from the list of receivers and updates the receiver list accordingly in which every element format is (name, receiver, sender).", "Arguments": ":param self: Signal. An instance of the Signal class.\n:param receiver: Object. The receiver to be disconnected from the Signal instance. Defaults to None.\n:param name: String. The name of the receiver. If not provided, it is inferred from the receiver's name. Defaults to None.\n:param sender: Object. The sender of the signal. If provided, only the receiver with the specified sender will be disconnected. Defaults to None.\n:return: No return values."}, "tests": ["tests/signals.py::TestSignals::test_connect_disconnect", "tests/signals.py::TestSignals::test_disconnect_issue_2687"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_only.compute_likelihood_windows_in_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_only.py", "signature_position": [199, 208], "body_position": [242, 277], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_only.compute_likelihood_window"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the likelihoods of a sliding window of commands in a session. It iterates through the session and calculates the likelihood of each window based on the prior probabilities and transition probabilities.", "Arguments": ":param session: List[str]. A list of commands in a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, start_token and end_token will be added to the session before calculations.\n:param start_token: str. A dummy command to signify the start of the session.\n:param end_token: str. A dummy command to signify the end of the session.\n:param use_geo_mean: bool. If True, each likelihood of the sliding windows will be raised to the power of (1/window_len).\n:return: List[float]. A list of likelihoods for each sliding window."}, "tests": ["tests/analysis/test_anom_seq_cmds_only.py::TestCmdsOnly::test_compute_likelihood_windows_in_session"], "indent": 4}
{"namespace": "pyramid.util.TopologicalSorter.remove", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/util.py", "signature_position": [447, 447], "body_position": [449, 460], "dependency": {"intra_class": ["pyramid.util.TopologicalSorter.name2after", "pyramid.util.TopologicalSorter.name2before", "pyramid.util.TopologicalSorter.name2val", "pyramid.util.TopologicalSorter.names", "pyramid.util.TopologicalSorter.order", "pyramid.util.TopologicalSorter.req_after", "pyramid.util.TopologicalSorter.req_before"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Remove a node from the sort input in the TopologicalSorter instance.", "Arguments": ":param self: TopologicalSorter. An instance of the TopologicalSorter class.\n:param name: The name of the node to be removed.\n:return: No return values."}, "tests": ["tests/test_util.py::TestTopologicalSorter::test_remove"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_values.compute_prob_setofparams_given_cmd", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_values.py", "signature_position": [268, 275], "body_position": [313, 335], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix"]}, "requirement": {"Functionality": "This function computes the probability of a set of parameters and their values given a command. It takes into account the conditional probabilities of the parameters given the command and the conditional probabilities of the values given the parameters. It also includes the probabilities of values for modellable parameters in the calculation of the likelihood. The function allows for the option to use the geometric mean to compare probabilities across different commands with varying numbers of parameters.", "Arguments": ":param cmd: str. The name of the command.\n:param params_with_vals: Union[dict, set]. A dictionary or set of parameters and their values for the command.\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of parameters conditional on the command.\n:param value_cond_param_probs: Union[StateMatrix, dict]. Computed probabilities of values conditional on the parameter.\n:param modellable_params: set. A set of parameters for which the probabilities of their values will be included in the likelihood calculation.\n:param use_geo_mean: bool. If True, the likelihood will be raised to the power of (1/K), where K is the number of distinct parameters that appeared for the given command across the training set plus the number of values included in the modeling for this command.\n:return: float. The computed probability."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_values.py::TestCmdsParamsValues::test_compute_prob_setofparams_given_cmd"], "indent": 4}
{"namespace": "mssqlcli.telemetry.conclude", "type": "function", "project_path": "Database/mssql-cli", "completion_path": "Database/mssql-cli/mssqlcli/telemetry.py", "signature_position": [122, 123], "body_position": [124, 128], "dependency": {"intra_class": [], "intra_file": ["mssqlcli.telemetry.TelemetrySession.end_time", "mssqlcli.telemetry.TelemetrySession.generate_payload", "mssqlcli.telemetry._session", "mssqlcli.telemetry.output_payload_to_file", "mssqlcli.telemetry.upload_payload"], "cross_file": []}, "requirement": {"Functionality": "This function concludes the session by setting the end time, generating the payload, outputting the payload to a file, and uploading the payload to a service endpoint.", "Arguments": ":param service_endpoint_uri: String. The URI of the service endpoint to upload the payload to. It defaults to 'https://vortex.data.microsoft.com/collect/v1' if not specified.\n:param separate_process: Bool. Whether to upload the payload in a separate process. It defaults to True if not specified.\n:return: The result of the upload."}, "tests": ["tests/test_telemetry.py::TelemetryTests::test_telemetry_vortex_format"], "indent": 4}
{"namespace": "alembic.operations.ops.DropIndexOp.from_index", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/operations/ops.py", "signature_position": [1050, 1050], "body_position": [1051, 1058], "dependency": {"intra_class": ["alembic.operations.ops.DropIndexOp.__init__"], "intra_file": ["alembic.operations.ops.CreateIndexOp", "alembic.operations.ops.CreateIndexOp.from_index"], "cross_file": []}, "requirement": {"Functionality": "This function creates a DropIndexOp instance based on the given index. It extracts the necessary information from the index object and initializes the DropIndexOp instance with those values.", "Arguments": ":param cls: Class. The class of the DropIndexOp instance.\n:param index: Index. The index object from which the DropIndexOp instance is created.\n:return: DropIndexOp. The created DropIndexOp instance."}, "tests": ["tests/test_autogen_render.py::AutogenRenderTest::test_drop_index", "tests/test_op.py::ObjectFromToTest::test_drop_index_add_kw", "tests/test_op.py::ObjectFromToTest::test_drop_index", "tests/test_autogen_render.py::AutogenRenderTest::test_drop_index_func", "tests/test_autogen_render.py::AutogenRenderTest::test_drop_index_schema_batch"], "indent": 8}
{"namespace": "alembic.script.revision.RevisionMap.filter_for_lineage", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [674, 679], "body_position": [680, 694], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._resolve_revision_number"], "intra_file": ["alembic.script.revision._TR"], "cross_file": []}, "requirement": {"Functionality": "Filter a list of targets based on their lineage in the RevisionMap instance. It checks if each target shares a lineage with the specified revision number and includes it in the result if it does.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:param targets: Iterable. A list of targets to filter.\n:param check_against: Optional string. The revision number to check against. If not specified, all targets will be included.\n:param include_dependencies: Bool. Whether to include targets that are dependencies of the specified targets. Defaults to False.\n:return: Tuple. A tuple of targets that share a lineage with the specified revision number."}, "tests": ["tests/test_revision.py::LabeledBranchTest::test_filter_for_lineage_labeled_head_across_merge", "tests/test_revision.py::LabeledBranchTest::test_filter_for_lineage_heads"], "indent": 8}
{"namespace": "mingus.containers.note_container.NoteContainer.transpose", "type": "method", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/containers/note_container.py", "signature_position": [286, 286], "body_position": [289, 291], "dependency": {"intra_class": ["mingus.containers.note_container.NoteContainer.notes"], "intra_file": [], "cross_file": ["mingus.containers.note.Note.transpose"]}, "requirement": {"Functionality": "This function transposes all the notes in the container up or down by the given interval.\n", "Arguments": ":param self: NoteContainer. An instance of the NoteContainer class.\n:param interval: int. The interval by which to transpose the notes.\n:param up: bool. Whether to transpose the notes up or down. Defaults to True (transpose up).\n:return: NoteContainer. The same NoteContainer instance after transposing the notes.\n"}, "tests": ["tests/unit/containers/test_note_containers.py::test_NoteContainers::test_transpose", "tests/unit/containers/test_note_containers.py::test_NoteContainers::test_determine"], "indent": 8}
{"namespace": "pyramid.config.views.MultiView.match", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/views.py", "signature_position": [124, 124], "body_position": [125, 130], "dependency": {"intra_class": ["pyramid.config.views.MultiView.get_views", "pyramid.config.views.MultiView.name"], "intra_file": [], "cross_file": ["pyramid.exceptions.PredicateMismatch"]}, "requirement": {"Functionality": "This function matches a view based on the given context and request. It iterates through the views obtained by request and checks if each view has the `__predicated__`. If a view does not have the attribute or if the predicated result is `True` for the given context and request, that view is returned. If no matching view is found, a predicate mismatch exception is raised.", "Arguments": ":param self: MultiView. An instance of the MultiView class.\n:param context: The context for matching the view.\n:param request: The request for matching the view.\n:return: The matched view."}, "tests": ["tests/test_config/test_views.py::TestMultiView::test_match_predicate_succeeds", "tests/test_config/test_views.py::TestMultiView::test_match_predicate_fails", "tests/test_config/test_views.py::TestMultiView::test_match_not_found"], "indent": 8}
{"namespace": "boltons.funcutils.FunctionBuilder.get_invocation_str", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/funcutils.py", "signature_position": [848, 848], "body_position": [849, 865], "dependency": {"intra_class": ["boltons.funcutils.FunctionBuilder._KWONLY_MARKER", "boltons.funcutils.FunctionBuilder.varkw", "boltons.funcutils.FunctionBuilder.args", "boltons.funcutils.FunctionBuilder.varargs", "boltons.funcutils.FunctionBuilder.kwonlyargs"], "intra_file": ["boltons.funcutils.inspect_formatargspec"], "cross_file": []}, "requirement": {"Functionality": "This function returns the invocation string of a function based on the arguments and keyword-only arguments of the FunctionBuilder instance.", "Arguments": ":param self: FunctionBuilder. An instance of the FunctionBuilder class.\n:return: str. The invocation string of the function."}, "tests": ["tests/test_funcutils_fb.py::test_get_invocation_sig_str", "tests/test_funcutils_fb_py3.py::test_get_invocation_sig_str"], "indent": 12}
{"namespace": "mrjob.compat.translate_jobconf", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/compat.py", "signature_position": [657, 657], "body_position": [661, 667], "dependency": {"intra_class": [], "intra_file": ["mrjob.compat._JOBCONF_MAP", "mrjob.compat.map_version"], "cross_file": []}, "requirement": {"Functionality": "Translate a job configuration variable to a specific Hadoop version. If the variable is not recognized, it remains unchanged.\n", "Arguments": ":param variable: String. The job configuration variable to be translated.\n:param version: String. The target Hadoop version to translate the variable to.\n:return: String. The translated variable based on the specified Hadoop version. If the variable is not recognized, it returns the unchanged variable.\n"}, "tests": ["tests/test_compat.py::TranslateJobConfTestCase::test_translate_jobconf", "tests/test_compat.py::TranslateJobConfTestCase::test_version_may_not_be_None"], "indent": 4}
{"namespace": "boltons.cacheutils.ThresholdCounter.update", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/cacheutils.py", "signature_position": [805, 805], "body_position": [812, 821], "dependency": {"intra_class": ["boltons.cacheutils.ThresholdCounter.add", "boltons.cacheutils.ThresholdCounter.update"], "intra_file": ["boltons.cacheutils.xrange"], "cross_file": []}, "requirement": {"Functionality": "This function updates the counts in the ThresholdCounter instance by adding multiple items in one call.\n", "Arguments": ":param iterable: Iterable or Mapping. An iterable of keys to add or a mapping of keys to integer counts.\n:param kwargs: Additional key-value pairs that need to be updated in the ThresholdCounter instance.\n:return: No return values.\n"}, "tests": ["tests/test_cacheutils.py::test_threshold_counter"], "indent": 8}
{"namespace": "datasette.utils.is_url", "type": "function", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/utils/__init__.py", "signature_position": [690, 690], "body_position": [692, 699], "dependency": {"intra_class": [], "intra_file": ["datasette.utils.whitespace_re"], "cross_file": []}, "requirement": {"Functionality": "Check if a given value is a valid URL. It checks if the value is a string, starts with \"http://\" or \"https://\", and does not contain any whitespace.", "Arguments": ":param value: The value to be checked if it is a valid URL.\n:return: Bool. True if the value is a valid URL, False otherwise."}, "tests": ["tests/test_utils.py::test_is_url"], "indent": 4}
{"namespace": "mrjob.parse.to_uri", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [69, 69], "body_position": [72, 75], "dependency": {"intra_class": [], "intra_file": ["mrjob.parse.is_uri"], "cross_file": []}, "requirement": {"Functionality": "This function takes a path or URI as input and converts it to a \"file:///\" URI if it is not already a URI.", "Arguments": ":param path_or_uri: str. The path or URI to be converted.\n:return: str. The converted URI."}, "tests": ["tests/test_parse.py::URITestCase::test_relative_path_to_uri", "tests/test_parse.py::URITestCase::test_to_uri"], "indent": 4}
{"namespace": "dominate.dom_tag.dom_tag.render", "type": "method", "project_path": "Text-Processing/dominate", "completion_path": "Text-Processing/dominate/dominate/dom_tag.py", "signature_position": [325, 325], "body_position": [326, 327], "dependency": {"intra_class": ["dominate.dom_tag.dom_tag._render"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Render the DOM tag and return the rendered output as a string. It recursively renders the tag and its children.", "Arguments": ":param self: dom_tag. An instance of the dom_tag class.\n:param indent: String. The string used for indentation. Defaults to two spaces.\n:param pretty: Bool. Whether to add line breaks and indentation for a prettier output. Defaults to True.\n:param xhtml: Bool. Whether to use XHTML syntax. Defaults to False.\n:return: String. The rendered output of the DOM tag."}, "tests": ["tests/test_html.py::test_lazy"], "indent": 4}
{"namespace": "pythonforandroid.prerequisites.OpenSSLPrerequisite.darwin_installer", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [283, 283], "body_position": [284, 285], "dependency": {"intra_class": ["pythonforandroid.prerequisites.OpenSSLPrerequisite.homebrew_formula_name"], "intra_file": [], "cross_file": ["pythonforandroid.logger.info"]}, "requirement": {"Functionality": "This function installs OpenSSL on a macOS system using the Homebrew package manager.", "Arguments": ":param self: OpenSSLPrerequisite. An instance of the OpenSSLPrerequisite class.\n:return: None."}, "tests": ["tests/test_prerequisites.py::TestOpenSSLPrerequisite::test_darwin_installer"], "indent": 8}
{"namespace": "rest_framework.fields.Field.bind", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/fields.py", "signature_position": [358, 358], "body_position": [367, 390], "dependency": {"intra_class": ["rest_framework.fields.Field.field_name", "rest_framework.fields.Field.label", "rest_framework.fields.Field.parent", "rest_framework.fields.Field.source", "rest_framework.fields.Field.source_attrs"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function is used to initialize the field name and parent for the Field instance. It is called when a field is added to the parent serializer instance.", "Arguments": ":param self: Field. An instance of the Field class.\n:param field_name: String. The name of the field being added.\n:param parent: The parent serializer instance.\n:return: No return values."}, "tests": ["tests/test_fields.py::Test5087Regression::test_parent_binding"], "indent": 8}
{"namespace": "boto.sts.credentials.Credentials.to_dict", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/sts/credentials.py", "signature_position": [94, 94], "body_position": [99, 103], "dependency": {"intra_class": ["boto.sts.credentials.Credentials.access_key", "boto.sts.credentials.Credentials.expiration", "boto.sts.credentials.Credentials.request_id", "boto.sts.credentials.Credentials.secret_key", "boto.sts.credentials.Credentials.session_token"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function converts the Credentials object into a Python dictionary. The dictionary contains the important information about the Session Token, such as the access key, secret key, session token, expiration, and request ID.", "Arguments": ":param self: Credentials. An instance of the Credentials class.\n:return: dict. A Python dictionary containing the important information about the Session Token."}, "tests": ["tests/unit/sts/test_credentials.py::STSCredentialsTest::test_to_dict"], "indent": 8}
{"namespace": "pyt.vulnerabilities.vulnerabilities.find_triggers", "type": "function", "project_path": "Security/python-taint", "completion_path": "Security/python-taint/pyt/vulnerabilities/vulnerabilities.py", "signature_position": [129, 133], "body_position": [144, 148], "dependency": {"intra_class": [], "intra_file": ["pyt.vulnerabilities.vulnerabilities.label_contains"], "cross_file": []}, "requirement": {"Functionality": "This function finds triggers from a list of trigger words in a given list of nodes. It iterates through each node and checks if the line number of the node is not in the set of nosec_lines. If it does, it checks if the label of the node contains any of the trigger words and adds the finded trigger node to the list of trigger_nodes.", "Arguments": ":param nodes: List of Node objects. The nodes to find triggers in.\n:param trigger_words: List of Sink or Source objects. The trigger words to look for.\n:param nosec_lines: Set of integers. Lines with # nosec whitelisting.\n:return: List of TriggerNode objects. The found trigger nodes."}, "tests": ["tests/vulnerabilities/vulnerabilities_test.py::EngineTest::test_find_triggers"], "indent": 4}
{"namespace": "boltons.strutils.strip_ansi", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/strutils.py", "signature_position": [392, 392], "body_position": [415, 428], "dependency": {"intra_class": [], "intra_file": ["boltons.strutils.ANSI_SEQUENCES", "boltons.strutils.bytes", "boltons.strutils.unicode"], "cross_file": []}, "requirement": {"Functionality": "This function strips ANSI escape codes from the input text. It is useful when a log or redirected output accidentally captures console color codes. The function supports unicode, str, bytes, and bytearray content as input and returns the same type as the input.", "Arguments": ":param text: The input text from which ANSI escape codes need to be stripped.\n:return: The cleaned text with ANSI escape codes removed."}, "tests": ["tests/test_strutils.py::test_strip_ansi"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.DefaultContainer.to_payload", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [520, 520], "body_position": [521, 531], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.Payload", "bentoml._internal.runner.container.DataContainer.create_payload"], "cross_file": []}, "requirement": {"Functionality": "This function converts a batch of data into a Payload object. It first checks if the batch is a generator and converts it into a list if necessary. Then, it serializes the batch using pickle. Finally, it determines the batch size and creates a Payload object with the serialized data and batch size.", "Arguments": ":param cls: DefaultContainer. The class itself.\n:param batch: Any. The batch of data to be converted.\n:param batch_dim: int. The dimension of the batch.\n:return: Payload. The created Payload object."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_default_container"], "indent": 8}
{"namespace": "zxcvbn.time_estimates.estimate_attack_times", "type": "function", "project_path": "Security/zxcvbn-python", "completion_path": "Security/zxcvbn-python/zxcvbn/time_estimates.py", "signature_position": [3, 3], "body_position": [4, 19], "dependency": {"intra_class": [], "intra_file": ["zxcvbn.time_estimates.display_time", "zxcvbn.time_estimates.float_to_decimal", "zxcvbn.time_estimates.guesses_to_score"], "cross_file": []}, "requirement": {"Functionality": "Estimate the time it would take to crack a password based on the number of guesses. It calculates the crack times in seconds for different scenarios and converts them into a more readable format. It also calculates a score based on the number of guesses.", "Arguments": ":param guesses: The number of guesses to crack the password.\n:return: Dictionary. A dictionary containing the crack times in seconds for different scenarios, the crack times in a more readable format, and the score based on the number of guesses."}, "tests": ["tests/time_estimates_test.py::test_long_ints_dont_overflow"], "indent": 4}
{"namespace": "datasette.facets.DateFacet.facet_results", "type": "method", "project_path": "Database/datasette", "completion_path": "Database/datasette/datasette/facets.py", "signature_position": [503, 503], "body_position": [504, 568], "dependency": {"intra_class": ["datasette.facets.DateFacet.type"], "intra_file": ["datasette.facets.Facet.database", "datasette.facets.Facet.ds", "datasette.facets.Facet.get_configs", "datasette.facets.Facet.get_facet_size", "datasette.facets.Facet.get_querystring_pairs", "datasette.facets.Facet.params", "datasette.facets.Facet.request", "datasette.facets.Facet.sql"], "cross_file": ["datasette.database.QueryInterrupted", "datasette.utils.escape_sqlite", "datasette.utils.path_with_added_args", "datasette.utils.path_with_removed_args", "datasette.app.Datasette.absolute_url", "datasette.app.Datasette.execute", "datasette.app.Datasette.setting"]}, "requirement": {"Functionality": "This function retrieves facet results for a DateFacet instance. It executes a SQL query to retrieve the facet values and their corresponding counts from the database. It then formats the results and returns them.", "Arguments": ":param self: DateFacet. An instance of the DateFacet class.\n:return: Tuple. A tuple containing two lists - facet_results and facets_timed_out. facet_results contains dictionaries representing each facet value, its count, and other information. facets_timed_out contains the names of facets that timed out during execution."}, "tests": ["tests/test_facets.py::test_date_facet_results"], "indent": 8}
{"namespace": "pythonforandroid.recommendations.check_ndk_api", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/recommendations.py", "signature_position": [178, 178], "body_position": [180, 189], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.recommendations.MIN_NDK_API", "pythonforandroid.recommendations.OLD_NDK_API_MESSAGE", "pythonforandroid.recommendations.TARGET_NDK_API_GREATER_THAN_TARGET_API_MESSAGE"], "cross_file": ["pythonforandroid.logger.warning", "pythonforandroid.util.BuildInterruptingException"]}, "requirement": {"Functionality": "This function checks if the NDK API version is compatible with the target Android API version. If the NDK API version is higher than the target Android API version, it raises a build interrupting exception with a specific error message. If the NDK API version is lower than the minimum supported NDK API version, it displays a warning message.", "Arguments": ":param ndk_api: Integer. The NDK API version.\n:param android_api: Integer. The target Android API version.\n:return: No return values."}, "tests": ["tests/test_recommendations.py::TestRecommendations::test_check_ndk_api_error_android_api", "tests/test_recommendations.py::TestRecommendations::test_check_ndk_api_warning_old_ndk"], "indent": 4}
{"namespace": "pythonforandroid.prerequisites.AutoconfPrerequisite.darwin_installer", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [299, 299], "body_position": [300, 301], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pythonforandroid.logger.info"]}, "requirement": {"Functionality": "This function installs Autoconf on a macOS system using the Homebrew package manager.", "Arguments": ":param self: AutoconfPrerequisite. An instance of the AutoconfPrerequisite class.\n:return: No return values."}, "tests": ["tests/test_prerequisites.py::TestAutoconfPrerequisite::test_darwin_installer"], "indent": 8}
{"namespace": "boto.ec2.networkinterface.NetworkInterface.attach", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/networkinterface.py", "signature_position": [193, 193], "body_position": [207, 212], "dependency": {"intra_class": ["boto.ec2.networkinterface.NetworkInterface.connection", "boto.ec2.networkinterface.NetworkInterface.id"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.attach_network_interface"]}, "requirement": {"Functionality": "This function attaches a network interface (ENI) to an EC2 instance.", "Arguments": ":param self: NetworkInterface. An instance of the NetworkInterface class.\n:param instance_id: str. The ID of the EC2 instance to which the ENI will be attached.\n:param device_index: int. The interface number on the instance (e.g., ethN).\n:param dry_run: bool. Whether to perform a dry run. Defaults to False.\n:return: bool. True if the attachment is successful."}, "tests": ["tests/unit/ec2/test_networkinterface.py::NetworkInterfaceTests::test_attach_calls_attach_eni"], "indent": 8}
{"namespace": "alembic.config.Config.set_section_option", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/config.py", "signature_position": [276, 276], "body_position": [296, 298], "dependency": {"intra_class": ["alembic.config.Config.file_config"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function sets an option programmatically within a specific section of a configuration file. If the section does not exist, it creates the section. The value provided will override any existing value in the configuration file.", "Arguments": ":param self: Config. An instance of the Config class.\n:param section: str. The name of the section in the configuration file.\n:param name: str. The name of the value to be set.\n:param value: str. The value to be set. This value supports variable interpolation using pyformat. A raw percent sign not part of an interpolation symbol must be escaped with another percent sign. The given value may refer to another value already in the file using the interpolation format.\n:return: None."}, "tests": ["tests/test_config.py::ConfigTest::test_config_no_file_section_option", "tests/test_config.py::ConfigTest::test_config_set_section_option_interpolation", "tests/test_config.py::ConfigTest::test_config_set_section_option_percent"], "indent": 8}
{"namespace": "mrjob.py2.to_unicode", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/py2.py", "signature_position": [161, 161], "body_position": [170, 178], "dependency": {"intra_class": [], "intra_file": ["mrjob.py2.string_types"], "cross_file": []}, "requirement": {"Functionality": "This function converts bytes to unicode. \nIt first tries to decode the bytes using UTF-8, but if that fails, it falls back to Latin-1, which always works.\n", "Arguments": ":param s: bytes. The input string to be converted. It can be either bytes or unicode.\n:return: String. The converted unicode string.\n"}, "tests": ["tests/test_py2.py::ToUnicodeTestCase::test_latin_1_bytes", "tests/test_py2.py::ToUnicodeTestCase::test_utf_8_bytes", "tests/test_py2.py::ToUnicodeTestCase::test_ascii_unicode", "tests/test_py2.py::ToUnicodeTestCase::test_ascii_bytes", "tests/test_py2.py::ToUnicodeTestCase::test_non_ascii_unicode"], "indent": 4}
{"namespace": "msticpy.analysis.anomalous_sequence.model.Model.compute_scores", "type": "method", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/model.py", "signature_position": [131, 131], "body_position": [156, 167], "dependency": {"intra_class": ["msticpy.analysis.anomalous_sequence.model.Model.compute_geomean_lik_of_sessions", "msticpy.analysis.anomalous_sequence.model.Model.compute_likelihoods_of_sessions", "msticpy.analysis.anomalous_sequence.model.Model.compute_rarest_windows", "msticpy.analysis.anomalous_sequence.model.Model.prior_probs"], "intra_file": [], "cross_file": ["msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes various likelihood-based scores/metrics for each session in the model. It calculates the likelihoods and geometric mean of the likelihoods for each session. It also uses a sliding window approach to compute the rarest window likelihoods for each session, with window lengths of 2 and 3.\nNote that if a session has a length of k and a sliding window of length k+1 is used, the rarest window likelihood metric for that session will be np.nan. However, if the parameter `use_start_end_tokens` is set to True, the session will be treated as a session of length k+1 because the start and end tokens will be appended, resulting in a non np.nan value for that session.", "Arguments": ":param self: Model. An instance of the Model class.\n:param use_start_end_tokens: Bool. If True, the start and end tokens will be prepended and appended to each session respectively before the calculations are done.\n:return: No return values."}, "tests": ["tests/analysis/test_anom_seq_model.py::TestModel::test_compute_scores"], "indent": 8}
{"namespace": "ydata_profiling.model.pandas.discretize_pandas.Discretizer.discretize_dataframe", "type": "method", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/model/pandas/discretize_pandas.py", "signature_position": [38, 38], "body_position": [48, 61], "dependency": {"intra_class": ["ydata_profiling.model.pandas.discretize_pandas.Discretizer._discretize_column", "ydata_profiling.model.pandas.discretize_pandas.Discretizer._get_numerical_columns", "ydata_profiling.model.pandas.discretize_pandas.Discretizer.reset_index"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function takes a pandas DataFrame as input and discretizes the numerical columns in the DataFrame. It creates a copy of the input DataFrame and applies the discretization process to each numerical column. The discretized DataFrame is then returned.", "Arguments": ":param self: Discretizer. An instance of the Discretizer class.\n:param dataframe: pd.DataFrame. The input pandas DataFrame.\n:return: pd.DataFrame. The discretized DataFrame."}, "tests": ["tests/unit/test_pandas/test_discretize.py::test_mixed_discretization", "tests/unit/test_pandas/test_discretize.py::test_discretize_uniform", "tests/unit/test_pandas/test_discretize.py::test_discretize_quantile"], "indent": 8}
{"namespace": "mopidy.internal.validation.check_uris", "type": "function", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/internal/validation.py", "signature_position": [129, 129], "body_position": [130, 131], "dependency": {"intra_class": [], "intra_file": ["mopidy.internal.validation._check_iterable"], "cross_file": []}, "requirement": {"Functionality": "This function checks if the input argument is a list of URIs. If it is not, it raises an exception with a custom error message. It then iterates over each URI in the list and calls the check_uri function to validate each URI.", "Arguments": ":param arg: Any. The input argument to be checked.\n:param msg: String. The custom error message to be displayed if the input argument is not a list of URIs. It defaults to \"Expected a list of URIs, not {arg!r}\".\n:return: No return values."}, "tests": ["tests/internal/test_validation.py::test_check_uris_error_message", "tests/internal/test_validation.py::test_check_uris_with_invalid_values"], "indent": 4}
{"namespace": "rest_framework.parsers.FileUploadParser.get_filename", "type": "method", "project_path": "Internet/djangorestframework", "completion_path": "Internet/djangorestframework/rest_framework/parsers.py", "signature_position": [192, 192], "body_position": [197, 211], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["rest_framework.compat.parse_header_parameters"]}, "requirement": {"Functionality": "This function is used to get the filename of an uploaded file. It first checks if the filename is provided as a URL keyword argument. If not, it tries to parse the Content-Disposition header to extract the filename.", "Arguments": ":param self: FileUploadParser. An instance of the FileUploadParser class.\n:param stream: The file stream of the uploaded file.\n:param media_type: The media type of the uploaded file.\n:param parser_context: The context of the parser.\n:return: The filename of the uploaded file, if found."}, "tests": ["tests/test_parsers.py::TestFileUploadParser::test_get_encoded_filename", "tests/test_parsers.py::TestFileUploadParser::test_get_filename"], "indent": 8}
{"namespace": "imapclient.fixed_offset.FixedOffset.for_system", "type": "method", "project_path": "Communications/IMAPClient", "completion_path": "Communications/IMAPClient/imapclient/fixed_offset.py", "signature_position": [37, 37], "body_position": [41, 45], "dependency": {"intra_class": ["imapclient.fixed_offset.FixedOffset.__init__"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a FixedOffset instance based on the current working timezone and DST conditions. It checks if the current time is in daylight saving time and if daylight saving time is enabled. If both conditions are true, it sets the offset to the alternate time zone offset. Otherwise, it sets the offset to the default time zone offset.", "Arguments": ":param cls: Class. The class object.\n:return: FixedOffset. The created FixedOffset instance."}, "tests": ["tests/test_fixed_offset.py::TestFixedOffset::test_for_system_DST_not_active", "tests/test_fixed_offset.py::TestFixedOffset::test_for_system_DST_active", "tests/test_fixed_offset.py::TestFixedOffset::test_for_system_no_DST"], "indent": 8}
{"namespace": "msticpy.analysis.anomalous_sequence.utils.cmds_params_only.compute_likelihood_windows_in_session", "type": "function", "project_path": "Security/msticpy", "completion_path": "Security/msticpy/msticpy/analysis/anomalous_sequence/utils/cmds_params_only.py", "signature_position": [319, 329], "body_position": [368, 404], "dependency": {"intra_class": [], "intra_file": ["msticpy.analysis.anomalous_sequence.utils.cmds_params_only.compute_likelihood_window"], "cross_file": ["msticpy.analysis.anomalous_sequence.utils.data_structures.Cmd", "msticpy.analysis.anomalous_sequence.utils.data_structures.StateMatrix", "msticpy.common.exceptions.MsticpyException"]}, "requirement": {"Functionality": "This function computes the likelihoods of a sliding window in a session. It takes a session, prior probabilities, transition probabilities, parameter conditional command probabilities, window length, start and end tokens, and a flag to indicate whether to use geometric mean. It iterates through the session and calculates the likelihood for each sliding window. If the use_geo_mean flag is set to True, it raises each likelihood to the power of (1/window_len) before appending it to the list of likelihoods.", "Arguments": ":param session: List[Cmd]. A list of Cmd objects representing a session.\n:param prior_probs: Union[StateMatrix, dict]. Computed probabilities of individual commands.\n:param trans_probs: Union[StateMatrix, dict]. Computed probabilities of sequences of commands (length 2).\n:param param_cond_cmd_probs: Union[StateMatrix, dict]. Computed probabilities of the parameters conditional on the command.\n:param window_len: int. The length of the sliding window for likelihood calculations.\n:param use_start_end_tokens: bool. If True, start and end tokens will be prepended and appended to the session respectively before the calculations are done.\n:param start_token: str. A dummy command to signify the start of the session. Defaults to None.\n:param end_token: str. A dummy command to signify the end of the session. Defaults to None.\n:param use_geo_mean: bool. If True, each likelihood of the sliding windows will be raised to the power of (1/window_len).\n:return: List[float]. A list of likelihoods."}, "tests": ["tests/analysis/test_anom_seq_cmds_params_only.py::TestCmdsParamsOnly::test_compute_likelihood_windows_in_session"], "indent": 4}
{"namespace": "boltons.urlutils.URL.path", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/urlutils.py", "signature_position": [586, 586], "body_position": [587, 589], "dependency": {"intra_class": ["boltons.urlutils.URL.path_parts"], "intra_file": ["boltons.urlutils.to_unicode"], "cross_file": []}, "requirement": {"Functionality": "This function splits the given path into its components and caches the result. It splits the path_text by '/' and unquotes each part if it contains '%'.", "Arguments": ":param self: URL. An instance of the URL class.\n:param path_text: str. The path text to be processed.\n:return: No return values."}, "tests": ["tests/test_urlutils.py::test_netloc_slashes"], "indent": 8}
{"namespace": "mrjob.job.MRJob.sandbox", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/job.py", "signature_position": [1603, 1603], "body_position": [1658, 1662], "dependency": {"intra_class": ["mrjob.job.MRJob._stderr", "mrjob.job.MRJob._stdin", "mrjob.job.MRJob._stdout"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function redirects the standard input, standard output, and standard error for automated testing. By default, they are set to empty BytesIO objects. The function returns the MRJob instance with the redirected file handles.", "Arguments": ":param self: MRJob. An instance of the MRJob class.\n:param stdin: File object. The file object to be used as the standard input. Defaults to None, in which case the standard input is set to an empty BytesIO object.\n:param stdout: File object. The file object to be used as the standard output. Defaults to None, in which case the standard output is set to an empty BytesIO object.\n:param stderr: File object. The file object to be used as the standard error. Defaults to None, in which case the standard error is set to an empty BytesIO object.\n:return: MRJob. The MRJob instance with the redirected file handles."}, "tests": ["tests/test_local.py::SortBinTestCase::test_empty_sort_bin_means_default", "tests/test_sim.py::NoMRJobConfTestCase::test_no_mrjob_confs", "tests/test_inline.py::InlineRunnerStepsTestCase::test_adding_2", "tests/test_hadoop.py::BadHadoopBinAfterFork::test_permissions_error", "tests/test_job.py::CountersAndStatusTestCase::test_counters_and_status"], "indent": 8}
{"namespace": "mrjob.runner.MRJobRunner._bootstrap_mrjob", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/runner.py", "signature_position": [1062, 1062], "body_position": [1064, 1067], "dependency": {"intra_class": ["mrjob.runner.MRJobRunner._opts"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Check if mrjob should be bootstrapped. If the option is not set, it returns True.", "Arguments": ":param self: MRJobRunner. An instance of the MRJobRunner class.\n:return: Bool. True if mrjob should be bootstrapped, False otherwise."}, "tests": ["tests/test_bin.py::BootstrapMRJobTestCase::test_default", "tests/test_bin.py::BootstrapMRJobTestCase::test_no_bootstrap_mrjob"], "indent": 8}
{"namespace": "exodus_bundler.launchers.construct_bash_launcher", "type": "function", "project_path": "System/exodus-bundler", "completion_path": "System/exodus-bundler/src/exodus_bundler/launchers.py", "signature_position": [93, 93], "body_position": [94, 98], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["exodus_bundler.templating.render_template_file"]}, "requirement": {"Functionality": "Construct a bash launcher script based on the given parameters. It creates a bash launcher script by rendering a template file with the provided parameters.", "Arguments": ":param linker: String. The path to the linker executable.\n:param library_path: String. The path to the library.\n:param executable: String. The path to the executable.\n:param full_linker: Bool. Whether to use the full linker path. Defaults to True.\n:return: String. The constructed bash launcher script."}, "tests": ["tests/test_launchers.py::test_construct_bash_launcher"], "indent": 4}
{"namespace": "benedict.dicts.keylist.keylist_util.set_item", "type": "function", "project_path": "Text-Processing/python-benedict", "completion_path": "Text-Processing/python-benedict/benedict/dicts/keylist/keylist_util.py", "signature_position": [69, 69], "body_position": [70, 80], "dependency": {"intra_class": [], "intra_file": ["benedict.dicts.keylist.keylist_util._get_or_new_item_value", "benedict.dicts.keylist.keylist_util._set_item_value"], "cross_file": []}, "requirement": {"Functionality": "This function sets a value in a nested dictionary based on a list of keys. It iterates through the keys and checks if each key exists in the dictionary. If a key does not exist, it creates a new dictionary and assigns it as the value for that key. Finally, it sets the desired value in the last nested dictionary.", "Arguments": ":param d: Dictionary. The dictionary in which to set the value.\n:param keys: List of keys. The list of keys representing the nested structure in the dictionary.\n:param value: Any. The value to be set in the nested dictionary.\n:return: None."}, "tests": ["tests/dicts/keylist/test_keylist_util.py::keylist_util_test_case::test_set_item_with_indexes"], "indent": 4}
{"namespace": "pythonforandroid.graph.get_recipe_order_and_bootstrap", "type": "function", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/graph.py", "signature_position": [243, 244], "body_position": [245, 343], "dependency": {"intra_class": [], "intra_file": ["pythonforandroid.graph.RecipeOrder", "pythonforandroid.graph.RecipeOrder.__init__", "pythonforandroid.graph.find_order", "pythonforandroid.graph.fix_deplist", "pythonforandroid.graph.get_recipe_order_and_bootstrap", "pythonforandroid.graph.obvious_conflict_checker", "pythonforandroid.graph.recursively_collect_orders"], "cross_file": ["pythonforandroid.bootstrap.Bootstrap", "pythonforandroid.bootstrap.Bootstrap.get_bootstrap_from_recipes", "pythonforandroid.logger.info", "pythonforandroid.recipe.Recipe", "pythonforandroid.recipe.Recipe.get_recipe", "pythonforandroid.util.BuildInterruptingException"]}, "requirement": {"Functionality": "This function takes in a context, a list of recipe/dependency names, an optional bootstrap instance, and an optional blacklist. It performs various operations on the input names to clean them up and add bootstrap dependencies. It then checks for conflicts and generates all possible order graphs based on the names. It converts each order graph into a linear list and sorts them based on preference. Finally, it returns the chosen order, along with the corresponding recipes, python modules, and bootstrap instance.", "Arguments": ":param ctx: The context in which the function is being called.\n:param names: List of strings. The recipe/dependency names.\n:param bs: Bootstrap instance. An optional bootstrap instance. Defaults to None.\n:param blacklist: Set of strings. An optional set of names to be blacklisted. Defaults to None.\n:return: Tuple. The chosen order of dependencies, the corresponding recipes, python modules, and bootstrap instance."}, "tests": ["tests/test_graph.py::test_bootstrap_dependency_addition2", "tests/test_graph.py::test_bootstrap_dependency_addition", "tests/test_graph.py::test_invalid_recipe_order_and_bootstrap", "tests/test_graph.py::test_blacklist"], "indent": 4}
{"namespace": "fs.path.splitext", "type": "function", "project_path": "System/fs", "completion_path": "System/fs/fs/path.py", "signature_position": [321, 322], "body_position": [340, 347], "dependency": {"intra_class": [], "intra_file": ["fs.path.join", "fs.path.split"], "cross_file": []}, "requirement": {"Functionality": "This function splits the extension from a given path. It separates the path and the extension and returns them as a tuple.", "Arguments": ":param path: Text. The path to split.\n:return: Tuple[Text, Text]. A tuple containing the path and the extension."}, "tests": ["tests/test_path.py::TestPathFunctions::test_splitext"], "indent": 4}
{"namespace": "bplustree.node.Node._find_entry_index", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/node.py", "signature_position": [123, 123], "body_position": [124, 131], "dependency": {"intra_class": ["bplustree.node.Node._entry_class", "bplustree.node.Node._tree_conf", "bplustree.node.Node.entries"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function finds the index of the entry in the Node instance based on the given key. It creates an entry object with the given key and compares it with the entries in the Node instance to find the index.", "Arguments": ":param self: Node. An instance of the Node class.\n:param key: The key to find the index for in the Node instance.\n:return: int. The index of the entry corresponding to the key."}, "tests": ["tests/test_node.py::test_insert_find_get_remove_entries"], "indent": 8}
{"namespace": "mopidy.http.Extension.get_default_config", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/http/__init__.py", "signature_position": [16, 16], "body_position": [17, 18], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mopidy.config.read", "mopidy.config"]}, "requirement": {"Functionality": "This function retrieves the default configuration for the Extension class. It reads the configuration file \"ext.conf\" located in the same directory as the script and returns the configuration data.", "Arguments": ":param self: Extension. An instance of the Extension class.\n:return: dict. The default configuration data read from the \"ext.conf\" file."}, "tests": ["tests/http/test_extension.py::test_default_config_is_valid", "tests/http/test_extension.py::test_get_default_config"], "indent": 8}
{"namespace": "zulipterminal.ui_tools.buttons.TopButton.update_count", "type": "method", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/ui_tools/buttons.py", "signature_position": [58, 58], "body_position": [59, 67], "dependency": {"intra_class": ["zulipterminal.ui_tools.buttons.TopButton.count", "zulipterminal.ui_tools.buttons.TopButton.count_style", "zulipterminal.ui_tools.buttons.TopButton.original_color", "zulipterminal.ui_tools.buttons.TopButton.update_widget"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Update the count value and text color of a TopButton instance. It first determines the new text color based on the input parameters. Then, it updates the count value and generates the count text based on the count value. Finally, it calls the corresponding method to update the widget with the new count style and count text.", "Arguments": ":param self: TopButton. An instance of the TopButton class.\n:param count: int. The new count value to be updated.\n:param text_color: Optional[str]. The new text color to be updated. Defaults to None.\n:return: No return values."}, "tests": ["tests/ui_tools/test_buttons.py::TestTopButton::test_update_count"], "indent": 8}
{"namespace": "discord.utils.resolve_invite", "type": "function", "project_path": "Software-Development/discord-py", "completion_path": "Software-Development/discord-py/discord/utils.py", "signature_position": [838, 838], "body_position": [855, 869], "dependency": {"intra_class": [], "intra_file": ["discord.utils.ResolvedInvite"], "cross_file": ["discord.invite.Invite"]}, "requirement": {"Functionality": "This function resolves an invite from a Discord invite, URL, or code. It returns a data class containing the invite code and the event ID.", "Arguments": ":param invite: Union[Invite, str]. The invite to resolve.\n:return: ResolvedInvite. A data class containing the invite code and the event ID."}, "tests": ["tests/test_utils.py::test_resolve_invite_event", "tests/test_utils.py::test_resolve_invite"], "indent": 4}
{"namespace": "boto.ec2.autoscale.connect_to_region", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/autoscale/__init__.py", "signature_position": [64, 64], "body_position": [75, 77], "dependency": {"intra_class": [], "intra_file": ["boto.ec2.autoscale.AutoScaleConnection"], "cross_file": ["boto.regioninfo.connect"]}, "requirement": {"Functionality": "Connect to a specific region and return an instance of the AutoScaleConnection class.", "Arguments": ":param region_name: String. The name of the region to connect to.\n:param kw_params: Additional keyword arguments that can be passed to the connect function.\n:return: AutoScaleConnection or None. A connection to the specified region, or None if an invalid region name is given."}, "tests": ["tests/unit/test_connect_to_region.py::TestAutoscaleConnection::test_connect_to_region"], "indent": 4}
{"namespace": "mrjob.hadoop.HadoopJobRunner._stream_task_log_dirs", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [557, 557], "body_position": [562, 573], "dependency": {"intra_class": ["mrjob.hadoop.HadoopJobRunner._hadoop_log_dirs", "mrjob.hadoop.HadoopJobRunner.fs"], "intra_file": ["mrjob.hadoop.log"], "cross_file": ["mrjob.fs.composite.CompositeFilesystem.join", "mrjob.logs.mixin.LogInterpretationMixin._read_logs", "mrjob.logs.wrap._logs_exist", "mrjob.util.unique"]}, "requirement": {"Functionality": "This function yields lists of directories to look for task logs in. It first checks if reading logs is enabled. Then, it iterates over unique log directories obtained from the hadoop log directories. For each log directory, it constructs a path based on the application ID: '{log dir}/userlogs/{application id}' if the application ID is available, otherwise '{log dir}/userlogs'. It then logs an info message: 'Looking for task logs in {directory}...'. It then yields a list containing the directory.", "Arguments": ":param self: HadoopJobRunner. An instance of the HadoopJobRunner class.\n:param application_id: str. The ID of the application for which task logs are to be retrieved. Defaults to None.\n:param output_dir: str. The output directory where logs are stored. Defaults to None.\n:return: List of directories. A list of directories to look for task logs in."}, "tests": ["tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_basic", "tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_io_error_from_fs_exists", "tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_application_id", "tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_no_read_logs", "tests/test_hadoop.py::StreamTaskLogDirsTestCase::test_fs_exists"], "indent": 8}
{"namespace": "boltons.iterutils.get_path", "type": "function", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/iterutils.py", "signature_position": [1221, 1221], "body_position": [1254, 1278], "dependency": {"intra_class": [], "intra_file": ["boltons.iterutils.PathAccessError", "boltons.iterutils.PathAccessError.__init__", "boltons.iterutils._UNSET", "boltons.iterutils.basestring", "boltons.iterutils.is_iterable"], "cross_file": []}, "requirement": {"Functionality": "This function retrieves a value from a nested object using a tuple as the lookup path.  If the lookup fails at any level, a default value can be specified to be returned instead. This function also improves error messaging by providing specific information about the error that occurred during the lookup.\n", "Arguments": ":param root: The target nested object, can be dictionaries, lists, or other objects that support the `__getitem__` method.\n:param path: Tuple. A list of strings and integers representing the lookup path within the nested object.\n:param default: Any data type. The value to be returned if any `PathAccessError` exceptions are raised during the lookup. Defaults to _UNSET.\n:return: The value retrieved from the nested object using the specified lookup path. If the lookup fails and a default value is provided, the default value will be returned, or else the exception will be re-raised.\n"}, "tests": ["tests/test_iterutils.py::TestGetPath::test_depth_one", "tests/test_iterutils.py::TestGetPath::test_depth_two"], "indent": 4}
{"namespace": "mopidy.config.types.Float.deserialize", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/config/types.py", "signature_position": [175, 175], "body_position": [176, 183], "dependency": {"intra_class": ["mopidy.config.types.Float._maximum", "mopidy.config.types.Float._minimum", "mopidy.config.types.Float._required"], "intra_file": ["mopidy.config.types.decode"], "cross_file": ["mopidy.config.validators.validate_maximum", "mopidy.config.validators.validate_minimum", "mopidy.config.validators.validate_required", "mopidy.config.validators"]}, "requirement": {"Functionality": "Deserialize a value into a float. It decodes the input value, validates if it is required, and converts it into a float. It then validates if the float value meets the minimum and maximum constraints.", "Arguments": ":param self: Float. An instance of the Float class.\n:param value: The value to be deserialized into a float.\n:return: The deserialized float value."}, "tests": ["tests/config/test_types.py::TestFloat::test_deserialize_enforces_maximum", "tests/config/test_types.py::TestFloat::test_deserialize_conversion_failure", "tests/config/test_types.py::TestFloat::test_deserialize_enforces_required", "tests/config/test_types.py::TestFloat::test_deserialize_enforces_minimum", "tests/config/test_types.py::TestFloat::test_deserialize_conversion_success"], "indent": 8}
{"namespace": "hl7.parser._ParsePlan.container", "type": "method", "project_path": "Communications/hl7", "completion_path": "Communications/hl7/hl7/parser.py", "signature_position": [401, 401], "body_position": [405, 410], "dependency": {"intra_class": ["hl7.parser._ParsePlan.containers", "hl7.parser._ParsePlan.esc", "hl7.parser._ParsePlan.factory", "hl7.parser._ParsePlan.separators"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns an instance of the appropriate container for the given data based on the current plan. It uses the containers list to determine the type of container to create and initializes it with the specified parameters including data, esc, separator and factory.", "Arguments": ":param self: _ParsePlan. An instance of the _ParsePlan class.\n:param data: The data for which the container needs to be created.\n:return: The instance of the appropriate container for the given data."}, "tests": ["tests/test_parse.py::ParsePlanTest::test_parse_plan"], "indent": 8}
{"namespace": "boto.s3.website.RoutingRules.to_xml", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/s3/website.py", "signature_position": [167, 167], "body_position": [168, 171], "dependency": {"intra_class": ["boto.s3.website.RoutingRules.to_xml"], "intra_file": ["boto.s3.website.tag"], "cross_file": []}, "requirement": {"Functionality": "Convert the RoutingRules instance to an XML string representation.", "Arguments": ":param self: RoutingRules. An instance of the RoutingRules class.\n:return: String. The XML representation of the RoutingRules instance."}, "tests": ["tests/unit/s3/test_website.py::TestS3WebsiteConfiguration::test_builders"], "indent": 8}
{"namespace": "mingus.core.keys.get_key", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/keys.py", "signature_position": [66, 66], "body_position": [73, 76], "dependency": {"intra_class": [], "intra_file": ["mingus.core.keys.keys"], "cross_file": ["mingus.core.mt_exceptions.RangeError"]}, "requirement": {"Functionality": "This function returns the major key and its relative minor key corresponding to the number of accidentals provided as input.\n", "Arguments": ":param accidentals: int. The number of accidentals. It defaults to 0 if not specified.\n:return: tuple of str. The major key corresponding to the accidentals and its relative minor key.\n"}, "tests": ["tests/unit/core/test_keys.py::test_keys::test_get_key"], "indent": 4}
{"namespace": "chatette.adapters.factory.create_adapter", "type": "function", "project_path": "Communications/chatette", "completion_path": "Communications/chatette/chatette/adapters/factory.py", "signature_position": [11, 11], "body_position": [19, 31], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["chatette.adapters.jsonl.JsonListAdapter", "chatette.adapters.rasa.RasaAdapter", "chatette.adapters.rasa_md.RasaMdAdapter"]}, "requirement": {"Functionality": "This function creates and returns an instance of an adapter based on the given adapter name. The adapter names are used to determine which adapter class to instantiate. The mames are the following format:'rasa','rasa-md' or 'rasamd','jsonl'.", "Arguments": ":param adapter_name: String. The name of the adapter to be instantiated.\n:param base_filepath: String. The base file path to be used by the adapter. Defaults to None.\n:return: Adapter. The instantiated adapter instance based on the given adapter name."}, "tests": ["tests/unit-testing/adapter/test_factory.py::test_invalid", "tests/unit-testing/adapter/test_factory.py::test_valid"], "indent": 4}
{"namespace": "bentoml._internal.runner.container.PandasDataFrameContainer.from_payload", "type": "method", "project_path": "Scientific-Engineering/bentoml", "completion_path": "Scientific-Engineering/bentoml/src/bentoml/_internal/runner/container.py", "signature_position": [418, 421], "body_position": [422, 428], "dependency": {"intra_class": [], "intra_file": ["bentoml._internal.runner.container.Payload"], "cross_file": ["bentoml._internal.runner.container.Payload.data", "bentoml._internal.runner.container.Payload.meta", "bentoml._internal.utils.pickle.pep574_loads", "bentoml._internal.external_typing"]}, "requirement": {"Functionality": "This function creates a Pandas DataFrame container from the given payload. If the payload contains a buffer, it decodes the buffer and uses it along with other metadata to create the DataFrame. If the payload does not contain a buffer, it creates the DataFrame directly from the payload data.", "Arguments": ":param cls: Class. The class object.\n:param payload: Payload. The payload containing the data and metadata for creating the DataFrame.\n:return: ext.PdDataFrame. The created Pandas DataFrame."}, "tests": ["tests/unit/_internal/runner/test_container.py::test_pandas_container"], "indent": 8}
{"namespace": "oletools.rtfobj.is_rtf", "type": "function", "project_path": "Security/oletools", "completion_path": "Security/oletools/oletools/rtfobj.py", "signature_position": [785, 785], "body_position": [795, 828], "dependency": {"intra_class": [], "intra_file": ["oletools.rtfobj.RTF_MAGIC", "oletools.rtfobj.UNICODE_TYPE"], "cross_file": []}, "requirement": {"Functionality": "This function determines whether the given file, stream, or array represents an RTF file. It checks the magic bytes at the start of the input to determine if it matches the RTF magic bytes.", "Arguments": ":param arg: The input file, stream, or array to check.\n:param treat_str_as_data: Bool. Specifies whether the input string should be treated as a file name or as the data itself. Defaults to False.\n:return: Bool. True if the input represents an RTF file, False otherwise."}, "tests": ["tests/rtfobj/test_is_rtf.py::TestIsRtf::test_iterable", "tests/rtfobj/test_is_rtf.py::TestIsRtf::test_tuple", "tests/rtfobj/test_is_rtf.py::TestIsRtf::test_bytearray", "tests/rtfobj/test_is_rtf.py::TestIsRtf::test_files", "tests/rtfobj/test_is_rtf.py::TestIsRtf::test_bytes"], "indent": 4}
{"namespace": "boto.utils.pythonize_name", "type": "function", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/utils.py", "signature_position": [884, 884], "body_position": [897, 899], "dependency": {"intra_class": [], "intra_file": ["boto.utils._end_cap_regex", "boto.utils._first_cap_regex", "boto.utils._number_cap_regex"], "cross_file": []}, "requirement": {"Functionality": "This function converts a camel case name to a \"pythonic\" name by inserting underscores between words. It inserts underscores based on the capitalization of letters in the input name, and convert all upper case letters to lower case letters.", "Arguments": ":param name: String. The camel case name to be converted.\n:return: String. The converted \"pythonic\" name."}, "tests": ["tests/unit/utils/test_utils.py::TestPythonizeName::test_all_upper_case", "tests/unit/utils/test_utils.py::TestPythonizeName::test_empty_string", "tests/unit/utils/test_utils.py::TestPythonizeName::test_camel_case", "tests/unit/utils/test_utils.py::TestPythonizeName::test_all_lower_case", "tests/unit/utils/test_utils.py::TestPythonizeName::test_string_with_numbers"], "indent": 4}
{"namespace": "mrjob.setup.UploadDirManager.add", "type": "method", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/setup.py", "signature_position": [314, 314], "body_position": [319, 330], "dependency": {"intra_class": ["mrjob.setup.UploadDirManager._names_taken", "mrjob.setup.UploadDirManager._path_to_name", "mrjob.setup.UploadDirManager.uri"], "intra_file": ["mrjob.setup.name_uniquely"], "cross_file": ["mrjob.parse.is_uri"]}, "requirement": {"Functionality": "This function adds a path to the UploadDirManager instance. If the path has not been added before, it assigns it a name and ensures the file will not be hidden. If the path is a URI, it does not add it and just returns the URI.", "Arguments": ":param self: UploadDirManager. An instance of the UploadDirManager class.\n:param path: The path to be added.\n:return: The URI assigned to the path."}, "tests": ["tests/test_setup.py::UploadDirManagerTestCase::test_underscores_only", "tests/test_setup.py::UploadDirManagerTestCase::test_dot_underscore", "tests/test_setup.py::UploadDirManagerTestCase::test_name_collision", "tests/test_setup.py::UploadDirManagerTestCase::test_uri", "tests/test_setup.py::UploadDirManagerTestCase::test_hidden_file_name_collision"], "indent": 8}
{"namespace": "pyramid.predicates.CustomPredicate.text", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/predicates.py", "signature_position": [210, 210], "body_position": [211, 216], "dependency": {"intra_class": ["pyramid.predicates.CustomPredicate.func", "pyramid.predicates.CustomPredicate.__text__"], "intra_file": [], "cross_file": ["pyramid.util.object_description"]}, "requirement": {"Functionality": "This function returns the text representation of the CustomPredicate instance. If the '__text__' is present in the instance's function, it is returned. Otherwise, a default text is returned which includes the description of the function.", "Arguments": ":param self: CustomPredicate. An instance of the CustomPredicate class.\n:return: String. The text representation of the CustomPredicate instance."}, "tests": ["tests/test_predicates.py::TestCustomPredicate::test_text_func_has___text__", "tests/test_predicates.py::TestCustomPredicate::test_text_func_repr"], "indent": 8}
{"namespace": "fs.info.Info.suffix", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/info.py", "signature_position": [207, 208], "body_position": [222, 226], "dependency": {"intra_class": ["fs.info.Info.get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the suffix of a file name. It checks if the file name has a suffix and returns it. If there is no suffix, it returns an empty string.", "Arguments": ":param self: Info. An instance of the Info class.\n:return: Text. The suffix of the file name, including the dot."}, "tests": ["tests/test_info.py::TestInfo::test_suffix", "tests/test_info.py::TestInfo::test_basic"], "indent": 8}
{"namespace": "viztracer.report_builder.ReportBuilder.save", "type": "method", "project_path": "System/viztracer", "completion_path": "System/viztracer/src/viztracer/report_builder.py", "signature_position": [172, 172], "body_position": [173, 193], "dependency": {"intra_class": ["viztracer.report_builder.ReportBuilder.final_messages", "viztracer.report_builder.ReportBuilder.generate_report", "viztracer.report_builder.ReportBuilder.print_messages"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function saves the report generated by the ReportBuilder instance to an output file. It supports saving the report in different formats such as HTML, JSON, and GZ. If the output_file parameter is a string, it determines the file format based on the file extension and saves the report accordingly. If the output_file parameter is a file object, it saves the report directly to that file. After saving the report, it appends a message to the message list indicating the command to view the saved report and then prints all the messages. The format of the message is \"('view_command', {'output_file': the absolute path of output file})\"", "Arguments": ":param self: ReportBuilder. An instance of the ReportBuilder class.\n:param output_file: Union[str, TextIO]. The output file where the report will be saved. It can be either a string representing the file path or a file object. Defaults to \"result.html\".\n:param file_info: bool. Whether to include file information in the report. Defaults to True.\n:return: No return values."}, "tests": ["tests/test_report_builder.py::TestReportBuilder::test_combine", "tests/test_report_builder.py::TestReportBuilder::test_invalid"], "indent": 8}
{"namespace": "bplustree.tree.BPlusTree._root_node", "type": "method", "project_path": "Database/bplustree", "completion_path": "Database/bplustree/bplustree/tree.py", "signature_position": [272, 272], "body_position": [273, 275], "dependency": {"intra_class": ["bplustree.tree.BPlusTree.LonelyRootNode", "bplustree.tree.BPlusTree.RootNode", "bplustree.tree.BPlusTree._mem", "bplustree.tree.BPlusTree._root_node_page"], "intra_file": [], "cross_file": ["bplustree.memory.FileMemory.get_node"]}, "requirement": {"Functionality": "This function retrieves the root node from memory.", "Arguments": ":param self: BPlusTree. An instance of the BPlusTree class.\n:return: Union['LonelyRootNode', 'RootNode']. The root node of the BPlusTree instance."}, "tests": ["tests/test_tree.py::test_left_record_node_in_tree"], "indent": 8}
{"namespace": "pyinfra.api.operation.add_op", "type": "function", "project_path": "System/pyinfra", "completion_path": "System/pyinfra/pyinfra/api/operation.py", "signature_position": [85, 85], "body_position": [96, 115], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pyinfra.api.exceptions.PyinfraError", "pyinfra.api.host.Host", "pyinfra.api.inventory.Inventory.iter_active_hosts", "pyinfra.api.state.State", "pyinfra.api.state.State.inventory", "pyinfra.api.util.get_call_location", "pyinfra.context.ctx_host", "pyinfra.context.ctx_state", "pyinfra.is_cli", "pyinfra.context.ContextManager.use"]}, "requirement": {"Functionality": "This function prepares and adds an operation to the input `pyinfra.State` instance by executing it on all hosts. It takes the operation function and its arguments as input and executes the function on each host.", "Arguments": ":param state: State. An instance of the pyinfra.State class. The deploy state to add the operation to.\n:param op_func: function. The operation function from one of the modules, such as `server.user`.\n:param args/kwargs: Additional arguments passed to the operation function.\n:return: No return values."}, "tests": ["tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_failure", "tests/test_api/test_api_operations.py::TestOperationsApi::test_op_cannot_change_execution_kwargs", "tests/test_api/test_api_operations.py::TestOperationsApi::test_rsync_op_with_strict_host_key_checking_disabled", "tests/test_api/test_api_operations.py::TestOperationsApi::test_file_upload_op"], "indent": 4}
{"namespace": "pyramid.config.Configurator.begin", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/__init__.py", "signature_position": [754, 754], "body_position": [772, 778], "dependency": {"intra_class": ["pyramid.config.Configurator.manager", "pyramid.config.Configurator.registry"], "intra_file": ["pyramid.config._marker"], "cross_file": ["pyramid.threadlocal.ThreadLocalManager.get", "pyramid.threadlocal.ThreadLocalManager.push"]}, "requirement": {"Functionality": "This function is used to indicate that application or test configuration has begun. It pushes a dictionary containing the application registry and the request onto the thread local stack. If request is not specified and the registry owned by the configurator is already pushed as the current threadlocal registry then this method will keep the current threadlocal request unchanged.", "Arguments": ":param self: Configurator. An instance of the Configurator class.\n:param request: The request to be pushed onto the thread local stack. Defaults to _marker.\n:return: No return values."}, "tests": ["tests/test_config/test_init.py::ConfiguratorTests::test_begin_overrides_request", "tests/test_config/test_init.py::ConfiguratorTests::test_begin_with_request", "tests/test_config/test_init.py::ConfiguratorTests::test_begin_does_not_propagate_request_for_diff_registry", "tests/test_config/test_init.py::ConfiguratorTests::test_begin", "tests/test_testing.py::TestDummyRequest::test_del_registry"], "indent": 8}
{"namespace": "discord.utils.resolve_annotation", "type": "function", "project_path": "Software-Development/discord-py", "completion_path": "Software-Development/discord-py/discord/utils.py", "signature_position": [1161, 1166], "body_position": [1167, 1175], "dependency": {"intra_class": [], "intra_file": ["discord.utils.evaluate_annotation"], "cross_file": []}, "requirement": {"Functionality": "This function resolves the given annotation by evaluating it based on the provided global and local namespaces. It first checks if the annotation is None and returns type(None) if it is. Then, it checks if the annotation is a string and converts it to a ForwardRef object. Next, it determines the namespace to use (global or local) and initializes a cache if it is not provided. Finally, it evaluates the annotation and returns the result.", "Arguments": ":param annotation: Any. The annotation to resolve.\n:param globalns: Dict[str, Any]. The global namespace to use for evaluation.\n:param localns: Optional[Dict[str, Any]]. The local namespace to use for evaluation. Defaults to None.\n:param cache: Optional[Dict[str, Any]]. The cache to use for storing evaluated annotations. Defaults to None.\n:return: Any. The resolved annotation."}, "tests": ["tests/test_utils.py::test_resolve_annotation", "tests/test_utils.py::test_resolve_annotation_with_cache", "tests/test_utils.py::test_resolve_annotation_optional_normalisation"], "indent": 4}
{"namespace": "pyramid.registry.Introspectable.__repr__", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/registry.py", "signature_position": [240, 240], "body_position": [241, 246], "dependency": {"intra_class": ["pyramid.registry.Introspectable._assert_resolved", "pyramid.registry.Introspectable.category_name", "pyramid.registry.Introspectable.discriminator"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "It returns a string representation of the instance, including the type name, the category name and discriminator, with the format '<%s category %r, discriminator %r>'.", "Arguments": ":param self: Introspectable. An instance of the Introspectable class.\n:return: str. The string representation of the instance, including the category name and discriminator."}, "tests": ["tests/test_registry.py::TestIntrospectable::test___repr__"], "indent": 8}
{"namespace": "mrjob.logs.history._match_history_log_path", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/logs/history.py", "signature_position": [95, 95], "body_position": [99, 108], "dependency": {"intra_class": [], "intra_file": ["mrjob.logs.history._HISTORY_LOG_PATH_RE"], "cross_file": []}, "requirement": {"Functionality": "This function returns paths/uris of all job history files in the given directories. If the path is not a job history file, it returns None. If job ID is not None but the job ID in the file name does not match the given job ID, it returns None.", "Arguments": ":param path: str. The path to the directory containing the job history files.\n:param job_id: str. The job ID to filter the files. Defaults to None.\n:return: dict. A dictionary containing the job ID (with the key 'job_id') and whether '.jhist' is in the suffix (with the key 'yarn')."}, "tests": ["tests/logs/test_history.py::MatchHistoryLogTestCase::test_pre_yarn", "tests/logs/test_history.py::MatchHistoryLogTestCase::test_yarn_filter_by_job_id", "tests/logs/test_history.py::MatchHistoryLogTestCase::test_yarn", "tests/logs/test_history.py::MatchHistoryLogTestCase::test_pre_yarn_filter_by_job_id"], "indent": 4}
{"namespace": "mopidy.models.immutable.ValidatedImmutableObject.replace", "type": "method", "project_path": "Multimedia/Mopidy", "completion_path": "Multimedia/Mopidy/mopidy/models/immutable.py", "signature_position": [195, 195], "body_position": [214, 219], "dependency": {"intra_class": [], "intra_file": ["mopidy.models.immutable.ImmutableObject", "mopidy.models.immutable.ImmutableObject.replace"], "cross_file": []}, "requirement": {"Functionality": "This function replaces the fields in the ValidatedImmutableObject instance with new values and returns a new instance with the updated fields. It also memoizes the instances to optimize memory usage.", "Arguments": ":param self: ValidatedImmutableObject. An instance of the ValidatedImmutableObject class.\n:param kwargs: Keyword arguments to set as fields on the object.\n:return: ValidatedImmutableObject. An instance of the model with replaced fields."}, "tests": ["tests/models/test_models.py::PlaylistTest::test_with_new_last_modified", "tests/models/test_models.py::GenericReplaceTest::test_replace_track_with_missing_values", "tests/models/test_models.py::PlaylistTest::test_with_new_uri", "tests/models/test_models.py::GenericReplaceTest::test_replace_track", "tests/models/test_models.py::GenericReplaceTest::test_replace_playlist"], "indent": 8}
{"namespace": "prometheus_client.exposition.choose_encoder", "type": "function", "project_path": "System/prometheus-client", "completion_path": "System/prometheus-client/prometheus_client/exposition.py", "signature_position": [241, 241], "body_position": [242, 248], "dependency": {"intra_class": [], "intra_file": ["prometheus_client.exposition.CONTENT_TYPE_LATEST", "prometheus_client.exposition.generate_latest"], "cross_file": ["prometheus_client.openmetrics.exposition", "prometheus_client.openmetrics.exposition.CONTENT_TYPE_LATEST", "prometheus_client.openmetrics.exposition.generate_latest", "prometheus_client.registry.CollectorRegistry"]}, "requirement": {"Functionality": "This function chooses an encoder based on the accept header. It checks if the accept header contains \"application/openmetrics-text\" and returns the corresponding encoder and content type. If not found, it returns the default encoder and content type.", "Arguments": ":param accept_header: String. The accept header sent by the client.\n:return: Tuple. A tuple containing the chosen encoder and content type."}, "tests": ["tests/test_exposition.py::test_choose_encoder"], "indent": 4}
{"namespace": "fs.info.Info.created", "type": "method", "project_path": "System/fs", "completion_path": "System/fs/fs/info.py", "signature_position": [328, 329], "body_position": [339, 341], "dependency": {"intra_class": ["fs.info.Info._make_datetime", "fs.info.Info._require_namespace", "fs.info.Info.get"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns the creation time of a resource. It checks if the \"details\" namespace is present in the Info instance and raises an exception if it is not. It then retrieves the creation time from the \"details\" namespace and returns it.", "Arguments": ":param self: Info. An instance of the Info class.\n:return: Optional[datetime]. The creation time of the resource, or None if it is not available."}, "tests": ["tests/test_info.py::TestInfo::test_details"], "indent": 8}
{"namespace": "pyramid.testing.DummyRendererFactory.add", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/testing.py", "signature_position": [571, 571], "body_position": [572, 575], "dependency": {"intra_class": ["pyramid.testing.DummyRendererFactory.renderers"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "Add a renderer to the DummyRendererFactory instance. It adds the renderer to the renderers dictionary with the specified spec as the key.", "Arguments": ":param self: DummyRendererFactory. An instance of the DummyRendererFactory class.\n:param spec: String. The specification of the renderer.\n:param renderer: The renderer object to add.\n:return: No return values."}, "tests": ["tests/test_testing.py::TestDummyRendererFactory::test_add_with_colon", "tests/test_testing.py::TestDummyRendererFactory::test_add_no_colon"], "indent": 8}
{"namespace": "mrjob.parse._parse_progress_from_job_tracker", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/parse.py", "signature_position": [173, 173], "body_position": [180, 194], "dependency": {"intra_class": [], "intra_file": ["mrjob.parse._JOB_TRACKER_HTML_RE"], "cross_file": []}, "requirement": {"Functionality": "This function parses the progress of a running job from the HTML content of a job tracker. It extracts the map_percent and reduce_percent values as floats and returns them. The content searched is extracted between 'Running Jobs' and 'Jobs' in the HTML content. If the HTML content does not contain the necessary information, it returns (None, None).", "Arguments": ":param html_bytes: bytes. The HTML content of the job tracker.\n:return: Tuple of floats. The map_percent and reduce_percent values extracted from the HTML content, or (None, None) if the information is not found."}, "tests": ["tests/test_parse.py::JobTrackerProgressTestCase::test_on_html_snippet", "tests/test_parse.py::JobTrackerProgressTestCase::test_empty", "tests/test_parse.py::JobTrackerProgressTestCase::test_ignore_complete_jobs"], "indent": 4}
{"namespace": "falcon.response.Response.delete_header", "type": "method", "project_path": "Internet/falcon", "completion_path": "Internet/falcon/falcon/response.py", "signature_position": [651, 651], "body_position": [678, 683], "dependency": {"intra_class": ["falcon.response.Response._headers"], "intra_file": [], "cross_file": ["falcon.errors.HeaderNotSupported"]}, "requirement": {"Functionality": "This function deletes a header that was previously set for the response. If the header was not previously set, nothing is done. Otherwise, all values set for the header will be removed from the response.", "Arguments": ":param self: Response. An instance of the Response class.\n:param name: String. The name of the header to be deleted (case-insensitive).\n:return: No return values."}, "tests": ["tests/test_headers.py::TestHeaders::test_set_cookie_disallowed"], "indent": 8}
{"namespace": "ydata_profiling.utils.cache.cache_file", "type": "function", "project_path": "Software-Development/pandas-profiling", "completion_path": "Software-Development/pandas-profiling/src/ydata_profiling/utils/cache.py", "signature_position": [9, 9], "body_position": [20, 30], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["ydata_profiling.utils.paths.get_data_path"]}, "requirement": {"Functionality": "This function checks if a file with the given name already exists in the data path. If it does not exist, it downloads the file from the provided URL and saves it in the data path.", "Arguments": ":param file_name: str. The name of the file.\n:param url: str. The URL of the dataset.\n:return: Path. The relative path to the downloaded file."}, "tests": ["tests/issues/test_issue416.py::test_issue416", "tests/unit/test_dataset_schema.py::test_dataset_schema_empty", "tests/unit/test_dataset_schema.py::test_dataset_schema"], "indent": 4}
{"namespace": "diffprivlib.tools.utils.var", "type": "function", "project_path": "Security/diffprivlib", "completion_path": "Security/diffprivlib/diffprivlib/tools/utils.py", "signature_position": [304, 305], "body_position": [358, 361], "dependency": {"intra_class": [], "intra_file": ["diffprivlib.tools.utils._var"], "cross_file": ["diffprivlib.utils.warn_unused_args"]}, "requirement": {"Functionality": "This function computes the differentially private variance of an array along the specified axis. It adds noise to the variance calculation to satisfy differential privacy. The function closely follows the behavior of the `numpy.var` function.", "Arguments": ":param array: array_like. An array containing numbers whose variance is desired.\n:param epsilon: float, default: 1.0. The privacy parameter epsilon.\n:param bounds: tuple, optional. Bounds of the values of the array, in the form (min, max).\n:param axis: int or tuple of ints, optional. The axis or axes along which the variance is computed. The default is to compute the variance of the flattened array.\n:param dtype: data-type, optional. The type to use in computing the variance.\n:param keepdims: bool, default: False. If True, the axes which are reduced are left in the result as dimensions with size one.\n:param random_state: int or RandomState, optional. Controls the randomness of the algorithm.\n:param accountant: BudgetAccountant, optional. An accountant to keep track of privacy budget.\n:param **unused_args: Should warn the user if any other parameters are passed.\n:return: ndarray. Returns a new array containing the variance."}, "tests": ["tests/tools/test_var.py::TestVar::test_no_bounds", "tests/tools/test_var.py::TestVar::test_no_params", "tests/tools/test_var.py::TestVar::test_clipped_output", "tests/tools/test_var.py::TestVar::test_missing_bounds", "tests/tools/test_var.py::TestVar::test_large_epsilon"], "indent": 4}
{"namespace": "boltons.ioutils.SpooledBytesIO.seek", "type": "method", "project_path": "Utilities/boltons", "completion_path": "Utilities/boltons/boltons/ioutils.py", "signature_position": [329, 329], "body_position": [330, 331], "dependency": {"intra_class": ["boltons.ioutils.SpooledBytesIO.buffer"], "intra_file": ["boltons.ioutils.SpooledIOBase._checkClosed"], "cross_file": []}, "requirement": {"Functionality": "This function seeks to a specified position in the SpooledBytesIO instance. It checks if the instance is closed and then seeks in the buffer.", "Arguments": ":param self: SpooledBytesIO. An instance of the SpooledBytesIO class.\n:param pos: int. The position to seek to.\n:param mode: int. The mode to use for seeking. Defaults to 0.\n:return: The result of the seek operation."}, "tests": ["tests/test_ioutils.py::TestSpooledBytesIO::test_iter"], "indent": 8}
{"namespace": "zulipterminal.platform_code.successful_GUI_return_code", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/platform_code.py", "signature_position": [57, 57], "body_position": [65, 68], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.platform_code.PLATFORM"], "cross_file": []}, "requirement": {"Functionality": "This function returns the success return code for GUI commands, which can be OS specific. If the platform is Windows Subsystem for Linux (WSL), it returns 1. Otherwise, it returns 0.", "Arguments": ":param: No input parameters.\n:return: int. The success return code for GUI commands."}, "tests": ["tests/platform_code/test_platform_code.py::test_successful_GUI_return_code"], "indent": 4}
{"namespace": "pythonforandroid.prerequisites.AutomakePrerequisite.darwin_installer", "type": "method", "project_path": "Utilities/python-for-android", "completion_path": "Utilities/python-for-android/pythonforandroid/prerequisites.py", "signature_position": [315, 315], "body_position": [316, 317], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["pythonforandroid.logger.info"]}, "requirement": {"Functionality": "This function installs Automake on a macOS system using the Homebrew package manager.", "Arguments": ":param self: AutomakePrerequisite. An instance of the AutomakePrerequisite class.\n:return: No return values."}, "tests": ["tests/test_prerequisites.py::TestAutomakePrerequisite::test_darwin_installer"], "indent": 8}
{"namespace": "pyramid.config.actions.ActionState.processSpec", "type": "method", "project_path": "Internet/pyramid", "completion_path": "Internet/pyramid/src/pyramid/config/actions.py", "signature_position": [164, 164], "body_position": [173, 176], "dependency": {"intra_class": ["pyramid.config.actions.ActionState._seen_files"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function checks whether a callable needs to be processed based on its unique identifier. Return True if processing is needed and False otherwise. If the callable needs to be processed, it will be marked as processed, assuming that the caller will process the callable if it needs to be processed.", "Arguments": ":param self: ActionState. An instance of the ActionState class.\n:param spec: The unique identifier for the callable.\n:return: Bool. True if processing is needed, False otherwise."}, "tests": ["tests/test_config/test_actions.py::TestActionState::test_processSpec"], "indent": 8}
{"namespace": "alembic.script.revision.RevisionMap.heads", "type": "method", "project_path": "Database/alembic", "completion_path": "Database/alembic/alembic/script/revision.py", "signature_position": [134, 134], "body_position": [143, 144], "dependency": {"intra_class": ["alembic.script.revision.RevisionMap._revision_map", "alembic.script.revision.RevisionMap.heads"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function first initializes the revision map and then returns all \"head\" revisions as strings.", "Arguments": ":param self: RevisionMap. An instance of the RevisionMap class.\n:return: A tuple of string revision numbers."}, "tests": ["tests/test_revision.py::APITest::test_add_revision_two_head", "tests/test_revision.py::MultipleBaseCrossDependencyTestTwo::test_what_are_the_heads", "tests/test_revision.py::MultipleBaseCrossDependencyTestOne::test_what_are_the_heads", "tests/test_revision.py::APITest::test_add_revision_one_head"], "indent": 8}
{"namespace": "mingus.core.keys.get_key_signature_accidentals", "type": "function", "project_path": "Multimedia/mingus", "completion_path": "Multimedia/mingus/mingus/core/keys.py", "signature_position": [94, 94], "body_position": [96, 106], "dependency": {"intra_class": [], "intra_file": ["mingus.core.keys.get_key_signature"], "cross_file": ["mingus.core.notes", "mingus.core.notes.fifths"]}, "requirement": {"Functionality": "This function returns a list of accidentals present in the key signature of a given key. It first determines the number of accidentals in the key signature. Then, it creates a list of accidentals based on the number of accidentals and the key.", "Arguments": ":param key: String. The key for which the key signature accidentals are to be determined. It defaults to \"C\" if not specified.\n:return: List of strings. The list of accidentals present in the key signature."}, "tests": ["tests/unit/core/test_keys.py::test_keys::test_get_key_signature_accidentals"], "indent": 4}
{"namespace": "zulipterminal.config.keys.is_command_key", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/config/keys.py", "signature_position": [424, 424], "body_position": [429, 432], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.config.keys.InvalidCommand", "zulipterminal.config.keys.KEY_BINDINGS"], "cross_file": []}, "requirement": {"Functionality": "This function checks if a key is mapped to a command in the KEY_BINDINGS dictionary. If the key is mapped, it returns True. Otherwise, it returns False.", "Arguments": ":param command: str. The command to check the key mapping for.\n:param key: str. The key to check if it is mapped to the command.\n:return: bool. True if the key is mapped to the command, False otherwise."}, "tests": ["tests/config/test_keys.py::test_is_command_key_matching_keys", "tests/config/test_keys.py::test_is_command_key_invalid_command"], "indent": 4}
{"namespace": "zulipterminal.config.keys.keys_for_command", "type": "function", "project_path": "Communications/zulip-term", "completion_path": "Communications/zulip-term/zulipterminal/config/keys.py", "signature_position": [435, 435], "body_position": [439, 442], "dependency": {"intra_class": [], "intra_file": ["zulipterminal.config.keys.InvalidCommand", "zulipterminal.config.keys.KEY_BINDINGS"], "cross_file": []}, "requirement": {"Functionality": "This function returns the actual keys for a given mapped command. It retrieves the keys from the KEY_BINDINGS dictionary based on the input command.", "Arguments": ":param command: str. The command for which the keys are to be retrieved.\n:return: List[str]. The list of keys mapped to the given command.\n:raises: InvalidCommand. If the given command is not found in the KEY_BINDINGS dictionary."}, "tests": ["tests/config/test_keys.py::test_keys_for_command_identity", "tests/config/test_keys.py::test_is_command_key_matching_keys", "tests/config/test_keys.py::test_is_command_key_nonmatching_keys", "tests/config/test_keys.py::test_keys_for_command_invalid_command", "tests/config/test_keys.py::test_updated_urwid_command_map"], "indent": 4}
{"namespace": "boto.ec2.volume.Volume.attach", "type": "method", "project_path": "Internet/boto", "completion_path": "Internet/boto/boto/ec2/volume.py", "signature_position": [137, 137], "body_position": [152, 157], "dependency": {"intra_class": ["boto.ec2.volume.Volume.connection", "boto.ec2.volume.Volume.id"], "intra_file": [], "cross_file": ["boto.ec2.connection.EC2Connection.attach_volume"]}, "requirement": {"Functionality": "Attach this EBS volume to an EC2 instance. It uses the provided instance ID and device name to attach the volume to the instance.", "Arguments": ":param self: Volume. An instance of the Volume class.\n:param instance_id: str. The ID of the EC2 instance to which the volume will be attached.\n:param device: str. The device on the instance through which the volume will be exposed (e.g. /dev/sdh).\n:param dry_run: bool. Whether to perform a dry run of the attachment. Defaults to False.\n:return: bool. True if the attachment is successful."}, "tests": ["tests/unit/ec2/test_volume.py::VolumeTests::test_attach_calls_attach_volume"], "indent": 8}
{"namespace": "mrjob.hadoop.fully_qualify_hdfs_path", "type": "function", "project_path": "System/mrjob", "completion_path": "System/mrjob/mrjob/hadoop.py", "signature_position": [108, 108], "body_position": [110, 116], "dependency": {"intra_class": [], "intra_file": [], "cross_file": ["mrjob.parse.is_uri"]}, "requirement": {"Functionality": "This function takes a path as input and returns a fully qualified HDFS path. If the input path is already an \"hdfs://\" URL, it is returned as is. If the input path starts with a \"/\", it is converted into an \"hdfs://\" URL by appending \"hdfs://\" to the beginning. If the input path does not start with a \"/\", it is converted into an \"hdfs://\" URL by appending \"hdfs:///user/{username}/{path}\" where {username} is the current user's username and {path} is the input path.", "Arguments": ":param path: str. The input path that needs to be converted into a fully qualified HDFS path.\n:return: str. The fully qualified HDFS path."}, "tests": ["tests/test_hadoop.py::TestFullyQualifyHDFSPath::test_s3n_uri", "tests/test_hadoop.py::TestFullyQualifyHDFSPath::test_s3a_uri", "tests/test_hadoop.py::TestFullyQualifyHDFSPath::test_other_uri", "tests/test_hadoop.py::TestFullyQualifyHDFSPath::test_empty", "tests/test_hadoop.py::TestFullyQualifyHDFSPath::test_hdfs_uri"], "indent": 4}
{"namespace": "jinja2.utils.LRUCache.items", "type": "method", "project_path": "Internet/Jinja2", "completion_path": "Internet/Jinja2/src/jinja2/utils.py", "signature_position": [544, 544], "body_position": [546, 548], "dependency": {"intra_class": ["jinja2.utils.LRUCache._queue"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function returns a list of items in the LRUCache instance. The order should be reversed from the order in the queue.", "Arguments": ":param self: LRUCache. An instance of the LRUCache class.\n:return: Iterable[Tuple]. A list of tuples containing the key-value pairs in the LRUCache instance."}, "tests": ["tests/test_utils.py::TestLRUCache::test_items"], "indent": 8}
{"namespace": "praw.util.token_manager.SQLiteTokenManager.register", "type": "method", "project_path": "Utilities/praw", "completion_path": "Utilities/praw/praw/util/token_manager.py", "signature_position": [181, 181], "body_position": [189, 194], "dependency": {"intra_class": ["praw.util.token_manager.SQLiteTokenManager._connection", "praw.util.token_manager.SQLiteTokenManager.key"], "intra_file": [], "cross_file": []}, "requirement": {"Functionality": "This function registers the initial refresh token in the database. It checks if there is already a refresh token for the associated key and saves the refresh token to the database if it is not already present.", "Arguments": ":param self: SQLiteTokenManager. An instance of the SQLiteTokenManager class.\n:param refresh_token: The refresh token to be registered in the database.\n:return: Bool. Returns True if the refresh_token is saved to the database, otherwise returns False if there is already a refresh_token for the associated key."}, "tests": ["tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_register", "tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_multiple_instances", "tests/unit/util/test_token_manager.py::TestSQLiteTokenManager::test_pre_refresh_token_callback"], "indent": 8}
